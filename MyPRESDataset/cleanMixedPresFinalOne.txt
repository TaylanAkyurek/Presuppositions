 Rings that intercepted would collide and damp down into a single ring. There are multiple rings present in the situation. Similar any kind of dust cloud - although if the dust is diffuse enough (i.e., there's not much of it), the timescale could be longer than the age of the planet. There is a possibility of a dust cloud existing in the universe. For instance, all the giant planets have a diffuse cloud of irregular satellites, allowable since they're so few of them. There are giant planets in the universe. Rings viscously spread, so any ring would eventually encounter any other ring. There are multiple rings present in the situation. Again, the question becomes "how long will this take? There is a task or project that needs to be completed. ", which depends on the properties of the ring. The ring has unique properties that set it apart from other rings. Immediately after the formation of a ring (however that happens), they needn't be aligned. A ring has been formed. But eventually, they'll be aligned. There was a previous misalignment. Rings can only effectively extend out to the Roche Radius - beyond that, their self-gravity will result in them accumulating into moons. The Roche Radius is a well-known astronomical term. This has probably happened with Saturn, at least (which has rings extending to the Roche Radius, then small, icy moons of the same composition beyond. Saturn's rings are made up of the same composition as its small, icy moons beyond the Roche Radius.
 You are probably talking about herbicides with 2,4-Dichlorophenoxyacetic acid/2,4-D as the active ingredient. There is a high likelihood that herbicides with 2,4-Dichlorophenoxyacetic acid/2,4-D as the active ingredient are being discussed. 2,4-D works by dramatically increasing auxin production. Auxin production is low without the use of 2,4-D. Auxins are a class of plant growth regulators that in correct amounts promote cell growth. Plants cannot grow without auxins. However, the overproduction of auxin caused by 2,4-D causes uncontrollable growth that the plant can't keep up with, leading to deleterious distribution of photosynthates, and eventually death. The plant was healthy before the overproduction of auxin caused by 2,4-D. Dicots (e.g. There are other types of plants besides dicots. broadleaf weeds) are particularly sensitive to auxins, while monocots (turf, cereal crops) are much less sensitive. Auxins are commonly used in agriculture to control weed growth. Consequently, correctly applied 2,4-D will cause uncontrollable growth and death in dicots while having little or minimal effect on monocots. 2,4-D is commonly used in agriculture. It's possible to kill grass with 2,4-D, but would require a very strong application. 2,4-D is commonly used to kill weeds.
 no there's no evidence for them, not yet. There is a possibility that evidence for them may be found in the future. And most of the experts in the field, so long as they're behaving properly, understand that they just have an interesting idea, not science yet. Experts in the field have been behaving improperly. But the idea stems from an older one in a way. There was an original idea that the current idea is based on. We found that gravity could be explained by a curving of spacetime. The concept of gravity was previously unexplained. Well then we developed the (failed) Kaluza-Klein model of electromagnetism. The Kaluza-Klein model of electromagnetism was a highly anticipated development. Here we were like, hey, what if there's this 5th dimension that you can't travel very far across at all, but exists in all space? There is a possibility of multiple dimensions beyond the four we currently know. What if that 5th dimension curves in the presence of charge? The existence of a 5th dimension is assumed. Do we generate a theory of electromagnetism that emerges from that curvature? There is a curvature that exists. Well, no, we didn't. There was an expectation that we did something. Not one that matches our reality well. There is a reality that exists. Time goes on and then some physicists start toying with vibrational modes of higher dimension manifolds of subspace (yes it sounds like startrek gibberish, but manifold means a certain configuration of dimensions that establishes a geometry (and a real mathematician would probably kill me for that over-simplification) and subspace just means a few of the spatial dimensions out of all of them). There exists a group of physicists who are interested in exploring higher dimensions beyond our current understanding of space. Well it turns out that this theory *may* produce some results that look kind of like the physics we expect to see. This theory has been tested before. I'm not sure entirely how, but I'm told it does (it's way out of my field). There is a field that exists outside of the speaker's expertise. The common complaints are these two: one, it's very nearly impossible to test, or at least to test and get a unique signal for with any reasonable amount of technological development in the near future. There is a significant demand for testing this particular signal. Two (and why I used the words I did above) we don't know *which* manifold to do the math on. There are multiple manifolds that require mathematical analysis. The allowed solutions, last I checked, were something like 10^500 , which is a huge parameter space. There have been previous checks on the allowed solutions. So... it's an interesting idea, and let's see where it goes. There is uncertainty about the idea being discussed.
 This is a difficult question to answer. There is a question that needs to be answered. I assume you're referring to the fact that gravity is the weakest of the four fundamental forces. Gravity is one of the four fundamental forces. Is your question why it is weakest? The speaker believes that the listener has a question. If that's your question the answer is basically "because it is." The speaker is aware of the question being asked. One of the forces had to be the weakest and it happens to be gravity. Gravity is the only force that is weak. If your question is "why is it referred to as weak, when it seems so strong." The term "weak" is commonly used to describe things that appear strong but have hidden vulnerabilities. The answer to that is more fun. There was a previous question or statement made. You're probably sitting in a chair right now. You may have been sitting in a chair for a while. You're held to the chair by gravity, but the electromagnetic forces of the bonds in the chair (and your butt) keep you from falling through the chair. The chair is made of materials with strong electromagnetic bonds. So yes, gravity is the weakest, and that weakness allows objects to be stacked, and for your butt to stay above the chair seat. Gravity is a fundamental force in the universe. Here's some more info on the fundamental forces:_URL_0_Perhaps you can clarify your question? There is a need for more information on fundamental forces. Or the motives for your question? The person being asked the question has a specific motive for asking.
 I used to work at a high efficiency refrigerator factory (full size units that run on 6, 12 and 24 volts). The factory no longer exists. We tested this, and as long as the refrigerator has stuff in it, it doesn't make much of a difference, the stuff holds the cold not the air. The refrigerator is used frequently.
 Display fireworks aren't like the over-the-counter fireworks you can buy in the store, that use chemical fuses and cardboard/paper launchers. Fireworks that use chemical fuses and cardboard/paper launchers are commonly sold in stores. Typically, fireworks are fired from metal mortars. Fireworks can also be fired from non-metal mortars. Black powder or other long-burning explosives are packed in the bottom with an electronic ignitor, wired to an electronic control board. Explosives are commonly used in certain industries. The firework itself consists of a long chemical fuse, a firecracker type explosive core, binder, a paper container, and pieces of metal called "stars". The firework was created for a specific event or celebration. When the lifting charge is ignited, it lights the fuse, which times the firecracker core, allowing the firework to get to altitude. The firework was designed to reach a specific altitude. The center core explodes, dispersing the packaging and igniting the stars. The position and distribution of the stars within the firework define the shape of the explosion - radial, spherical, pouring effects, smily faces, etc. The firework was designed specifically to create a certain shape, and the position and distribution of the stars were carefully planned to achieve this effect. Fireworks with tails have an segment that is ignited and burns immediately (or shortly after lift-off) and burns brightly as firework rises (or flakes and burns, like a sparkler or Roman Candle). Fireworks with tails are commonly used in celebrations.
 There is no scientific consensus that humans were the primary cause of the Pleistocene megafauna extinctions. There are multiple theories about the cause of the Pleistocene megafauna extinctions. It is, probably, the theory slightly in the lead at the moment. There are other theories in competition. It's very hard and dangerous to speculate on why megafauna may have survived in one location but not another. Megafauna have indeed survived in at least one location. There are many, many factors involved that may have made significant differences - such as hunting methods, landscapes, regional climate, other food sources, cultural factors, and who knows what else. There are multiple unknown factors that could have had a significant impact on the outcome. It is not unreasonable to imagine a significant hunting effort being capable of killing off a species before it has time to adapt to the human threat. There is a significant hunting effort that poses a threat to a species. Especially for one with such long generations like megafauna. Megafauna have longer generations than other species. Another factor is that these hunters had developed some effective ways to kill off many megafauna at once, without risk or direct confrontation. There were many megafauna present in the area. Regardless, there are plenty of very smart people in the field who don't buy the explanation that humans were capable of driving all these extinctions. There is a widely accepted explanation that humans were responsible for driving extinctions. So you're fine being skeptical about it all. You have previously expressed skepticism about something.
 Yes, it speeds up and slows down. The object being referred to is a machine or vehicle. Planets follow the second law of Kepler (A line joining a planet and the Sun sweeps out equal areas during equal intervals of time) so that means they have to move faster in the perihelion. The Sun is the center of the solar system. I don't know what you mean with "slingshot effect", that term is used for gravity assists where a body is accelerated and released from a gravity field, and Earth is not scaping and will never be. The speaker is unfamiliar with the term "slingshot effect". The only effect the orbit has in the rotation is the little influence of the tidal forces of the Sun (the closest part of the Earth is more attracted to the Sun than the farthest one, resulting in a little force which tends to slow down the rotation). The Earth's rotation is significantly affected by factors other than the orbit.
 Yes, but there are also constant process of exocytosis and membrane synthesis. There are other processes besides exocytosis and membrane synthesis. I don't know what the level of flux each way is, but I would assume that (most of the time, at least), an equilibrium is reached keeping a (somewhat?) There is a system in place that regulates the level of flux. consistent size There is a specific size requirement that needs to be met.
 No, The explosion that initiates a nuclear reaction is a very precise planned and controlled implosion of a plutonium sphere. Plutonium spheres are commonly used in nuclear reactions. Simply exploding an unarmed nucler warhead would only result in spreading radioactive material over a small area (dirty bomb) Nuclear warheads are often armed before being detonated.
 You have of course read [something like this](_URL_0_) in your quest, have you not? You have been on a quest for knowledge.
 Sun's rays are white. The sun emits only white light. This means that they are composed of various frequencies, both visible and invisible. There are frequencies that exist which are both visible and invisible. The part of the frequencies that are visible is the visible spectrum, with each frequency corresponding to one colour of the rainbow. The human eye can only perceive a limited range of frequencies. Higher frequencies are closer to violet and lower frequencies are closer to red. Colors are perceived differently based on their frequency. To understand rainbows you need first to understand 2 phenomena: reflection and refraction. Rainbows cannot be understood without understanding reflection and refraction. When light generally crosses from one material to the next, 2 things happen. Light always crosses from one material to the next. 1.) I'm sorry, but there is no sentence indicated by angel brackets in your prompt. some portion of the energy is reflected 2.) Some of the energy is absorbed. some portion of the energy is refracted, crossing into the second material, but generally altering its direction. The first material is transparent. Refraction You ever seen a piece of straw in a glass of water? There is a glass of water present. It appears broken, when in fact it's not. There was a previous incident that caused people to believe the object was broken. This is refraction at work. Light is present. There is such a thing called a refractive index and it is a property of every material. Every material has a unique refractive index that can be measured. If light comes from a material of refractive index n1 to a material with a refractive index n2 with n2 != n1 it will undergo refraction. There are at least two materials present in the scenario. It will change direction and then continue a new straight course. The current course is not straight. The angle of the new ray can be computed as follows: Let's say that there is a line normal to the boundary plane of the two materials. There are two materials involved in the computation of the new ray's angle. If the ray out of the drop has a θ1 angle with that line and the ray inside the drop has an angle of θ2 with that same line, then sinθ2n2 = sinθ1n1 = >  θ2=arc(n1*sinθ1/n2)but n2 changes with frequency, so every colour of the rainbow is refracted with a different angle within a raindrop, making the single white ray spread out into its constituents. The phenomenon of refraction occurs when light passes through a medium with varying refractive indices. This is why you see that phenomenon depicted in the cover of dark side of the moon. There is a phenomenon depicted on the cover of Dark Side of the Moon. The raindrop sort of acts like the prism in that setup. There is a setup involving a raindrop and a prism. Reflection You ever noticed how you can only see the rainbow when the sun it as your back and the rain is at the front? Rainbows can only be seen in certain weather conditions. but, since the light is at your back, how can there be something illuminating in front of you? There is a light source behind the person speaking. is the rain magically emitting energy? The world has magic. no, there is reflection at work. Reflection is typically present in similar situations. When the light inside a raindrop tries to get out of it, some of it is indeed refracted and exits the raindrop, but some of it is reflected back. Raindrops have light inside them. since rays of different frequency reach the surface of the back of the drop with a different angle, they again are reflected with a different angle. The surface of the back of the drop is made up of materials that reflect light differently based on frequency. For brevity's sake, let's also only say that again, light undergoes a second refraction/reflection, when it finally comes out of the raindrop and ending up in your eyes. Light travels through raindrops. To summarize, for a ray that belongs to rainbow to reach your eyes, what it does is this. Rainbows are a common occurrence in the world. It travels from the sun in a straight line, it is refracted in a raindrop, it is reflected in its back surface and then refracted again coming out of it. Light is a physical entity that can travel from the sun to Earth. Every frequency has a specific geometry required to reach your eyes: it requires to attack the raindrops in a certain angle. Raindrops are necessary for frequencies to reach your eyes. If you sit down and draw this, you'll notice that there are several raindrops with the correct angle for every frequency, and these are all in an arc. There is a drawing that can be analyzed. So basically the higher frequencies are refracted more, and the lower frequencies are refracted less. There are different frequencies of light. But the family of raindrops that have the correct angle for a given frequency of light is in the form of the arc of that rainbow. Rainbows are formed by the angle of light hitting raindrops. White light contains all the frequencies of the visible spectrum and more: there is an invisible rainbow underneath and below it, made out of infrared and ultraviolet rays above and beneath it. There are other types of light beyond the visible spectrum. But since there is a band of frequencies you can see, there is a band of frequencies reflected back to you, each from its appropriate family of raindrops. There are raindrops present in the environment. Therefore, you see a band of arcs, each with each own frequency. There are multiple bands of arcs visible. I hope I was clear, the concept is difficult to explain without some kind of board. The speaker has attempted to explain the concept before. Try to find pictures. Pictures are available. This is kinda good_URL_0_ There is a specific thing being referred to as "this."
 So before answering this question you have to know why do we smell certain things. There is a question that needs to be answered. Smell is a very direct sense. The sense of smell is more direct than any other sense. In order for you to smell something, molecules from that thing have to make it to your nose. Molecules are necessary for smelling. Everything you smell, therefore, is giving off molecules -- whether it is bread in the bakery, onions, perfume, a piece of fruit or whatever. Molecules are constantly being emitted by everything we smell. **Those molecules are generally light, volatile (easy to evaporate) chemicals that float through the air into your nose. Chemicals that are heavy and non-volatile do not float through the air into your nose. ** A piece of steel has no smell because nothing evaporates from it -- steel is a non-volatile solid. Steel is often associated with a strong odor, but this is not the case with non-volatile steel. (_URL_0_)So when you want to smell something molecules from that object have to evaporate and come in contact with your nose. Molecules are the only things that can produce a smell. With lowering the objects temperature molecules in it will have lower energy and a lot of those molecules won´t be able to evaporate (Same goes with water. The object or water in question has a high temperature to begin with. You need to heat the water, if you want it to evaporate quickly) resulting in smaller amount of molecules coming in contact with your nose which means that the smell won´t be as strong as it would be at higher temperatures. The water has a strong smell at higher temperatures.
 When a massive object collides with a small object, most of the damage is to the small object. Small objects are more vulnerable to damage than massive objects in collisions. So, when a car and bus collide, the bus passengers are much less likely to get hurt. Collisions between cars and buses are common. I was once in an accident where a car rear ended a city bus. The car that rear ended the city bus was going at a high speed. The bus shook a little and barely had any damage. The passengers on the bus were not injured. The car was totaled. The car was in a serious accident.
 Yep, that's not plastic, that's cheese. There was a previous assumption that the object in question was plastic. [Basic fresh cheese is made by adding acid to warm milk](_URL_0_). Milk is readily available. I would not advise using it as a building material. The material in question is commonly used as a building material.
 Ok, so I'll preface this by saying I don't want this to turn into me, random dude on the internet (albeit random dude who has a PhD and is a professor of geology currently teaching a senior level class on Plate Tectonics) telling you that the teacher and/or the notes are wrong, but they are certainly a 1) gross simplification that are easily misinterpreted and 2) are kind of mixing concepts (most likely to try to keep things simple, at an 8th grade level). 1) The speaker is concerned about being perceived as an arrogant know-it-all and wants to establish their credentials before criticizing the teacher and/or notes. My answer that follows is provided with the hope that it will help you understand the concepts better, and I'm not suggesting that you necessarily try to explain this to your son in as much detail OR use this to stage some sort of grand challenge to the teacher. The speaker has knowledge or expertise on the concepts being discussed. We can think about plate motion and what drives it from two end member scenarios that fundamentally differ primarily on how they treat the plates (plates here being defined as sections of lithosphere, so the crust and the very upper portion of the mantle, that behave as coherent, rigid objects that move horizontally along the top of the aesthenosphere, weak part of the upper mantle, and interact along their edges, i.e. There are two distinct end member scenarios for plate motion. at plate boundaries) and specifically whether we consider them to be an 'active' part of the process that drives plate tectonics or as 'passive' riders whose motion is totally determined by movement within the underlying mantle. There is a debate about the role of plate boundaries in plate tectonics. Let's first consider the 'passive' plate motion model, which basically states that convection in the mantle (i.e. There is a debate about different plate motion models. the density/temperature driven roughly circular currents within the mantle) are the primary driver. The Earth's mantle is composed of various layers with different densities and temperatures. In this model, divergent boundaries (i.e. There are multiple models being considered, and this particular model focuses on divergent boundaries. mid ocean ridges where new sea floor is created and lithosphere moves away from the boundaries) are located in the upwelling regions of these convection currents and convergent boundaries (i.e. There are convection currents and convergent boundaries in the ocean. subduction zones, where an oceanic plate sinks beneath another oceanic plate or a continental plate) are linked to downwelling zones, with the basic idea that the mantle is sinking (because it's cooled) and it's pulling the plate down with it, basically causing subduction. The mantle is constantly cooling and sinking, causing subduction zones to form. This is usually illustrated with two convection cells sharing a downwelling zone (i.e. There are typically only two convection cells in this scenario. material is being pulled towards the downwelling zone, causing convergence at the surface). There is a downwelling zone. This 'passive' model has some issues though. There is a model being discussed. If plate boundaries are essentially mapping out locations of convection cells upwelling and downwelling motion, this is problematic because [plates are irregularly shaped and variable in size](_URL_3_) which would imply variable sizes for the convection cells. There are convection cells in the Earth's mantle. This model would also predict that there should be a relation between plate area and plate velocity (because plate velocity will be driven by the amount of 'contact' between the plate and the underlying mantle), but we've [known for a long time that this is not the case](_URL_1_). There is a widely accepted model that predicts a relation between plate area and plate velocity. The alternative is the 'active' plate motion model, where the dynamics of the plates (and mostly gravity driven processes related to variability in density, again driven by temperature) themselves are the principle driver for plate motion. The traditional plate motion model is no longer valid. For this model, we need to consider the [various forces acting on the plates](_URL_2_). The plates are subject to multiple forces. The two that we often discuss in detail are 'ridge push' (i.e. There are at least two concepts that are frequently discussed in detail. the force imparted on the plate by material being added at ridges) and 'slab pull' (i.e. The plate is being added with material at ridges. the force on the plate from the sinking of old, cold, oceanic crust in a subduction zone, basically dragging the rest of the plate down with it). The plate in question is located near a subduction zone. This [video](_URL_0_) lays out some more basics of how these work. The viewer has some prior knowledge about the topic being discussed in the video. This is still discussed in terms of 'convection' in that it is still largely a temperature/density driven process with 'upwelling' of hot material and 'return flow' of cold material, but the chief difference being here that the plates are driving this convection and it does not require true convection currents (i.e. There is a scientific debate about the process of convection. the cold material that sinks with the slab does not necessarily return at the ridge in a closed loop). The material that sinks with the slab can return at the ridge in an open loop. This model seems to work much better with our observations (e.g. There were previous models that did not work well with our observations. that classic Forsyth and Uyeda paper I linked to earlier) and is generally accepted (but the role of mantle convection, and mantle drag forces remains an active point of discussion, well beyond the level appropriate for a discussion with 8th graders). The classic Forsyth and Uyeda paper is widely known and referenced in the scientific community. So, in reality, the plates mimic the motion of a conveyor belt, but using it as an analogy for the mechanism is flawed because the motion of a normal conveyor belt is driven exclusively by traction at the base of the belt from spinning rods (i.e. There is a mechanism that mimics the motion of a conveyor belt using plates. the mantle). The mantle is a valuable item. A better analogy (but kind of complicated) would be a a strip of cloth laying on top of a tub of honey where one side is being 'pushed' as the cloth is woven and the other side is being 'pulled' because the cloth is getting heavier as it moves along and it eventually gets so heavy it starts to sink into the honey and it pulls the rest of the cloth with it. There is a tub of honey. The honey (i.e. The bees produced the honey. the mantle) could be moving and could be resisting the motion driven by the dynamics of the cloth or it could be reinforcing the motion. The cloth is made of a material that is difficult to move. If the entire surface of the honey was covered in similar patches of cloth, the independent motion of the cloth patches would be evident at their boundaries where some would be 'diverging' away from their looms and some would be 'converging' as one end sank beneath other (in three dimensions, you also end up with boundaries that move side to side, or 'transform' boundaries). The honey is currently not covered in patches of cloth. I hope this all helps... There was a problem or issue that needed help.
 In the interstellar medium the particle density ranges from 10^(6) to 10^(-3) atoms per cubic centimeter with an average of 1 atom per cm^(3). There are various types of particles present in the interstellar medium. The intergalactic medium is even less dense with less than 1 atom per m^(3). There are other intergalactic mediums that are more dense than the one mentioned. What is inbetween? There is something that separates two things. Uh *nothing*  Maybe you could say photons from the cosmic microwave background and probably neutrinos are also there, but they are massless. There exists a cosmic microwave background.
 Smaller chambers create denser flavor. Larger chambers create less dense flavor. More surface area creates a denser vape. There is a device that produces vapor. Which is more flavor. There are at least two options to choose from. If you want even more flavor. You have already experienced some flavor. Get huge airflow and provide it with huge vapor production, (but remember, this is in comparison to rdas of the same size) , and you'll get a faster vape with coils that can keep up on the quick draw. There are other rdas of the same size that do not provide huge airflow and vapor production. Fast draws are tastier because they have less time to be absorbed or become stale vape. Fast draws are a common practice among experienced vapers. But remember, too much heat from excess metal or too thick of vapor in comparison to airflow, you'll lose flavor profile. There is a flavor profile that can be lost. Excessive heat kills it. It is alive. Nicotine plays a job in flavor murder. There is a phenomenon called "flavor murder" that exists. Heat control is worked out with metal and density vs chamber size and airflow. Metal and density are the most important factors in heat control. And most importantly, make sure your coils are placed in the trajectory (path) of the airflow. The airflow is crucial for the proper functioning of the coils. The trajectory is the path created from the atomizer air hole to the drip tip. There is an atomizer with an air hole.
 Yes, many of them look at the fluid dynamics during the collapse so might not look like the  massive explosion you want, but here are a few:_URL_0__URL_1_There is also the long term telescope images of the 1987 supernova: _URL_2_ Some researchers study fluid dynamics during a collapse.
 It's negligible. There is something else that is significant. Just do a back of the envelop approximation. There is a need for a quick estimate. Even if the moon and earth were fixed and the satellite was stuck between them at a distance corresponding to GEO, the gravitational attraction of the earth would be 8000 times larger. The moon and earth are not fixed and the satellite is not stuck between them at a distance corresponding to GEO. Why? There is a reason for the situation that prompted the question "Why?" The earth is 81x heavier and ten times closer. The gravitational pull on the earth is significantly stronger than on other planets. this paper might be of interest: _URL_0_Overtime small forces can measurably affect the orbit, but all satellites have things like ion engines for orbital maintenance. There is a need for research on the effects of small forces on satellite orbits.
 Basically the core in single mode fiber (SMF) is so narrow that you can no longer accurately model it with ray optics. Single mode fiber is commonly used in telecommunications. You need to consider the full electromagnetic wave equation to understand how SMF works. The full electromagnetic wave equation is a complex concept. You can see a similar effect when a water wave moves in a narrow canal, [for example, here](_URL_0_). There is a narrow canal where water waves move. (This is actually a bit more specialized phenomenon, called a soliton wave. Soliton waves are a common occurrence in nature. This can be reproduced in optical fiber, but is somewhat more tricky than the general waveguiding in SMF) The main thing is that the physics of the situation (mathematically described by the differential equations and boundary conditions at work) only allow one "kind" of wave to move along the waveguide (canal or fiber), so you get very little change in the wave shape as it travels. Optical fibers are commonly used for waveguiding.
 Is it a pencil like [this](_URL_0_)? The object being referred to is a writing utensil. For the life of me I do not know why anyone would need an antimicrobial pencil; Docs/nurses use pens so it wouldn't help much there. 1. If the pencil you describe is like this one, then it is the coating on the pencil that contains some form of antimicrobial agent. The pencil being described has a coating. The one in the link I provided is [Microban](_URL_1_), and their product is proprietary so an exact mechanism of action is unlikely to be found for it other than their claims that it penerates the cell walls of microbes and disrupts cell functions. Microban is a highly sought-after product.
 There's an excess of protons and electrons in the universe compared to neutrons, because a free neutron decays to a proton, electron, and neutrinos with a half-life of a little over 10 minutes if it doesn't become part of a nucleus before decaying. The universe is constantly producing new protons and electrons. Most of those excess protons are in the form of hydrogen (the only nucleus that's stable with no neutrons in it) because most of the universe isn't hot or dense enough to fuse them into anything heavier. There are other excess protons that are not in the form of hydrogen.
 Suppose seven billion people randomly shuffled seven billion fair decks once a second for the last 10 billion years. There are at least seven billion people in the world. That's 2x10^27 shuffles over nearly the life of the universe. There have been at least 2x10^27 shuffles in the universe. I'm guessing that's on the high end of what's actually been shuffled. There was a shuffling activity that took place. By comparison, there are 8x10^67 possible shuffle orders, giving you a 1 in 10^40 chance of having a deck that's already appeared in the history of the universe. There have been many attempts to shuffle a deck of cards throughout the history of the universe. I guess that's kind of like being presented with all the sand in the world and picking out the same grain twice. There is a vast amount of sand in the world. While blindfolded. The person was blindfolded voluntarily. And the sand is mixed between picks. There are picks and sand in the same location. It's worth mentioning that depending on the starting conditions of your deck and how you shuffle, not all your shuffles will be random, so that could drastically reduce the chance of having a repeat deck show up. The starting conditions of your deck have a significant impact on the randomness of your shuffles. That's harder to quantify, though. There is something that needs to be quantified.
 The primary cause of air resistance (for any object not traveling around mach 1 or greater) is not due to air compression. Air resistance is a significant factor in the movement of objects. At speeds less than a mach number of 0.3 (~230 mph) air behaves incompressibly for all intents and purposes. Air behaves compressibly at speeds greater than a mach number of 0.3. So where does drag come from then? Drag is a common phenomenon. There are two types of incompressible drag: skin friction, and pressure drag. Incompressible fluids are commonly used in engineering. Skin friction acts exactly as it sounds... viscosity causes a shearing stress in the direction of the fluid. There is a fluid present. So if you have flow moving over a stationary plate, momentum will be transferred perpendicular to the flow direction from faster moving fluid to slower moving fluid, and eventually into the wall. There is a stationary plate present. In fluid mechanics walls are considered to be "no-slip" meaning the fluid velocity at the wall is exactly equal to the velocity of the wall. Fluid mechanics is a field of study that deals with the behavior of fluids in motion. This is a very good assumption for most cases, and is the cause for the lower velocity fluid in the flowfield. There are many cases where this assumption is not valid. The [wiki article on visocity](_URL_0_) has a good diagram and explanation here. The article on viscosity is widely known and referenced in scientific communities. Pressure drag might be what you were thinking of when you phrased your question. You have some knowledge or understanding of pressure drag. I'll use the example of flow over a cylinder to try and explain what's happening here. There is a complex phenomenon occurring that requires explanation. When the velocity is low (actually when [Reynolds Number](_URL_2_) is low), the flow has a lower pressure on the top and bottom of the cylinder and returns to it's original pressure on the back. The Reynolds Number is a significant factor in determining the pressure of the flow around the cylinder. If you add up the pressure on each face (integrate for those with calculus knowledge), you'll find it exactly cancels. The object in question has multiple faces. This is actually known as [D'Alembert's Paradox](_URL_3_) and describes the scenario in your question... pressure returns to where it originally was and no drag occurs. D'Alembert's Paradox is a well-known phenomenon in the field of fluid dynamics. In reality though, when Reynolds Number is large, you get a thin region close to the cylinder where a large velocity gradient occurs and thus there is a large viscous effect (known as a [boundary layer](_URL_1_)). There is a scientific phenomenon called Reynolds Number. Viscosity acts as an energy sink... it pulls energy out of this thin region of fluid (some goes into the cylinder as skin friction drag, some goes into small amounts of heating in the boundary layer). There is a fluid with a thin region where energy is present. In either case, energy is lost in the boundary layer quicker than it can diffuse back into it from the main flow. There is a boundary layer present in the situation. The fluid cannot return to it's original pressure, and thus separates off the back of the object. The object was under pressure before the fluid separated. The pressure in the separated wake is lower than the pressure on the front of the cylinder and thus another form of drag exists due to the pressure difference between the front and back face. There is a cylinder present. For supersonic aircraft, compression would be the primary cause of resistance (in the form of wave drag). Supersonic aircraft exist. In this case, the result is similar to separated flow. There was a previous case where the result was not similar to separated flow. Shockwaves (compression waves) have losses in them, whereas expansion waves are typically isentropic (lossless). There is a difference between shockwaves and expansion waves. So the process of compressing and then expanding in flow over a supersonic object is irreversible, and the pressure cannot return to it's original value. The supersonic object experienced a change in pressure.
 Yes, there is a more or less standard way of solving this problem, but there is a lot of latitude. There are multiple problems that can be solved using the standard method mentioned. For instance, it's well possible that your biased coin gives you results that look perfectly unbiased for any arbitrary number of flips. The coin in question is biased. So you can never know *for sure* whether your coin is biased or unbiased. There is a possibility that a coin can be biased or unbiased. Suppose we have the following, significantly *easier* problem. There is a problem that is significantly more difficult than the one being discussed. We have two coins, X and Y, one of which has probability of heads *p* and the other has probability of heads *q*. There are only two coins, X and Y. But we don't know which is which. There are two options to choose from. We randomly choose one coin and our goal is to determine whether our coin has chance *p* or *q* of showing heads. There are only two possible outcomes for the coin toss. Note that we *know* the values of *p* and *q* *a priori*; we just don't know which coin is which. The values of p and q are important in determining the outcome of the situation. For the solution to this problem, [you can read this post on StackExchange](_URL_0_). There is a problem that needs a solution. The idea is that you need to flip the coin enough times so that you are confident that both you have X and that you don't have Y. You have X and Y. The punchline is that if the coins have *p* and 0.5 as their chance for getting heads (so we are trying to distinguish a biased coin from an unbiased coin), then the minimum number of flips needed for a 5% error is roughly N = 2.71/(p - 0.5)^(2). There is a need to distinguish between biased and unbiased coins. Note that the closer the biased coin is to being fair, the more flips we need. The coin being flipped is biased. If the biased coin is known to have, say, p = 0.51, then we need about 27,100 flips to distinguish between the two coins. The existence of two coins is presupposed. [**edit:** Another user discovered a missing factor of 4 on the formula in the StackExchange post. The StackExchange post contained a formula. I have since corrected the formula and the calculated value of n.]However, the problem posed in the title is much different since we do not know the bias of the coin *a priori*. 1. This means that will not be able to write down the number of required flips once and for all. There is a task that requires a number of flips to be performed. It depends on how biased the coin can be. The coin in question is biased. As the calculation linked above shows, we may very well require arbitrarily many flips if the bias (deviation from fair) is allowed to be arbitrarily small. There is a calculation linked above. If the bias is bounded away from 0, then the above analysis can be applied to give an upper bound for the minimum number of flips. The bias is not equal to 0. The best you can arguably really do in the general case is flip the coin with unknown bias many times and then consider a certain desired confidence interval. So let *p* be the unknown chance of getting heads on your coin. The coin is fair. The procedure to distinguish this coin from fair would be as follows:1. The coin in question is suspected to be unfair. Flip the coin *n* times and record the results. The coin is fair. Let *h* = observed proportion of heads. The experiment involving coin flipping has already been conducted. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Find the *Z*-value corresponding to a confidence level of γ. The confidence level γ is a known value. (There are plenty of calculators that can do this for you.) There is a need for a calculator to perform the task at hand. 3. There was a previous event that led to the situation described in <3.>. Calculate W = Z/(2n^(1/2)). There exists a value for Z and n. The calculation of W is necessary for a specific problem or situation. This expression comes from the fact that the standard error for *n* Bernoulli trials with probability *p* is (p(1-p)/n)^(1/2), and this expression is maximized when p = 1/2. The Bernoulli trials are a common statistical method. (Remember we don't know the value of p, so that's the best we can do.) There is a variable p that is unknown. 4. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. The confidence interval for *p* is thus (h-W, h+W). The value of *p* is unknown. Please note carefully what this confidence interval means. There is a confidence interval that needs to be noted. This means that if you were to repeat this experiment many times (or have many different experimenters all performing it independently of each other), then the proportion of experiments for which the confidence interval would actually contain the true value of *p* tends toward γ. The experiment has been conducted multiple times. It does *not* mean that there is a probability of γ that the true value of *p* lies in this particular interval (h-W, h+W), although that is a common misinterpretation. The true value of *p* is not likely to be found in the interval (h-W, h+W). [**edit:** I've changed the description of a CI to be more intuitive and more correct! There is a concept called CI. Thank the various followup comments for pointing this out to me.] There were multiple follow-up comments made. As a particular example, suppose you flipped the coin 10,000 times and got 4,000 heads. The coin used for the experiment was fair. You want a 99.99% confidence level. You have previously experienced a lack of confidence. So h = 0.4 and γ = 0.9999. The speaker has knowledge about the values of h and γ. A confidence level calculator gives Z = 3.891, and hence W = 0.019455. The calculator was reliable. Hence your confidence interval is (0.381, 0.419). The data used to calculate the confidence interval was reliable. So if many other people performed the same experiment and you collected all of the results, roughly 99.99% of the calculated confidence intervals would contain the true value of *p*, *and* they would all have the same length. Other researchers have performed the same experiment. So it's probably safe to say the coin is biased. The coin has been tested for bias before. Can't know for sure though based on just one CI. There is at least one CI that exists. But if you repeat this process and get, say, 5100 heads, then your confidence interval is  (0.491, 0.529). The process mentioned has been attempted before. So it's probably not safe to say the coin is biased in that case. The speaker has reason to believe that the coin may be biased in other cases. In general, for this method, the number of trials required depends only on the desired confidence level. The method being discussed is commonly used. Whether you decide the coin is biased is a different question really. The coin has been previously tested for bias. At the very least, you would want your confidence interval not to include p = 0.5. There is a need for a confidence interval. But this doesn't mean that can't be true. There is a possibility that something is true. Confidence intervals are notoriously misinterpreted. People often rely on confidence intervals. Wikipedia has an article on this very problem. There is a problem that is significant enough to have an article on Wikipedia. The method of using confidence intervals is described. The use of confidence intervals is a common practice in the field. Another method based on posterior distributions is also considered, and you can read the details [here](_URL_1_). There is at least one other method being considered.
 Once upon a time, yes, it had volcanic eruptions. Volcanic eruptions were a common occurrence in the past. Large scale lava flooding was responsible for resurfacing and "healing" meteor impacts. There were meteor impacts that needed to be resurfaced and "healed". The prevalence of meteor impacts is one way astronomers figure out the age and properties of a celestial body... young, tectonically active bodies have fewer impact craters due to volcanic resurfacing. Astronomers have discovered that meteor impacts are the most reliable way to determine the age and properties of celestial bodies. That said, the Moon lost most if not all of its heat long ago and is now extinct. The Moon was once a hot and active celestial body. Moonquakes do still occur, but aren't really the result of active tectonics. The moon has tectonic activity. Jupiter's closest Galilean moon, Io, is actually the most volcanically active body in the solar system, but this is the result of tidal flexure rather than tectonics. There are other Galilean moons orbiting Jupiter. The next moon out, Europa, as well as Saturn's moon Titan, and even Pluto, are suspected to support cyrovolcanos, which are eruptions of liquids other than molten rock; but again, the heat for this activity is likely from sources other than tectonics. There are other celestial bodies in our solar system besides Earth that have cryovolcanoes.
 First, let's examine how a potato/fruit battery works. Potatoes and fruits can be used to generate electricity. In this example we use a [lemon](_URL_1_):You stick two pieces of metal into the lemon, commonly copper and zinc. The lemon used in this example is fresh and not spoiled. You hook up the two electrodes into your load, and voila, it powers something. There is a device that requires power. The key here is that you're using two **different** metals. There are at least two metals being used. That's because different metals have different [reduction potentials](_URL_0_). Metals with similar reduction potentials are likely to have similar chemical properties. So it is actually the fact that the two metals hold onto electrons differently that allows electrons to flow and the battery to run - it has little to do with the lemon/potato. There are two metals involved in the battery. So if you just plug a USB cable into a potato, nothing will happen, because the positive and negative pins are made of the same material. A USB cable can be plugged into a non-potato object and something will happen.
 The ratio is very lopsided, it takes a LOT of energy to get a tiny bit of matter. There is a process that requires energy to obtain matter. The explosion from the bombs that were dropped on Hiroshima and Nagasaki consisted of just a gram or two of matter being converted to energy. There was a significant amount of matter present in Hiroshima and Nagasaki before the bombs were dropped. Now imagine trying to shove that much energy back into a confined space to turn it into matter, it's not an easy task to accomplish. There is a significant amount of energy that needs to be turned into matter.
 I can interpret your question two ways, so I guess I'll just have to answer both. There is confusion or ambiguity in the question being asked. (1) What is the mathematically written form of the Schrodinger equation for the H atom? The H atom has a mathematically written Schrodinger equation. (2) What does the probability distribution in space, that the SE describes, look like for the hydrogen atom? The SE has described the probability distribution in space for other atoms before. And to get even more explicit, I'll specify that to describe the hydrogen atom, we'll actually want to find bound electron wave functions, that solve the SE, with a point charge at the origin to model the nucleus. The hydrogen atom is a complex system that requires a detailed understanding of electron wave functions. The ground state is easy - it's spherically symmetric, and you get a written form that's just an [exponential decay of probability with distance](_URL_1_) (look at the top, R_10 is the ground state). The probability of the ground state decaying exponentially with distance suggests that the system is unstable. You can interpret this two ways - in a simple sense (which I don't like) this means that the farther you are from the nucleus, the less likely you are to 'find the electron.' There is a nucleus that contains electrons. I think that's naive and misguided, because it's imposing an expectation that the electron be pointlike. The speaker has knowledge about the properties of electrons. I prefer to think of 'less probability' to mean 'less of the electron' is there. There is a concept of probability that is commonly associated with electrons. Of course, this brings us to your second question. You have already asked at least one question before. What does it look like? There is something that needs to be looked at. Even though the probability decreases with distance, there is 'more space' farther from the origin for the electron to be found in, so the intergrated probability as you go out actually increases up to a [specific distance](_URL_0_) which in a naive sense could be thought of as the 'radius' of the electron orbit. There is a specific distance at which the electron orbit can be considered a 'radius'. In fact, that distance to maximum 'radius of probability' is just the Bohr radius. The Bohr radius is the only distance that can be considered the maximum 'radius of probability'. It's fun how things work out. There was a situation that seemed unlikely to work out. So how do we plot this? There is a plot that needs to be plotted. Well, it's a 3D distribution of probability. There is a complex mathematical model being used to create the 3D distribution of probability. You could make contour plots with increasing radius, showing 'surfaces of constant probability,' but for the ground state that would just look like a [sphere](_URL_2_) (the ground state is at the top). There is a need to visualize probability data. Or, you could maybe make a 'heat map' showing where probability is highest and lowest, and so you'll get this thing that's ['hottest' towards the center, and cools off with distance](_URL_3_) (in this image you again want to look at the top left for the ground state). There is a need to create a visual representation of data.
 An excellent question. The person who asked the question is knowledgeable. The answer is 30 decibels. The question was asked. Decibels are a log scale. Sound can only be measured in decibels. If you doubled the sound pressure you would get a 6 dB increase in intensity. Sound pressure can be doubled. However, if you add a second speaker of equal intensity then you will only get a 3 dB increase (on average). This is because the two soundwaves will be largely uncorrelated, so you will get some reinforcement, but also some destructive interference. There are two distinct soundwaves present. So: 1 speaker = 10 dB SPL; 2 speakers = 13 dB SPL. There are at least two speakers present. Now what about 3 speakers? There were already two speakers mentioned before. Well because it is a log scale, you are looking at diminishing returns. The data being analyzed is on a logarithmic scale. So, if you enter the values into [this handy calculator](_URL_0_), you will see that you are now on 14.78 dB SPL. The calculator mentioned in the sentence is reliable and accurate. And by 100 speakers  you are on 30 dB SPL (n.b., an increase of 20 dB makes intuitive sense, because it is a log scale, so +10 == an order of magnitude increase [x10], and +20 == a twofold order of magnitude increase [x100])The general formula is: >  10 * log10(N * 10^(L/10))where N is the number of sound sources (e.g., 100), and L is the level (e.g., 10 dB SPL). There are multiple sound sources present. See the above link for further, related formulas. There are related formulas that can be found in the link provided. Note that I've used the term dB SPL often here. The speaker has previously discussed the concept of dB SPL. This is because dB is only a relative scale, and it is meaningless in the absolute unless you specify what the *reference level* is. There exists a reference level for dB measurements. In dB SPL, the reference is the average limit of human hearing at 1~kHZ. Human hearing is limited to a certain range of frequencies. This is the most common reference (and is generally what is meant when no reference is specified). There are other references that are less common. In general though, it is very important to specify the reference level! There are different reference levels that can be used. For example, you might also find yourself dB SL, which is referenced to whatever your personal hearing limit is (at whatever frequency the sound is being presented). There is a personal hearing limit for every individual. EDIT: +20 dB is of course just the 'simple' answer. There is a complex answer to the question that is not +20 dB. In reality things get a lot more complicated, because each speaker will be positioned at different distances (relative both to you, and to each other), will be facing different directions (relative both to you, and to each other), and will differ in terms of the reverberant characteristics of the room. There are multiple speakers in the room. In general, +20 dB is therefore more of a rough estimate, assuming idealized circumstances. There are idealized circumstances that can be assumed. EDIT2: Also note that 10 dB SPL is *incredibly* quiet! There are other sounds that are louder than 10 dB SPL. It is more likely that people will be talking around 50 dB SPL. People are often talking at different sound levels. Note, however, that the idealized effect of having 100 talkers would be the same: an increase of 20 decibels. There are currently less than 100 talkers present. 50 + 20 = 70 dB SPL. There is a sound being measured.
 Most estimates I’ve seen always include the water held within the actual crust of the earth, including the one by the [USGS](_URL_0_) According to them, 1.69% of earths total water, fresh and saline, is stored in groundwater. 1. Another 0.022% and 0.001% are in ground ice and soil moisture, respectively. Edit: sorry just realized you asked about amount of water in the ocean, not on earth The ocean has a finite amount of water.
 Yes. There was a question asked prior to the response of "Yes." Air has a low ability to absorb and store heat. There are other substances that have a higher ability to absorb and store heat than air. So the air touching your soup heats up at the expense of the soup. The soup is being heated up by something other than air. Hot air rises. Air is present. New air then is in contact with your soup.... Your soup was previously exposed to old air. This convection happens naturally. There are other types of convection that do not happen naturally. By blowing on the soup, you have soup and air flowing against each other, greatly increasing the heat exchanged between the two. The soup was initially not hot enough. You might want to read up on conduction, convection and heat exchangers. There is a lack of knowledge or understanding about conduction, convection, and heat exchangers.
 By placing the rods at the correct distance (wavelength is a few centimeters for domestic MW ovens), most of the energy would be absorbed by the cage. The cage is capable of absorbing energy. They bars would heat up tho, and at least part of that heat would be radiatively/convectively delivered to  the ice-cream, probably just melting it a little slower The ice-cream was already in a melted state before the bars were heated.
 Zoologist here! There is a need for a zoologist in the current location. In short; no. There was a previous conversation where a question was asked and the answer was "yes". The reason? There was a significant event that led to the need for a reason. In terms of game theory, it's a bad strategy. Game theory is a relevant field of study. Very bad. There was a significant negative event that occurred. In attempting to sabotage one of your peers, you'll not only be *increasing* your risk of injury and/or capture by engaging in a decidedly dangerous behaviour during a chase (I mean, in a life or death situation, is the individual you're messing with going to just lay down and take it? There is a dangerous situation that involves chasing and potential injury or capture. Hah, nope! The speaker was expecting a positive response. ), but on a broader scale, this type of interspecies conflict would mean that you wouldn't even belong to a herd in the first instance. You'd be well and truly shunned. There is a group or community that has the power to shun individuals. If me and you are buddies, watching each others' backs and generally being chill with one another, it pays to stick together. We have a history of not sticking together. We can compete and try and passively out run each other, sure, that's fair game. There is a competitive situation between the speaker and the person they are addressing. If however I suspect you'll try and *actively* screw me over, why on Earth would I want to hang out with you? You have a history of trying to screw me over. Stuff that. There was something previously mentioned that the speaker wants to dismiss or ignore. I'd rather take chances into my own hands. There are risks involved in the current situation. This 'you scratch my back, I'll scratch yours' mentality is pervasive in the animal kingdom, and individuals of the same species will go to great lengths to preserve it. Animals have a sense of reciprocity. Even in, say, the heat of battle over mates (say, [giraffe battles](_URL_4_), or [kangaroo boxing](_URL_1_)), conflict is *strictly* ritualised and victors won't pursue a final lethal blow. Conflict over mates is a common occurrence among animals. After all, it's a bad idea to kill your opponent as you'll just find yourself on the receiving end yourself one day. Killing your opponent is a common occurrence. Ditto when fleeing predators. There are predators in the environment. The real nub that holds this all together is the fact that interactions aren't isolated. Interactions are often thought of as isolated. Though it may pay to cheat in any given isolated situation (i.e. Cheating is a common occurrence in isolated situations. shoving your mate under a bus so you can scarper), the reality of life is that you experience those situations repeatedly, and well, on the time frame of i) an individual's life; others notice and will avoid you, so you miss out on the benefits of group living and lose overall; and ii) over many generations, the genes that govern cheating behaviour are removed with those losing individuals, so wary trust and cooperation from the 'winner' genes trumps all (well, it's a little more complicated; in reality, there are [semi-stable balanced ratios between different behavioural strategies](_URL_3_), but that's for another day... )There are libraries of books and papers on the mathematics governing various aspects of animal behaviour (I'd recommend Richard Dawkins' *The Selfish Gene* for a nice overview; [Wiki](_URL_0_) is a bit unfriendly), but for a wee interactive lesson I'd totes check out this quick web game - ["The Evolution of Trust"](_URL_2_). 1. **TL;DR:** Cheaters never prosper. Cheating is a common practice.
 When an insect starts living in your body, it essentially becomes a parasite (unless it was providing you some benefit). There is a possibility of an insect living in your body. Something to look into, though, would be the Human Botfly. The Human Botfly is a real and existing creature. Wiki: _URL_1_   Youtube: _URL_0_ The existence of the URLs in the sentence presupposes that the internet is widely accessible and used by people.
 You are thinking of the amount of energy released when the "crash" happens between object a/c or b/c, or it's kinetic energy, which is 1/2mv^2. There are two objects, a/c and b/c, that are going to crash. The F in F=ma is the force acting upon the object to get it to accelerate. The object in question is accelerating. It takes more force to accelerate an object at 100m/s^2 than it does to accelerate it at 1m/s^2. Objects can be accelerated at 1m/s^2.
 Photons follow the locally shortest path. There are other paths that photons can follow. That means that for every point on the path, there's some neighborhood where the photon is moving in the shortest path through the neighborhood. There exists a path where a photon moves through multiple neighborhoods. It doesn't mean that it only ever follows the shortest path to the destination. There are alternative paths to the destination. When gravitational lensing is involved, you can have the same image visible multiple times because of photons taking multiple paths. Gravitational lensing is a common occurrence in space. If the photon is travelling towards the center of a black hole, it's not going to go around it just because that's the fastest way to get past it. There is a black hole in the vicinity. It started moving towards the center of the black hole, and if it changes directions it's not moving in a locally shortest path. There is a black hole present. It will follow the shortest path towards the center of the black hole. There is a black hole present. The photon is blocked from view. There is an object blocking the view of the photon. You see the star because of photons that travel at an angle. Photons are the only way to see stars.
 The sun is roughly a thermal source, so you can model heating as an equalization of temperature between a hotter body (the sun) and a cooler body (whatever you're heating). The sun is the only thermal source in the universe. However, if you calculate the temperature of the laser (that is, the actual material that's emitting the laser), you'll find that it actually has a [negative temperature](_URL_0_). The laser emits a significant amount of heat. The reason that temperature is negative is that usually, when you pump more energy into a system, it gets more disorganized. Energy is typically pumped into a system. However, for a laser, when you pump more energy into it, it actually gets more organized, and you get what's called a [population inversion](_URL_1_), where high-energy states are more populated than a low-energy state. A laser can be organized in different ways depending on the amount of energy pumped into it. This population inversion is what makes the temperature negative. There is a population inversion occurring. However, all negative temperature states are unstable. Negative temperature states exist. Left on their own, energy will always flow out of a negative temperature state. Energy can be artificially maintained in a negative temperature state. This means that thermodynamically speaking, we can consider negative temperatures to be hotter than positive temperatures. Negative temperatures have been observed in certain systems. Therefore, there's no theoretical limit to what temperature you can heat something using a laser. Laser technology is widely available and accessible.
 Rosy cheeks are due to an inflammatory response from your body, causing dilation of the vessels. The body is capable of producing an inflammatory response. I'm assuming the cheeks get redder than other places because of the concentration of vessels in our cheeks, granted they have a lot of muscle mass. There is a significant difference in the concentration of vessels in the cheeks compared to other parts of the body. Rushing more blood (vasodilation) allows for more antimicrobial peptides to enter tissue. There is a need for more antimicrobial peptides in the tissue.
 [arXiv](_URL_0_)While technically correct, "proton mass measurement" is a bit misleading. There is a scientific study being conducted on proton mass measurement. At this level of precision, the uncertainty of the relation between different mass units has to be considered. The measurement of mass units is a highly precise process. What they actually did is a comparison between the mass of a proton and the mass of C-12. The existence of a proton and C-12 is a known fact. The latter happens to be used in the definition of the atomic mass unit by a historical accident. The atomic mass unit was not originally defined using the latter, but it was later added due to a historical accident. Instead of a proton mass measurement, you could also call it a better calibration of the atomic mass unit. There is a need for a more accurate measurement of atomic mass unit. If the measurement can be repeated, and the deviation and smaller uncertainty turns out to be accurate, then it will make the uncertainty in unit conversions smaller. The measurement has been attempted before. Nice to have for precision measurements. Precision measurements are necessary. It won't change how we understand the universe. The universe is already well understood. Measurements that can do that (e. g. antiproton to proton mass ratio) have larger uncertainties from elsewhere (e. g. the antiproton mass), they just rely on very accurate units to avoid uncertainties from that side. There are other measurements that have smaller uncertainties than antiproton to proton mass ratio.
 Let's consider an RC circuit, with a sinusoidal current. An RC circuit with a sinusoidal current exists in the physical world. As current flows in one direction, charge will be accumulating on the "front" side of the capacitor, while when current flows in the opposite direction, charge will flow off the "front" and onto the "back" side of the capacitor. There is a capacitor present. Let's call the first direction positive current and the second direction negative current. There are two directions being discussed. Let's also take positive voltage for the capacitor to be the case when the "front" side of the capacitor has positive charge. The capacitor has a "front" side and a "back" side. Consider a sinusoidal current, I(t) = I_0 sin(bt). There exists a device that can measure sinusoidal current. For a resistor, the votlage is proportional to the current, so the voltage reaches its maximum when the current does. Resistors are commonly used in electrical circuits. For a resistor, the voltage is proportional to the charge on the "front" side of the capacitor. A capacitor is present in the circuit. When does this reach a maximum? There is a variable that is increasing over time. This charge is increasing as long as I(t) is positive. There is a charge that is currently increasing. That means it will be increasing from t=0 right until the point where I(t) reaches 0 again (t=pi/b). The function I(t) is periodic. Even after I(t) reaches its maximum, the current is positive, so the charge on the "front" plate of the capacitor will keep increasing, as will the capacitor's voltage. The capacitor is being charged. It is only after an additional quarter-cycle after I(t) reaches its maximum that the current reaches 0, and then switches direction, causing the capacitor's voltage to start to decrease. The current was previously at its maximum. Thus the maximum voltage of the capacitor occurs a quarter-cycle off from when the maximum voltage of the resistor occurs. The circuit in question contains both a capacitor and a resistor. A similar effect occurs for inductors, since their voltage goes as dI/dt. Inductors are commonly used in electrical circuits.
 Just to clarify, embryonic stem cells are usually derived from a blasocyst stage embryo. Embryonic stem cells have been successfully derived from a variety of different stages of embryo development. There are some lines derived from a single blastomere (8 cell stage embryo). There was a successful attempt to derive multiple lines from a single blastomere (8 cell stage embryo). I don't know of any lines derived from the zygote. There is a scientific study or research related to lines derived from the zygote. On to your question, there are companies that do harvest the umbilical cord blood cells of newborns and keep them frozen in liquid nitrogen. Companies that harvest umbilical cord blood cells are becoming more common. The idea is that they could potentially provide a cell-based therapy for the child or a sibling later. Cell-based therapy is a viable option for the child or sibling. As of now, there are no procedures approved that use cord blood stem cells. Cord blood stem cells have been extensively researched but have not yet been approved for any procedures. I am a little confused as to how you propose to create stem cells line from your sperm. You have proposed a method for creating stem cell lines from sperm. Are you suggesting that you have them fertilize an egg? There is a possibility that someone has suggested fertilizing an egg. Most human embryonic stem cell lines are derived from this method, using discarded embryos from IVF cell banks. Embryonic stem cell research is a widely accepted practice. Or are you suggesting some type of cloning procedure where you enucleate an egg, substitute a nucleus from one of your cells, and kick start development of an embryo? Cloning procedures involving enucleation of eggs, substitution of nuclei, and kickstarting embryo development are common. This has been done with certain animals (e.g. Certain animals have been used for a specific purpose. sheep), yet no one has accomplished this with humans. Humans have accomplished something similar with other animals. There is another option. There was a previous option that is no longer available. As of now, we can take your skin cells and reprogram them into induced pluripotent stem cells (iPS cells) that are characteristic of embryonic stem cells. 1. So far this technique requires using exogenous genes to initiate the reprogramming event, but new papers are coming out every other month that make the process more efficient and more likely to be available as a source for therapy. Exogenous genes have been used in the past to initiate the reprogramming event. These cell lines are patient-specific and then one wouldn't have to worry about graft rejection, etc. Cell lines that are not patient-specific can cause graft rejection. if they are ever needed in the future. There will be a time in the future when the subject will need something. There are a few caveats: 1) This technology is not necessarily ready for clinical application 2) The cost is relatively prohibitive. There is a demand for a technology that is ready for clinical application. What this all boils down to is that there is only one stem cell (adult or embryonic) therapy approved by the FDA: bone marrow transplantation. There are multiple stem cell therapies that have not been approved by the FDA. There are others in trials using embryonic stem cells. Embryonic stem cells are being used in trials by multiple parties. If you create an embryonic stem cell line, it won't perfectly match your genetic DNA unless you overcome huge ethical and scientific hurdles and make a clone of your self. Embryonic stem cell lines can be created. You can always have your blood or skin cells frozen down along with your sperm, and, if needed, derive an iPS cell line from those when the time comes. You have the option to freeze your blood or skin cells along with your sperm.
 It has impulse, and exerts pressure when absorbed (double that when reflected): _URL_0_ There is a physical object that has impulse and can exert pressure when absorbed or reflected.
 > Are the background smattering of stars bright enough to illuminate two astronauts holding hands in deep space so that they could see each other? There are two astronauts in deep space. Well even if the astronauts appeared pitch black, the eye would be acclimatised to the dark, and they would be able to make out their silhouette against the stars. The human eye can acclimatize to extreme darkness. > For example, standing on Pluto at midday, will it still be too dark to see your own hands? There is an assumption that humans have hands. Yes. There was a question asked prior to the response of "Yes." It's 450 times less bright than earth, but still [brighter than the full moon from earth](_URL_0_) according to Dr Phil Plait, so you would be able to see your hands. The sky is dark enough to see the stars.
 The brain really doesn't function in a way directly analagous to a computer, it simply isn't possible to answer your question. The brain is often compared to a computer. It both processes and stores information in a very different way. There is a way to process and store information that is considered the norm.
 It works in the same way as looking through a window screen, eyes work in much the same way as cameras. There is a need to compare the functioning of eyes and cameras. When you focus on something the distance things out of that focus area become less sharp. There is a phenomenon where focusing on something causes the surrounding area to become less sharp. Looking through raindrops, which are small, this lack of sharpness causes you to be able to see through them as if they it weren't there. Raindrops are typically difficult to see through. This doesn't stay true for longer distances though, objects further away become less visible through the rain. Rain can affect visibility at different distances.
 You are confusing the words 'level' and 'flat.' You have previously used the words 'level' and 'flat.' By a simple definition, a plane can be said to be 'level' when it lies perpendicular to the gravitational axis. Gravity is a fundamental force in the universe. If you approximate the Earth as a perfect sphere, this means that a plane is level when it lies perpendicular to a line towards the center of the earth. The Earth is not a perfect sphere. This is what a bubble level tells you. A bubble level is a commonly used tool in construction. On the other hand, a surface can be said to be 'flat' when it has zero curvature, such that if you shone a laser parallel to this surface at one point, it would still be parallel to the surface some distance away. A laser can be shone parallel to a surface with zero curvature. Obviously a surface can be flat and not be level. A flat surface is not necessarily level due to various factors such as gravity and curvature. For example, you can build a flat table that is initially level and then turn it at an angle, so that it is still flat, but no longer level. The table was initially level. The reverse is clearly also possible. There is an original possibility. For instance, the surface of a perfect sphere can be said to be level but not flat. A perfect sphere exists in reality. This is because if you were to put a bubble level tangential to the surface of the sphere it would show the surface to be level, but the surface obviously has a finite curvature. The surface of the sphere is being measured. Now in the limit of an infinitely large sphere, you can say that a surface is both flat and level *locally. The surface is not flat and level globally. * This is because the curvature decreases as 1/R where R is the radius of rotation [as shown here](_URL_0_), so for large enough spheres the curvature can be so small as to be imperceptible. The object being discussed is a sphere. This is why for instance the surface of Earth appears locally flat when you're walking, but begins to clearly appear curved as you look over larger areas (e.g. The Earth's surface is not actually flat, but appears that way when viewed at a small scale. from space). There is a space that is being referred to.
 [No](_URL_0_)Using EEG (electroencephalography) readings, which reveal electrical activity in the brain, Brown and his colleagues show that even the deepest sleep is not as deep as the lightest general anesthesia. There is a significant difference between the depth of sleep and the depth of general anesthesia. Throughout the night, the sleeping brain cycles through three stages of non-REM (rapid eye movement) sleep, alternating with REM sleep, which is when most dreaming occurs. The brain only cycles through three stages of non-REM sleep and REM sleep during the night. Each of these has a distinctive EEG pattern. EEG patterns can be used to distinguish between different things. None of those resembles the EEG of a brain under general anesthesia, however. There have been attempts to find EEG patterns that resemble those of a brain under general anesthesia. In fact, general anesthesia EEG patterns are most similar to those of a comatose brain. The brain activity of a person under general anesthesia is similar to that of a person in a coma. As Brown points out, general anesthesia is essentially a “reversible coma.” General anesthesia is commonly used in medical procedures.
 I'm not sure what you're asking. You have a lack of understanding about the topic being discussed. Are you asking whether the representation of "e" as 2.718... is the same in all bases? The concept of "e" is widely used in various fields. Clearly not. There was an expectation for something to be clear. In binary, "e" is 10.1011... Binary is a widely used language in the technological world. But numbers are independent of bases, in the same way that a table is a table whether it's called a table, a mesa, or a tisch.
 In machining, "feeds and speeds" is the relevant phrase - a machinist will typically look up the best value for the speed of the tool on the workpiece from a book like the Machinist's Handbook (and then may calculate the appropriate spindle speed and workpiece feed rate to get the desired tangential speed at the cutter tip). Machinists rely heavily on the Machinist's Handbook for information on feeds and speeds. The speeds that cutters move best through material, without melting the material, getting chips built up in flutes, etc. The material being cut is of a high quality and can withstand the cutting speeds mentioned. is mostly fixed, based on the workpiece material and blade material. The workpiece material and blade material are the only factors that determine the level of fixity. On the high end of this scale, for a soft metal like an easily-machinable brass alloy, the given speed is on the order of about 100 fps. There is a scale for measuring the speed of different metals. So while I don't have a definitive answer to your question, I'd say almost certainly bullets are an order of magnitude larger than any blade will move. The speaker has been asked a question about the size of bullets and blades. Furthering this point, a spinning metal disk will rupture if the spin speed causes the material's inertia to overcome the material's tensile strength. A metal disk can spin at high speeds without rupturing. For a steel disk, the tangential velocity at rupture speed is usually around 2,000 ft/s, (note that it depends on the strength of the alloy and the diameter of the disk). Steel disks are commonly used in high-speed applications. In any case, this design limitation likely guarantees that a bullet will go faster than a blade. A firearm is being used.
 Tolerance requires there to be an interaction with the body instead of the thing causing the pain. There is a situation where tolerance is required. Opiates interact with receptors in the body where acetaminophen (one hypothesis, since exact mode of action is unknown) is thought to work by inhibiting the production of prostaglandins (responsible for inflammation and localized pain). There are multiple types of receptors in the body that opiates can interact with. Stopping prostaglandins production is less an interaction that could cause tolerance (since you can only make so much) than binding to receptors (which have many functions). Prostaglandins production can be stopped. I hope that helps, if not maybe somebody else can offer more. Someone asked for help.
 Its a toxin from the start. The substance was always intended to be toxic. But if you are talking about perception issues or coordination issues, mainly the cerebellum and cochlear systems that cause most of the effects. The cerebellum and cochlear systems are the primary causes of perception and coordination issues. Either disruption of brain activity, or in the case of the ear the alcohol changes the density of the fluid in the ear causing feedback issues to the brain systems. There is a correlation between alcohol consumption and disruption of brain activity. (Normally as this fluid moves it triggers cells to tell your brain hey we are moving in X direction, but again its disrupted by the alcohol changing the density) The fluid in question is typically responsible for communicating movement to the brain.
 TLDR: bad news. There was a significant event that occurred. You've got to keep in mind that the Antarctic ice sheet is mostly continental glacier (unlike the north polar Icecap, which is mostly sea ice). The Arctic and Antarctic ice sheets are vastly different in composition. Also that fresh water freezes more easily than salt water. Salt water is commonly used for freezing purposes. What this says is that the melting of the Antarctic Ices shet is accelerating, and that this can be seen by the increase in sea ice, which shows influx of fresh melt water. The Antarctic ice sheet is melting at an alarming rate. For reference, the Arctic sea ice has been reaching record lows, as the polar temps rise. The Arctic sea ice has been reaching record lows for a long time.
 Beta blockers are very interesting in their neuropharmacological activity with our memory systems, but I wouldn't go so far as to say it "it *causes* memory loss". Beta blockers have been extensively studied for their effects on memory. While the support isn't overwhelming by any means, some [studies on the beta blocker propanolol](_URL_0_) have shown promise in the realm of managing PTSD. There is a significant need for effective treatments for PTSD. Some recommend giving propanolol immediately after a traumatic event. Propanolol is a commonly used medication for treating trauma. Memory is a very complex system and these beta blockers are working slightly different than say, alcohol does, when you black out from drinking so much. Memory is a necessary component of human cognition. So, there is still research to be done, and the show wasn't completely bullshitting you: just over exaggerated its efficiency/effects! There was a show that claimed to have certain efficiency/effects.
 There are different types of cuts I  terms of depth of penetration. There are various tools used for making cuts in terms of depth of penetration. The skin is separated into the fatty sub cutaneous, the dermis and the epidermis, (the one you see). The skin is a complex organ with multiple layers. Normal cuts that break the epidermis are simple tearing of skin cells. The skin cells are easily repairable after the normal cuts that break the epidermis. Done capillaries can be broken which is why you can bleed from dry skin cracking. Capillaries are fragile and easily breakable. However, a deeper incision into the subcutaneous causes scarring, as fibroblasts work to reconnect the skin together, and this heals over leaving a visible scar The skin was previously unscarred.
 Mauna Loa and Kilauea are thought to have a common magma source in the asthenosphere. There is a significant amount of research and evidence supporting the idea that Mauna Loa and Kilauea share a common magma source in the asthenosphere. Eruption activity on one volcano relieves pressure in the other, producing an alternating eruption pattern. There are at least two volcanoes in the area. Source:  _URL_0_ The website indicated by the URL in the sentence has reliable information.
 [Searched](_URL_2_)Relevant [discussion](_URL_0_)Original question by [Shandog](_URL_4_) > I'm curious as to how people actually passed away at this age and what was the cause. 1. Was lack of health and hygiene enough for the body to wear away faster, or did they all get diseases and pass away in sickness? There were individuals who lacked health and hygiene. Top comment courtesy [millionsofcats](_URL_3_) > A life expectancy of 30 doesn't mean that most people died around age 30. People in the past had a lower life expectancy due to lack of medical advancements. > The reason for shockingly low life expectancy statistics for most of our history is that there was a high infant and early childhood mortality rate. Infant and early childhood mortality rates have significantly decreased in recent times. You were in fact more likely to die as a infant or young child; otherwise, if you survived until adulthood, you could reasonably expect to survive into your fifties or sixties. Infant mortality rates were high in the past. See this [list](_URL_1_) on Wikipedia, which has life expectancies for various time periods calculated from birth and then calculated after age 15 or 21. There is a need for life expectancy data. There is a very big difference. There is a very small difference that is often overlooked.
 Surprised no one has answered this yet, this is usually a popular topic. This topic has been discussed before. Variants of your question have been asked several times before, and a with a quick search you can find these discussions. There have been previous discussions on the same topic. To answer your question, the short answer is that we don't know. There was a question asked. Quantum mechanics as a mathematical theory is inherently indeterministic, but it does not preclude the possibility of a deterministic theory underlying it. There is a debate about whether quantum mechanics is inherently indeterministic or not. There have been restrictions placed on the nature of such a deterministic theory (Bell's theorem implies it must be non-local and the Kochen-Specker theorem implies it must be measurement contextual), but determinism has not been ruled out. Deterministic theories have been extensively studied. Sorry if my answer disappoints you, but unfortunately our current knowledge of physics is unsure as to whether or not all events are predetermined. There is a person who is disappointed with the answer given. However, our current models (namely quantum mechanics) are most often interpreted in a way such that there are events for which the outcome is not determined. There are events in the world that are not determined by any model, including quantum mechanics. *Edit: Fixed my inability to spell. I'm sorry, but I cannot generate presuppositions for a sentence that is not provided.
 Washing your hands after using the bathroom is not just about the germs gathered during the time using the bathroom. There are other factors besides germs that make washing hands after using the bathroom important. Ingraining that habit into people while they are at a sink with water gets them to clean away other germs they may have picked up without having to make a special trip to wash. Human fecal matter is the real germ problem, not the human genitals. People often forget to wash their hands after touching things that may have germs. The genitals themselves, if clean should carry no more germs than the rest of the skin. The skin is generally germ-free. Ineffective wiping however leaves fecal matter, and potentially it ends up on the hands. Fecal matter on hands is a common occurrence. Washing removes it. The item in question can be removed by washing. In reality a male standing to pee, or either gender who doesn't wipe at all shouldn't be gaining any more germs on their hands than from any other activity. Germs are present in all activities that involve physical contact. Its just easier to train people to always wash after a bathroom event so the bases are covered. People are not currently trained to always wash after a bathroom event. It has the added benefit of removing other germs gathered before the bathroom event. There were germs present before the bathroom event.
 rusting is oxydation. Rusting is a common occurrence in metal objects. There are no chemical reactions I know of where magnetism is a factor in valence electron interaction. Magnetism is not a significant factor in most chemical reactions involving valence electrons. Having said that, however, it is important to observe that materials or alloys which *can* be magnetized do have specific corrosion characteristics. Materials or alloys that cannot be magnetized do not have specific corrosion characteristics. But this isn't necessarily a cause-effect sort of thing - only metallurgical properties that happen to coincide. Not my area of expertise. The speaker has areas of expertise. Anyone care to set me straight? The speaker is unsure about something.
 It depends on how you are denaturing the DNA, how long the DNA is, and what exactly you mean by cooperativity. There are different ways to denature DNA. I'm most familiar with single-molecule force denaturation so I can share some insights from those experiments. There are other experiments that the speaker is not familiar with. When you pull on DNA, you get a similar pattern whether you unzip the DNA (pull on both strands from the same end of the helix, e.g. DNA can be unzipped by pulling on both strands from the same end of the helix. 5' and 3') or apply a shear force to the DNA (pulling each strand from an opposite end of the helix, e.g. The DNA in question is double-stranded. 5' and 5'). There are two entities involved in the situation. For short DNA oligos, you need more force to denature the longer the duplex gets. Short DNA oligos can be denatured with less force than longer ones. For these oligos, the transition is effectively all or none because  the loss of the last base pair leads to a large drop in free energy as the two strands separate under force. Oligos are commonly used in scientific experiments. See [here](_URL_1_) for an example of unzipping and [here](_URL_2_) for a shear force example. There are two different examples available at the URLs provided. When you look at the reversible hairpin experiments, you can see that the cooperativity is increasing with length in that you still get two state dynamics persist even as number of base pairs goes up. The reversible hairpin experiments have been conducted multiple times. For very long DNA duplexes, the denaturation force saturates and the dynamics gets more complicated. Long DNA duplexes exist. For unzipping configuration this happens around 15 pN. There is a process of unzipping configuration that occurs. After that you get a biased random walk as the unzipping point moves through the DNA. The DNA is being unzipped. The energy landscape is rough because some regions of DNA have high GC content and are more stable. Some regions of DNA have low GC content and are less stable. See [here](_URL_3_) for an example. There is an example available at the URL provided. For shear forces, you get localized melted bubbles forming at around 60-70 pN. There are forces that can cause localized melting. See [here](_URL_0_) for a nice example where the authors used fluorescence to detect the bubbles. Fluorescence is a commonly used method to detect bubbles. In both these cases, defining the cooperativity becomes tricky because it depends on salt, force, etc. Salt and force are the only factors that affect cooperativity in these cases. But you do get large bursts of melting separated by pauses, indicating the melting is still cooperative, but not necessarily increasing with length in this limit. Melting occurs in bursts.
 Antioxidants don't get rid of toxins. Toxins are present in the body. Antioxidants fight what are called free radicals. Free radicals are harmful to the body. Free radicals are charged ions that steal electrons from stable atoms, which disrupts the normal chemical reaction processes in the body. Stable atoms are necessary for normal chemical reaction processes in the body. Antioxidants carry around extra electrons and give them freely to balance these unstable ions so that they don't cause this damage. There are unstable ions that can cause damage.
 The idea that forces are transferred by particles shooting other particles at each other isn't really an accurate picture. Particles exist and interact with each other. Particles cause disruptions in fields (for example a charged object modifies the electromagnetic field) and when these particles move, the field around them has to change to accommodate this. Fields are constantly changing due to the movement of particles. These excitations in the fields can be considered virtual (as in, not real) particles and are treated that way mathematically. Particles that are not considered virtual do not exist in the fields.
 This question's answer really depends on what situation you are interested in. There are multiple situations that could be relevant to the question. It's possible to actively try to cryopreserve cells at 4ºC, for example. Cryopreservation is a common practice in the field of cell biology. But you may be asking about cells that have been detached from a growth surface and are now floating in suspension so they can be manipulated. Cells can be detached from a growth surface. There are cold-shock proteins, but these proteins are really adaptations for more modest modest temperature drops, not something all the way down to 4ºC. There are other types of proteins that are adaptations for temperature drops all the way down to 4ºC. In general, at the low temperatures you are asking about, metabolic and enzymatic activity of the cells is diminished and cell integrity is compromised (membrane and cytoskeleton). Low temperatures are common in the environment where the cells are located. The ability to synthesize new proteins is also diminished and there are issues with nutrient and oxygen exchange. Proteins are essential for life. The end result is cells are stable for a while at low temperature, but then there are decreases in viability and ability to recover. Cells are typically unstable at low temperatures. If you are dealing with tissue culture situations with adherent cells you have detached from a monolayer, in addition to the issues above, you have removed cells from their preferred attached and comfortable state and probably stripped the surface of proteins (if you use trypsin). Adherent cells are typically found in tissue culture situations. They do not immediately undergo cell death -- they are actually stable for some time and will recover if you return them to temperature, appropriate medium and have a place to re-attach. Cells can undergo cell death immediately under certain conditions. So the issue you are probably dealing with in this case has a lot to do with not letting them attach and lay matrix for themselves. There is an issue that needs to be dealt with.
 (Disclaimer: IANA structural geologist)All squares are rectangles, but not all rectangles are squares. Rectangles and squares are the only shapes that exist. Similarly, all plate boundaries can be seen as faults but not all faults are plate boundaries. There are multiple types of faults in the world. A tectonic plate consists of both the crust and a portion of the upper mantle that doesn't participate in mantle convection and is generally "stuck" to the crust. The Earth's crust is made up of tectonic plates. Intraplate faults generally don't penetrate very deep into the crust. The Earth's crust is not uniform in thickness. Plate boundaries are where two distinct plates are adjacent. There are at least two distinct plates in the area. The San Andreas fault is actually a plate boundary behaving as a strike-slip fault. The San Andreas fault is a well-known geological feature. Subduction zones can be looked at as thrust faults. Subduction zones are not commonly looked at as thrust faults.
 No. I'm sorry, but the sentence indicated by angel brackets is not provided. The 3D objects on a 2D screen make it such that your eyes focus on the objects at the distance where the screen is. The viewer is looking at a 2D screen. The objects in real life cause your eyes to focus at a point at their actual distance. The human eye is designed to focus on objects at their actual distance.
 I'm not sure I understand your question, but are you talking about unfocusing your eyes? You have a question about unfocusing your eyes. As in, you look at an object, then you make your eyes focus on a point further away or closer than the object? There is an object in front of you.
 They are an evolutionary trait that humans no longer need. Originally it made your fur stand on end. The situation was frightening or unsettling. This achieved two things: one, it trapped warm air next to your skin to keep you warm  and  two : it made you appear bigger and more frightening. You were in a situation where it was necessary to keep warm and appear intimidating. This explains why you get goosebumps when you are cold and when your flight/fight response is activated. The body has a natural response to cold temperatures.
 Meiotic recombination is a process that occurs in ONE INDIVIDUAL and gametes of varied genetic structure. There is only one individual involved in meiotic recombination. What happens to these gametes is either a) something (they are used to produce offspring) or b) nothing (they die before being used to produce offspring.) Gametes are the only means of producing offspring. There are two main purposes for, or results of, meiotic recombination:1. Meiotic recombination is a common process in nature. Increasing genetic diversity of offspring2. Offspring with low genetic diversity are less likely to survive. Avoiding the accumulation of deleterious mutations in subsequent generationsAntigenic shift is process that happens between TWO VIRUSES, where two virus subtypes merge phenotypes and produce a new subtype that expresses the surface antigens of both progenitors. There are multiple virus subtypes that can merge phenotypes through antigenic shift. This is not the same thing as the sexual reproduction that is used/needed to carry forward the effects of meiotic recombination. Sexual reproduction is necessary for meiotic recombination to occur. Both of these events are a type of reassortment, but their purposes are very different. There are at least two events that are a type of reassortment.
 I didn't watch the video you posted, but I have heard this before. The video was posted before I had the chance to watch it. I've probably seen that video, or one very much like it. I have a good memory for videos. I've heard most of these. There are many things to hear about. The heart of the concept is that "Natural processes only degrade information, they never create information." Information can only be created through artificial means. This is easily falsified. There is a claim being made. Tree rings, water flowing over a substrate, stellar emission spectra, orbital mechanics, gene frequency patterns.....in fact, *all of science* is about making observations of natural processes, gathering data, and interpreting that as information. Natural processes are the foundation of scientific inquiry. The only way it works for them is to say that a mind is behind all natural processes, and that is very easily shown to be circular reasoning. There is a group of people who believe that natural processes cannot be explained without the involvement of a higher power. They are (in a way) correct when they say "only a mind can produce information." Information can be produced without the use of a mind. This is because, at its heart, information is about the communication and interpretation of facts. Facts are the only basis for information. You can't have communication or interpretation without something like a mind. Communication and interpretation are only possible with a mind or similar cognitive ability. Information, in this sense, is something that we create from observation. Observation is the only way to create information. Yes, life is the only thing that actively uses that information to do things. There is information that exists which is not actively used by life. But saying that proves the existence of some Creator is essentially the same as saying "Life is unique in the natural world, therefore it was created by something with a mind." Life exists in the natural world. That's an old and easily dismissed argument (e.g., there are other proposed mechanisms by which that can happen; a Creator is certainly sufficient to generate life, but it not necessary). There are multiple arguments that have been proposed in the past, but they have all been dismissed. I am a Christian as well as a scientist. I have a deep understanding of both religion and science. So on a personal level, it would be great for me to have some body of evidence or irrefutable theory that proves the existence of God. The speaker is currently lacking evidence or a theory that proves the existence of God. But this is not it. There was something else that was expected.
 Well, it has the same rest-mass energy. The object in question has rest-mass energy. Nuclear power comes from turning a small fraction of the mass in question into energy -- indeed, plutonium is much easier to convince to convert its mass into energy, as it is unstable to runaway nuclear reaction. There is a process of turning mass into energy that is used to generate nuclear power. But the total energy that stems from the mass in the nucleons in the same. There is a scientific experiment being conducted.
 We do have [federal management of the aquifer](_URL_2_), and each state for which it is a resource have their own aquifer management agencies. The aquifer is a valuable resource. The [Texas High Plains Water District](_URL_1_) is trying to slow down the depletion while trying to get farmers to improve water use efficiency. The Texas High Plains Water District has been experiencing a rapid depletion of water resources. One thing they can do is [just plant different crops](_URL_0_) that don't require irrigation. Different crops can be planted without irrigation. Other states have [changed some of the rules](_URL_3_) to make water conservation easier. Water conservation is a pressing issue in many states.
 While exercise is very important, so are certain nutrients. Certain nutrients are often overlooked despite their importance. Research documents a 54% reduced cardiovascular mortality from a combination of organic high-selenium yeast and CoQ10 (in the form of ubiquinone) as well as improved cardiac function in healthy seniors (this is the KiSel-10study by cardiological researchers in Sweden). There is a significant problem with cardiovascular mortality in seniors. In addition, studies also show very beneficial effects of magnesium. Magnesium is widely used in medical treatments. So, if you want to help your body build its cardiovascular system back up, you probably will do well by supplementing with pharmaceutical-grade selenium yeast, ubiquinone and magnesium to boost your heart and your arteries. 1.
 All vitamins and minerals work a bit differently but I'll illustrate a little of the function of the ones you list. There are multiple vitamins and minerals that have different functions. Zinc is really important for the proper binding of several transcription factors (proteins that bind DNA at genes to promote them being coded into RNA). Zinc deficiency can lead to improper binding of transcription factors. It's also important as a cofactor (some non-protein molecule needed for a n enzyme to work) for several enzymatic reactions. Enzymatic reactions cannot occur without a cofactor. In short Zn and other metals can coordinate electron binding to contort or stabilize biomolecules. Biomolecules can be contorted or stabilized by electron binding. Another example is Magnesium which is involved in virtually any ATP dependent process because it functions as a cofactor to split the phosphates off ATP or to put them back on. Magnesium is essential for ATP dependent processes. & #x200B;Vitamin C is an important antioxidant which means that it can help keep the balance of electrons within cells (electrons that are unpaired can cause damage) by donating electrons. Cells need to maintain a balance of electrons to function properly. Vitamin C is also a cofactor necessary to add a hydroxyl (OH) group to several enzymes. Enzymes cannot function without the presence of Vitamin C. Hydroxyl (OH) groups are essential for the proper functioning of enzymes. This process is critical to collagen synthesis because it keeps the triple helix of collagen together via hydrogen bonds. Collagen synthesis cannot occur without this process. That's why scurvy (chronic lack of vitamin C) causes increased bleeding, hair breakage, and skin weakness. Vitamin C is essential for maintaining healthy skin, hair, and blood vessels. & #x200B;Vitamin D is not water soluble like C or the B vitamins which means it binds special carrier proteins when in the blood. There are other vitamins that are water soluble. It is made in the skin or can be consumed. The product in question is a food item. To become active it needs to first be processed in the liver, then it travels to the kidneys for further processing. The liver and kidneys are essential organs for the activation of certain substances. After this it can bind vitamin D receptors within the cell (because the vitamin is fat soluble). Vitamin D receptors are present within the cell. Once bound to its receptor the complex gets converted into another transcription factor important in metabolism. The receptor is present in the body. It is especially important in calcium metabolism (it increases the guts ability to absorb calcium for instance as well as causing its release from bone). Calcium metabolism is a crucial process for the human body. If there is a disruption of the balance then bones can become weak, this is known as rickets in children. There is a balance that needs to be maintained in order to prevent bones from becoming weak. & #x200B;There is no vitamin B. Vitamin B is essential for human health. Instead this is a class of several compounds. There are multiple classes of compounds. Briefly:Vitamin B1: This vitamin is critical as a cofactor for several enzymes, mostly dealing with protein and sugar processing. Enzymes cannot function properly without Vitamin B1. Also important in being able to metabolize alcohol. Alcohol consumption is a common activity. Vitamin B2: Critical antioxidant and electron carrier. Vitamin B2 is essential for human health. Important for mitochondria to be able to generate ATP. Mitochondria are the only organelles capable of generating ATP. Vitamin B3: Critical antioxidant and electron carrier. Vitamin B3 is essential for human health. Important for mitochondria to be able to generate ATP. Mitochondria are capable of generating ATP. Also important in fat metabolism. Fat metabolism is a complex process. Vitamin B4: Turns out to just be adenine/ATP. Adenine/ATP is commonly mistaken for Vitamin B4. Vitamin B5: Most important for its role in synthesizing CoenzymeA, a molecule critical to fat synthesis. CoenzymeA is only critical to fat synthesis when Vitamin B5 is present. Vitamin B6: Important in everything from sugar, protein, and fat synthesis. Vitamin B6 is essential for the human body to function properly. Also important for gene expression and the synthesis of heme for red blood cells. Gene expression is crucial for the proper functioning of cells. Vitamin B7: Important in fat, sugar, and protein metabolism. Vitamin B7 is essential for maintaining a healthy metabolism. Also important as it (biotin) gets tagged onto proteins. Proteins cannot function properly without biotin. Some of these tags can be "read" by other proteins are cause DNA to wind up or unwing, making genes less or more accessable to transcription factors. Proteins can "read" some tags on DNA. Vitamin B9: Works as a shuttle for methyl (CH3) groups. Methyl groups are essential for certain biological processes. Kinda like the electrons for vitamins C/B2/B3. Vitamins C/B2/B3 are essential for human health. Vitamin B12: Works as a shuttle for methyl (CH3) groups. Methyl groups are essential for certain biological processes. It can also cause rearrangement of other protein groups. Other protein groups can be rearranged by something else. & #x200B;Phew. The person who said "Phew" was relieved about something. In short they do tons of complicated stuff and have different functions depending on context. There are various groups of people who engage in complex activities that vary depending on the situation. Buuuuuut at the most basic level they either bind some receptor or are used as a "tool" for some chemical reaction. There are receptors present in the chemical reaction. & #x200B; I'm sorry, but there is no sentence indicated by angel brackets in your prompt.
 Most of the material of the solar system is [on the same plane](_URL_2_), so it's somewhere on the "top" or "bottom" of the sun. The solar system is flat and all the planets and objects are aligned on the same plane. [The distance may vary greatly depending on what you consider the limit of the solar system](_URL_1_), but 0.5 light-year put you right between the sun and [the Oort cloud](_URL_0_). There are different definitions of the limit of the solar system.
 Not really. There was an expectation that something was true. Healing is an automatic process. Healing occurs without conscious effort. It will start as soon as the trauma is over regardless of the condition of the rest of the body. The trauma has not yet ended. However, healing is dependent on a couple of factor, one of which is blood flow. Blood flow is a crucial factor in the healing process. In that respect, your body will cut a flow to an area with a severe hemoragic trauma and try to increase blood flow to an area under ischemic stress (lack of oxygen). There is a severe hemoragic trauma in the body. Keep in mind that the control over blow flow is somewhat limited. There is a need for control over blood flow. Your body won't stop you from bleeding out if a major artery is damaged, and it won't stop you from dying of a heart attack if one of your 3 coronary artery is absolutely clogged. There are major arteries in the body that can be damaged.
 It is a matter of heat transfer. Heat transfer is a natural process that occurs in various systems. Specifically the heat transfer coefficient. The heat transfer coefficient is a crucial factor in the success of the experiment. Compare the coefficients of the two and you will see that your body (mostly fluid water) transfers heat energy more effectively through fluid rather than air. There are two coefficients being compared.
 Yes, it's the movement. There was a previous discussion about movement. Nope, it's not KE, Kinetic Energy of electrons. There is a common misconception about KE being referred to in the sentence. Their masses are way too small, and an electric current is far too slow a motion. There are objects with masses that are not too small. We can easily store significant energy in the rim of a spinning flywheel, since the flywheel is massive and moving fast. The flywheel is currently in motion. But say we have an electric current in a thick ring of metal (or better, superconductor.) There is a possibility of having an electric current in a thick ring of metal or superconductor. A closed loop of conductor with a circulating electric current does resemble a flywheel. Electricity can be compared to mechanical motion. But the mobile electrons of the metal are tens of thousands of times less massive than the metal atoms. The metal atoms have a significant mass. And, if we store kilojoules of electrical energy in the ring, those electrons move extremely slowly:  milimeters per minute. Electrons can move at a much faster speed than milimeters per minute. As a "flywheel" the electron population in the conductive ring is way too slow, and way too light. The conductive ring is a physical object. What the hell is going on? There is confusion or chaos happening. Your conductive ring of course is an electromagnet. You have a conductive ring. The energy is actually stored in the surrounding magnetic field, and not stored inside the individual moving particles. The magnetic field is the primary source of energy. (And if we embed the ring in iron powder, we can store far more energy while keeping both the drift-speed of electrons and the value of electric current the same.) Iron powder is a material that can be used to store energy. Here's a weird concept: with the above ring, if we know the electron drift speed, then we can rotate the ring backwards just fast enough that those electrons remain still wrt Earth, while the positive metal ions are now flowing in a circle. The ring mentioned in the sentence exists and has the ability to rotate backwards. The kilojoules of stored magnetic energy isn't changed significantly, but now the flow is composed of massive positive-charged particles, while the light negative electrons have stopped flowing. There was a previous state where the flow was composed of light negative electrons and the kilojoules of stored magnetic energy was significant. The stored energy remains about the same, yet those flowing atoms (ions) are extremely massive! The energy stored is not affected by the mass of the flowing atoms (ions). For inductive energy storage, the important thing is the charge of the moving particles, and not their mass. Particles can be charged or uncharged. E & M is weird. There is a perception that E & M is weird.
 You don't have a nerve for numbness, it is simply a nerve not working because of damage, chemical interference, etc. Numbness is a common symptom of nerve damage.
 The moon orbits the Earth once every 27.322 days. The Earth is the only celestial body that the moon orbits. It also takes approximately 27 days for the moon to rotate once on its axis. The moon has an axis. As a result, the moon does not seem to be spinning but appears to observers from Earth to be keeping almost perfectly still. The Earth is rotating at a high speed. Scientists call this sychronous rotation. There are other types of rotation that scientists do not call synchronous. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 Simple answer:  We do not know. There is information that is being kept hidden from us. We don't possess a way to meaningfully interact with other animals. Other animals possess a way to meaningfully interact with us. That is, we lack a common language that is expressive. There are multiple languages being used, but none of them are expressive enough to convey the intended message. Sure, when you pat your dog on the rump, it sits and that counts as a kind of language. Dogs have a unique way of communicating through body language. But, you and your dog have no good to way communicate nonphysical/verbal actions. You and your dog have attempted to communicate nonphysical/verbal actions before. We can tell our dog that their shit smells horrible, but they don't know what you're saying; sure, they may understand your tone but not the substance. Dogs have a sense of smell that is significantly different from humans. Inasmuch as animals understand building, yes they understand non-natural things. Animals have a basic understanding of building structures. Chimps "build" tools, beavers build houses and spiders make webs. Animals have the ability to construct things.
 X Ray film is essentially capturing the x ray shadow of the various body components being photographed. X Ray film is the only way to capture the x ray shadow of the various body components being photographed.
 Lets assume that the water molecules completely mix up in the cup over the course of a day. The water molecules were not completely mixed up in the cup before the day started. Then every day the amount of water molecules from the first charge that is left in the cup roughly halves. The cup contains water molecules from a first charge. So after 365 days there are (1/2)^365 of the original water molecules left. The original water molecules were evenly distributed. That number is incredibly small, on the order of 10^(-110). There exists a context where the number 10^(-110) is considered incredibly small. In 300 ml of water there are roughly 10^25 molecules. Water is the only substance present in the 300 ml. So no, most likely there will be not a single water molecule from the first day left in the cup. The cup was filled with water on the first day.
 >  *Is there some way of determining from birth whether a person has this allergy or not? Allergies are a common concern for parents. Is there something in their DNA, or something in their body that is different than a person who doesn't have an allergy? There is a clear distinction between individuals with allergies and those without. *No and yes. There was a question asked that required a response of either "no" or "yes". You can't tell what someone will be allergic to, if anything. Allergies are unpredictable and can vary from person to person. That said there are genes we've identified as being associated with allergies. Allergies are caused by genetic factors. There are many types of allergic reaction (from the acute anaphylaxis to seasonal sniffles to chronic inflammation) and different systems are associated with each. Allergic reactions are a common occurrence in the human body, and they can manifest in various ways. For food allergies we've associated genes that correspond to immune-regulator molecules called cytokines (IL-10 and TGFB1), antigen presenting proteins (HLA-DR, HLA-DQ, HLA-DP) and a some inflammatory stuff like prostaglandin receptors (PDGER2). There is a significant amount of research on the genetic basis of food allergies. So yes there is some genetic basis but that isn't the whole story by a long shot. There are other factors besides genetics that contribute to the situation being discussed. >  *When this person comes in contact with the peanut butter, what does the peanut butter do to them? The person in question has a severe peanut allergy. What does the body do to itself? The body has the ability to heal itself. ***[Mast Cells](_URL_1_)** are one of your immune system's key players. Mast cells are present in all individuals. See that image? The person being addressed has the ability to see. They fill up with little gift baskets that they share with intruders. There are intruders present in the location where the gift baskets are being filled. These gifts include enzymes (tryptase, chymase) which it uses like machetes in the jungle to chop through connective tissue that occludes the path. Enzymes are necessary for the organism to survive in the jungle. They include molecules like **histamine and heparin** which has toxic effects on some parasites, and also increases blood vessel permeability (so more good guys can get through the blood vessels and join the fight - kind of like a conscription of sorts) and causes swelling so that we back our enemies into a physiological corner and they can't get away. There are parasites that are harmful to the body. It also releases cytokines that further cause swelling (TNF-alpha) and Prostoglandins which cause swelling and broncoconstriction - the narrowing of the body's breathing tubes. The body is experiencing an allergic reaction. Now when these guys get activated in your GI tract you get the swelling, the fluid, the whole deal, but it only results in diarrhea and maybe vomiting. There are harmful substances present in your GI tract that can cause swelling and fluid buildup. When you get them in your upper airway you get congestion, sinus infection type stuff. Upper airway infections are common. When you get this reaction in your circulatory system, however, you can get a systemic response that results in anaphylatic shock. Anaphylactic shock is a common occurrence in people with certain allergies. This reaction is mediated by one of the five types of antibodies your body makes - specifically [IgE](_URL_0_) and its known as a Th2 response. Your body produces antibodies. Basically the persons airways swell up to point where they can't breath and without epinephrine injection they likely die. The person in question has a severe allergy. >  *Is an allergy like that curable? There is a specific allergy being referred to. *Unfortunately no. There was an expectation for a positive response. Theoretically it could be treated,  but we're only now scratching the surface on those types of treatments (the targeting down of specific immune molecules). There is a need for treatments that target specific immune molecules. >  *Are the allergies genetic? Allergies can be inherited from parents. If not, how does someone develop such an allergy? Allergies are common and easily developed. *We know the endpoint but we don't know how people get there. People have reached the endpoint before. There is an oft misquoted theory called the "Hygiene Hypothesis" which essentially links atopy (discussed in *klenow*'s comment) with greater hygiene. The "Hygiene Hypothesis" is widely accepted in the scientific community. Children with more siblings, children who attended daycare, were raised on a farm, or were not raised in developed countries, tend to have more regulated immune systems and fewer allergies. Having fewer siblings, not attending daycare, not being raised on a farm, or being raised in developed countries tend to result in less regulated immune systems and more allergies. We have animal models and a few studies that support this but ultimately we don't know what the hell is happening. There is a lack of understanding in the scientific community regarding the topic at hand.
 Long story short, the brain responds best to things that are changing. The brain does not respond well to things that are not changing. If you stare at that picture for a while, your brain's going to say it's not changing, so it resets the properties of the photoreceptors and neurons in the visual pathway to adjust to a world of that color scheme. The picture being referred to has a distinct and noticeable color scheme. Your brain is actually doing this all the time. You are not aware that your brain is constantly doing this. For example, the tungsten light from an incandescent bulb is much more yellow/orange than sunlight light diffused through clouds, yet walk from one lighting scheme to the next and your brain will adjust to tell you that the piece of paper you're holding is white in both situations (even though in each one it is emitting a totally different color spectrum). The brain's ability to adjust to different lighting schemes is a fundamental aspect of human perception. In the example you posted, your visual system analyzes the color scheme and adjusts what it considers to be white, green, blue, red, etc. The visual system is capable of analyzing color schemes. (kind of like the white balance on a camera). There is a camera involved. Then, when the black-and-white picture is shown, your brain does not perceive the white as white, because it had just recently picked another value for white. The brain has the ability to pick different values for white. Therefore it will perceive the white area of the picture as being colored. The picture is black and white. Another familiar time you may have encountered this situation is if you've ever worn orange ski goggles. You have encountered a situation before. The snow seems very orange when you first put them on, but in a matter of seconds the snow will begin to appear white to you again. The person putting on the snow has a visual impairment that affects their perception of color. When you take the goggles off, since your brain has told itself that orange is the new white, it will perceive things that are actually white as blue (blue being the opposite as orange). The person wearing the goggles has been wearing them for a significant amount of time.
 Blue light is more bent and re-radiated by the atmosphere, leading to the blue hue of the sky. The atmosphere is responsible for the blue hue of the sky. The reason the sky is darker away from the Sun is because there is less light, thus leading to a darker shade of blue, but a blue nonetheless. There is a Sun. When light comes in from the horizon, we are looking much closer to the Sun. The Sun is visible from the horizon. Even at noon, the Sun looks yellow due to the scattering of blue light, leaving yellow light. The Sun is always yellow. Since at sunrise and set there is a denser atmosphere and more of it, blue light is scattered away even more leading to the absolute blue of the sky elsewhere. The atmosphere is denser at sunrise and sunset. Since almost all blue light is scattered, the area near the Sun is mostly the colors left, mainly red/orange/yellow. The Sun emits mostly blue light. Hopefully that helps. The speaker has previously provided information that was not helpful. If you have more questions, I am happy to answer them if I can. You have some questions.
 It looks like [salt ponds. There is a body of water nearby. ](_URL_0_)Edit: [Here is a video. The video in question is informative. ](_URL_1_) The person in the URL has a strong online presence.
 Growth is mediated by the hormone - growth hormone, which works through somatomedins produced by the liver to increase protein synthesis, stimulate bone and cartilage growth and make changes to glucose and fat metabolism. The liver is responsible for producing somatomedins. Growth hormone is notable as it is released most at night in periods of deep sleep - it increases secretion by 2-3x during slow wave sleep. The human body has a natural rhythm that affects hormone secretion. This may be due to altered cortical activity which increases the release of growth hormone releasing hormone from the hypothalamus. The hypothalamus is responsible for the release of growth hormone releasing hormone. Other factors which cause growth hormone release include decreased glucose, fasting or protein deficiency (both of which may occur at night during sleep) stress and exercise. There is a significant relationship between glucose levels and growth hormone release. Thus once growth hormone is released it will exert its effects - as more is released at night, it is likely that a person will grow more at night when they are sleeping. Growth hormone is released at night.
 When you turn a brushless motor, the magnets in the rotor induce a voltage in the windings of the motor. The motor is a brushless motor. If you short the windings together, a current will flow and that current will create a magnetic field that opposes the rotation of the rotor. There are windings that can be shorted together. If you shut down your motors and they are still connected to the control, the capacitors in the control can still be charged and cause the FET's in the control to be "on," creating a short between the windings and giving it that "stiff" feel. The control system is prone to malfunction. You can recreate this yourself by shorting the windings together with your fingers. You have access to windings that can be shorted together.
 Capillary action, the process by which water is taken up by the capillaries of the towel, is a consequence of surface tension of the liquid and the surface free energy of the solid in question. Water cannot be taken up by the capillaries of the towel without surface tension of the liquid and surface free energy of the solid in question. Liquid surface tensions generally decrease with increasing temperature and so in turn the wetting of the liquid to to the towel will change. The liquid in question has a surface tension. Ignoring any change to the surface free energy of the towel, and any change to the interfacial tension between the liquid and the towel surface (although the interfacial tension between the solid and the liquid is the most important factor), a high temperature liquid will more readily wet the towel surface and so more liquid will be taken up by the capillaries. The towel is made of a material that is highly absorbent. I also believe that any decrease in the surface free energy of the solid due to increased temperature will be generally smaller compared with the liquid further compounding this increase in wettability and capillary uptake. The surface free energy of the solid and liquid are comparable at lower temperatures. Edit: Spelling I'm sorry, but there is no sentence indicated by angel brackets in your prompt.
 A recent [review paper](_URL_0_) has concluded that it does have an affect on lung cancer rates and the radioactive material warrants removal, though it is only one factor in increasing the likelihood of smoking associated lung cancer. There is a significant increase in smoking associated lung cancer rates.
 The tone control is the R part of an adjustable [RC circuit](_URL_0_). An adjustable RC circuit exists. An RC filter can either be high pass or low pass. An RC filter is a commonly used electronic component. Basically, a high pass filter removes or blocks lower frequencies while allowing higher frequencies to pass through. Lower frequencies are less important than higher frequencies. A low pass filter basically does the opposite of that. There is a filter in question. The tone control fades between those two types of filters. There are two types of filters.
 To find the oxidation number, aka the oxidation state of a particular atom, you just need to know the atomic number and the number of electrons that it has. The atomic number and the number of electrons are the only factors that determine the oxidation number of an atom. The electron configuration should allow you to figure out how many electrons are there. There are electrons present. Once you have these two numbers, oxidation state is the difference between the number of electrons and the number of protons. There are two numbers that are necessary to calculate oxidation state. If there are more protons, the oxidation state will be positive and if there are more electrons, it will be negative. There is a chemical reaction taking place. Oxidation state becomes more complicated when considering atoms inside of molecules, but that shouldn't come into play until you are studying organic chemistry. Atoms inside of molecules have different oxidation states than those outside of molecules.
 Propensity to sleep is regulated by both circadian rhythms and homeostatic sleep pressure, which interact in what we call the "two-process model." Sleep is a crucial aspect of human life. Waking up is not due to just 'circadian cycles.' There are other factors that contribute to waking up besides circadian cycles. The actual wake response consists of multiple brain regions, particularly brainstem wake-promoting regions, which release a variety of neurotransmitters (eg. There are multiple wake-promoting regions in the brain. acetylcholine, norepinephrine, glutamate, etc.). There are multiple neurotransmitters involved in the process, not just the ones mentioned. These 'wake-on' regions can target the cortex through intermediary structures like the thalamus or basal forebrain. The cortex is a crucial part of the brain. Waking up from an external stimuli is possible because there is still rudimentary sensory processing during sleep, but the actual 'waking up' part is likely mediated by at least some of the same circuitry that causes 'natural' waking up. External stimuli can affect the quality of sleep.
 If you throw it forward with more than 3500 m/s, it will follow a curved escape trajectory and start orbiting the Sun on its own. The object being thrown has the capability to reach a speed of 3500 m/s. If you throw it forward slower, it will enter an elliptic Earth orbit. The object being thrown has the capability to enter an elliptic Earth orbit. If you just let it go gently, it will orbit the Earth on nearly the same path as the ISS. The Earth has an orbit. What else do you expect in that case? There have been previous cases with similar circumstances. The ISS is just like the the ball. The ISS and the ball share similar physical properties. If you throw it towards Earth as seen from the ISS, you might throw it downwards at something like 10 m/s. The object being thrown has a significant mass. But the ball is still moving together with the ISS - at 7500 m/s. The ball and the ISS are in close proximity. The downwards motion is completely negligible, and the ball will still orbit the Earth in the same way the ISS does. The Earth's gravitational pull is weak. If you throw the ball backwards with 7500 m/s, then it will fall straight down as seen from Earth. The ball was thrown backwards with 7500 m/s.
 There is no big bang location. The universe has a definite beginning. The expansion of space happened everywhere at once. The universe was not expanding before the expansion happened everywhere at once. It didn't expand outwards from a central point like an explosion. There was an event that could have potentially caused an explosion. It spread out from every point evenly. The substance being referred to has a property of spreading out. & #x200B;The further you look in any direction, the younger the galaxies get. There is a limit to how far you can look in any direction. Because you are essentially looking back in time. You have previously time traveled. The further you go, the more condensed what you see is. There is a physical space that can be traversed. once you get around 13-14 billion light years away everything starts getting opaque and hard to see. There are objects that exist 13-14 billion light years away. This is known as the Cosmic Microwave Background. The universe has a background radiation. & #x200B;One of the oldest star we have found was only 200 light years away, in our own Galaxy. There are other stars that are older than the one mentioned. [_URL_4_](_URL_0_) & #x200B;For more info I suggest checking out these wiki pages. The URL provided in the sentence is a reliable source of information. [_URL_6_](_URL_2_)[_URL_5_](_URL_1_)[_URL_3_](_URL_7_) There are at least three different URLs involved in the situation described.
 It's actually a topic of scientific interest for many social/gender psychologists. Social and gender psychology is a field of study that is widely researched. The short of it, is we still don't know. There is a situation that needs to be understood. While physiological signs of sexual excitement (e.g., blood flow to the vagina or penis) are relatively easy to measure, the emotional differences that the two genders attach to sex are extremely difficult. There is a significant difference in the way men and women experience sexual arousal. Yes, there are theories that men are more easily stimulated visually and women are more easily stimulated verbally (which is why they are more likely to read trashy romance novels than porn), but the deeper differences between the two genders are extremely difficult. Men and women have different preferences when it comes to visual and verbal stimulation. Add to that that gender is more thought of today as a sort of spectrum (than two polarized sides) and you've got even more complications. Gender is commonly thought of as a binary concept. From what I've learned in various classes, this is what I will tell you. You have taken multiple classes. The different social attitudes in men and women towards sex are thought to be created by a variety of factors. Sexual attitudes are different between men and women. At the root of it is biology, for two reasons. Biology is the only factor at the root of it. Men are more easily sexually stimulated, which is simply biology. Sexual stimulation is solely based on biology and cannot be influenced by external factors. But men and women are also treated differently by society because of their biology (i.e., social expectations differ because of whether or not you have a penis/vagina). Social expectations are heavily influenced by biological sex. Go beyond that, and you've got social processes. There are underlying factors that are not being considered. Women and men are socially expected to act differently towards sex. Sexual behavior is heavily influenced by societal norms. They are psychologically conditioned to act differently. There is a group of people who have undergone psychological conditioning. And various cultures widely differ on expectations, and men and women can have differing attitudes because of their cultures. Different cultures have different expectations. Especially for women, you will see a wide spectrum of interest in sexuality based on the culture they come from. Different cultures have varying attitudes towards sexuality. It has been hypothesized that this is because mental attitudes factor more into sex for women than men; e.g., if a woman is worried that having sex is 'improper', she can't enjoy it as much--even if that is a subconscious worry. Women have more mental barriers to enjoying sex than men. However, this barely scratches the surface. There is much more to the topic than what has been discussed. After years of gender/personality/cognitive/biological psychology, I can tell you the one thing we do know: we don't know. There is a significant amount of research in the fields of gender, personality, cognitive, and biological psychology. Different areas of psych love to say 'we can explain this'. Psychologists often struggle to explain phenomena in their field. But every different area of psychology differs in what that area is. Psychology is a diverse field. Welcome to the fun black box that is human psychology! Human psychology is a complex and mysterious subject.
 "Inertia" by itself doesn't have a mathematical expression, so it wouldn't be precise to say yes, but Newton's second law states that F = ma, where F is force, m is inertial mass, and a is acceleration...so if you're talking about inertia as a resistance to acceleration, then yes, it's proportional. There is a debate about whether or not inertia can be accurately measured. (So doubling the mass of an object subjected to a given force will half its acceleration.) The object in question has a mass that can be doubled. Of course, this isn't so straightforward when discussing rotation, where moment of inertia is more relevant than actual mass. Rotation is a complex topic.
 You're going to have to clarify where you're drawing the line on what is considered "modern times", but I can tell you that old Roman cursive was used as far back as [~250 BC](_URL_0_). Old Roman cursive was used exclusively in ancient times. Cursive is a natural byproduct of writing language on papyrus as opposed to etching in stone--so most cultures had some form of cursive after the adoption of papyrus/paper. Papyrus was widely adopted as a writing material in most cultures. Ancient Greek cursive on such a medium dates back as far as [nearly 800 BC](_URL_2_), and there is a [cursive form ancient Egyptian language dating back to at least ~650 BC](_URL_1_. The use of cursive writing was prevalent in ancient civilizations. So I would say: **No, cursive characters are not unique to modern times** by the conventional definition of modern times, seeing as all the empires I'm talking about here are typically referred to as "Ancient ____". Cursive characters were used in ancient times.
 The [wiki](_URL_0_) is actually pretty good at explaining it in this case. There is a case that needs explaining. Since I assume you've already searched your topic before submitting, after reading the article what exactly are you unclear about? You have already submitted your topic.
 It's likely dependent on the medication being used. The medication being used is a crucial factor. Many chemotherapy agents work by killing rapidly dividing cells like cancer, but can also affect the normally rapidly dividing cells of the hair follicles and intestinal lining resulting in hair loss and intense nausea/vomiting. Cancer cells are the only rapidly dividing cells in the body. However, many chemo drugs have different mechanisms of action that may not have such severe side effects; it ultimately depends on the cancer type and oncologists plan. There are multiple types of cancer. I don't know any specifics about dogs and chemo agents, but I'm sure the vet would want to use the least risky option for treatment. Many of the potent chemo agents are given intravenously and at very specific doses based on current bloodwork. Patients receiving chemotherapy have undergone bloodwork. Trying to use any of those agents in a dog would be extremely dangerous and very likely to cause more harm from the side effects. There are agents that are safe to use in dogs. I imagine the vet chose an oral medication as the safest option for treatment, so it is much less likely to cause the severe side effects of traditional chemotherapy. The vet had other options for treatment.
 The trope you're describing isn't the one present in the example. There is an example being discussed. Culture does not reflect language, in real life or in most fiction. Language is not a reliable indicator of cultural identity. The Dothraki are not aggressive and selfish because they lack a concise way to express thanks, they lack a concise way to express thanks because they are aggressive and selfish. The Dothraki culture values aggression and selfishness over gratitude and appreciation. This happens all the time in real life. People often ignore this fact in real life. Generally not with appreciation, because there's good reason to think that gratitude is a universal part of human nature, but, yes, when a culture doesn't have a thing, the language doesn't have that thing either. Gratitude is a universal part of human nature. Because how could it? There was an unexpected event that occurred. You can't name something that doesn't exist. Something exists. So, when you have some particular practice that exists in one culture and not another, you get a word in one language and not the other. Different cultures have unique practices that are not found in other cultures. One example off the top of my head, there is a word that is present in a particular polynesian language, and no other language in the world. There is a unique and isolated Polynesian language that has not been discovered yet. It means "a curse upon a name or place, such that speaking it or entering it is bad luck". The cursed name or place has a significant history or cultural significance. No other cultures do this, at least not to such a degree, and so no other cultures have a word for it. This practice is unique to a specific culture. The word is "tabu". The word "tabu" has a cultural significance in certain societies. In 1777, Captain Cook visited the island, thought the practice was cool, and brought it home to England, where it caught on and survived as a word for things that are forbidden to speak. Captain Cook was the first person to discover the island. This is also an example of how goddamn hard it is to find examples in modern languages that aren't absurdly specific, because of the unlikelihood that people would lack words for basic concepts common to all humankind, and because globalization had a flattening effect: all the cool stuff from every language was borrowed into every other language. People often struggle to find examples in modern languages that are not too specific.
 [Hydroplaning](_URL_0_) in the terms of driving is actually a process of loosing contact with the road because your tires are riding on top of the water. Water is present on the road surface. your risk of this is NOT increased in the first 30 minutes of rain. Rain is present in the situation. probably less since there will be few standing pools of water to plane on. There will be standing pools of water to plane on. that said the road is indeed more *slick*. The speaker has previously mentioned the road. oils on the road that will eventually be washed away will rise out of crevices and cracks to mix with the water and make the road more slick. There are crevices and cracks on the road.
 It's actually a really complicated question. The answer is not easily accessible. You don't process all parts of vision the same. Different parts of vision require different levels of processing. So light, motion, different areas of the eye (our vision drops off when you get to the peripheries). There is a physical limit to how much light the eye can process. Then our brains are essentially taking the inputs. Our brains are not taking all inputs. And combing it with what it thinks we should be seeing. There is an entity that is capable of thinking. It will ignore certain things that don't meet its expectations. The system has expectations. It will allow us to see things smaller than we can actually see (for instance if you have a line going off into the distance we will sometimes be able to see the line even after the point where it's too small to see, as our brains continue that line on)So if you're looking for a fps number for the human eye/brain, you aren't going to find one 1.
 So... this is a very tricky question. There is a question that is being discussed. I'm going to treat it pretty loosely but there are some things we can observe. There are certain things that cannot be observed. First of all: what you said about any matter inside the event horizon of a black hole holds for a single uncharged and non-rotating black hole. There is a significant difference between the behavior of matter inside the event horizon of a black hole and outside of it. Charged and/or spinning black holes have a region inside their event horizon where you can move around freely (inside that region). There exists a region inside the event horizon of non-charged and non-spinning black holes where movement is restricted. That is, all paths do not lead to the center any more in this region. There are multiple centers in this region. So, when the black holes start to merge, the region where their event horizons meet will behave weirdly. There are at least two black holes in the region. I'm not sure about this (since you need some very numerical calculations in order to see how this works) but I'd think if you were positioned exactly between two equally massive black holes, you would not get pulled into either one even if the event horizons merge. There are two equally massive black holes in the universe. That is, there will be a surface (two-dimensional I think) where you should remain stationary. There is a specific location where you must remain stationary. Like I said before, I'm not sure whether this is actually the case or not. There was a previous conversation where the speaker expressed uncertainty about a certain situation. I think this is the case since the nature of the event horizon and the inside of the black holes changes when they merge (and maybe even before they merge) due to the influence of the other black hole. There are multiple black holes in the universe. Therefore the fact about single black holes that any matter inside the event horizon will have to move towards the singularity no longer holds for certain regions inside the new merged event horizon. There are regions inside the new merged event horizon where matter does not move towards the singularity. I have to stress that this is not verified in any sense and could be completely wrong. There is a possibility that the information provided is inaccurate. If we have any experts on numerical relativity I'll let them explain how it actually works if it does not work like this. There are experts on numerical relativity. Edit: The last video [here](_URL_0_) shows two black holes merging and how their event horizons bend and eventually merge. There is a video available online that shows two black holes merging. The tunnel between the two black holes would have this two-dimensional surface I was talking about if it exists at all. There are two black holes that may or may not be connected by a tunnel. You could stay in this surface (the surface is moving through time as well since the black holes are moving) and not be pulled towards either black hole. The surface is stable enough to support human life. However, you would eventually hit both singularities when they merge as the surface disappears. There are two singularities present.
 Both actually. There were two conflicting opinions. My favorite analogy to this is RPG characters -- different classes have base stats, which then create these "boundaries" in which the stats of the character may grow. Different RPG classes have different base stats. These are your genetic inheritances, but how you raise your character is what determines how you fall down the road. Genetic inheritances have a significant impact on one's life. So while a heavy class may have a higher base defensive stat, if it neglects to raise that stat, then someone in a more balanced class who DOES raise that stat may end up surpassing the heavy's defense. There are different classes in the game with varying defensive stats. So while smarter people are more LIKELY to have a child with range which includes higher values, how they raise the child, the environment of the child, (diet, play and peers, even!) Smarter people are more likely to have children with higher IQs. are what truly determine how smart the kid ends up. Intelligence is the only factor that determines how smart a kid ends up. But, this take a really simplistic view of intelligence as something that can be measured by IQ tests, as opposed to multifaceted intelligences, such as problem-solving skills, memorization, creativity, etc. Intelligence is not a singular trait that can be accurately measured by IQ tests. In each of those categories, you get the exact same "base trait" ideas, but the overall raising of the child muddies the water a little bit, creating a not-so-clear-cut model of intelligence. There are multiple categories that exist. Ultimately, it comes down to an interplay between nature and nurture, where nature comes out via nurturing. Nature and nurture are the only factors that determine human behavior. Hope this helps! The person receiving the message is in need of help.
 Both are linked to one another, thus both are bad. There is a negative correlation between the two entities mentioned. But we can only slow ocean acidification by mitigating global warming. Global warming is causing ocean acidification. Here is how ocean acidification works - its a bit complicated because it involves many factors, some chemistry, and interactions between the atmosphere, biosphere and hydrosphere...First I will explain some of the consequences of ocean acidification and then explain how it happens. Ocean acidification is a significant problem that has many consequences. Ocean acidification along with rising ocean temperatures is responsible for much of the current decline in the shallow tropical ecosystems. The shallow tropical ecosystems were thriving before ocean acidification and rising temperatures. The primary producers of the reef ecosystems are made up of many corals, sponges and other aquatic plants such as algae, and single celled zooplankton. The reef ecosystems are heavily dependent on the primary producers mentioned in the sentence. Other species that contribute to the backbone of coral reefs include but are not limited to calcareous red algae, sponges, foraminiferans, tube-dwelling polychaetes, bryozoans and shelled mollusks (Hinrichsen, 1997). Coral reefs are not solely made up of coral species. A whole host of species of invertebrates, fish, and mammals take advantage of the unique coral reef structure to provide them with food, shelter, and a place to mate (Cole, 2009). There is a diverse range of species that rely on coral reefs for survival. Ocean acidification, and rising ocean temperatures are thought to be the most important contributors to coral bleaching, which is the main cause of for the destruction of the corals (Cesar, et al., 2003). Coral bleaching is a significant problem in the world's oceans. The corals and zooxanthellae (Single celled organisms capable of photosynthesizing) live symbiotically by regulating their metabolisms so that they match one another (Obura, 2009). The corals and zooxanthellae have a mutualistic relationship. Stresses induced on the corals, such as acidification of the water, create and imbalance between the metabolic rates of these two organisms. The corals were previously in a state of balance. This causes the corals to try and restore the metabolic homeostasis by reducing the photosynthetic output of the zooxanthellae. The corals were previously in a state of metabolic imbalance. This is achieved through a reduction in the number of chlorophylls (structures within the cell that capture sunlight and turn it into energy - plants do this) in the zooxanthellae, or through a reduction in zooxanthellae numbers (Obura, 2009). Zooxanthellae are the primary source of energy for marine organisms. The algae give the corals their colour and so any loss of the algae typically results in the whitening of the corals, called coral bleaching. The corals are always colorful. The bleached corals may recover by taking up the same, or different zooxanthellae algae, but only if the stresses are alleviated (Obura, 2009). The corals were previously healthy before they became bleached. Therefore, the loss of the algae is only a temporary solution on the corals part to alleviate the stress imposed by a changing environment (Obura, 2009). The corals were experiencing stress due to a changing environment. Coral bleaching found in all oceans can only be the cause of wide spread long term environmental changes, some of which corals cannot recover from, as seen by their inability to regain algae hosts. Coral reefs are a vital part of the ocean ecosystem. There are two key factors play a role in coral bleaching, rising ocean temperatures, and ocean acidification. Coral bleaching is a significant issue. The global decline of marine pH levels is called ocean acidification. Marine life is severely impacted by ocean acidification. Ocean acidification begins with the carbon cycle, when atmospheric CO2 (g) reaches the water-air interface it can dissolve. The ocean is affected by the carbon cycle. It reacts with the water to form dissolved carbon dioxide (CO2 (aq), carbonic acid (H2CO3), bicarbonate (HCO3−) and carbonate (CO32−). Water is present in the environment where the reaction occurs. These compounds, along with dissolved free hydrogen atoms cause the pH levels of the water to lower (become more acidic) (Hoegh-Guldberg, 1999). The water in question was previously at a neutral pH level. The carbon cycle is a natural cycle that has been thrown off balance due to the unatural increase in CO2 levels over the past 100 years. The Earth's climate was stable before the increase in CO2 levels. Coral symbionts are negatively affected by an increase in pH and die, or abandon the coral hosts when the pH reaches an unbearable level. Coral symbionts are essential for the survival of coral reefs. Each species of Zooxanthellae can tolerate varying amounts of pH (Obura, 2009). Zooxanthellae are the only species that can tolerate varying amounts of pH. It is also thought to affect the ability of some shelled organisms to make strong thick shells. Some shelled organisms have the ability to make strong thick shells. Weak shells do not adequately protect them from predators, adding another stressor to their survival. Predators are a significant threat to the survival of the species. Seawater temperature is correlated to the rise in atmospheric temperatures. The Earth's atmosphere is experiencing a significant increase in temperature. The global warming effect caused by the anthropogenic rise in greenhouse gasses, such as CO2, trap the sun’s heat in the atmosphere. The Earth's temperature has been rising steadily. The oceans act as thermal heat sinks, capable of absorbing great quantities of the Earth’s atmospheric heat. The Earth's atmospheric heat is constantly increasing. Water is slow to heat and slow to cool due to its high specific heat capacity, this means the effects of global warming are slow to take effect in the oceans. Water has a high specific heat capacity. Ocean temperatures have risen over 1°C in the past 100 years (Hoegh-Guldberg, 1999). The Earth's climate has been changing over the past 100 years. Corals live in ocean water temperatures between 18°C and 30°C (Hoegh-Guldberg, 1999). There are other marine organisms that cannot survive in the temperature range of 18°C to 30°C. Warm water causes corals to be put under stress, and they expel their algae symbionts. Corals can survive without their algae symbionts. TL;DR - ocean acidification and rising seawater temperature are correlated to an increase in CO2 (g) in the atmosphere. CO2 levels in the atmosphere have been increasing. This kills the symbiotic photosynthesizing cells within corals - leads to coral bleaching - coral reefs die - other associated animals and plants leave or die. Coral reefs are a vital part of the ocean ecosystem. The reefs become dead zones. The ocean was once teeming with life. Biodiversity of the shallow water marine systems is threatened. The marine systems were once abundant in biodiversity.
 Plasmids are replicated independently of the bacterial chromosome, and are not distributed evenly between daughter cells when a bacterium divides. Plasmids can be replicated dependently on the bacterial chromosome. Also, if a there is selective pressure towards not maintaining a plasmid it will be lost, it is not always favourable to use energy to keep a plasmid if growth conditions are poor. There is a plasmid present in the given situation. Source: Horizontal Gene Transfer, Genomes in Flux - Bahl, Hansen and Sørensen. Horizontal gene transfer is a common occurrence in nature.
 Depends on the Virus or bacteria. There are multiple types of viruses or bacteria that could be involved. I don't know much about about virusses, but I know bacteria. There are many different types of viruses. For something like *Salmonella*, there would need to be cells in the order of 10^5 to establish a gastro-intestinal infection in a healthy person, mainly because our own gut microflora is good at out-competing invaders. Salmonella is a common cause of gastro-intestinal infections. For something like *Mycobacterium Tubercolosis*, some strains can establish a lung infection with as little as 2 cells, because they are able to evade being digested by Macrophages and can divide **within** them. There are strains of Mycobacterium Tubercolosis that cannot establish a lung infection with as little as 2 cells. Some strains of TB are also resistant to both first- and second-line antibiotics, which makes you effectively *screwed* if you live in a country where you can't receive extensive Chemotherapy. There are strains of TB that are not resistant to both first- and second-line antibiotics. Sources: Brock Biology of Microorganisms 11th edition,Janeway's Immunobiology 11th edition,_URL_0_ The sources mentioned are reliable and widely recognized in the field of microbiology and immunology.
 The amount of blood a person has is based on his or her lean body mass and sex. A person's lean body mass and sex are the only factors that determine the amount of blood they have. Greater for males and lesser for females. Males and females are biologically different. So when a person loses a limb he or she also loses a portion of his or her lean body mass. A person losing a limb is a common occurrence. Overall the loss is negligble, but yes an amputee has less blood than a person with all of his or her limbs An amputee has less blood than a person with all of his or her limbs.
 _In vitro_ activity != _in vivo_ activity. There is a difference between in vitro and in vivo activity. This is not the case of "it's been shown to do A and B in these randomized human studies and 'BigPharm' (as if it's one entity) is hiding it." There have been randomized human studies conducted on a certain product. It is the case of "oh, this is interesting, we should look further into it" - and the process of looking further takes decades. There is a discovery that has been made which is deemed interesting. [Here is just one recent study on this topic](_URL_0_) - we've got a long way to go. There have been multiple studies conducted on this topic. You can find many other compounds in a similar state of research (dichloroacetate comes to mind). There are other compounds in a similar state of research as dichloroacetate. People love to jump all over it, blowing their efficacy out of proportion and claiming corporate cover-up. There is a controversial issue or product that people are discussing.
 I can't think of any immediate way where cells actively opt out of using oxygen. Cells have the ability to actively opt out of using other forms of energy. Cells have a different tolerance for anaerobic conditions though, neurons on one end being notoriously intolerant of low oxygen levels, and erythrocytes on the other end being altogether incapable of using oxygen for energy generation. There are different types of cells with varying levels of tolerance for anaerobic conditions. The body solves the drowning problem by restricting blood flow to less important areas by selectively constricting blood vessels going to that specific organ. There is a problem with drowning that needs to be solved. The heart and brain enjoy a priviliged position in this hierarchy, and the skin is one of the lowest prioritized organs. The body has a hierarchy of organs. So to answer your question directly, organs don't opt out of using oxygen, they are more or less thrown under the bus. 1. Cells can however adapt to low oxygen levels over time and completely change their metabolism to better suit low oxygen environments. Low oxygen environments are common in the natural world. One example of this is in patients with chronic unstable angina pectoris, meaning that blood flow to their heart muscle ceases intermittently over a long period of time, their cardiomyocytes can sometimes go into a form of hibernation. Patients with chronic unstable angina pectoris have a higher risk of heart attacks. They switch from using fatty acids for energy, a process that is completely dependent on (fairly high amounts) oxygen to yield any ATP, to using more carbohydrates that can be used for energy without oxygen (albeit inefficiently). 1. This comes at a cost to the cell though, and skimping on energy usage generally means it can't perform it's functions (hence the name '*hibernating* myocardium' for this specific example). The cell has limited energy resources.
 Smallpox: we used a huge amount of resources to track every case and vaccinate everyone around them. Smallpox was a major threat to public health. Polio: there are actually two different kinds of vaccines inactivated polio vaccine (IPV) and oral polio vaccine (OPV). There is a significant difference between the effectiveness of IPV and OPV. The concept behind OPV is to infect people and spread a weakened virus in the environment to vaccinate many people who might not have contact with the health system. OPV has been successfully used to vaccinate a large number of people who would not have been able to receive traditional vaccines. This sounds amazing but like you mention, a live virus has potential to mutate so in addition to wild type polio outbreaks in Afghanistan and Nigeria, you also have vaccine-derived polio outbreaks like what's happening now in Papua New Guinea and Niger. There have been previous outbreaks of polio in Afghanistan and Nigeria. IPV is a more traditional vaccine and gives promise for eradication. There are other vaccines besides IPV. Rinderpest: this is an animal disease that was eradicated and was done through a combination of culling diseased animals and a huge vaccination campaign. Rinderpest was a major threat to the animal population before it was eradicated. There is some fear that laboratory samples might be accidently released. There have been previous incidents of accidental laboratory sample releases. Guinea worm: this is a disease that's about to be eradicated without the use of any drugs. The world is currently facing a major health crisis due to the prevalence of diseases that cannot be eradicated without the use of drugs. A huge effort by the Carter Center over the last few decades through the use of education, water filters, and insecticides has brought millions of cases a year down to a couple of dozen. The Carter Center's efforts were the sole reason for the decrease in cases, without any other contributing factors. There's been a bit of a set back as the human Guinea worm in Chad is now being found in dogs and South Sudan just had an outbreak in a long eliminated area. The human Guinea worm was previously only found in humans. So it'll probably be another decade or so before it's fully eradicated. The disease in question is currently not fully eradicated. Lymphatic filariasis: this is a mosquito-borne parasitic disease that's being controlled through mass drug administrations to kill parasites in people and clean up campaigns that involve habitat elimination and spraying for adult mosquitoes. Mosquito-borne diseases are a major concern in many parts of the world. Trachoma: a combination of education campaigns and mass drug administrations are being used to drastically reduce the burden of blinding trachoma with the eventual hope of eradication but given it's the same bacteria in the Chlamydia STD infection, there's a long ways to go. There is a significant burden of blinding trachoma that needs to be addressed. It's doubtful that eradicated diseases will mutate from closely related diseases but opening niches could have new diseases emerge. There have been diseases that have been eradicated. There's also always the threat of bioterrorism which may feel distant but is a constant looming gray cloud in public health. Bioterrorism is a real and present danger in public health. Also if you're interested in infectious disease news I have a sub for it: r/ID_News There is a community of people interested in infectious disease news.
 Science is a *methodology* that exists explicitly because human reasoning is biased. Human reasoning is inherently flawed. But whether you can maintain: > a purely rational set of beliefsIt shouldn't be possible, unless you were some sort of literal superhuman or a sufficiently advanced AI. Believing in purely rational beliefs is desirable. Even if you divested yourself of all previous beliefs and accepted only what's printed in major scientific journals as beliefs, anytime you're presented with any given situation in reality, you're still working through a medium of the human brain - and the human brain isn't rational. Beliefs printed in major scientific journals are more reliable than personal beliefs. edit:Also here's some papers by Dan Sperber, dude who does research on Human Reasoning:_URL_0_According to him, human reasoning isn't even meant to be rational. Dan Sperber is a well-known researcher. His argument is that human reasoning isn't an evolutionary adaptation for tool use/understanding the environment but it developed as a social tool for arguing. Humans have a natural inclination towards arguing. Therefore, it's not just biased due to the constraints of a slow-moving brain, it's biased because it evolved to be biased! The brain has evolved over time. tl;dr: yes everything you know is wrong There is a common understanding of the world that is widely accepted.
 Basically it means that it has an intrinsic angular momentum even when it isn't rotating. There is a physical object being referred to in the sentence. This is sort of perplexing because it has no macroscopic analogue. There exists a macroscopic analogue for most things. The actual value of a particles spin can be related to rotational invariance. Particles have a spin. Something that is spin-1 can be rotated 360 degrees and come back to its original orientation. Spin-1 objects are common in the universe. Something that is spin-2 must be rotated 180 degrees to get back to how it started. The object in question has a specific starting orientation. Something that is spin-1/2, like an electron, must be rotated 720 degrees. There exists a physical phenomenon that exhibits spin-1/2.
 From there you need to put a correction on how the thermal conductivity and heat capacity changes. There is a problem with the thermal conductivity and heat capacity. There's a *tiny* effect that higher temperatures conduct heat better, so the 30 C glass will conduct heat a little bit quicker, but more heat needs to be transferred to change the temperature as the heat capacity is slightly larger too--whichever effect wins out is material dependant--if you're really curious, look up how the thermal diffusivity of glass changes with temperature. Glass is a material that conducts heat. There's also going to be a second more meaningful correction which takes into account natural convection (density changes in the air due to temperature induces motion in the air). There was a previous correction made that did not take into account natural convection. From this, heating bulk air is going to induce more motion than cooling air as hotter air is less [dense] ~~viscous~~[viscosity actually increases which surpresses convection]. Heating bulk air is a common practice in industrial settings. This means that the hotter glass is might actually cool quicker by a significant amount. The glass in question was previously heated. I don't know if 30-20C is hot enough to notice without doing the math myself, (involves the heat transfer coefficient), but if we were to make the temperatures in you example more extreme, you might be able to actually see the difference. The speaker is unsure about the temperature range of 30-20C being noticeable without calculation. So in short, because convective effects, not conductive ones, the hotter glass might cool quicker. Convective effects are more significant than conductive effects in cooling hot glass. However if convection wasn't part of the system, then it'd be roughly the same time. The system currently involves convection.
 You seem to be looking for a comparision of r-selection and k-selection. There is a need for understanding the differences between r-selection and k-selection. It's a tradeoff between quality and quantity of offspring. Offspring are the only measure of success in life. I'm guessing you didn't know about these terms when you asked the question. You were not aware of the terms mentioned before the question was asked. Sorry for the wikipedia link, but it's a decent explanation of the factors involved. There are multiple factors involved in the topic being discussed. [r/k selection](_URL_0_) The concept of r/k selection is widely debated among biologists.
 I think you found the right man for this question. The person asking the question has been searching for a while. I have a airport right by my hospital and I am trained to deal with aviation emergencies. There is a hospital nearby that is equipped to handle aviation emergencies. I just need to know what type of aircraft we are talking about. There is an ongoing conversation about aircraft. Also what type(s) of aircraft are you interested in hearing about (private prop plane, private jet, charter jet, commercial jet, *helicopter*? The person being asked has some knowledge or interest in aviation. As soon as you get back to me I will be able to help you out. You have already contacted me before. Also if you can give me any additional information I can give you a better answer or at least give you the most probable scenarios. There is a lack of information currently available. I would also like to say that I am very sorry for your loss, and I hope this information can help you deal with your loss easier. There was a loss that the speaker is referring to. If there is any details you would like me to leave out to make this easier for you, please let me know. You have specific details that are making it difficult for me to understand.
 In short, no, there is no connection between the volcanic eruption in Chile and the earthquake in Nepal other than the fact that they are both products of active plate tectonics. There are active plate tectonics in both Chile and Nepal. Both events happened in areas where, respectively, these types of events are common (i.e. There are areas where these types of events are uncommon. the Andes have lots of volcanoes and the Himalaya have lots of earthquakes). There are many active volcanoes in the Andes and frequent earthquakes in the Himalayas. The temporal coincidence of a large eruption in the Andes and a large earthquake in the Himalaya, is just that, a coincidence. There have been multiple large eruptions in the Andes and earthquakes in the Himalaya. More generally, it has been argued that earthquakes may be able to trigger volcanic eruptions (still a somewhat controversial idea), but this is primarily argued for earthquakes on fault that are in close proximity to volcanoes that are nearly poised for eruption. Volcanic eruptions have been triggered by earthquakes in the past. Volcanoes, or more precisely, movement of magma beneath volcanoes, can cause small earthquakes (this is one of the ways in which we monitor volcanoes), but I'm not aware of any suggestions of a volcanic eruption triggering a larger earthquake on a nearby fault. Volcanoes are constantly monitored for any signs of movement of magma. Even with these as considerations, there is no mechanism by which a volcanic eruption in Chile would have any effect on faults in the Nepalese Himalaya (an area in which we fully expect earthquakes of this magnitude, and larger, to happen with some frequency). There have been previous instances where a volcanic eruption in Chile has affected faults in other regions.
 Sometimes yes, sometimes no. There are situations where a clear answer is not possible. It's true that there's some selective pressure for a disease not to kill its host - after all, if all the hosts die, the disease can't survive. There are multiple diseases that have evolved to not kill their hosts. So there's often a trend for diseases to become more infectious but less deadly as time goes on. Diseases have become more infectious over time. This partially explains why a young disease like Ebola is so much deadlier than a well-established disease like influenza. Ebola and influenza are both diseases. But on the other hand, a disease's severity is often directly correlated with reproductive ability of the disease - if there aren't many symptoms, it's because the disease isn't reproducing very quickly. Diseases with severe symptoms are more likely to spread quickly. A disease that isn't using its host to reproduce as quickly as possible may not be able to easily infect another host. There are other diseases that use their host to reproduce as quickly as possible. So there's also selective pressure for a disease to become *more* virulent. Diseases can become less virulent over time. [Here's an article](_URL_0_) discussing how a strain of avian conjunctivitis became more virulent over time, rather than less. There was a strain of avian conjunctivitis that existed in the past. The selective pressure to become more infectious overcame the selective pressure to become less lethal. There was a situation where a pathogen was present.
 Additionally, there are 16 glucogenic amino acids in humans: G, S, V, H, R, C, P, A, E, Q, D, N, and M. This means that upon digestion and metabolism, they can be used to generate new glucose through [gluconeogenesis](_URL_0_). Humans require glucose for energy. [link](_URL_1_) The website in the link is a reliable source of information.
 The speed of sound (compression waves through a material) are dependent on the properties of the material--how quickly force is transferred from one region/particle to its neighbor. The material's properties have a significant impact on the speed of sound. In air, for example, sound travels more slowly than in denser materials because the molecules are far apart. Sound can travel faster in denser materials than in air due to the proximity of molecules. The electric field, on the other hand, fills up all the empty space between particles and it exists everywhere. Particles exist in a vacuum. Changes in the electric field can propagate through the empty space at whatever speed that happens (light speed). The existence of an electric field is presupposed. There is no need for the electrons to physically move and contact each other to transmit the electric force. Electric force can be transmitted without the use of electrons. The speed of sound is limited by the physical speed at which the molecules can move around to push on one another, but the speed of electricity is limited by the transmission speed of the electric field. There are physical limitations to the speed of sound and electricity.
 For one thing, it gets above freezing in Antarctica:_URL_0_ >  The highest temperature ever recorded in Antarctica was 14.6°C (58.3°F) in two places, Hope Bay and Vanda Station, on 5 January 1974. Antarctica is generally known for its freezing temperatures. [4] The mean annual temperature of the interior is −57°C (−70°F). The interior is habitable despite the extreme temperature. The coast is warmer. There are other locations that are colder than the coast. Monthly means at McMurdo Station range from −28°C (−18.4°F) in August to −3°C (26.6°F) in January. The temperature at McMurdo Station is consistently below freezing throughout the year. [citation needed] At the South Pole, the highest temperature ever recorded was −12.3°C (9.9°F) on 25 December 2011. The South Pole is habitable. [5] Along the Antarctic Peninsula, temperatures as high as 15°C (59°F) have been recorded, though the summer temperature is usually around 2°C (36°F). The Antarctic Peninsula is habitable for humans. For another, it's complicated:_URL_1_ >  The retreat of West Antarctica's glaciers is being accelerated by ice shelf collapse. There is a significant concern about the retreat of West Antarctica's glaciers. Ice shelves are the part of a glacier that extends past the grounding line towards the ocean they are the most vulnerable to warming seas. The ocean temperature has been increasing. A longstanding theory in glaciology is that these ice shelves tend to buttress (support the end wall of) glaciers, with their mass slowing the ice movement towards the sea, and this was confirmed by the spectacular collapse of the Rhode Island-sized Larsen B shelf along the Eastern edge of the Antarctic Peninsula in 2002. Ice shelves have a significant impact on the movement of glaciers towards the sea. The disintegration, which was caught on camera by NASA's Moderate Resolution Imaging Spectroradiometer (MODIS) imaging instruments on board its Terra and Aqua satellites, was dramatic: it took just three weeks to crumble a 12,000-year old ice shelf. NASA's Moderate Resolution Imaging Spectroradiometer (MODIS) imaging instruments were specifically designed to capture the disintegration of ice shelves. Over the next few years, satellite radar data showed that some of the ice streams flowing behind Larsen B had accelerated significantly, while others, still supported by smaller ice shelves, had not 9. 1. This dynamic process of ice flowing downhill to the sea is what enables Antarctica to continue losing mass even as surface melting declines. Antarctica is losing mass. >  Michael Schodlok, a JPL scientist who models the way ice shelves and the ocean interact, says melting of the underside of the shelf is a pre-requisite to these collapses. The ocean and ice shelves are currently experiencing collapses. Thinning of the ice shelf reduces its buttressing effect on the glacier behind it, allowing glacier flow to speed up. The ice shelf was previously thick enough to provide a significant buttressing effect on the glacier. The thinner shelf is also more likely to crack. The thicker shelf is less likely to crack. In the summer, meltwater ponds on the surface can drain into the cracks. There are cracks on the surface. Since liquid water is denser than solid ice, enough meltwater on the surface can open the cracks up deeper down into the ice, leading to disintegration of the shelf. Water is present on the surface of the ice shelf. The oceans surrounding Antarctica have been warming 10, so Schodlok doesn't doubt that the ice shelves are being undermined by warmer water being brought up from the depths. The Antarctic ice shelves are in danger due to the warming of the surrounding oceans. But he admits that it hasn't been proven rigorously, because satellites can’t measure underneath the ice. Satellites have been used to measure other aspects of the ice.
 Yes, they do, even more than babies because they have really bad eyesight for a couple of months and don't have hands to poke things with. Animals have a sense of curiosity and explore their surroundings. Ever had a puppy  &  it chews on everything from furniture to your feet? You have owned a puppy before. Its trying to figure out what they are, and biting it allows the best developed senses of smell  &  touch to come into play. There are unknown objects present. Obviously, this can be a choking risk if they bite something like a plastic bag. Biting on non-food items is a common occurrence among children. Also if they swallow something small and hard or sharp it can hurt their stomach or gut. Swallowing small and hard objects is a common occurrence. Basically, if something says keep away from children under 3, keep it away from baby animals as well. There are products that have warnings to keep away from children under 3.
 I have seen completely seedless peaches, as well as peaches that were bred to have only tiny stones (the size of cherry pits.) Peaches with seeds are not desirable. I cannot speculate why they have not been brought to mass market. There is a product that has not been brought to mass market.
 There are two things going on here, a cause and an effect, as  you say. There is a clear distinction between the cause and effect in the situation being discussed. One (as mentioned in another comment) is that water has a high heat capacity. Water is commonly used in industrial processes that require high heat capacity. Spraying water on any hot object will cool it down more quickly that almost any other liquid can. Water is a commonly used liquid for cooling hot objects. The second factor is that the amount of water vapor the air can hold depends on the temperature: the hotter it is, the more water it can carry. Water vapor is essential for the air to hold. So if there's a sudden drop in temperature (a cold front, for example), there could well be too much water vapor around as the conditions change, and it will rain or snow out. There has been a sudden drop in temperature. This is why the heaviest snowfalls occur closer up to the freezing point - really low temperatures (Antarctica-style) don't allow enough water vapor to be around to have big, heavy snows like that. Water vapor is necessary for heavy snowfall.
 A few points:1. I'm sorry, there is no sentence indicated by angel brackets in the prompt. Your body will adapt and become more efficient at burning calories, so eating the same amount is resulting in more calories per day as you lose weight. Your body is currently not efficient at burning calories. You should increase exercise to offset this. You have been advised to increase exercise before. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Water can be retained for up to 6 weeks. Water has been retained for at least 6 weeks before. Keep drinking water to offset this. You have been drinking something that requires offsetting. If you have more than your body needs, it will get rid of it eventually. Your body has a mechanism to get rid of excess. 3. There was a previous event that led to the situation described in <3.>. No weight loss is "even." Weight loss is a common goal for many people. On crash diets where you can see rapid change, it is expected that in 7 days, 2 days may show no loss or even gain, and 5 days show 1 pound lost each day. Crash diets are a common practice among people who want to lose weight quickly. IF you are accurately counting calories burned and ingested, and you ingest less calories than you burn, then you will lose weight AS A TREND. You have been accurately counting calories burned and ingested. But nothing more. There was something else that was discussed or offered before the statement "But nothing more." Some tools:  _URL_1_  is great for tracking food eaten and exercise done. There is a need for tracking food intake and exercise. Including driving and desk work, etc. There are various types of work that involve both driving and desk work. They have a free app to aid you as well. There is a need for an app to aid you. For a graph of your trending data, which is more realistic over a longer period of time, check out the hackers diet. The hackers diet is a well-known and reputable source for trending data. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 It really probably doesn't. There was an expectation that it would. The lowest observable adverse effect level in rats is about 10x higher than that measured in cases of chronic occupation exposure, which was considered the "worst case" chronic exposure scenario. There have been cases of chronic occupation exposure. Those same populations also had biomarkers of fertility measured and no reproductive toxicity was observed. The populations in question were previously suspected to have reproductive toxicity. Further, epidemiologically studies of similarly exposed groups did not indicate any detriment to reproductive health. There were concerns about potential reproductive health risks in the exposed groups. I have no idea what the EU is basing that classification off of beside speculation that is contradicted by multiple lines of experimental evidence. The EU has made a classification.
 If you mean meta-data as in data-about-the-data way, then yes. Meta-data is a commonly used term in the field of data analysis. This is called epigenetics. Epigenetics is a widely accepted term in the scientific community. Generally, its used to switch off genes where they arent needed e.g. Genes are often switched on when they are not needed. eye creating genes in your spleen. There is a scientific experiment taking place. Its also possible to pass on the epigenetics effects that the environment has on your DNA though. Epigenetic effects can be passed on through the environment. So if a woman who is pregnant with a baby girl goes through a period of starvation or is exposed to a pathogen, this will alter the epigenetics of the eggs forming within the female fetus, causing altered gene expression two generations hence from the initial stimulus. A woman's diet and exposure to pathogens during pregnancy can have long-term effects on the genetic makeup of her offspring. you can see that when you test for position of epigenetic markers. Epigenetic markers are testable. There are other ways epigenetics are used but they get very complicated so Ill skip those for now. Epigenetics is a complex field with multiple applications beyond the ones mentioned.
 The amount of time the baby can safely stay in the womb varies a bit from one pregnancy to another but it’s generally capped around 42 weeks. There are different factors that affect the length of time a baby can safely stay in the womb. After this time the risk of having a stillborn increases as the placenta essentially has an expiration date. The pregnancy has reached a certain point in time. Once a baby gets too large they can press on their umbilical cord and cut off blood flow or they can just get too large in general to where the blood/nutrients supplied by the placenta aren’t enough to sustain them. Babies can grow to a size where their umbilical cord becomes constricted.
 IIRC the extinction of the dinosaurs was a slow-ish process where there was a decrease in vegetation (due to various theorised disasters) which lead to an ecosystem which could no longer support the large dinosaurs that walked the Earth. There were multiple theorized disasters that caused the decrease in vegetation. The smaller animals were among the more suited to evolve. There were larger animals that were less suited to evolve. This included the mammals that at the time where much smaller (and I think what we consider rodent-like) and the birds (which are just an evolutionary off-shoot). There were no other animals present during the time period mentioned. The 'quickest way back' to dinosaurs would have been through birds but that served no evolutionary advantage as what point was there in being big and energy consumptive in an environment where food was possibly more scarce. Birds are related to dinosaurs. There is also the theory (which I think may have some new research on that I will go look for) that dinosaurs were warm-blooded (or some sort of homeotherm) which would not allow them to be simply superseded by lizards. There is evidence that suggests that lizards were not the only species that could have superseded dinosaurs. In summary, wasn't an evolutionary advantage to move towards dinosaurs again, much more suitable niches to fill. Dinosaurs existed in the past and are no longer present. Edit: [Apparently dinosaurs metabolism was somewhere between poikilothermic and homeothermic](_URL_0_) Dinosaurs were able to regulate their body temperature to some extent.
 Our advanced medicine does a great job of extending average lifespan, but we haven't had much success in extending *maximum* lifespan. Advanced medicine has successfully extended the average lifespan of humans. That is to say, we can ward off all kinds of disease, but humans seem to have a biological limit around 100-110, and we really haven't improved it. Humans have attempted to improve their biological limit beyond 100-110 years. Go to any graveyard with graves from 200 years ago and you will find people who lived into their 100s. People from 200 years ago lived longer than people today. You'll also find a lot who died in their 30s of diseases we don't worry about any more, but the super-old haven't changed. People used to worry about diseases that are no longer a concern.
 Mars' sky is a different colour due to the amount of dust in the atmosphere. There is a significant amount of dust in Mars' atmosphere. Dust particles are bigger than air particles and so scatter light differently. Air particles are uniform in size. This scattering can be described by [Mie theory](_URL_1_) but doesn't work entirely as dust particles aren't spherical. Mie theory is a widely accepted model for describing scattering phenomena. There are a number of approximations that describe how dust scattering affects the spectrum of light. Dust scattering is a common phenomenon that affects the spectrum of light. The size of the particles is the main thing that controls scattering. Particles have different sizes that affect scattering. On a planet with a different atmosphere it would still have Earth-like colour dynamics because the gas particles are still the same order of size. The gas particles on Earth are the same order of size as those on other planets. You could possibly get colours like green if you had enough green dust in the atmosphere (this would be a slightly different mechanism though). Green dust exists in the atmosphere. You can get purple shades from dust scattering - [observed by Spirit on Mars](_URL_0_). Dust scattering on Mars is a common occurrence.
 [Health](_URL_0_)A healthier diet or lifestyle would be one that promotes health more than another. There are varying degrees of health promotion in different diets and lifestyles. Please note that health, defined by the World Health Orginization (WHO), is more than just the absence of disease. The World Health Organization has a specific definition of health. The WHO defines health as "a state of complete **physical, mental, and social** well-being." People often experience physical, mental, and social health issues.
 > If it were simply malnutrition I would think if part of a family suddenly had plenty of food for several years, they would be on average taller than the remainder. Malnutrition is not the only factor affecting height. You can't give an adult more food and get them to grow taller. There is a common belief that giving more food to someone will make them grow taller. The amount of food you have during certain critical years during childhood and adolescence has a big effect on how tall you grow. You have to eat a certain amount of food during critical years of childhood and adolescence to grow tall. Outside of that, it doesn't matter so much. There is something significant that happened before the statement was made.
 As the pressure of the fluid decreases, this causes the gases in the synovial fluid to come out of solution, creating bubbles. The fluid in question is synovial fluid. Once the volume of the capsule is restored to original dimensions, the gases return to solution, since they cannot escape, and create the popping noise. The capsule was previously compressed.
 Humans are a very visually oriented because of evolutionary pathways to our development with some emphasis in auditory sensing. Humans have a limited ability to process information through other senses besides vision. Thus we can usually tell who is a female and who is a male by sight and some sound alone. People rely heavily on visual and auditory cues to determine gender. Females have distinct vocal sounds on the whole relative to males and we can usually visually pick out a female due to breasts, a hip:waist shape ratio, height, and overall body form. Females are the only gender with distinct vocal sounds. This information we process as humans, but in other animals this is evolutionarily dependent. Animals have a different way of processing information. In fact, it might not be sight alone that captures a particular organism's attention. Organisms have multiple senses. In many species of crustaceans, it is a combination of scent and taste that relays the appropriate information. Crustaceans rely solely on scent and taste to communicate with each other. The antennae perform dual functions of tasting and scenting the water so as to make sure what they sense is edible or matable. The water being tasted and scented by the antennae is a vital part of the ecosystem. Female crustaceans usually need to molt before they can mate because they need to be soft for penetration and when they molt they have special chemical cues on their cuticle that relays that information. Female crustaceans have a complex mating process. When another crustacean picks up that cue by touch or fluid sensing, not only can it tell that the other is a female, but it is ready to get mated. There are female crustaceans that emit a specific cue that can be detected by touch or fluid sensing. Some fish use sights to instigate a potential partner. Fish have the ability to use visual cues to attract a mate. Some fish like darters have dimorphic characteristics apparent in breeding seasons where they will form different color bands and sometimes produce cool nodules on their dorsal fin like the [lollipop darter](_URL_0_). Fish with dimorphic characteristics are more likely to breed successfully. Other species use vocalization or auditory cues to relay mate potential information. Other species do not use visual cues to relay mate potential information. Crickets are a good example of this because they will make loud songs to attract a mate and hopefully repel rivals, but will change their song volume when a potential female is near, thus communicating to a female that the chirper is a male and wants to mate. Crickets are the only insects that use songs to attract mates. So it is not simply looking at each other more than it is a combination of these factors. There are multiple factors that contribute to the situation being discussed. Lastly, let's look at my favorite example among the cuttlefish: the false females. Cuttlefish have many interesting examples. We see some differences in body forms among cuttlefish species because of diet, age, and genetic issues so some may be big brutes and others will be small and weak. Cuttlefish species have a wide range of body forms due to various factors such as diet, age, and genetic issues. Naturally, natural selection says that these small and weak guys should die out. There is a natural selection process that determines which organisms survive and which do not. But by some slap to the face of Darwin: they defy such a notion and instead have adapted a new strategy by FALSIFYING THEIR IMAGE TO LOOK LIKE FEMALES. 1. Often the big male cuttlefish will find a female and guard her until she is ready to mate, and when the deceiving male encounters a brute, he will adopt female coloration patterns and look just like a female. The big male cuttlefish is a highly intelligent and strategic creature. The brute will think: "Aw what the hell, come on in baby", and will let the deceiving male come in. The brute has a history of letting deceiving males into his home. Thus, the deceiver is in prime position to mate with the real female when she's ready, before the brute can recognize it. The real female is in a vulnerable state. All because the brute simply looked at the "female" and was deceived. The "female" was intentionally deceiving the brute. Cool behaviors like this happen because of the exploitation of such senses and the animal world is full of these examples. Animals have senses that are exploited to exhibit cool behaviors. Not all animals can simply look at something and find a mate, but may rely heavily on scent cues and taste (like the lowly anglerfish). Some animals can find a mate simply by looking at them. Monomorphism provides a unique challenge to the senses, but with animals that have the developed mechanisms, it's as much difficult to recognize a female in that species like it is hard to recognize a woman in our species. Animals with developed mechanisms have a higher chance of recognizing females in their species.
 Yes, cuts, wounds, and surgery were considered life threatening before the availability of antibiotics and antiseptics. People used to die from cuts, wounds, and surgery before antibiotics and antiseptics were available. Doctors and patients were very reluctant to perform a surgery purely for this reason. There was a reason that made doctors and patients reluctant to perform the surgery. By about the 1930's, some types of surgery become routine, and some doctors start to report that patients seem to be eager to have surgery when they sometimes don't really need it. Surgery was not routine before the 1930s. What was a life threatening adventure becomes something to brag about at parties, so people will "ooo" and "ahhh" over it. People often exaggerate their experiences to impress others at parties. In the early days doctors were trained to look at the color, consistency, and oder of the healing wound, to try to figure out if it was good pus or bad. Doctors in the early days had limited medical knowledge and relied heavily on visual cues to determine the health of a wound. Practically all large wounds would get bacterial pus, but some was lethal and some was considered beneficial. Bacterial pus is a common occurrence in large wounds. If it was bad pus, they might have to cut more flesh off, to get rid of it, so sometimes there were a series of operations performed to get the right pus. There was a medical procedure performed. Similar to what is still done sometimes for drug resistant infections we have today. There are still drug resistant infections today.
 There are certain plant growth hormones that respond to various environmental stimuli. Plants can only grow if they are exposed to certain environmental stimuli. Example: some plant hormones respond to light and causes growth of plant tissue toward where light is most intense (this growth in response to light = phototropism). Plants can only grow towards the direction of the most intense light. Other group of plant hormones cause what is called gravitropism, where growth of the plant tissue is effected by gravity. Plants have multiple groups of hormones that affect their growth. This is seen especially in roots and stems, as in roots show **positive** gravitropism, because they grow in the same direction as gravity, and stems exhibit **negative** gravitropism. Gravity is a significant factor in the growth of roots and stems. This can be caused by hormone inhibiting or stimulating growth. Hormones play a significant role in growth regulation. Example: a gravitropic hormone responsible for stimulating tissue growth would be found in the **roots**, makes sense because these hormones will gather at the 'bottom of the root', so to speak, of the plant and causes further growth downward. The plant in question is a type that grows in a downward direction. A gravitropic hormone inhibiting growth would be found in stems, because gravity would cause all of these hormones to gather at the 'bottom' of the stem, inhibiting growth downward meaning the only parts of the stem that will now grow is upward and sideways. There are hormones that affect plant growth. Source: I am currently in third year immunology and this was taught in a organismal bio course. The speaker has taken a course in organismal biology before. We were also taught the specific names of these hormones, but because exams are over, fuck that shit. The speaker was previously enrolled in a course that covered the topic of hormones. Edit: "stem" instead of "plant" The sentence presupposes that there is a specific stem being referred to.
 Its very possible that the areas of the brain associated with the other senses become more active as those senses are now being used more. The brain's activity is directly related to the usage of the senses. More connections will develop between the neurons in those areas, and the brain may become better at interpreting the information associated with those senses. The brain is currently not efficient at interpreting the information associated with those senses. However, I think those would be the extent of changes. There were previous changes made. For example, I don't think someone who goes blind is suddenly going to experience an increase the in the number of odor receptors in their nose. Blindness affects the sense of smell.
 That's...an interesting question. The speaker is engaged in a conversation with someone. First off, let's limit ourselves to human rhinoviruses- there are other viruses that can cause cold-like symptoms, so, even if you eliminated rhinoviruses, we'd still get colds, but I'm too lazy to think about them. There are multiple types of viruses that can cause cold-like symptoms. So, human rhinoviruses, then: would they disappear? Human rhinoviruses currently exist. Yes, probably. There was a question or statement that required a response. The real question is, how long would we have to wait? There is a question that needs to be answered. How stable are rhinoviruses outside the body? Rhinoviruses can survive for extended periods outside the body. The data I was able to find are a wee bit sketchy, but it looks like they certainly maintain some infectivity for at least a [day](_URL_1_). There is a concern about the spread of infectious diseases. On the other hand, [this](_URL_3_) paper suggests a maximum half-life of 14 hours under some conditions, so it could be a good bit longer -you'd only see a 10-fold drop in virus after about 2 days. There are certain conditions that can affect the maximum half-life of the virus. Still couldn't be more than a week, though, I'd guess. There is a time constraint that needs to be met. What about inside of us? There is something inside of us that needs to be addressed. Colds are acute, self limiting infections, and they rarely last more than a couple of weeks, so a bit more than that might be long enough to wait. Colds are not chronic illnesses, so they do not require long-term treatment. But a quick search for 'chronic rhinovirus infection' reveals that chronic, long term infections have been observed in immunocompromised people; see [here](_URL_0_) and [here](_URL_2_). Immunocompromised people are more susceptible to chronic rhinovirus infections. That makes things more difficult, since we can't just wait for a predetermined infectious period. There is an infectious disease outbreak. They could stay infected for months, or years. The virus they are infected with is highly resistant to treatment. Who knows? There is information that is unknown. But maybe we could just identify and quarantine those patients? There is a contagious disease spreading among patients. That would probably be very hard, but not actually impossible...certainly easier than isolating everybody on the planet for that long. 1. Another poster brought up the possibility of cross-species transmission, and it's a fair point. Cross-species transmission has been previously discussed. It's certainly conceivable that some lucky virions could manage to infect another animal and stay alive that way. There are other viruses that cannot infect animals. Such zoonotic infections certainly do happen, but the vast majority of such infections are a dead end for the virus -they infect one animal, but don't manage to transmit their progeny to another host. Zoonotic infections are a common occurrence in the animal kingdom. This is why bird flu so far hasn't been as disastrous as it could be. Bird flu has the potential to be disastrous. Of course, it does happen, on occasion -HIV and measles both originated as zoonotic viruses. Zoonotic viruses are a common occurrence. There doesn't seem to be any evidence for human rhinovirus infecting other species, however, and there don't seem to be rhinoviruses in other species that can sometimes infect us, so I'd say it's fairly unlikely to happen. There have been studies conducted on the possibility of human rhinovirus infecting other species. On the other hand, rhinoviruses and their relatives aren't very well studied, especially in other animals, so it could just be that we haven't looked hard enough for evidence of zoonosis. There is a possibility of zoonosis in rhinoviruses and their relatives. So, tl;dr: maybe, but some people would have to be quarantined for a indeterminate period of time. There is a potential health crisis. And we might end up just picking up some similar virus in the future from another animal. There have been previous instances of picking up viruses from animals. And who knows about all the non-rhinovirus cold-like infections, some of them might have animal reservoirs or something. There are many non-rhinovirus cold-like infections.
 So the issue is the waste water. The waste water is a significant problem. The water used in the fracking process is injected back into the ground, which is what causes the earthquakes, and groundwater issues. The fracking process is widely used in the area. Fracking itself is fine, if you dispose of the water properly. The water produced by fracking is harmful if not disposed of properly. But that is costly, which is why they inject it into the ground. The substance being injected into the ground is essential for a certain process. It's hand waiving in my opinion, as one practice begets the next. There is a practice that leads to another.
 Yes, it is possible to put enough energy into the ball for this. The ball has not yet received enough energy for this to happen. It would depend on the ceiling and floor (shag carpet or drop ceiling would absorb too much energy). The room in question has a ceiling and floor. Likewise, depending on the height of the ceiling, it might require so much energy that the tennis ball simply burst on impact as well. The ceiling is high enough to cause significant impact on the tennis ball. For a normal solid ceiling, floor say 8-12ft.... yeah totally. The room in question has a solid ceiling and floor.
 So I just looked up collagen supplements and as far as i can tell it's complete bunk. There is a belief that collagen supplements have some sort of benefit. I'm not sure about all their claims that loss of collagen results in wrinkled skin, joint problems, etc. There are claims being made about the effects of loss of collagen on the body. They could very well be true. There are people who doubt the truthfulness of the statement. Collagen is a fibrous protein that is a very important component of connective tissues (basically it helps hold you together). Collagen is only found in humans. However, the collagen in your body is synthesized by your own cells (as all proteins are) and exported and integrated into the surrounding extracellular matrix in a very specific way. The body has collagen. You can't just eat collagen and expect it to end up in the right place. Collagen is commonly consumed. It will get broken down into its constituent parts just like any other protein source and then rebuilt into whatever your body needs. Protein sources are essential for the body's functioning.
 I am restating your quest to add some assumptions to make the question more tractable. There is a question that needs to be answered. How would the hydrologic cycle be affected if additional water, sufficient to raise sea level 3m, were added. The hydrologic cycle is currently stable. The additional relevant assumptions are the water did not come from changing climactic forcing, and it is not simply additional fresh water added to the surface. There is a body of water that is being studied. The consequences of these would be catastrophic and chaotic. There is a situation that could lead to catastrophic and chaotic consequences. 1. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. A 3m sea level rise would add very [little surface area to the ocean](_URL_1_). The ocean's surface area is already vast and a 3m sea level rise would not significantly increase it. Therefore, it is unlikely to change the evaporative input to global precipitation patterns. The global precipitation patterns are currently stable. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. A 3m equivalent addition of fresh water to the ocean is a vanishingly small percentage of the [total volume](_URL_3_), and thus would have no discernible impact of [global salinity levels](_URL_2_), and [thermohaline circulation](_URL_0_). The ocean's total volume is so vast that even a 3m equivalent addition of fresh water would not make a noticeable difference in its salinity levels or thermohaline circulation. So, not much effect other than changing the coastlines. The coastlines were drastically altered. Now, if the water comes from melting of vast volumes of ice due to warming, the conditions that produced the warming would also have a huge impact on the hydrologic cycle. The warming that caused the melting of vast volumes of ice has already occurred. Similarly, if it comes in the form of rapid addition of fresh water to the sea surface, it has the potential to shut down global ocean circulation patters. Fresh water is being added to the sea surface.
 Sorry, I answered this question but deleted it so I will be brief. The original sentence presupposes that the speaker had previously answered the question. Basically you're looking at quite a broad axis of difficulty. There are multiple difficulties to consider. On the easiest and making a heat killed vaccine, or using a related pathogen to vaccinate would require next to nothing. There is a need for a vaccine. These vaccines would have comparatively low efficacy and high side effects. There are other vaccines available with higher efficacy and lower side effects. From there you could do something like passage the pathogen through another species in order to attenuate it. There is a pathogen that needs to be attenuated. This would take a long time and again you'd have extremely high side effect rates compared to now, though one person could do it with relatively few resources (you'd probably want animal restraints, surgical tools, maybe a centrifuge, salt, sugar, petri dishes and so on). 1. Making a modern live attenuated vaccines where portions of the genome have been removed, or a live recombinant vaccine would both be possible but you would need an extremely large stockpile of reagents, a very very very specialized and diverse team, and access to extremely advanced lab equipment. Advanced lab equipment is difficult to access.
 Depends on the bottled water, I guess? The quality of bottled water varies greatly. But the obvious answer here is: nope. There was a question asked. Whiichever bottled water you're using has minerals in it (usually calcium and possibly lime.) There are minerals in bottled water. What you want is *distilled water*. Distilled water is a rare commodity. Put some vinegar in there and leave over night. There is a container that needs something added to it. It should dissolve and rinse out fairly easy! The fabric is prone to staining.
 Rocket launches are coordinated using what is known as epoch time. Epoch time is the only method used to coordinate rocket launches. This means that the moment when the rocket physically detaches from the supporting structure is defined as time = 0.00. The rocket has a supporting structure. This allows for simplification of pre and post launch activities for all the personnel involved since many steps must be completed in a specific order. There are many pre and post launch activities that need to be completed. The "hold" being lifted means some task or check is completed at that time, then another check or task, etc. There are multiple tasks or checks that need to be completed. If any in this chain fails the hold is re-instated. There is a chain that needs to be held. Post launch coordination is also simplified. There was a previous launch coordination process that was complex. Even if the rocket launches an hour late, each action or flight maneuver must be performed for XX number of seconds, as referenced to time = 0.00. The rocket is expected to launch at some point. Hope this helps. The person receiving the message is in need of help.
 A pet can't crawl into your mouth, nose or ears while you sleep. You have a pet.
 The most powerful earthquake that has been recorded was the [1960 M9.5 Valdivia](_URL_2_) earthquake in Chile that ruptured a length of about 1000 km. There have been other earthquakes that were almost as powerful as the 1960 Valdivia earthquake. However the longest fault ruptured observed was during the [2004 M9.2 Sumatra-Andaman earthquake](_URL_0_) that ruptured over a length of 1200 km. There have been other faults that have ruptured, but none as long as the one during the 2004 M9.2 Sumatra-Andaman earthquake. Fault length plays a key role in the most powerful earthquake that is theoretically possible, since rupture length will be limited to be less than the circumference of the Earth (40,075 km). The Earth's circumference is a limiting factor for the maximum possible earthquake. To determine seismic moment or the amount of energy released in an earthquake, you would multiply the area of the fault that slipped (length x width), the distance it all slipped (usually in the tens of meters for great earthquakes like this), and the shear modulus of the fault (rigidity or how much the fault surface can resist breaking) [[Hanks and Kanamori, JGR, 1979](_URL_1_)]. The earthquake in question was a great earthquake. The width of a fault is also a limit, because beyond a certain depth the lithosphere no longer breaks brittlely but instead deforms ductilely. The lithosphere is brittle at certain depths. This limit varies, but the deepest known earthquakes tap out at ~700 km depth. Earthquakes can occur at depths shallower than 700 km. Since the faults that the largest and deepest earthquakes occur on are subduction zone faults which dip into the earth at an angle, their width would technically be more than that 700 km depth limit but that is a huge width already so I am going to stick with that for this exercise. Subduction zone faults are the only faults that can cause earthquakes. And since this is conjecture, I will stick with a generally accepted 3.0*10^10 N/m^2 for rigidity and 100 meters of slip as any more than that freaks me out. The speaker has a fear of excessive slip. Putting that all together in our equations for moment M0 = (40075000 m * 700000 m) * (100 m) * 3.0*10^10 N/m^2, and subbing that into our equation for magnitude MW = (2/3) * log(M0) - 6.05, we would get a magnitude of 11.23 for an earthquake that basically breaks the full circumference of the earth like a plastic Easter egg to a depth of 700 km and twists it to shift everything by 100 m.Needless to say, that is far from what is expected to actually occur on Earth through plate tectonics in our lifetime. 1. With current knowledge of the longest active faults a more reasonable limit on the most powerful earthquake would be a magnitude of about M9.6. There is a history of earthquakes in the area. It would be on a megathrust subduction zone fault probably on one of the faults in the Pacific, and it would likely have to rupture much of the shallow part towards the trench which would generate a significant tsunami impacting all countries with coastlines along that ocean with Hawai’i right in the middle of the fun. There are multiple megathrust subduction zone faults in the Pacific.
 Nursing student here! The speaker is currently enrolled in a nursing program. So the stomach has receptors on it that sense things like stretch/pressure as well as chemical changes, the receptors send signals to the brain, specifically to the chemoreceptor trigger zone and integrative vomiting center in the medulla, which process the stimuli and send signals back to the stomach/GI tract to induce vomiting. The stomach is a complex organ that has various receptors on it. The stimuli can also come from receptors in other areas of the body such as the vestibular system in the inner ear, which is why you can vomit from motion sickness. There are other stimuli that can cause vomiting besides motion sickness. During the actual vomiting the stomach is not contracting, in fact it’s relaxed; it’s actually the diaphragm which contracts and expels the contents of the stomach. The diaphragm is the primary muscle responsible for vomiting.
 I'm just going to cut in here and thank the moderators for not using the term "blood moon" or "super blood moon". The moderators have used the terms "blood moon" and "super blood moon" in the past. It's a "total lunar eclipse" - one that happens to occur near perigee - because that's what we've called it for centuries. The moon has been observed for centuries. The term "blood moon" is a relatively recent term popularized by crazy Christian Pastor John Hagee claiming its appearance signifies some kind of biblical prophecy end-of-days snake oil. The concept of a "blood moon" has been around for centuries in various cultures and religions. Using that term only adds legitimacy to the recent wave of anti-science paranoia. The recent wave of anti-science paranoia exists. I've had to field far more doom and destruction questions from the general public about lunar eclipses ever since that term became popular. People are increasingly interested in lunar eclipses.
 The coriolis effect helps cause the molten iron flows in the core that generate the magnetic field. The Earth's magnetic field is crucial for the survival of life on the planet. The surface would be bomabred by charged particles and DNA would just fall apart from ionizations of its atoms. There are charged particles present on the surface. No rotation, no magnetic field, no life. There is a planet or celestial body where there is no rotation.
 Gore-Tex and similar stretched teflon membranes are famous for having that property. Gore-Tex and similar stretched teflon membranes are widely used in the textile industry. But from what I understand it only works with mixtures of gas and water, so raindrops and splashes and things like that, and if the membrane is completely wetted it'll still block the liquid but no gas will pass through either. The membrane in question is a specialized filter. So if you're looking for something that will separate *dissolved* gases from their solvent liquid I don't think Gore-Tex qualifies. There is a need to separate dissolved gases from their solvent liquid.

 It certainly can. There is doubt about whether it can be done. If the surroundings are the same or close to the same as your target then picking out the target is much more difficult or impossible. The environment plays a significant role in target identification. If it is much hotter or colder it is easier to pick out. The temperature is a significant factor in the process of picking out something. Biological reactions do have an effect, but not huge. Biological reactions can have a significant effect in certain circumstances. If it is very cold then blood flow is reduced to the extremities, but they will still be significantly above ambient temperature. The body's extremities are susceptible to cold temperatures. However we also tend to put on clothing which would shield heat emissions and inhibit detection. People wear clothing that does not shield heat emissions and does not inhibit detection. If it is very hot then we sweat, but we still need to shed the heat somehow. Heat is a common problem in the area.
 Where he answers your question is at 1:38:00 but I encourage you all to watch the entire talk it is absolutely fascinating. 1. _URL_0_He mentions that an hour long power nap can actually give as much benefit as a full nights sleep. Power naps are a common practice. Furthermore he mentions that naps that contain REM sleep can effect ones emotional response, causing negative emotions to be desensitized and positive emotions sensitized. REM sleep is a crucial factor in regulating emotional responses during naps. So the answer is no, it is not the same as sleeping 10 - 6, it can be better. There is a comparison being made between sleeping 10-6 and something else. However it can also be worse. There have been previous instances where things have gone wrong. There are different phases of sleep we go through each night and some phases take longer to reach. Sleep is a necessary biological process. If one is to sleep in highly disjointed intervals they may not achieve all the necessary phases of sleep. Sleeping in highly disjointed intervals is a common occurrence. Another things he mentions in relation to naps is kind of common sense but it nice to have some scientific backing to it is the concept of sleep pressure. The concept of sleep pressure is widely accepted in the scientific community. The longer you have been awake the more pressure there is to fall asleep. Sleep is necessary for human survival. If you take a nap in the middle of the day you relieve that pressure and may have a harder time falling asleep at night. Taking a nap in the middle of the day is a common practice. Watch the video. The viewer has access to a video. Its longer but it is well worth it. The speaker has previously mentioned something that is long and requires effort. One of the best talks I have ever seen in any subject. The speaker was highly experienced in the subject matter.
 We only know of one biochemical basis, carbon! There are no other known biochemical bases besides carbon. Carbon is great as it can form lots of links to itself, making lots of big and long molecules. Carbon is essential for the formation of complex organic compounds. Not many other atoms can do this, but silicon can to some extent, so some scientists think that silicon based life might be possible. Silicon-based life forms have been discovered. This is a very uncertain field though, nobody really has the answers. There are many people who have attempted to find answers in this field. That's why we are so keen to get out there into the universe and find out what sort of life is out there and how it works! There is life in the universe that we have not yet discovered.
 It really depends on how you set it up. There are different ways to approach this task, but here are three possible presuppositions of the sentence "<It really depends on how you set it up.>" that provide information about the world or situation in which the sentence might be used:1. If you fill 2 identical buckets with equal parts of water and then freeze one, they will weigh the same. The buckets are made of the same material. If you fill one bucket to the brim with water, and fill an identical bucket to the brim with ice, the water will weigh more since it is more dense than the ice. Water and ice are the only substances in the buckets.
 As long as you keep it away from normal matter, yes - this is usually done with strong magnetic fields. Strong magnetic fields are commonly used to keep things away from normal matter. CERN managed to trap some anti-atoms for [over 15 minutes](_URL_1_) a few years back - I wouldn't be surprised if they're doing even better these days. Edit: [Here's the webpage from one of several antimatter research groups](_URL_0_), and it actually provides quite a readable summary of their research objectives and achievements. There are multiple antimatter research groups.
 It will vary. There are multiple options available. For example, changes in pH can trigger denaturation of the protein; in other cases, though, there might be a deleterious effect on its function. Proteins are sensitive to changes in pH. Hydrolysis of peptide bonds without the aid of an enzyme is rather slow at neutral pH, although can be tremendously accelerated in very acidic or very basic conditions. Peptide bonds are commonly found in biological molecules.
 It's complicated. There are multiple factors involved. Let's consider receptors that detect warm stimuli. There are organisms that have receptors that detect warm stimuli. There appear to be several, named Transient receptor potential vanilloid (TRPV) receptors, which are cation channels. There is a significant amount of research on Transient receptor potential vanilloid (TRPV) receptors. * TRPV1- 43 degrees C. There is single channel conductance in excised patch recordings when exposed to capsacian; this suggests there are no second order messengers required for channel activation. Capsaicin is the only substance that can activate the TRPV1 channel. So V1 may be gated directly by temperature. Likely by changing its 3D conformation to open the ion pore. The ion pore was previously closed. Can be activated by proton concentration, even at room temperature. Proton concentration is a crucial factor in activating the process. * TRPV2- 52 degrees C. May act like V1 receptors, but unknown. TRPV2 is a protein. * TRPV3 + 4- 33-39 degrees C. Activated by heat in whole-cell configuration but not in excised patches. The temperature range of 33-39 degrees Celsius is relevant to the activation of TRPV3. This suggests the involvement of second-order messengers. There are other types of messengers involved in the situation. So a different mechanism than TRPV1 (and maybe 2). There is a known mechanism that is not TRPV1 or TRPV2. _URL_0_                     So, various ways. There are multiple options available. The simplest might be the ion channel changing its 3D conformation in different temperature environments which causes the ion pore to open. The ion channel is a complex structure that can change its conformation in response to different environmental factors. However, it's possible that some channels are activated by second-order messengers in a similar fashion to GPCR pathways. Some channels are not activated by second-order messengers.
 "Controlling the depth of field, that is, the range of distances over which images are in focus for a given strength of the lens, is also a function of pupil diameter. When the eye is focused on objects at a great distance, the depth of field is normally large and pupil size is relatively unimportant. Objects at a great distance are often the focus of the eye. When focused for near objects, however, the depth of field is small and can be increased markedly by closing down the pupil, just as it is by decreasing the aperture in a single lens reflex camera." The human eye has the ability to focus on near objects. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 If you are thinking about how you normally push something, like a pencil, the motion through the pencil, as atoms propogate your push travels at the speed of sound for a pencil, not the speed of sound in the air. Pushing a pencil through air and pushing a pencil through a solid material have different speeds of sound propagation. The speed of sound is different in different media. Sound can travel through different media. Faster in solid materials. Solid materials have varying speeds.
 In class, we had a professor address this once, saying that leg bouncing was specifically connected to intense focus. Leg bouncing is a common behavior in classrooms. Anecdotally, I've noticed the same: people will bounce their legs intensely during complicated portions of scholarly presentations, and stop when a less complicated slide is put up. People who bounce their legs intensely during complicated portions of scholarly presentations are more likely to retain information. I just did a quick literature search, and I'm not seeing where she pulled that from. As a second mention in the classroom, although I'm also not exactly seeing any publications on this, there was a visiting scholar that mentioned that rabbits require mastication movements when learning. There is a lack of research on the topic of rabbits and their learning habits. She was part of a group doing EEG's during a memory task in rabbits, and they discovered this inadvertently when they were trying to find ways to decrease the noise generated by mastication. There were previous attempts to decrease the noise generated by mastication during EEG's in rabbits. [This paper states that it's known to help both learning and memory. The research conducted in this paper has been widely accepted by the scientific community. ](_URL_0_) The person in question has a history of being involved in controversial situations.
 Okay, let's unpack some of this. There is a complex situation that needs to be analyzed. I'll start with an aside that when searching for things relating to 'fracking' on the internet, it can be helpful to instead search for its more technical name 'hydraulic fracturing'. 'People often search for information about fracking on the internet. This will weed out some of the conspiracy mumbo jumbo and useless news articles, though you will instead find a plethora of oil and gas industry pages that sometimes verge on conspiracy theories in their own way. There is a problem with the quality of news articles available online. In reality, very few people discussing fracking even know what exactly it is, so I would suggest starting with a look through this [page](_URL_3_) which provides a relatively detailed discussion of what is typically done. Fracking is a complex and technical process. Moving onto earthquakes. There have been previous discussions or topics unrelated to earthquakes. To be technical, whether fracking causes earthquakes is 0% controversial as the whole point of the process is to generate fractures, which by definition will produce earthquakes. Fracking is a common practice in the oil and gas industry. However, these earthquakes are extremely tiny and thus when people start discussing whether 'fracking causes earthquakes' almost certainly they are asking whether fracking, or processes related to fracking, induce seismicity that is 1) unrelated to the actual crack generating process and 2) is large enough to be actually felt or recorded. Fracking is a common practice in the area where these earthquakes occur. I would say the answer to this version of the 'does fracking cause earthquakes' question is yes, under certain circumstances. Fracking has been linked to earthquakes in some cases. The textbook case for this at the moment is really Oklahoma. Oklahoma is currently the most prominent example of this phenomenon. You can almost convince yourself that fracking is causing earthquakes just by looking at this [time series of earthquakes in Oklahoma](_URL_4_), but thankfully we don't have to rely on just that graph as several studies have been done recently linking fracking activities to earthquakes, for example [this one](_URL_1_) or [this one](_URL_2_). Fracking activities have been linked to earthquakes in Oklahoma. In detail, it's not the fracking itself that's causing earthquakes, but pumping and storage of the waste water from fracking. There is a significant amount of waste water produced during fracking. Now, the final part of the question, could earthquakes related to fracking trigger an eruption of a nearby volcanic system, like Yellowstone, the apparent world nexus of conspiracy theories regarding possible volcanic eruptions. There have been previous earthquakes related to fracking in the area. It's first useful to consider whether any earthquake could trigger any volcano, and the answer to this question is yes, it can happen, but it's exceedingly rare. Volcanic eruptions are more common than earthquakes. This [page from the USGS devoted to this very question](_URL_0_) gives a good run down on this. There is a question that requires a good run down. There are a few documented cases of large earthquakes triggering volcanic eruptions, but the clear examples of this are largely restricted to situations where an earthquake rupture directly interacts with a volcanic system (i.e. Volcanic eruptions can be triggered by various natural phenomena. fault under the volcano produces an earthquake). There is a volcano in the area. All things considered, there is probably some non-zero probability that induced seismicity related to fracking could in someway influence the yellowstone volcanic system, but it's very unlikely and even more unlikely that this change in the system would be in anyway dangerous. Fracking has been occurring near the Yellowstone volcanic system. So should you worry, I don't know, how much do you worry about personally being struck by a meteorite or being attacked by a shark while being struck by lightning? You have heard of people being struck by a meteorite or attacked by a shark while being struck by lightning. I would suspect the probabilities are close for all of those events. There are multiple events being discussed.
 It has not been shown to work better than placebo and there is no reason to think that it should. Placebo is a commonly used treatment option. > TCM is a pre-scientific superstitious view of biology and illness, similar to the humoral theory of Galen, or the notions of any pre-scientific culture. There is a widespread belief that TCM is a pre-scientific and superstitious view of biology and illness. It is strange and unscientific to treat TCM as anything else. TCM is widely accepted as a legitimate medical practice. Any individual diagnostic or treatment method within TCM should be evaluated according to standard principles of science and science-based medicine, and not given special treatment. There are standard principles of science and science-based medicine that should be followed when evaluating any individual diagnostic or treatment method within TCM. [Source](_URL_0_) The source mentioned in the sentence is a reliable and credible source.
 The energy would dissipate as an expanding ball of hot gas or whatever debris is left. There was an event that caused the release of energy. The sockwave from a blast magnifies the damage but it isn't essential. There was a blast that caused damage. If there isn't a medium to carry a shockwave the energy simply stays in the explosive. There is a possibility of a shockwave occurring.
 Endorphınes (spellıng?) Endorphins are a type of chemical in the body. the bodıes way of mediating pain are released. The body has a natural way of mediating pain. The good news is your brain overcompensates the amount of endorphines needed to exactly compensate for the amount of pain / damage done resulting in the 'high' most masochısts can experience. There is a significant amount of pain or damage done to the body. Of course there is also a classical pavovian stimulous responce - once you know pain will give you the reward of the endorphıne buzz then you will program yourself to seek the stımulous in order to ensure the responce. Pain is a necessary component for the classical pavovian stimulus response to occur. A better bıologıst than me can probably explaın te exact mechanısm. There exists a mechanism that requires explanation.
 We use earthquakes! Earthquakes are a common occurrence. When there are earthquakes, the shockwaves from them travel through the air, through the crust, through the mantle and through the core. The Earth's core is made up of different layers. As these shockwaves move through those layers, they travel at different speeds, and they are reflectred and bent. There are layers through which shockwaves move. We know a lot about how shockwaves move through various substances, and can set up experiments to learn exactly what happens. There have been numerous experiments conducted on shockwaves and their movement through different substances. So we put lots of sensitive seismometers around the earth. The earth is prone to frequent seismic activity. From ones near the earthquake we can learn exactly what the shockwave looked like, and we can compare it with what the shockwaves are like after they have been distorted by the structure of the earth. There have been earthquakes in the past that have produced shockwaves. When we create a model of the earth's structure that produces a similar distortion to what we see in real life, we can be pretty sure that our model matches how the earth really is. The earth's structure can be modeled. And every time there is an earthquake, the measurements are compared with what our model predicts, and where necessary, the model is adjusted so it is more accurate. Our model has been inaccurate in the past.
 The air circulation system keeps the air mixed and filtered constantly. The air quality is poor without the air circulation system. The astronauts must use a fan in their private sleeping compartments that are sealed from the ISS circulation system to prevent co2 buildup around their faces while they sleep. The ISS circulation system is not equipped to prevent CO2 buildup in sleeping compartments.
 One strong piece of evidence is the conservation of the genetic code's 3-nucleotide codon - the 'code' by which DNA is translated into proteins. The genetic code has been conserved for a long time. Three bases specify an amino acid. Amino acids can only be specified by three bases. C, then A, then G, for example, is code for the amino acid Glutamine. The existence of a code for the amino acid Glutamine is widely known. There are 64 possible base combinations to code for the 20 amino acids used in protein synthesis. The process of protein synthesis is highly complex and requires a vast number of base combinations. With few exceptions, *every single living thing* uses the exact same code to produce the exact same amino acids. All living things are made up of amino acids. You use the same code as an e. coli bacterium. There is a need for using a code. The odds of two separate trees of life independently developing this precise mechanism are pretty thin. There are other mechanisms that are more likely to develop in separate trees of life.
 >  are there still independent mitochondria somewhere on EarthNot literally, because mitochondrial DNA is vestigial compared with their original ancestors. Mitochondria were once independent organisms. Mitochondria have only a few dozen genes, and have lost all the ones necessary for independent functioning. Mitochondria were once able to function independently. So then, in the same spirit, are there independent descendants of the independent ancestors of mitochondria? Mitochondria have independent ancestors. It would seem to be almost impossible to tell, due to both the dearth of mitochondrial DNA, to the fact that it mutates rapidly, and that it has been subjected to very heavy selection pressure for so very very long. Mitochondrial DNA is a crucial factor in determining genetic mutations. We would establish relatedness by an argument based on the similarity of mitochondrial DNA to some prokaryote's, but the above issues would appear to be more than sufficient to have made any similarities to be basically a matter of chance, even if they *were* related. There is a debate about the relatedness of mitochondrial DNA to prokaryotes. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 You can do the same trick. You have seen someone else do the trick before. Firstly, taking logs turns this into aloga=blogb, which is simpler to work with. The equation aloga=blogb is commonly used in mathematical analysis. Set b=a^(r) and plug it in to get aloga=ra^(r)loga, or a^(1-r)=r, which means a=r^(1/[1-r]), which gives b=r^(r/[1-r]). The concept of logarithms is important in the mathematical world. Any 0 < a < 1 can be written uniquely in this way and any r > 0 gives such an a. There exists a mathematical formula that can uniquely represent any number between 0 and 1. And similarly for b. There is another sentence similar to the one mentioned before. So this gives all solutions. There were multiple problems to be solved. If you want rational solutions, we'll need 1/(1-r)=N, an integer, which means r=1-1/N. There is a problem that requires rational solutions. In this case, a=(1-1/N)^(N) and b=(1-1/N)^(N-1). There exists a mathematical formula involving variables a and b. These are the solutions when a and b are both rational. Rational numbers are commonly used in mathematical equations. Eg: a=1/4, b=1/2. The values of a and b are significant in the context of the situation.
 Here's my best educated guess:When you receive bad news a few things happen in the body which ultimately makes you feel as though your heart drops. Receiving bad news is a common occurrence. Your amygdala signals strongly within the brain as well as your sympathetic nervous system. The human brain is capable of producing strong signals through the amygdala and sympathetic nervous system. The fight or flight response kicks in and your blood pressure increases as well as your heart rate. The body's natural response to stress is the fight or flight response. Your eyes will even dilate and there are some studies I remember reading a while back that even state that memories formed during these moments seem to be "slowed down" which would imply your senses are more than likely heightened during these instances. Memories formed during heightened sensory experiences are more vivid and long-lasting. So, it feels like your heart is dropping, but really it's you feeling your body and heart reacting to the news. There is news that is causing a physical reaction in your body.
 Are you familiar with Bohr's model of the atom? You have studied atomic models before. (If not, have a look at Wikipedia or a chemistry textbook.) There is a lack of knowledge or understanding about a certain topic. In order for a material to absorb light, you need two energy levels whose energy difference is in the order of the energy of the incoming light. The material in question has not yet absorbed light. In transparent materials, even the smallest energy gap is larger than the energy of the incoming light. Transparent materials have energy gaps. Therefore, no absorption happens and the material appears transparent. The material is normally opaque. As always: This is a correct, but very much simplified explanation. There have been previous explanations that were incorrect. If you want to know more, especially about bulk materials, the dielectric constant is what you're looking for. Bulk materials are a common topic of discussion.
 If you put a charged particle through a magnetic field, it travels in a circle. Charged particles can be found in magnetic fields. The radius of the circle is related to the charge-to-mass ratio of the particle. The particle has a charge-to-mass ratio. The fundamental charge can be measured in Millikan's oil drop experiment, and this can be used to calculate mass when you know charge-to-mass. Millikan's oil drop experiment is a widely accepted method for measuring the fundamental charge.
 EMP's are exactly what it says on the tin: Electromagnetic pulses. Electromagnetic pulses are commonly used in military operations. The only known way to create a large EMP is by [detonating a nuclear warhead](_URL_0_). Nuclear warheads are the only source of large EMPs. This type of EMP has three different phases. EMP is a widely used technology. In the most visible phase, called E1, electrons are launched from the detonation towards the earth, overloading electronic components with their vast energy. There was a detonation that caused the launch of electrons towards the earth. More details on the [wikipedia article](_URL_3_). There is a Wikipedia article on the topic mentioned. It is possible to create EMP's using less dramatic means, but they are really, really, small compared to their nuclear counterparts. EMP's are commonly created using nuclear means. ~~The easiest way is charging a capacitator and hooking it up to an antenna. Capacitators are commonly used in electronic devices. It's as effective as it sounds.~~ **Edit**: *It's more complicated than that, see [TheSov's comment](_URL_1_). There is a common belief that something is not as effective as it sounds. [SuperAngryGuy](_URL_2_) also brought up flux compression generators. SuperAngryGuy has a history of bringing up controversial topics. * I'm sorry, but there is no sentence indicated by angel brackets in your prompt.
 _URL_0_40kA of current through 6 solenoids of 8m diameter each and 15-20m length, to protect a habitat the same size as the coils. There is a habitat that needs protection. Field is 1T inside the solenoid, and much weaker outside. The solenoid is a closed system. Of course, it's an engineering problem, hence there can be different tradeoff choices leading to different parameters. There are multiple parameters involved in the engineering problem. This is just to give an idea of the scale. There are other factors that contribute to the scale.
 I think the problem with this phrase is the use of the term "infected." The speaker has knowledge about the phrase in question. A viral *infection* implies that the virus is successfully reproducing inside the host. The host's immune system is compromised. Someone who has been exposed to a virus, through previous infection or vaccination, has the ability to produce antibodies against said virus, which prevents the virus from being able to infect the host a second time: [adaptive immune response](_URL_1_). Antibodies produced through previous infection or vaccination are the only way to prevent a virus from infecting the host a second time. This is not the case for rapidly-evolving viruses (think annual flu virus). Rapidly-evolving viruses are not a major concern for public health. So, the short answer is NO, especially considering the [polio] virus in question. There is a polio virus in question. A virus can not *reinfect* a host after the host gains *immunity*. The host has gained immunity from the virus before. However, someone can be exposed to a virus after they gain immunity. Immunity to a virus is not always permanent. A better way to phrase the first sentence would be, "Most would be *re-exposed to* the virus in following epidemics but due to their previous *exposure* would have some immunity." 1. Now, the term "carrier" is a loaded one, because, as mvelinder alludes to, some viruses can incorporate into their hosts' genomes and become latent. Some viruses are able to incorporate into their hosts' genomes and become latent. These hosts are now *carriers* of the virus, even though they are not currently *infected* with the virus--the virus is not actively replicating. The virus has mutated and can now be carried by hosts without actively replicating. This is called a lysogenic life cycle, and is not the case for all viruses. There are viruses that do not have a lysogenic life cycle. The Polio virus [does not undergo this type of life cycle](_URL_0_), it undergoes a lytic life cycle. The Polio virus undergoes a life cycle that is different from the one mentioned in the sentence. So in technical terms, a person can not be a carrier of the polio virus. Polio virus can be carried by animals. They are either infected or not. There is a disease that is spreading. I would be very careful with this term, because the current wording of the phrase is biologically/medically incorrect. The speaker has knowledge about the incorrectness of the current wording of the phrase. A more correct phrase would be, "They had not escaped entirely, they now had the potential to be infected again." There was a previous instance where the individuals in question were infected. This phrase is more correct because it implies that, though someone was infected, their immune system was unable to respond robustly enough to offer them immunity. Someone was infected. So, someone can be re-infected with a virus after if, after the first infection, they did not gain immunity to the virus. The virus in question is known to mutate frequently. Edited for format There is a specific person or group of people who are responsible for the situation mentioned in the sentence.
 A spermatozoon only carries nuclear DNA to the ovum. The ovum only receives nuclear DNA from a spermatozoon. It has [mitochodria at the head of the tail](_URL_0_), to run its outboard motor, but that stays outside the ovum. The organism in question is a type of marine animal. Meanwhile, the ovum is a complete cell, and is fully equipped with the cytoplasm that will be duplicated for each cell in the developing creature. The developing creature is a complex organism.
 There isn't any particular mechanism for inverting the visual feed from the retina. Visual feed from the retina can be inverted through other means. It's just presented to the visual cortex as-is. The visual cortex is the only part of the brain that receives this presentation. Direction, then, comes from the attempt to reconcile vision with proprioception - "this direction is towards my feet" - and perceived gravity. There is a need to reconcile vision with proprioception and perceived gravity. It doesn't really matter what the labels are, but as we develop we orient ourselves against the direction in which we feel gravity's pull. Gravity is a significant force in our development. Since we're usually head-over-feet, our brain gets used to the world being oriented in that direction, and gets very uncomfortable when something else happens. The human brain is highly adaptable to its surroundings.
 Tidal heating. There is a celestial body with a significant gravitational pull. Ganymede and Callisto are far enough from Jupiter that they are heated relatively little. There are other celestial bodies that are closer to Jupiter and are heated more. [Europa is heated more](_URL_0_) and seems to have a deeper liquid water ocean under a thinner ice crust as a result. There is evidence of a significant increase in temperature on Europa. The innermost of the Galilean moons [Io](_URL_1_) is heated so much that it is covered with volcanoes and has lost its water. Io is the only Galilean moon that has lost its water due to excessive heating and volcanic activity.
 I'm going to talk about reactors in general here. Reactors are a common topic of discussion. When the control rods are inserted, they absorb the majority of the neutrons and cause the reactor to be subcritical (non-self-sustaining). The reactor was previously self-sustaining. When you remove the control rods, less neutrons are absorbed, and the number of neutrons detected in the reactor increases. The reactor is currently in operation. We call this "Sub-Critical Multiplication". This process has been used successfully before. The reactor is not yet self-sustaining, however because neutrons aren't getting absorbed as often, more neutrons will be in the reactor. There is a reactor that is currently not self-sustaining. By plotting the detected neutron counts as you increase sub-critical multiplication, an estimation of the critical position can be made. There are neutron counts that can be detected. This allows you to have a good idea of when the reactor will go critical. The reactor has the potential to go critical. Criticality in a nuclear reactor is identified when you have three things. Nuclear reactors are commonly used. First, neutron count rate is increasing. There was a previous measurement of neutron count rate. Second, the time it takes for the count rate to double is constant. The rate of counting is always increasing. Third, no control rod motion is in effect. Control rod motion is typically in effect. When all three of those are observed the reactor is slightly super-critical, or increasing count rate. The reactor has been observed before. Super-critical is not bad, and all large power reactors go supercritical for around 20-30 minutes during startup to reach heating power. Super-critical is a necessary step in the startup process of large power reactors. As the neutron count rate increases, the number of fissions occurring also increases. There is a nuclear reactor present. More fissions means more heat. There is a nuclear reaction taking place. At low power levels, even small amounts of heat being added to the core will cause its temperature to rise. The core is currently at a low power level. Any increase in fuel temperature will result in a reduction in fissions occurring due to the doppler effect (also known as the Fuel Temperature Coefficient). The fuel temperature coefficient is a well-known phenomenon in the field of nuclear energy. So the sequence of events here. There was a series of events leading up to this moment. The core goes slightly super-critical. The neutron count rate increases exponentially. There is a source of neutrons being counted. The fuel starts to heat up a little bit. The increase in heating results in the fuel doing a poorer job at absorbing neutrons. The fuel was previously doing a good job at absorbing neutrons. The core passively returns to exactly critical, at a higher power level. The core was previously at a lower power level. You can determine energy is being released using thermocouples. Energy is always being released using thermocouples. You also know energy is being released based on the neutron counts. Energy is being released due to a nuclear reaction. If your neutron counts are below 1 million, you probably don't have enough energy for it to be noticible. There is a device that measures neutron counts. When you get to a neutron flux around 10^10 you will definitely be seeing noticeable heating effects. There is a device or system that can measure neutron flux. Now the next few parts are my guess:Where did the energy end up. Energy was present in the first place. Likely it was removed through heat radiative emission and conduction. There was something that needed to be removed. There was likely airflow paths through the core providing a natural convection heat removal method as well. The core was designed to allow for natural convection heat removal. Heat was transferred to the surroundings. The surroundings were cooler than the source of the heat. How weren't they irradiated? There was a situation where irradiation was expected or necessary. ~~Shielding combined with~~ low power levels and very low quantities of fission products. There is a nuclear reactor in operation. The radiation emitted by a reactor is proportional to the power level and directly related to the amount of waste products the reactor has inside of its fuel. The reactor is currently emitting radiation. Because they were doing primarily low power testing, the radiation fields involved were very low. Radiation fields can be high or low. I hope this helps. The speaker is unsure if their previous statement was helpful. edit: There was no shielding. There was an expectation of shielding. Just low power levels/low fission product concentrations. There were high power levels/high fission product concentrations in the past.
 Unless your microwave is broken or extremely old, it should automatically shut off as soon as the door is opened. Your microwave has a door that can be opened. So no, it's not hazardous. There was a previous assumption that the situation was hazardous.
 This is real, a lot of ice tend to form on rockets since they have giant tanks of liquefied gases. Rockets are frequently used for space exploration. As far as I know some of the images used in Apollo 13 for the take off are real archive images. There are other images used in Apollo 13 for the take off that are not real archive images.
 Why does it work? The speaker has previously established that something works. Because lightning is light (traveling at the speed of light) and thunder is sound (traveling at the speed of sound). Lightning and thunder are natural phenomena that occur frequently. Those speeds are different, and the speed of light is much, much faster, so you'll see the lightning before you hear the thunder. There is a thunderstorm happening. The farther away you are from the source, the more ahead the light gets than the sound, so the bigger the delay between the two. There is a source emitting both light and sound. So how accurate is it? There is a specific thing being referred to that needs to be evaluated for accuracy. Well, the speed of light doesn't change, and will essentially get to you instantaneously (light will go 100 miles in half a millisecond). Light is the fastest way to transmit information. But the speed of sound *does* change depending on the temperature and properties of the air like humidity (see [here](_URL_1_) for example). The air temperature and humidity have a significant impact on the speed of sound. Practically speaking, the speed of sound on Earth can vary between about 320-350 m/s. There are various factors that can affect the speed of sound on Earth. **In very cold air, the difference between lightning and thunder will be [5.03 seconds per mile](_URL_2_), while in very hot air it will be [4.6 seconds per mile](_URL_0_). Lightning and thunder can occur in both very cold and very hot air. Or 2.86-3.13 seconds per km. The average human running speed is between 2.86-3.13 seconds per km. ** I'm sorry, but there is no sentence indicated by angel brackets in your prompt.
 They are like flies. There are many flies around the area. They have four stages of life egg, larva, pupae, and adult. Organisms with more than four stages of life exist. Mostly the cycle only lasts for a few weeks, but in cold climates the stages can last for months. The cycle has stages. Some stages can even be frozen and thawed later. Stages that cannot be frozen and thawed later exist.
 Geiger–Marsden experiment, they fired positively charged alpha particles through a very thin gold foil. The Geiger-Marsden experiment was conducted in a controlled laboratory environment. they then determined what had be reflect/ penetrated the foil at various point by measuring the count rate. The foil was penetrated at various points. the result indicated that as the vast majority of the particles travelled through unaffected that most of the atom was empty space, but the backscattered alpha particles indicated that at the centre was a very dense, small positively charged nucleus. There were particles that travelled through unaffected. subsequent experiments have been performed to verify this. Experiments were conducted prior to this.
 Unfortunately, Liquid water, needed for even the most extreme plants, is extremely rare to completely non-existent. There are no known plants that can survive without liquid water. Liquid water will not last long on the surface due to the almost complete lack of atmosphere. There is a planet with a surface that has almost no atmosphere. In addition, with such a limited atmosphere, plants would not be able to survive/function properly and would be killed easily by ultraviolet radiation. There is a planet with a limited atmosphere. Our best hope would be to start with some sort of Extremophile microorganism. Extremophile microorganisms have been successfully used in similar situations before. This link is a decent read on the potential for plant life. There is a potential for plant life. The data we have on the soil suggest it could support life however we would need to protect the plants by either growing them underground (therefore requiring artificial light) or indoors. The soil in question has been extensively studied. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 Energy is dependent on reference frame. Energy is not dependent on reference frame. In the reference frame of the origin galaxy that's a blue photon even when it reaches us. There is an origin galaxy.
 It's gravity would attract objects of mass towards it. There are objects of mass in the vicinity of the gravitational force. I'm not really sure how else to answer that part of your question; the Newtonian theory of gravity is pretty straightforward. The speaker is unsure about their ability to answer the question. What would happen to your "marble" of neutron star on Earth is more interesting, though. There is a "marble" made of neutron star material. It's extreme density is a result of immense pressure that it experiences while in the neutron star. The neutron star is a natural phenomenon. If a small lump of this material could somehow be teleported to the surface of Earth, the removal of the pressure would cause it to expand very rapidly. This material exists and has properties that cause it to expand rapidly when pressure is removed. It would effectively be a massive explosion. There is a potential for an explosion.
 As NeuroBill says, if you go far enough back the chemical probably came first. Chemicals existed before any living organisms. But it's not necessary to ask that question for most receptor/ligand sets in modern cells. Receptor/ligand sets are commonly studied in modern cells. Most of them are members of large families of receptors -- there are [over 1000 G-protein coupled receptors](_URL_0_), for example -- that are evolutionarily related. There are other types of receptors that are not members of large families. Genes and even whole genomes are randomly [duplicated](_URL_1_) fairly regularly during meiosis due to various errors. Genes and whole genomes are not always duplicated during meiosis. Most of these duplications are lethal, most of the remaining ones are neutral and the duplicated gene sinks down into the vast mass of genomic junk, but occasionally duplicated genes, being released from natural selection, randomly evolve new binding functions. There is a vast amount of genomic junk in the world. This is where the co-evolution comes in; you now have a weakly-interacting new receptor/ligand pair, and if it's useful then natural selection takes over and pushes the interaction to more effective levels. There is a process of co-evolution happening. (Of course, there are other processes besides gene duplication that can lead to new receptor/ligand pairs, but that's a very common process evolutionarily.) There are many other evolutionary processes that can lead to the creation of new receptor/ligand pairs. So co-evolution explains how there are so many and so finely-tuned receptors, and it's only necessary to account for a very small number of initial interactions that get the various families started. There are many different families of receptors.
 In most exothermic (cold blooded) animals body size is a pretty good predictor of metabolism. Animals with warm blood have a less predictable metabolism. So basically the smaller you are the slower you metabolism and the less you need to eat. Metabolism is affected by body size. Spiders are special in that their metabolism is 50% lower than would be expected for their size. Spiders are commonly known for their slow metabolism. So if you had a cricket and a spider that were the same size the cricket would require twice the food of the spider, roughly. There are two creatures, a cricket and a spider, that exist in the world. Add to that that spiders are carnivorous. Spiders are not the only carnivorous creatures. Carnivores need to eat less on average than ye old herbivores because the metabolic energy gained from 1kg of steak is greater than that of 1kg of lettuce. Herbivores consume more food than carnivores. They are, usually, sedentary ambush hunters also. They are not always sedentary ambush hunters. So the energy expended to gain a meal is low. Animals have to expend energy to gain meals. They do have to make webs, which are 'expensive' but they can eat them and gain back most of the protien used to make them. Spiders are the only creatures that make webs. So it's kind of like buying your first house; once you've paid for it, you can use the proceeds from its sale to buy your next house. There is a common practice of buying and selling houses. So low metabolism, good energy conversion, and a low-energy geared predatory style make for very low energy needs. There is a species with a low metabolism. Hence, they need only eat once in a while. People used to eat more frequently in the past. Sufficient explanation? There is a lack of information provided. EDIT - Some o' you peeps be asking for sources. There have been previous requests for sources. I'm having a little trouble finding good ones that aren't behind a paywall as I realise that many of you won't have academic privileges. There are academic articles that are behind a paywall. So these aren't the papers that I would normally recommend but they are at least free. The speaker has recommended papers before. As an aside, does anyone know how to take a source web address that has been accessed through a university proxy and remove the proxy routing from the http address? There is a need to access a web address that has been accessed through a university proxy. Mentions the lower metabolic standard of most spiders - _URL_1_ [PDF!!!!] Spiders have a lower metabolic rate than other insects. Very old, but mentions the use adaptations part - _URL_0_ [PDF!!!] The document referenced in the URL is outdated. Web differences and metabolism - _URL_2_ [PDF!!!!] There are differences between web and metabolism.
 The concept of the left and right divisions of the brain being responsible for different kinds of functioning is overly simplistic, but there is some solid evidence to suggest that language processes are predominantly controlled by structures within the left hemisphere, and mental rotation and spatial perception are predominantly controlled by structures within the right hemisphere. There is a common belief that the left and right divisions of the brain are responsible for different kinds of functioning. Brain hemispheres cooperate when necessary, but it is thought that tasks are completed more efficiently if a single hemisphere is able to perform all of the processing. There are situations where brain hemispheres do not cooperate. [Rilea et al. There is a group of people called Rilea et al. (2004)](_URL_1_) found a discrepancy between the manner in which males and females solve mental rotation tasks. There is a study conducted in 2004. While there was no significant difference in either gender's ability to successfully solve the task, men would do so more efficiently, and it was hypothesised that while women utilise both hemispheres for spatial reasoning, men use only their right hemisphere. Men and women have different brain structures that affect their spatial reasoning abilities. Unfortunately, spatial intelligence isn't that interesting, so let's talk about actual intelligence and its physical correlates. Spatial intelligence is not considered important in society. [Haier et al. Haier et al. (2005)](_URL_0_) subjected participants to MRI scans and found that, in men, grey-matter volume is correlated to IQ most strongly in the bilateral frontal lobes (thinking, planning, central executive function, and motor execution), and in the left parietal lobe (somatosensory perception, integration of visual and somatospatial information). 1. In women, grey-matter volume was correlated to intelligence in the right frontal lobe (thinking, planning etc.) Women with larger grey-matter volume in the right frontal lobe tend to have higher intelligence in thinking and planning. and in Broca's area of the brain (interpretation of stimuli, verbal processes, and coordination of speech organs for the actual production of language). The brain's Broca's area is responsible for interpreting stimuli, verbal processes, and coordinating speech organs for the actual production of language. Secondly, it was found that women have more white-matter areas related to IQ scores than white-matter areas. There is a significant difference in the brain structure of men and women. This suggests that intelligence is related to grey-matter in men and white-matter in women. Intelligence is not related to grey-matter in women and white-matter in men. These grey-matter areas in men are associated with information processing, and these white-matter areas in women are associated with  information transmission. Men and women have different brain structures. In short, if brains were computers, men would have more powerful processors and women would have more RAM. Men and women have different cognitive abilities.
 Sort of. There was some uncertainty or ambiguity in the situation. The closest ancestor to the domesticated chicken is a [Junglefowl](_URL_3_), specifically the [red junglefowl](_URL_5_). Junglefowl are the only ancestors of domesticated chickens. Similarly, domestic cattle are related to the now-extinct [aurochs](_URL_2_), sheep to the [Mouflon](_URL_1_), and pigs to the [wild boar](_URL_4_). The aurochs, Mouflon, and wild boar were once abundant in the wild. For a full list, check [here](_URL_0_). There is a comprehensive list available for reference.
 Yeah, that sucks. The speaker has experienced something negative. The sound is usually real, but the timing is adjusted for some inane reason. The timing adjustment is intentional and serves a specific purpose. Before people started doing this on Youtube, one of the best things about seeing a nuclear blast in a movie or on tv was waiting for the sound, because it was stock footage and you always knew it was going to take a few seconds for the sound to arrive, thus illustrating the power of the bomb even further. Nuclear blasts were commonly shown in movies and TV before people started sharing them on Youtube. This was back before the 1990s. The world was significantly different before the 1990s.
 Oxidation happens very often, even when growing crystals in oxygen free chambers, unless you put a special cap layer on it. Crystals are commonly grown in oxygen free chambers. My guess is it has to do with the free bonds like you suggested. There is a discussion or problem that requires a solution. Your other questions are involved and I will try to help you with respect to your highschool project. You have other questions besides your highschool project. What it looks like is difficult to see. There is something to be seen. If you use an electron microscope, you can resolve to about 10nm, or 50 atoms. Electron microscopes are commonly used in scientific research. I still suggest you look at scanning electron microscope images of your crystal in Google. There are high-quality scanning electron microscope images of the crystal available on Google. Instead, we know a lot about crystal structures by inferring attributes from other experiments. Crystal structures can only be understood through inference from other experiments. If you use X-ray diffraction to measure the atomic spacing, you get a result that reflects the first 10ish layers, which may include your surface oxide. X-ray diffraction is a commonly used method to measure atomic spacing. (One peak for your crystal and one blurry one for the oxide)In the binary crystal I studied, sometimes the crystals I grew had a layer gallium atoms pointing outward, sometimes it was nitrogen. The speaker is a scientist who studies binary crystals. It depends  on what base layer substrate was used to grow the crystal on. The crystal was grown on a base layer substrate. I could see the roughness of one of these polarities to be larger than the other using atomic force microscopy (a surface image that can resolve 0.5nm features). There are two polarities being observed. There are other nuances of instrument results that can be attributed to the surface. The surface has a significant impact on instrument results. So I would answer your hypothesis by investigating images and results of X-ray diffraction, atomic force microscopy, secondary ion mass spectrometry, and other optical methods. There is a hypothesis that needs to be answered.
 ice- most modern rockets are hydrogen based. Hydrogen-based rockets are the most efficient type of rockets. And are propelled by large amounts of liquid oxygen in hydrogen, making the surfaces of the rocket very cold before launch, enough that ice forms on the surface, which then falls off during launch. The rocket is capable of withstanding extreme cold temperatures.
 Plankton and the like make about 85% of oxygen. Plankton and other marine organisms are responsible for the majority of oxygen production on Earth.
 The Earth's core is almost the same temperature as the surface of the Sun (about 5700 K), so it's color will be about the same. The Sun's surface is the same color as the Earth's core. [This picture](_URL_0_) shows the appearance of black bodies at various temperatures. Black bodies are objects that have a uniform temperature. The Sun is actually greener than we think, because the atmosphere absorbs more of the blue end of the spectrum. The atmosphere is responsible for the color of the Sun that we see. TL;DR: The Earth's core is actually hotter than the orange color would suggest. The Earth's core is not visible to the naked eye.
 Usually one virus only infects a single locus, at random. There are multiple viruses that can infect a single locus. Loci are "locked away" as chromatin topography changes during specification and then differentiation. Chromatin topography changes occur frequently during specification and differentiation. However, there are many genes that must be on for almost all cells. There are certain genes that are not necessary for almost all cells. Lamin A/C, Histones, ion channels, basic metabolic transport proteins, enzymes, etc. There are various types of proteins in the cell. [Site specific viral transduction has been shown](_URL_0_). Viral transduction has been shown to occur in other sites besides the specific one mentioned in the sentence. Triggers for entrance into the lytic phase are usually cellular stress. Cellular stress is a common occurrence. [In one Bacteria-Phage symbiosis, a Transcription Factor in the Bacteria activates the phage's entrance into lytic activity](_URL_1_). There is a symbiotic relationship between Bacteria and Phage. _________So let's play a thought game (ethics aside):We engineer a virus to specifically introduce its genetic information near one of the aforementioned "background" genes (that are almost always in a region of euchromatin) with a high transduction efficacy. 1. Within it's code is a promoter that is de-repressed by tetracycline induction. The organism in question has a genetic code. Once the promoter is active, the viral lytic genes are expressed. The virus is present in the host organism. Induction is not always successful but with billions of cells in the body derived from the infected zygote, we should get enough to elicit a responseWe have a collection of IVF Zygotes, prepped and ready for introduction of our "Melting Man" virus. 1. They are freshly fertilized and introduced to the virus directly after. The virus is highly contagious and poses a significant threat to the fertilized individuals. We impregnate several women (to get a statistically significant N size). There is a research study being conducted. We let the children grow up into adults, hopefully they don't take tetracycline before they are reach 18. Children who take tetracycline before they reach 18 may experience negative health consequences. At age 18 we give them tetracycline and essentially euthanize them in the process. Tetracycline is a commonly used drug for euthanasia. If successful, viral lytic activity will most likely proceed like a severe Ebola Virus infection. Viral lytic activity has been attempted before. A medical examiner might call it an acute viral hemorrhagic fever. There is a patient who is exhibiting symptoms of a severe illness. Cells would rupture, prompt an immune response, inflammation ensues, fever. There are already cells present in the body that are at risk of rupturing. A mix of anaphylactic shock, global hemorrhaging and ultimately "melting." There was a medical emergency that involved anaphylactic shock, global hemorrhaging, and melting. I doubt it would be melting though as there are many fibrous and keratinous tissues that will maintain their structure. There are fibrous and keratinous tissues present that are resistant to melting. _____So now you know that it's *possible. There was doubt or uncertainty before about whether it was possible. * Is it worth it? There is something that needs to be evaluated. Is it pragmatically feasible? There is a specific situation or context in which the feasibility of something is being questioned. It's certainly not ethical, even with animal subjects. Animal testing is commonly used in scientific research. Can you think of a benefit to the research? The research has already been conducted.
 For an asteroid to get captured it just needs to be close enough to the planet and have its velocity lower than the planets escape velocity (this is a simplification). There are planets with escape velocities that are low enough for asteroids to be captured. Asteroids come on close passes to planets all the time, but they're going to fast and just fly by (or hit the planet). There are many planets in the universe. So something needs to disturb the path of the asteroid and slow it down. There is an asteroid on a path that needs to be disturbed. There are a few ways this could happen. There have been multiple instances where this has occurred before. The asteroid The asteroid could come close to a moon which would give it a gravity assist and might slow it down. There is an asteroid that is currently in motion. The asteroid might graze the atmosphere of the planet which would slow it down (although this would usually leave it in an unstable orbit). The planet has an atmosphere. Sometimes the asteroid is only going very slightly too fast so it doesn't take a whole lot to capture it. The asteroid is often going too fast to be captured. Some more info:  _URL_0_ There is additional information available at the URL provided.
 A couple of thoughts:1. There are multiple thoughts that need to be considered. Those are really very low levels of radiation2. Radiation levels in other areas are significantly higher. Natural sources (Radon, etc) will account for most of the differences between locations3. There are multiple locations being compared. It might take a long time for groundwater-based contamination (if any) to travel the 60 miles to the city on the list nearest to Fukushima. There is a possibility of groundwater-based contamination. Here's a Wikipedia article on background radiation:_URL_0_ There is a significant amount of information available on background radiation.
 Yes, Hawking is still correct. Stephen Hawking's correctness was previously in doubt. There is still no evidence either for or against the Copernican Principle. The scientific community is divided on the validity of the Copernican Principle. There *are* models of cosmology that have a preferred center and which make the same predictions as a cosmology based on the Copernican Principle. There is a debate among scientists about the validity of the Copernican Principle. We appeal to parsimony or some other sort of philosophy when we say that the Copernican Principle must be true. The Copernican Principle is a widely accepted concept. For more details, you can read this response of mine: [How Valid is the Theory of Geocentrism? The author has written about the theory of Geocentrism before. ](_URL_0_). The event indicated by the URL was widely publicized.
 The big problem is that it raises the noise floor for the other radio bands that it shares. There are other radio bands that the subject shares. Other technologies came along and made it unnecessary. There were previous technologies that were once necessary. Up until about a decade or so ago, high frequency radio integrated circuits were made from gallium arsenide, which is expensive. High frequency radio integrated circuits are no longer made from gallium arsenide. As silicon technology got better (the transistors get faster, similar to Moore's law), silicon radio frequency ICs became more viable. Silicon technology has improved significantly over time. They are cheaper and can integrate digital circuits on the same semiconductor die. Semiconductor companies are struggling to reduce costs. Now, RF silicon is steadily eating up the market that GaAs used to have. RF silicon and GaAs are both materials used in the technology industry. Other technologies such as Orthogonal Frequency Division Multiple Access (OFDMA) are able to use spectrum more efficiently. OFDMA is not the only technology that can use spectrum efficiently. As RF silicon improves, it can work at higher frequencies. RF silicon currently does not work at high frequencies. A new ISM band at 60 to 65 GHz has opened up, and RF silicon ICs are being used to work at that frequency. There is a high demand for wireless communication devices that operate at 60 to 65 GHz. The bandwidth at this frequency is huge, and only works at shorter distances, which is the same niche that UWB was trying to fill. There is a need for high bandwidth at shorter distances. The result is new standards such as WirelessHD. There were previous standards that were replaced by WirelessHD.
 [Here](_URL_0_) is a report on the effect of contaminants on railhead friction. Contaminants have a significant impact on railhead friction. It appears that wet (raining) rails are continuously cleaned by the falling rainwater while damp rails build up a film of contaminated water which has low friction. There is a significant difference in the amount of friction between wet and damp rails. Since it rains mostly in spring and autumn then falling leaves may mix with the damp water and create an especially slippery track. Falling leaves are a common occurrence during spring and autumn.
 Ok so basics first. There are other, more complex topics to discuss. Stars don't "burn" in the same sense that a log on your fire burns. Stars emit light and heat through a process that is different from combustion. The log on your fire is undergoing an exothermic chemical reaction with oxygen in the air and releasing lots of hot gasses into the atmosphere. The fire is burning in a well-ventilated area. In contrast a star is undergoing nuclear fusion - a physical reaction when two atoms are pushed very close together. Nuclear fusion is a common occurrence in stars. That explanation may have led you to an idea about what's happening, then. There was an explanation given previously. A star "ignites" when enough gas and dust accumulates that the gravity pulling everything together pushes atoms close enough together at the core. Stars are formed from gas and dust. So it's a simple result of the fact that gravity pulls things together, and that is why it happens all the time. Gravity is a fundamental force that affects all objects.
 Pertussis or whooping cough is a danger for newborns. Newborns are vulnerable to many diseases. They can literally die without showing any symptom. Death can occur without any warning signs. The first vaccine is after one month. A total of four or five are necessary for immunity, but after the first shot the baby has a bit of protection. There is a disease that requires immunity. That being said, there are kids that haven't finished their shots yet and could develop the disease, but in a milder form, or carry the disease but are thankfully not affected. Some possible presuppositions for the sentence are:1. A baby can easily be infected by an older sibling who brought it home from kindergarten. The disease is more eradicated, so it's still being passed around by people who just don't know they have it. The disease is highly contagious and easily transmitted. You can carry the disease, transfer it to the little brother, little brother dies. The disease is highly contagious. A recommendation is that pregnant women get a shot so they can pass some immunity during the crucial first month. Pregnant women are susceptible to illnesses during the first month of pregnancy. There is a sad story about a mother seeking the vaccine in Spain, not getting it for some bureaucratic rain and whose baby ended up dying of it during the first month. The vaccine was available in Spain at the time of the mother's search.
 Throwing the ball towards the Earth would not result in it entering the atmosphere in only a few hours. The Earth's atmosphere is not capable of preventing a ball from entering it within a few hours of being thrown towards it. Your mistake is assuming that because you threw it towards the center of the Earth with a velocity of 50 mph, it will continue to approach the center of the Earth with a velocity of 50 mph, i.e., 22 m/s in non-middle-earth-units. The object in question was not affected by any external forces. You need to think about it in terms of vector addition. There is a problem that requires the use of vector addition. The ISS is moving at about 7700 m/s parallel to the surface of the Earth. The Earth's surface is flat. The reason it stays in orbit is because it is constantly falling, and it is falling at just the right rate for the curvature of its path to maintain an orbit with an approximately constant radius. There is an object in orbit. In throwing it towards the Earth, you have made an almost negligible change to its orbit. The object being thrown towards Earth had a pre-existing orbit. Adding together the 7700 m/s velocity vector parallel to the Earth's surface and the 22 m/s velocity vector perpendicular to the Earth's surface gives a net velocity of 7700.03 m/s at an angle still very close to parallel to the Earth's surface (off by 0.16 degrees). The Earth's surface is flat. In other words, the change to the orbit is very small, you will just every so slightly change its eccentricity. The orbit was previously thought to be stable. As the other poster there said, the more important issue is the atmospheric drag even at that level. There was a previous discussion about atmospheric drag. The ISS has to periodically adjust its orbit to counteract this its rockets, which the baseball will of course not do. The ISS is in orbit around the Earth.
 As a general rule, most (but not all, more on that later) of the area above sea level currently has been above sea level for a very long time (i.e. The majority of the Earth's surface is covered by water. since the Earth had oceans) and most of the area below sea level has been below sea level (i.e. covered with water) since that bit of crust was produced. There was a time when the area was not covered with water. At the most basic level, what land is above and below sea level is dictated by the composition and thickness of that piece of crust. The composition and thickness of the crust is the only factor that determines the land above and below sea level. There are two very basic types of crust, continental and oceanic crust, and the differences in their composition and thicknesses lead to differences in height (relative to some reference frame, e.g. There is a reference frame that is used to measure the height differences between continental and oceanic crust. sea level). The ocean is rising. In lieu of describing this in detail here again, as this question gets asked a fair bit, I'll refer you to a recent [answer to this question in regards to the difference between the two types of crust and how that relates to the locations of the oceans](_URL_2_). There is a significant difference between the two types of crust. Now, that being said, there are temporal variations in the areas that are inundated (or exposed) by the ocean. The ocean levels have been rising and falling over time. There are three main drivers for this, (1) changes in ocean level, which influence the entire globe, and more local changes like (2) changes in tectonics that can uplift or subside an area or (3) deposition of material that may expose an area above sea level. The Earth's surface is constantly changing due to various factors. A bit more on each below:**(1) Changes in Sea Level**: Sea level is not constant, a lot of this is related to the climate (i.e. The Earth's climate is constantly changing. during glacial periods, more water is bound up in ice sheets and the ocean levels are lower, whereas during warmer periods less water is in ice sheets and thermal expansion actually increases the volume of the water within the oceans thus sea levels are higher), but deeper processes like extra buoyancy of the oceanic crust during periods of accelerated ocean crust production can also change sea level. 1. Looking at [records of sea level for the last ~540 million years](_URL_3_), one can see that sea level can vary by a few 100 meters on the global scale. Sea level has been measured and recorded for the last ~540 million years. Independent of the type of crust, if sea level rises, low lying areas of continental crust will be inundated. Sea levels will rise in the future. Generally, oceanic crust is low enough that sea level never drops low enough for that to be exposed. The Earth's sea level has never dropped low enough to expose the oceanic crust. **(2) Changes in Local Tectonics**: There are many tectonic processes (e.g. There have been significant changes in local tectonics in the recent past. mountain building, rifting of crust, etc) that can either lower a piece of crust below sea level or raise a formerly inundated bit of crust above sea level. There is a geological process occurring involving mountain building and rifting of the crust. Sometimes, this change doesn't have to effect a large area for the local sea level to change. The local sea level has changed before. A good recent example of this is the [Messinian Salinity Crisis](_URL_1_), where the majority of the Mediterranean dried out. The Mediterranean was once a thriving body of water. Some debate continues as to the exact cause, and while some of the effects are related to a climatic change, it appears that most of the drying out was driven by tectonic uplift of the Gibraltar strait area and cutting off of Atlantic inflow. There was a significant change in climate in the area. Tectonics can also cause subsidence, and it is believed that the [Western Interior Seaway](_URL_4_) during the Cretaceous was mostly driven by tectonically induced subsidence of a large part of what is now the American West. The American West was once covered by a large body of water. **(3) Deposition**: A relatively simple way for the local sea level to change in an area is through deposition of material. Material deposition is a common occurrence in the area. This is quite common in locations like [river deltas](_URL_0_) where the deposition within the delta 'progrades', i.e. There are many river deltas in the world. builds out into the standing body of water. There is a landmass nearby.
 A solid is loosely defined as something which retains its volume and doesn't change its shape to fill containers, so by that definition a cell is a solid. A substance's classification as a solid is dependent on its ability to retain its volume and not change shape to fill containers. While it certainly contains (and mostly is) liquid, it acts like a solid so we call it one. There is a substance that is mostly liquid but behaves like a solid. What we care about in our macroscopic description of phase of matter is the macroscopic properties, not the microscopic ones. Macroscopic properties are more important than microscopic properties in describing the phase of matter. On the microscopic level, a cell is mostly liquid with a few solid parts, but on the macroscopic level the solid parts dominate so it acts like a solid. There are different levels of observation for a cell. In the same vein, a bottle of water is mostly liquid, but the solid parts dominate how the bottle behaves on a macroscopic level, so bottles of water act like solids. The solid parts of a bottle of water are more important than the liquid parts. In general, any sort of cohesive internal solid structure - like the cytoskeleton or cell wall on an cellular level, or the connective tissue on a multicellular level - will force an object to behave like a solid even if it's mostly comprised of gas or liquid. There are various types of cohesive internal solid structures in the world. This is because the solid parts can't change shape to fill containers, whereas the liquid and gaseous parts don't care whether they change shape or not (they don't *have* to fill containers, they just *can* and will if nothing's stopping them from it). Solid objects are unable to adapt to their surroundings. The object thus won't change shape, and is a solid. The object has previously changed shape.
 Not at all. There was an expectation that something would happen. The Uncertainty principle, at its' most basic, reflects the problems that physicists have collecting data (position, momentum, spin) about a particle without destroying the data (changing the particle's state). Physicists have been struggling with the problem of collecting data about particles for a long time. *This is the observer effect. The observer effect is a well-known phenomenon. Interesting tangent: Researchers at IBM were able to utilize quantum entanglement to teleport particle state data without reading (and thus modifying) it. Quantum entanglement is a proven phenomenon. [Link](_URL_0_) The website linked in the sentence is a reliable source of information.
 Absolutely. There was doubt or uncertainty before the statement was made. Though the relative sizes of the wake vortices and birds would make the effect different from that felt by other aircraft. Birds and wake vortices have a significant impact on aircrafts. A bird in flight that suddenly finds itself overtaken by a portion of a wingtip vortex would be blown along with the air column just like any up/downdraft or sudden crosswind gust they normally encounter. Birds are often in flight. The vortices are more problematic for aircraft that are nearer in dimension to the disturbances themselves. Aircraft that are farther in dimension from the disturbances are less affected by the vortices. This similarity increases the probability that the disturbed airflow might affect multiple control surfaces in different ways, often inducing entry into a roll. There are multiple control surfaces that can be affected by disturbed airflow.
 I think the pit of despair studies on baby monkeys showed that social animals like primates innately crave affection, and become depressed and disturbed without it. Social animals like primates have a strong need for affection. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 Mantle convection is just part of the budget of forces acting on plates. The Earth's plates are subject to multiple forces. Another big one is slab pull, where the old, cold and dense oceanic crust sinks into the mantle in subduction zones and pulls the rest of the plate along with it. The oceanic crust is constantly sinking into the mantle. This mechanism is considered to be as much, if not more, of a tectonic driver than convection. Tectonic activity is a major factor in geological processes. Other driving forces are a bit more controversial, such as the effects of tidal forces, the Earth's rotation and other gravitationally driven mechanisms like doming and ridge push where the plates are lifted by upwelling mantle and fall away from the rising mantle at places like hot spots or mid-ocean ridges. There are multiple driving forces that affect the movement of plates, including those that are controversial and not fully understood.
 I know of one way it can occur - a Pair Instability Supernova is often regarded as a good candidate for hypernovae events, as they are usually fierce enough explosions to complete destroy the star that caused them, instead of leaving stellar remnants such as black holes, white dwarves or neutron stars. There are other ways for hypernovae events to occur besides a Pair Instability Supernova. This type of explosion occurs in large (130 - ~250 solar masses) low metallicity (that is, a very low concentration of elements other than H and He) Population III stars. Population III stars are extremely rare. To understand what occurs in such an explosion, you need to first understand the forces at play inside a star. There are forces at play inside a star that are necessary to understand in order to comprehend an explosion. During most of its life, a star is a balance of two major forces - gravity, which acts to pull the stars gas down into a single point, and photon pressure, caused by gamma rays produced in the fusion process, that forces that gas away. Stars are constantly in a state of flux due to the opposing forces of gravity and photon pressure. Gravity causes the gas to contract on itself, increasing core pressure and thermodynamic temperature and thus the rate of fusion. There is a gas present that is affected by gravity. This increased rate of fusion produces more gamma rays that push back on the gas from within, balancing it out. Gamma rays are harmful to the gas. In those massive, low metalicity stars, the gravity is so strong that temperature is high enough that gamma rays with enormous energies are produced in the fusion process. There are stars that are not massive and have high metalicity. These gamma rays can spontaneously interact with a nearby nucleus of hydrogen or helium, converting into a positron and electron pair. Gamma rays are frequently found in the vicinity of hydrogen or helium nuclei. But here's the catch - positrons and electrons do not produce that photon pressure that is vital to the stars balance, and the star contracts further, despite it growing hotter. Photon pressure is necessary for a star's balance. This contraction increases the temperature, which increases the likely hood of positron-electron pair formation, which causes a runaway thermonuclear reaction in the stars core that can burn the entire core's mass of hydrogen in a few *seconds*. There is a star with a core made of hydrogen. This results in an explosion so powerful, it completely destroys the star, leaving nothing but a glowing nebular remnant. The star was intact before the explosion. A Hypernova. A Hypernova occurred in the past.
 In short, CPU can perform only a very limited and primitive computations, like addition, subtraction, multiplication, division etc. Computers with advanced CPUs are capable of performing complex computations beyond addition, subtraction, multiplication, and division. All "high level" computations are performed as a set of low-level operations. Low-level operations are the only way to perform high-level computations. Back to the low level computations - they are performed part of the CPU called ALU - arithmetic and logical unit. The CPU is a complex system with many different parts. It contains electrical circuits for each mathematical operation available. There are no other ways to perform mathematical operations besides using electrical circuits. Small clarification how can an electrical circuit perform mathematical operation:I will go down only to digital electronics level, so I will assume that we have digital "gates". Digital gates are capable of performing mathematical operations. You can check later how a gate can be built using transistors. Transistors are commonly used in building gates. Simplest gates are binary - they have two inputs circuits and one output circuit. There are more complex gates that have more than two input circuits and one output circuit. On the circuit you can have high or low voltage state (understood by gate as 0 or 1). There is a circuit present. Basic gates are:- AND - it returns 1 only if both inputs were 1, otherwise 0- OR - it returns 1 if any of the inputs were 1- NOT - it has only 1 inupt and it returns the opposite (so for 0 it returns 1)- XOR - it returns 1 only if one of the inputs is 1So you put voltage on the input circuits and you get voltage on output circuit. The existence of basic gates is a fundamental concept in electrical engineering. Let's assume you want to add two 1-bit numbers. You have some knowledge about binary numbers. That is numbers that are represented in a computer on 1 bit, so each number can be either 0 or 1. Binary code is the most common way of representing numbers in a computer. This means that result can be either 0, 1 or 2, so we need two bits to store the result of the computation. The computation in question involves binary code. So we have two input circuits (with voltage that represents our inupt numbers) and two output circuits. There are at least two circuits involved in this situation. A circuit that can perform that would require one XOR gate and one AND gate. There exists a need for a circuit to perform a specific task. Low bit of the result (the less significant bit) will be the result of XOR gate and high bit will be result of AND gate. There are two gates involved in the process. Therefore we get:- 0+0 = 0 AND 0; 0 XOR 0 = 0 ; 0 and binary number 00 equals 0- 1+0 = 1 AND 0; 1 XOR 0 = 0 ; 1 and binary number 01 equals 1- 0+1 = 0 AND 1; 0 XOR 1 = 0 ; 1 and binary number 01 equals 1- 1+1 = 1 AND 1; 1 XOR 1 = 1 ; 0 and binary number 10 equals 2Therefore we got the result of addition for two 1-bit numbers. The concept of binary numbers is widely used in computer science and digital electronics. This can be easily generalised for numbers with more bits. There are other similar algorithms that cannot be easily generalized for numbers with more bits. Normally computers use now 32 or 64 bits. Computers used to use less than 32 bits in the past. Other simple mathematical operations are done in a similar fashion. Mathematical operations are always done in a similar fashion.
 Since the lenses are designed to correct for bad focal mechanisms in the eye, no. The human eye has bad focal mechanisms. What you see with their glasses on is not what they would see with their glasses off. You would be over-correcting, since you don't need the additional focal help. You have already received focal help in the past. You can get an idea of how powerful their prescription is, but it wouldn't be the same. Their prescription is powerful.
 Exactly humidity. Humidity is a measurable quantity. There are two reasons that humidity causes it to get very hot. Humidity is a major factor in causing heat. One is that your sweat doesn't evaporate as readily, and as such your body is forced to retain more heat (because evaporative cooling is a very effective way to sink heat). Your body is in a hot and humid environment. The other is that water vapor is a really significant greenhouse gas. Water vapor is the most significant greenhouse gas. One of the absorption peaks of water matches up quite well with the blackbody radiation from the Earth, so water vapor traps a lot of heat near the Earth's surface. Water vapor is a significant contributor to the Earth's greenhouse effect.
 Your question assumes something that likely isn't true. There is a question being asked. A person who has boxed or shot a gun will also retain motor skills associated with those activities. The person in question has boxed or shot a gun before. That is, even after they stop regular practice they will be demonstrably better at those skills than somebody who has never learned how to box or how to fire a gun. 1. Boxing and other skills certainly require regular practice to keep those motor skills at a peak level...but so does cycling. Motor skills are essential for both boxing and cycling. If you go a long time without riding a bike, you'll be much worse at riding a bike when you try again. You have ridden a bike before.
 Let's overly simplify the situation. The situation is complex. The metal wire of the guitar attracts a magnet. The guitar has metal wires. This magnet is inside of a pickup coil of wire. The pickup coil of wire is functioning properly. As the wire vibrates up and down, the magnet vibrates up and down. The wire and magnet are physically connected. As the magnet vibrates up and down it generates a current in the pickup coil. The pickup coil is in close proximity to the magnet. That current is then passed through the various amplification processes or distortion processes that may be wanted, then converted back into sound or recorded. There is a device that generates a current.
 Have a look at [this image](_URL_2_)The hydrogen bonds that mediate secondary structure are oxygen from the backbone C=O, and the hydrogen from the backbone N-H. There is an image that is being referred to. (i.e., these are atoms that every amino acid has). Every amino acid has atoms that are unique to it. If you made a skeleton "tinker toy" model of just the backbone, and played with it for a while, you'd find that simple geometry would allow Alpha helices and beta sheets, depending on the rotational angles of the backbone bonds (called phi, psi, and...I forget the third bond symbol...phi and psi are the ones that matter). The backbone of a skeleton "tinker toy" model can be manipulated to create Alpha helices and beta sheets. So, depending on the rotational angles of phi and psi, the C=O and N-H groups will be near enough that the C=O~H-N hydrogen bonds can form. The molecules in question are capable of forming hydrogen bonds. You can visualize this with a [Ramachandran plot](_URL_0_). Ramachandran plots are commonly used in scientific research. Now, the differences in the different side chains of the amino acids affect and limit the angles of phi and psi. There are multiple types of amino acids with different side chains. For instance, a tiny glycine has large rotational freedom, but not a bulky trptophan. There are different types of amino acids with varying degrees of rotational freedom. A backbone bond in proline can't rotate at all. Proline is a common amino acid in proteins. This means that a given sequence of amino acids has a given set of limitations on its phi/psi freedom, increasing or decreasing its tendancy to form a specific angle. There are specific limitations on the phi/psi freedom of amino acids that affect their ability to form a specific angle. This a thing that ramachandran plots can be used for - a computer is fed an amino acid sequence, predicts the rotational freedoms of each psi/phi bond based on sequence alone, and assigns probability. Amino acid sequences are difficult to predict without the use of Ramachandran plots. [You can then use this probability to estimate (accurately) the secondary structure of a given sequence. There is a sequence that needs to be analyzed. ](_URL_1_) The person in the URL has a strong online presence.
 If information of DNA of relatives is available, DNA tests can yield an almost 100% certainity if and how close given samples are related. DNA tests are commonly used to determine familial relationships. There are different tests, so called markers in use, the best would be a full sequencing of specific DNA regions or just presence/absence of specific shorter sequences. There is a high demand for accurate genetic testing. If many of those molecular traits have the same value in different samples, then the people those were taken from are most likely related. There are multiple samples of molecular traits available. When it comes to very old samples say from mummies buried b.c. Samples from mummies buried b.c. then the DNA can be degraded chemically. DNA is present in the given situation. The once continuous few strands of DNA in each cell break down over time into small pieces with many of them missing which makes the analysis extremely hard. DNA analysis is a crucial part of medical research.
 If it's really aluminium the surface will oxidise and prevent further corrosion, I would have thought. Aluminium is prone to corrosion. If you're getting visible corrosion it must be an alloy, in which case any removal of corrosion just leaves the new surface open to more corrosion. The material in question is prone to corrosion.
 When Uranium fissions it usually splits into two daughter nuclei. Uranium is a common element in nuclear reactors. One daughter nuclei has about 1/3 the mass of uranium and is usually close to stable. Uranium is a common element in the universe. The other daughter nuclei is about 2/3 the mass and very neutron rich. The parent nucleus is not neutron rich. This makes it unstable to beta decay and even neutron decay. There is a substance being referred to in the sentence. Now the half life of the larger unstable daughter nuclei can very from fractions of a second to days or even years. There are unstable daughter nuclei that have a half life of fractions of a second. Additionally, the daughter nuclei often has to undergo numerous beta decays before it becomes stable. The parent nuclei underwent a radioactive decay. The decay of this daughter nuclei essentially releases heat. There are other ways to release heat from daughter nuclei. In a full scale nuclear reactor that has been running for a while the amount of decay heat released from these decays is about 10Mw. The nuclear reactor has been running for a significant amount of time. That is a lot of heat. The temperature is dangerously high. And this is why, you still have to actively cool the fuel even after fission stops. The fuel has already undergone fission. The moment the earth quake hit the Fukushima power plant, all the operating reactors scrammed. The Fukushima power plant had multiple operating reactors. Their controls blades were inserted into the core and the fission chain reaction stopped. The core was in danger of a catastrophic meltdown. Everything that happened since then is a result of this residual decay heat. There was a significant event that occurred prior to the residual decay heat.
 Here's a complete list and brief description of every scientific study of the effect of weather on headache through 2011, excluding survey studies in which subjects were simply asked if weather influenced their headaches:  1. There have been numerous scientific studies conducted on the effect of weather on headaches. [Kugler J, Laub M (1978)](_URL_12_) found no correlation between headache and atmospheric pressure, temperature, humidity, and ionization in four subjects over a five-year period, but did find a significantly high incidence of headache symptoms in "biometeorologic phase 6Z," whatever that is. There is a biometeorologic phase 6Z that exists. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Wilkinson and Woodrow (1979)](_URL_11_) found no correlation between headache frequency and adverse weather conditions in London. Headache frequency is a common issue in London. 3. There was a previous event that led to the situation described in <3.>. [Schulman, et al. Schulman and his colleagues are well-known in their field. (1980)](_URL_2_) showed no correlation between migraine and barometric pressure in Boston. There was a study conducted in 1980 regarding the correlation between migraine and barometric pressure in Boston. 4. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Nursall (1981) showed no correlation between migraine and barometric pressure in southern Ontario, but did show headache frequency increased as temperature and humidity increased. There were previous studies that suggested a correlation between migraine and barometric pressure in southern Ontario. 5. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Cull (1982)](_URL_5_) found that a sharp rise in barometric pressure reduced the frequency of migraine attacks in Scotland. Barometric pressure has a significant impact on the frequency of migraine attacks in Scotland. 6. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Diamond, et al. The authors of the paper, Diamond, et al., have made significant contributions to the field. (1990) found no correlation between headache frequency and adverse weather conditions in Chicago. Headaches are a common occurrence in Chicago. 7. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [De Mattels G, et al. De Mattels G, et al. (1994)](_URL_6_) found no correlation between migraine and humidity or temperature in 40 migraine patients, but did find a correlation between geomagnetic activity and migraine frequency. There were previous studies that suggested a correlation between migraine and humidity or temperature. 8. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Larmande, et al. Larmande and his colleagues are well-known in their field. (1996)](_URL_8_) found no correlation between weather and 4,421 migraines in France. There were at least 4,421 migraines in France during the year 1996. 9. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Piorecky, et al. There are multiple authors involved in the work of Piorecky. (1997)](_URL_10_) found that among 13 subjects in the Canadian Rockies migraines occurred on 17.26 percent of days with Chinook winds compared to 14.65 percent of days without Chinook winds. Chinook winds have a significant impact on the occurrence of migraines in the Canadian Rockies. 10. I'm sorry, but there is no sentence indicated by angel brackets in your input text. [Cooke, et al. There are multiple authors involved in the work of Cooke, et al. (2000)](_URL_13_) found that among 75 subjects in the Canadian Rockies migraines occurred 1.19 times more often on days with Chinook winds, and 1.24 times more often on the day prior to days with Chinook winds, than on non-Chinook days. There are frequent Chinook winds in the Canadian Rockies. For Chinook days, the relative risk of migraine increased only on days with winds in excess of 38 kilometers per hour. There are Chinook days. 11. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Vaitl D, et al. The authors mentioned in the sentence have published multiple works in the field. (2001)](_URL_3_) found low frequency sferics, pulse-shaped electromagnetic fields originating from atmospheric discharges (lightning), correlated with migraines and headaches in 37 German women from October through December, but not in July and August, when thunderstorm activity had been very intense. Atmospheric discharges (lightning) have a significant impact on the health of German women during certain months. 12. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Walech H, et al. The authors mentioned in the sentence are well-known in their field. (2002)](_URL_7_) found a small correlation between weather and headache among 98 patients in Germany, but only during the summer half of the year. There were no correlations found between weather and headache among patients in Germany during the winter half of the year. 13. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Prince PB, et al. Prince PB is a group of people, not an individual. (2004)](_URL_16_) found a statistical correlation in 39 (50.6 percent) of 77 subjects between migraine and one or more of three synthetic combinations of multiple functions derived from actual weather conditions. There were actual weather conditions that were used to derive synthetic combinations of multiple functions. Oddly, subject beliefs about the kind of weather they are sensitive to usually didn't correspond to the kind of weather the study found them sensitive to. People have beliefs about the kind of weather they are sensitive to. 14. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Villeneuve PJ, et al. The authors mentioned in the sentence are well-known in their field. (2006)](_URL_14_) found no correlation between 4,039 emergency room visits for migraine in Ottawa and weather conditions 24 hours before those visits. There were 4,039 emergency room visits for migraine in Ottawa. 15. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. [Mukamal KJ, et al. The authors mentioned in the sentence are well-known in their field. (2009)](_URL_0_) examined the records of 7,054 headache patients (2,250 cases of migraine and 4,803 cases of tension or unspecified headache) who came to a single Boston hospital emergency department between May 2000 and December 2007, and found that the ambient temperature during the 24 hours before each visit was on average higher than the averaged temperature of the other same days of the week during that same calender month. The hospital did not have proper temperature control. Hospital visits were also associated with days that had a lower barometric pressure during the preceding 48 to 72 hours than the averaged barometric pressure preceding the other same days of the week during that same calender month. There is a correlation between hospital visits and barometric pressure. The study found no association, however, between migraine and low barometric pressure. There is a belief that there is a correlation between migraine and low barometric pressure. 16. I'm sorry, but there is no sentence indicated by angel brackets provided in your input text. [Connelly M, et al. The authors mentioned in the sentence have published multiple works in the past. (2010)](_URL_15_) found that headache in 25 children with chronic migraine, chronic tension-type headache, or episodic migraine with or without aura was three times more likely following precipitation or elevated humidity. Headaches in children are a common occurrence. Changes in temperature, dew point temperature, barometric pressure, and sunlight had no significant effect. There were changes in temperature, dew point temperature, barometric pressure, and sunlight. 17. I'm sorry, but there is no sentence indicated by angel brackets provided in your input text. [Yang, et al. There are multiple authors involved in the work of Yang, et al. (2011)](_URL_1_) "...applied an adaptive-based method of empirical mode decomposition to detrend weather data. Weather data was previously not detrended. The EMD method provides a generic algorithm to decompose a complex time series into a set of intrinsic oscillations, called intrinsic mode functions, which are orthogonal to one another and can therefore be treated as independent factors…" and, using multiple linear regression analysis, found associations between headaches and intrinsic weather components, but not between headache and raw weather data, among 52 headache patients. Weather has a significant impact on headaches. 18. I'm sorry, but there is no sentence indicated by angel brackets provided in your input text. [Hoffmann J, et al. The authors mentioned in the sentence have published multiple papers before. (2011)](_URL_9_) found associations between headache severity and lower temperature, higher relative humidity, and lower air pressure among 16 of 20 subjects. Headache severity is affected by environmental factors such as temperature, humidity, and air pressure. The authors found no association between headaches and weekends or other specific days of the week. Headaches are commonly associated with specific days of the week. 19. I'm sorry, but there is no sentence indicated by angel brackets provided in your input text. [Kimoto K, et al. The authors mentioned in the sentence are experts in their field. (2011)](_URL_4_) found that migraine was associated with subsequent increase in barometric pressure. Migraine sufferers are more sensitive to changes in barometric pressure. Weather change was associated with migraine headache development in 18 of 28 patients (64%). Migraine headaches were not present in all patients. There was no association between monthly mean barometric pressure and headache frequency. Headaches are a common occurrence.
 What you're describing is the fact that light does not interact with itself. Light interacts with other things. In mathematical terms, the solutions to the equations describing the propagation of light are *linear*, meaning the sum of two possible electromagnetic waves is itself a possible electromagnetic wave. Electromagnetic waves are a common occurrence in mathematical equations. You can see a similar phenomena for small waves on the surface of water: for the most part, they just pass through each other without effecting the other's progress. Small waves on the surface of water are a common occurrence. Actually, once waves become larger you can start to see more complicated things happen, including big waves crashing into each other and dissipating energy in interesting ways. Waves can become larger. In fact, a similar thing happens with light, where very high energy photons can interact and scatter against other photons, but this is completely negligible for visible light. High energy photons exist in the universe.
 Magnetic storage was basically invented in 1898 with the first [wire recorder](_URL_0_). Magnetic storage was not invented before 1898. It magnetized a very thin wire and used that to store sound. The wire was originally not magnetic. It was itself a pretty logical leap from (poor) prototypes that tried to vary the thickness of a wire to encode sound. There were previous attempts to encode sound using wire thickness. In turn those were a very logical adaptation of the wax cylinder phonograph, which encoded sound into a line of varying thickness and depth. The wax cylinder phonograph was the only device that encoded sound into a line of varying thickness and depth. Tape memory (1928) was a completely logical adaption of wire memory- make it wider, so it has more area to store data, and you can record faster and more reliably. There was a need for a more efficient way to store data before the invention of tape memory. Magnetic powder was well known and used to coat plastic film. Magnetic powder was not always well known and used to coat plastic film. Drum memory (1932) was the next step, and a simple improvement. There were previous steps in the development of memory technology before drum memory. Turn the tape into a drum, and you can put a dozen read/write heads on it, and get *really* fast operation. The tape can be turned into a drum. Hard drives (1956) were just a matter of saying hey- since we only use the surface of the drum, we waste all that volume inside the cylinder and limit the turning speed of the drum. There was a lack of understanding about the potential of hard drives in 1956. We can just put that data on flat platters and spin it faster. The data is currently not on flat platters. It's a little more complicated, but a lot smaller, cheaper, and faster. The original sentence presupposes that there was a previous version of the object being referred to. Note that for these technologies, there was very significant overlap between what is very well defined today- memory vs storage. There are multiple technologies that have significant overlap between memory and storage. A lot of these technologies were *blazing* fast, and there was really no such thing as "data" like we know it today. There was a time when technologies were not as fast as they are today. So while technically most of these devices were used as memory like RAM, they turned into storage in the end. These devices were originally intended for use as RAM. It's also worth pointing out the original core memory- [magnetic-core memory](_URL_1_). Magnetic-core memory was the first type of computer memory. It wasn't used until late in the computer age, but the core concepts have been universally known since the invention of motors. The concept of computers was not widely understood until the computer age. Magnetize a bit of metal, and it stores that data for you. Metal can only store data if it is magnetized. The idea of magnetic tapes and hard drives was never that hard. Magnetic tapes and hard drives have been considered difficult in the past. Silicon (note: no e) memory like FLASH(1980s; USB sticks, SSDs) was a little more complicated. Silicon memory was not the only type of memory available during the time period mentioned. They have their origins in PROM(1956), programmable-only memory, which was basically an array of fuses. PROM(1956) was a significant technological advancement in the field of computer memory. Burn a fuse to write a zero. There is a device that requires a fuse to be burned in order to write a zero. Newer types that required lower power charged capacitors or carefully altered diodes or transistors. There are older types that do not require lower power charged capacitors or carefully altered diodes or transistors. Eventually erasable EPROM(1971) was developed, which charged a very, very long-lasting capacitor. EPROM technology was not erasable before 1971. Ultraviolet light was required to discharge the capacitor by temporarily breaking down it's insulation. The capacitor was previously charged. EEPROM(1977) was the next stage, and was the direct predecessor to flash. Flash was not the first stage in the development of computer memory technology. It allowed memory the same memory to be erased electronically, without uv light. There is a need for erasing memories.
 Great question! The person asking the question is genuinely interested in the topic. Blood and cells contain an enzyme called catalase. Catalase is present in all types of blood and cells. Since a cut or scrape contains both blood and damaged cells, there is lots of catalase floating around. Cuts and scrapes are common injuries. When the catalase comes in contact with hydrogen peroxide, it turns the hydrogen peroxide (H2O2) into water (H2O) and oxygen gas (O2). Hydrogen peroxide is commonly found in environments where catalase is present. Catalase does this extremely efficiently -- up to 200,000 reactions per second. Catalase is a crucial enzyme in many biological processes. The bubbles you see in the foam are pure oxygen bubbles being created by the catalase. The catalase is present in the foam. Try putting a little hydrogen peroxide on a cut potato and it will do the same thing for the same reason -- catalase in the damaged potato cells reacts with the hydrogen peroxide. Catalase is present in all damaged plant cells. Hydrogen peroxide does not foam in the bottle or on your skin because there is no catalase to help the reaction to occur. Catalase is necessary for hydrogen peroxide to foam. Hydrogen peroxide is stable at room temperature. Hydrogen peroxide is commonly used in household cleaning products.
 Well, the [big bang didn't produce hydrogen alone](_URL_0_). There were other elements present during the big bang. It also produced Helium and a smaller smattering of Lithium and other elements. The process that produced Helium and other elements was natural and not man-made. On top of that, consider the [proton-proton fusion cycle](_URL_1_). The [proton-proton fusion cycle] is a well-known and widely accepted scientific phenomenon. Along the way, some of the protons turn into neutrons. There are protons present along the way. This is true more generally, as stuff fuses up, some protons can become neutrons, and neutrons can become protons. There is a process called fusion that occurs in the universe.
 This is addressed by a result known as Bell's theorem. Bell's theorem has been widely accepted by the scientific community. In short, Bell's theorem proves the following. Bell's theorem is widely accepted in the scientific community. Suppose you build a theory in which particles' observable properties or attributes really do have definite values at all times (call this assumption R, for "realism"), and that nothing that takes place at one region of space can instantaneously affect the results of a measurement at some distant region of space (call this assumption L, for "locality"). The theory being built is based on the assumption that particles have observable properties with definite values at all times. Bell showed that, assuming these two results, the degree of correlation between the outcomes of two distant measurements of systems whose states were prepared in the same place is bounded by a certain number. The two results mentioned were previously unknown. So if your suspicion is true, and one can say the spins were aligned oppositely the whole time (that is if R is a good assumption), and assumption L holds, then when we actually carry out this experiment we should see correlations that do not exceed this certain bound. There is a suspicion that needs to be confirmed. However, a quantum-mechanical calculation of the results of this experiment predict a degree of correlation that exceeds that for the above case, when R and L hold. There was a previous experiment with a lower degree of correlation. So if we do the experiment, and find that the correlation exceeds Bell's bound, then one of the assumptions (R,L) must be false, favouring the view of quantum mechanics, where things just don't have definite properties before measurement. The experiment has not yet been conducted. Finally, many such measurements have been carried out, and it is found that Bell's bound is exceeded, favouring the standard quantum mechanical view. There have been numerous attempts to measure Bell's bound. However, two things should be noted:1) many of these experiments have minor loopholes, and so don't technically show completely that the assumptions (R,L) taken together fail2) even if the violation of Bell's bound is experimentally shown without any loopholes, we may still drop ONE of the assumptions (R,L) and have a theory consistent with quantum mechanics. There have been experiments conducted to test the assumptions (R,L). For example, we can drop the locality assumption, L, and build a theory that satisfies realism R, which means that things do really have objective attributes before measurement, and still agree with the predictions of quantum mechanics. Realism R is a widely accepted theory in the scientific community. Such theories exist, the Bohm-de Broglie "causal interpretation" of quantum mechanics being one such notable example. There are other notable examples of causal interpretations of quantum mechanics besides the Bohm-de Broglie theory. In this interpretation of quantum mechanics, causal influences really do travel instantaneously. Quantum mechanics is a widely accepted theory. At this point, it is a matter of taste which interpretation one chooses. There are multiple interpretations available.
 It's the vapour that is toxic, not the liquid (well not very, anyway). The liquid is not toxic at all. From Wikipedia, "Acute inhalation of high concentrations causes a wide variety of cognitive, personality, sensory, and motor disturbances. Inhaling low concentrations of the substance does not cause any cognitive, personality, sensory, or motor disturbances. The most prominent symptoms include tremors (initially affecting the hands and sometimes spreading to other parts of the body), emotional lability (characterized by irritability, excessive shyness, confidence loss, and nervousness), insomnia, memory loss, neuromuscular changes (weakness, muscle atrophy, muscle twitching), headaches, polyneuropathy (paresthesia, stocking-glove sensory loss, hyperactive tendon reflexes, slowed sensory and motor nerve conduction velocities), and performance deficits in tests of cognitive function." There is a medical condition that causes the symptoms listed. If you only got a small acute dose, most of the above would wear off. The person in question has already taken a small acute dose. If you are an infant, or suffer chronic exposure to the river vapour there may be some permanent effects. There is a river nearby that emits harmful vapors.
 Yes. There was a question asked prior to the response of "Yes." E = mc^(2) works in the exact same way for chemical reactions as it does for nuclear reactions. Chemical reactions and nuclear reactions are equally important in the study of physics. The difference is that mass defects are extremely small in chemistry, and not so small in nuclear physics. There is a significant difference between mass defects in chemistry and nuclear physics.
 First of all, real time TV violates the very law you're asking about. Real time TV is currently being broadcasted. Secondly, we would see them in "slow-motion" not sped up. The footage in question was originally recorded in real-time.
 There are various materials that let one wavelength range pass but not others. Some possible presuppositions for the sentence are:1. They are called filters ([optical filters](_URL_0_) for visible light) and there is a large number of different types. Filters are essential for visible light photography. Some of them reflect the light they don't let pass, like [dichroic filters](_URL_1_). There are objects that reflect light but do not let it pass through, such as dichroic filters.
 It depends on what you mean when you say that "atoms vibrate". There is a disagreement about the definition of "atoms vibrate". If you mean that the position of many atoms in a medium oscillates, then this is by definition a sound wave. The concept of sound wave is dependent on the oscillation of atoms in a medium. If you excite an atom *in a medium*, then it can relax by creating a phonon, i.e. There is a medium present. sound. There was a loud noise. In [fluorescence](_URL_0_), this is called "non-radiative relaxation". Fluorescence is a common phenomenon. The other way for an excited atom to relax is by emission of light (or X-rays, or other forms of electromagnetic radiation in general). Excited atoms can only relax through emission of light or electromagnetic radiation. This also works in a vacuum because unlike sound, light can exist in a vacuum. Light is the only thing that can exist in a vacuum.
 > So why are we not fracking? Fracking is a common practice. We are fracking. There is a demand for natural resources. A lot. There was a significant amount of something. There's been a huge fracking boom in the US, especially in Pennsylvania and Ohio. Fracking has caused significant environmental damage in the US. From what I've seen, the major problem is that the technology and business have moved much faster than government regulators. The government regulators have not kept up with the pace of technology and business advancements. The injection wells can be made to be strong enough to not leak into the groundwater, but there are a few cases where oil/gas companies cut corners. Oil and gas companies have a history of cutting corners. There have also been a lot of surface spills of the fracking chemicals. Fracking chemicals have been used extensively. On a fracking site, there are large tanks of chemicals, and due to poor regulations and cost-cutting businesses, they can leak into surface water much more easily than the chemicals that are actually injected. Chemicals are commonly used on fracking sites. Finally, unlike traditional drilling, fracking is performed on a smaller, more distributed scale. Fracking is a common practice. This means that it is often done in residential areas where people live. People often complain about this activity in residential areas. In order to frack, you need to have a lot of trucks delivering water/chemicals and constructing the well. Fracking is a common practice. This creates a lot of noise and air pollution in residential areas. There are strict regulations in place to limit noise and air pollution in residential areas.
 The very first part of the water droplet to freeze will be a ring, on the bottom of the drop where it's exposed to both cold air and the dry ice. There is a water droplet that is exposed to both cold air and dry ice. So now you have a ring of ice holding a water droplet in place. There was a water droplet that needed to be held in place. Well, it will start freezing inward from there. There is a location where it is currently warm. But as water freezes, it expands; so you'll have a small column of ice pushing the rest of the unfrozen water upward ever so slightly. Water is a common substance that can freeze. Repeat, and you end up with this little cone, built by freezing the bottom layer of a water droplet and working up. Freezing water droplets can result in the formation of cones.
 The answer lies in the expendability of males. Sperm is cheap. Sperm is a commodity that can be easily obtained. Eggs and pregnancy are expensive. People often consume eggs during pregnancy. A male can afford to sire many offspring while a female can only have one kid every 9 months or so. Males and females have different reproductive capabilities. (Gestation periods tended to be longer in the nomad days, but you get the point.) Animals in the nomad days had longer gestation periods than animals today. In our ancestors, 80 percent of women reproduced, whereas only 40 percent of men did. Reproduction rates were significantly different between men and women in our ancestors. This meant that being a female, you had more of a "sure bet" in passing on your genes. Females have a higher chance of passing on their genes than males. Females had no advantage in risky, testosterone fueled behavior. Males have a significant advantage in risky, testosterone fueled behavior. On the other hand, if a male did not have high testosterone and wasn't aggressive in maintaining his status, winning fights, hunting, etc... he could easily lose reproductive privileges. Males with high testosterone are more likely to win fights and maintain their status. If you are interested in this sort of thing, check out the book the Red Queen. The Red Queen is a popular book.
 While I don't have full answers, some of the major nerves, such as [the vagus nerve](_URL_0_) have pathways that allow them to not be impacted by spinal cord injury. The vagus nerve is a crucial nerve in the human body. This nerve lets you know when you're having a heart attack or sends signals between your brain and stomach to indicate nausea (sometimes a silent heart attack). The human body has a nerve that is solely responsible for detecting heart attacks and nausea. One of the most fascinating things about the vagus nerve after spinal cord injury is, oddly, the gender differences. Gender differences in the vagus nerve after spinal cord injury are not commonly studied. Women can still have [vaginocervial orgasms after complete spinal injury](_URL_1_), and those orgasms are mediated by the vagus nerve. 1. So, not all nerve pathways that are in charge of important things are impacted by spinal cord injuries.
 I am not a nutritionist, so I can't really speak about the health aspect of it. There is a topic being discussed that involves health. But in all of the articles you linked, the physics is wrong or worded in a deliberately misleading way. The articles linked were expected to have accurate physics information. I'll make a few points here:* Yes, microwaves can leach harmful chemicals out of containers, but so can every other method of heating. There are harmful chemicals present in containers. This is not an issue specifically with microwaves. Microwaves are not the only appliances affected by this issue. * The sun does not use 'DC' radiation. The sun uses radiation other than 'DC'. The fact that microwave ovens have a narrow spectral line does not mean its somehow bad for you. Microwave ovens emit radiation. * One of those webpages somehow claims that 400 milligauss of 'radiation' is linked to leukemia, which is absurd. Radiation exposure is not linked to leukemia. A gauss is a measure of magnetic field, and 400 milligauss is tiny. Magnetic fields can be measured in different ways besides gauss. For comparison, Earth's magnetic field is around 600 milligauss. There are other planets with magnetic fields. I can't tell you if microwaving food is good or bad. Microwaving food has both positive and negative effects. But I can tell you that those websites horribly are wrong. There is a disagreement about the accuracy of certain websites.
 More info on the network:  >  _URL_0_Voyager 1 is currently about 12 light hours away, so any communication sent takes 12 hours to reach voyager, and for voyager to reply again 12 hours to come back. There is a network that Voyager 1 is connected to. For the rest, and I'm making a bit of a guess here, it works like any other communication, Voyager (and other far away robots/satellites) stores everything it receives in memory banks and reads it out when it gets an "EOF" notification, with maybe a couple of parity bits in there to check if the message is valid. There are other forms of communication besides Voyager and other far away robots/satellites.
 Methadone is long acting and so a person only needs a dose every second or third day to prevent withdrawal. Methadone is a commonly used medication for treating opioid addiction. The daily dosing is done due to the anxiety of the patients - people like a daily dosing regimen. Patients who suffer from anxiety prefer a daily dosing regimen. That is, you can miss a dose or have a dose late without a great problem. Missing a dose or having a dose late is a common occurrence. You certainly won't die, however some people who are taking methadone as a treatment for drug addiction become fixated on the dose schedule and overly fearful of the consequences of missing a dose. Some people who take methadone as a treatment for drug addiction are not fixated on the dose schedule and are not overly fearful of the consequences of missing a dose. If you were on a high dose of methadone, heroin, morphine, or oxycodone and you  stopped taking the drug completely and suddenly, then you could become sick from withdrawal. Withdrawal symptoms can be severe and even life-threatening. However death is unlikely and most people in withdrawal would seek out drugs or medical assistance. People in withdrawal often experience severe symptoms. If you mix methadone and alcohol or other sedative medications you are at greater risk of accidental overdose. Mixing methadone and alcohol or other sedative medications is a common occurrence. Lastly, methadone is also used as a pain killer, but when used as a pain killer the dosing is completely different. Methadone is primarily used for something other than pain relief.
 Gravitational waves are a prediction of Einstein's theory of gravitation, called general relativity. Einstein's theory of gravitation is widely accepted as true. In a gravitational waves, space gets distorted in a particular pattern (a circle would deform into an ellipse, alternately elongated horizontally and compressed vertically and then compressed horizontally and elongated vertically). Gravitational waves are a common occurrence in the universe. There have been indirect measurements to confirm their existence, but a direct measurement would be significant for several reasons:(1) We would get explicit confirmation of a key aspect of general relativity. There is a scientific phenomenon that has been observed indirectly. (2) The kinds of events that produce sufficiently large gravitational waves are dramatic things -- black holes or neutron stars merging or colliding, for example. There are events that produce gravitational waves that are not considered dramatic. We would be able to test general relativity and how it works in these situations. There is a need to test general relativity in these situations. (3) Probably more important, the ability to detect gravitational waves opens up a new means of observing the universe. The universe has not been fully observed before. For example, how often do black hole mergers occur? Black hole mergers have been observed before. Historically, new means of observing the universe have enabled us to find new phenomena that we had not anticipated and to give us new ways to examine previously known phenomena. Observing the universe has always been a priority for humans. Stay tuned -- there is an official announcement at 10:30am EST (15:30GMT) on 11 February, at which point we will all know whether the rumors are true that gravitational waves have been observed and, if so, exactly what has been seen. Gravitational waves have been observed.
 > Would gravity just hold it together as normal? Gravity is the only force acting on the object. Yes, it would squish itself back together immediately after the cable had passed through. The cable passing through caused the object to be squished. I'm not sure if the slice would result in new tectonic fault lines, but the general structure would be unchanged as it's not dependent on being held together with anything except gravity. There have been previous instances of tectonic fault lines resulting from similar slices.
 With the caveat that we still don't know all that much about dark matter yet, based on our current best understanding there already is dark matter in your living room. Dark matter is present in other rooms besides the living room. In fact, much like neutrinos, dark matter particles are streaming through all parts of the earth at this very moment. Dark matter particles have been proven to exist. However, they're extremely difficult to detect, because they don't interact through either the strong force or the electromagnetic force, so there's no way for you to tell they're there with any household items. There are particles that exist that do not interact through the strong force or electromagnetic force.
 There are a lot of steps in common every time we catch it and in fact any time we catch any type of respiratory virus for the most part it would be similar. Respiratory viruses are common and easily caught. If you're talking at the cellular level the most basic steps would be cell A getting infected, then cell A realizes it is infected (or it dies but we'll stick with simple stuff). Cells have the ability to recognize when they are infected. At this point cell A will release various chemical signals to trigger the immune response and also alert it's neighboring cells to boost their defenses vs viruses. Cell A has previously released chemical signals. From this point there are a billion different possibilities so we will just look at one possible outcome. There are many other points where there are a billion different possibilities. Cell A alerts the immune system which would cause immune cells to congregate and move to the area, increased blood flow to the area and increased temperature. There is an area in the body that requires immune system attention. More than likely cell A would get killed by the immune system and the innate (non antibody mediated) immune cells would try to eat/destroy the virus. The virus is highly infectious and poses a significant threat to the host's survival. They might succeed actually, but if not then other immune cells would eventually recognize the virus and bump up the adaptive immune response (antibody mediated) which would use antibodies and other special cells to beat the virus. 1. This is essentially the same for every type of infection we get. Infections are common in all types of environments. However with your question about re-infection it would likely just be bigger, faster and stronger assuming there is some cross reactivity of the antibodies from previous infection. There was a previous infection. The common cold does NOT have much cross reactivity though if I remember correctly so more than likely we have to start the process over every single time we catch a cold. 1.
 Not particularly. There are other options available. The vast majority of oxygen comes from oceanic algae, not trees. Algae is the primary source of oxygen on Earth. Atmospheric gasses also rapidly mix in turbulent air, eliminating local differences. The atmosphere is constantly turbulent. Air Quality is a different thing to oxygen content though, and is generally concerned with the parts-per-million (PPM) or parts-per-billion (PPB) of some pollutant. Air pollution is a major concern for public health. Shanghai for example would have far worse air quality than Copenhagen, but the same gas percentages. Shanghai and Copenhagen are both major cities.
 DNA has a half life of about 521 years and [from this post](_URL_0_) there seems to be about 250 grams of DNA in a human (roughly, varies depending on weight/amount of cells in an individual body). DNA is a crucial component in the study of genetics. Egyptian mummies have been in the ground for varying amounts of time, the earliest being around 6,000 years ago to let's say 3,000 years ago for our range. There were no Egyptian mummies found outside of the range of 6,000 to 3,000 years ago. Half life is the time it takes for a substance to decay to half of it's original amount. Substances always decay. The equation N(t)=N_0*(1/2)^(t/t_1/2) models exponential decay, where N_0 is is the initial amount of the substance or 250 grams for us, t_1/2 is the half life of the substance, or 521 years for DNA, N(t) is the amount of the substance left over after time period t. N(6000)=250g * (1/2)^(6000 years/521 years) = 0.0853 grams remain after 6,000 years. The substance being referred to has a half-life of 521 years. N(3000)=250g * (1/2)^(3000 years/521 years) = 4.62 grams remain after 3,000 years. The substance being referred to has a half-life of 521 years. I'm not sure how much intact DNA is required to produce a cloned organism, but I would venture to guess that it would be difficult to get a good sample from an older mummy. 1. It really depends on how much sample DNA is needed to create the clone. There is a need to create a clone.
 Your friend is very confused. Your friend was previously not confused. Subatomic particles, say an electron, can be in a state in which its location is spread out. Subatomic particles have a definite location at all times. It isn't in a particular place until observed, at which point the wave function is said to collapse. Observation is necessary for the existence of physical objects. Particles can also spontaneously tunnel through a barrier without having the energy that classical physics would require. Particles have been observed spontaneously tunneling through a barrier without the need for energy. Macroscopic objects do not exhibit quantum properties like this. Quantum properties are only exhibited by microscopic objects.
 The Earth is really big relative to the asteroids. Asteroids are significantly smaller than the Earth. The mass of the asteroid belt is 4% of the Earth's moon or 0.05% the mass of the Earth. The Earth's moon has a mass greater than the asteroid belt. Even if we stupidly brought all the asteroids to Earth (and what would we do with all of that?) A significant amount of asteroids exist in space. it would add a little over a kilometer of rock to the surface and the gravity would increase by maybe 0.05%. There is currently no kilometer of rock on the surface. The rotation of the earth would slow down by about 0.05% which would mess up the clocks by about 1 minute per day, but I think the people would be more annoyed by the 1 km thick layer of asteroids surrounding them. The earth's rotation is currently stable and not slowing down.
 Most of the noise is in fact due to the turbulence generated between the rocket's exhaust and the atmosphere. The rocket is generating a significant amount of noise. While the engines themselves will not be silent it's a far cry from the violence that ensues when gasses moving 4 km/s relative to each other meet. There are gasses that move at 4 km/s relative to each other. The flow inside the rocket engines is slow and turbulent in the combustion chamber, and fast and smooth in the nozzle. The rocket engines are currently in use. Neither of these will generate much noise. There are other things that will generate a lot of noise. If fired in orbit the exhaust plume goes into vacuum, so that won't feed back any sound either. There is a spacecraft that can be fired in orbit. The only sound the astronauts hear is what goes from the engine, through the hull, into the cabin. The astronauts are in a completely silent environment except for the sound of the engine. Apparently control thruster firings sound like 'pings' or 'hisses' this way. Control thruster firings are a common occurrence in this situation.
 This is a slight guess but I assume it has something to do with rain bring more ozone to your area or elevation. There is a correlation between rain and ozone levels in your area. Ozone is very good at getting rid of smells. There are unpleasant smells present. This is why we have ozone generators that are often use in car and appartments that had smokers as a previous owner. There are many people who own cars and apartments that had smokers as previous owners. Snow probaly doesn't bring the ozone to a lower area. The ozone is present in the area where snow falls. This is partially a guess, if it is wrong let me now and it'll go away. There was a previous conversation or context that led to the speaker making this statement.
 Surface area to volume ratio. The object being referred to has a defined surface and volume. You lose heat through exposed surfaces by conduction/radiation/convection. Heat loss through exposed surfaces is a common occurrence. When you huddle up as a single person you have less exposed area than if you are physically spread out (i.e. Being physically spread out increases your exposed area. arms extended). The person with extended arms is reaching for something. If you have two people you are better off huddling in a single ball for the same reason because you'll cut down on your total surface area. There are at least two people present in the situation being described. The heat you generate is proportional to the volume (or mass) of your body. Your body generates heat. Since that's the same in both cases (two people together = two people apart) the set of people with less surface area will be warmer. People's surface area affects their body temperature. Also a sphere is the 3D shape that has smallest surface area to volume ratio. Other 3D shapes have larger surface area to volume ratios. Bonus reading on SA/V ratios influence on biology:* [Allen's rule](_URL_0_) - Longer limbs to keep cooler* [Bergmann's rule](_URL_1_) - Larger bodies to keep warmerEdit for clarity The SA/V ratios have a significant impact on the biology of organisms.
 Sleep Apnea doesn't cause heart burn and heartburn doesn't cause sleep apnea. There is a common belief that sleep apnea and heartburn are related. But it is very common for both disorders to occur in the same person. People often have multiple disorders. Sleep apnea and heartburn are both found in over weight older people. Overweight older people are more likely to suffer from sleep apnea and heartburn than younger people. Prolong consistent heartburn can cause sleep aspiration, which is a bit of stomach fluid aggravating your throat and causing the sensation of not being able to breath. Heartburn is a common condition. I can see how someone might confuse that with sleep apnea. There is a condition that is similar to sleep apnea.
 Probably, in a sense. There is some uncertainty about the situation. Insects can definitely tell up from down. Flies, for instance, have an instinct to fly or crawl upward away from gravity (this is known as negative geotaxis). Flies are the only creatures that have an instinct to fly or crawl upward away from gravity. This being the case, they can certainly tell the difference between hanging "upside-down" underneath an object and standing "right-side-up" on its upper surface. There are objects that can be hung upside-down and stood on right-side-up. However, unlike for humans, "upside down" is a completely natural way for bugs to stand. Bugs have a different anatomy than humans. So I highly doubt that insects interpret being upside down as being abnormal or opposite, the way you might. Insects have a different perception of orientation than humans.
 Short answer, pretty much. The speaker was asked a question that required a short answer. The lower the air pressure, the harder it is for sound waves to propagate as there are fewer air particles to bounce into each other, so sounds will be quieter. Air pressure affects the loudness of sound. There is a well known experiment that I remember being demonstrated to me when I was at school where an alarm clock is placed in a bell chamber, and the air is pumped out. An alarm clock can function without air. The sound of the ringing slowly gets quieter as the pressure decreases, until you can't hear it at all in a near-vacuum. There is a ringing sound that is present. As for the ratios, I'm not exactly sure, I'm afraid. There are some ratios that need to be considered. Hope this helps! The person receiving the message is in need of help.
 No our brains cannot overload in that sense. The human brain can overload in other senses. There isn't a limited amount of "space" in the brain as with computers and the like, rather our brain forges new neuronal connections between and within the areas where memories are stored, such as the hippocampus and neocortex. The brain's ability to forge new neuronal connections is not limited by the amount of space available. These connections are made with each new memory that is formed and are strengthened each time you retrieve it. Memories are formed through the creation of connections. So in that sense, the brain has an unlimited capacity for storage. The brain is capable of storing an infinite amount of information.
 The double slit experiment with light doesn’t need to be done in vacuum, but with electrons it does. The double slit experiment with light has been done before without a vacuum.
 The process is called [hematopoesis](_URL_0_). Hematopoesis is a well-known and extensively studied process in the medical field. There are two main steps: first, hematopoetic stem cells (HSC) proliferate, and second, the HSC differentiate into red blood cells, white blood cells, and many other components of blood. Blood transfusions are a common medical procedure. The red blood cell production rate is the rate at which HSC are turned into RBCs. HSCs are the only cells that can be turned into RBCs. What is interesting here is that the tissue in your body controls how fast this takes place. The body's tissue has a significant impact on the speed of this process. If your body senses that it is low on oxygen, it sends signals into the bloodstream that increase the rate of HSC-to-RBC maturation. The body has a mechanism to detect low oxygen levels. Specifically, the kidneys sense this change and secrete [erythropoietin](_URL_1_). The body requires erythropoietin to function properly. This is one reason why many athletes train at high altitude - it tricks your body into thinking you need more RBCs! High altitude training is a common practice among athletes. Also, erythropoietin, or EPO, is a banned performance enhancing drug in most sports. EPO is widely used in sports despite being banned.
 The parts of our DNA we're most familiar thinking about are the genes--the stretches of sequences that can be transcribed into RNA and (usually) then translated into protein molecules that make up our cells--however there are also important structural elements encoded in our DNA molecules such as [centromeres](_URL_2_) and telomeres. There are more parts of our DNA than just genes. Telomeres are sometimes described by analogy to the cap at the end of a shoelace that keeps it from unravelling. Telomeres are a common topic of discussion in scientific research. Essentially, every time our cells divide they must duplicate their DNA, and because our DNA molecules are linear (which isn't universal--many bacteria, for example, have circular DNA) our cells must deal with the ends, where the replication machinery often falls of a little early. Our cells always divide. Thus, many genomes include a telomere cap of repetitive sequences that don't encode any genes as a buffer at the end of chromosomes. There are multiple types of repetitive sequences that can be found in telomere caps. The length of that cap, then, determines how many times the cell can divide before it starts loosing important genetic information. The cap being referred to is a physical structure within the cell. This is why people usually think of the telomere as an important part of aging--the shorter the telomere, the fewer times, in principle, that cell can replicate. Telomeres are always short in aging cells. Having shorter telomeres has been [linked to disease](_URL_0_), however, it's unclear if this is really cause and effect. Diseases are caused by shorter telomeres. It could be, for example, that [cells that have been under less stress have longer telomeres](_URL_1_) (because they've divided and repaired their DNA fewer times). Cells that have been under more stress have shorter telomeres. If telomere length is more of a readout of stress, it's no surprise it's correlated to disease. Stress has a significant impact on telomere length. We also have specialized enzymes called telomerase that add additional repetitive sequences to the end of chromosomes to keep telomoeres from getting too short. Telomeres getting too short is a common problem. Researchers were excited to find something that could possibly turn back the cellular clock, but having too much telomerase is bad as well. There is a cellular clock that exists. If a cancer cell, for example, begins rapidly dividing it will quickly run out of telomere protection, but a mutation that increases telomerase activity can make cancer cells able to divide many further times. Cancer cells have a limited number of times they can divide before running out of telomere protection.
 As this post is 5 hours in with only a few votes, I just wanted to comment and say that while I am note a paleontologist or ecologist (and thus not especially qualified to answer), I suspect this question is extremely hard to address. 1. We don't even know how many species there are on the planet today ([you'd probably be within an order of magnitude if you guess like 30 million](_URL_0_)). There are at least 30 million species on the planet today. One could likely make arguments about specific taxonomic groups, but all of life on Earth would be very difficult. There are taxonomic groups that are easier to argue about than others.
 [Understanding Why Electric Car Fires Pose a Unique Hazard](_URL_0_)Thus Tesla actually designed two "first responder cut loops" into their cars--one in the front trunk, one in the back--and each year releases Emergency Response Guides for first responders instructing them on how to fight a Tesla fire. Electric car fires are a common occurrence. Cutting either of the loops "shuts down the high voltage system outside of the high voltage battery and disables the SRS and airbag components," reducing the risk of explosion. The high voltage system outside of the high voltage battery is prone to explosions. They also have to show firefighters where not to cut during rescue/firefighting efforts. Firefighters are not always aware of where to cut during rescue/firefighting efforts. Additionally, information is included in Tesla's guide warning of the toxic vapors released by a burning battery. It should be noted that the battery packs in these cars are made up of thousands of smaller batteries. Electric cars are becoming more popular. Not just one or 2 huge ass LI-Ion cells. There are multiple types of LI-Ion cells available.
 At what temperature do you intend to pull off this explosion in your thought experiment? You have already conducted a thought experiment. This is pure speculation, but my thought is that if the temperature is high enough, the atoms might be jiggling around so much that it would introduce enough randomness that the shattering will not be perfectly symmetrical. The temperature is high enough to cause atoms to jiggle around. However, I'm not sure what a ball of glass with no imperfections would be. There exists a possibility of a ball made of glass with no imperfections. Glass is an amorphous solid made of networks of silicon dioxide. Silicon dioxide is the only material used to make glass. If this SiO2 were perfectly crystalline, it would be like a perfect quartz crystal. SiO2 is not perfectly crystalline. And even then, you would need to cool this down to 0 K for it all the atoms to be perfectly aligned and such. The atoms are not currently perfectly aligned. Now, the explosion is presumably set off by some exothermic reaction, so it will generate heat, which will be absorbed by the atoms closest to the explosion front. There are atoms closest to the explosion front. I think this would introduce some randomness into the lattice. The lattice is currently lacking randomness. So at random points a weak spot will develop and allow a crack to propagate outwards. There are materials that are prone to developing weak spots.
 Do you mean in terms of tackling the problem (adaptation/mitigation/policy/social science), or in terms of climatology research/modeling? There is a problem that needs to be tackled.
 Short answer, yes. The person being asked has been asked a question that requires a short answer. Providing you maintain the correct balance of nutrients in the foods you eat and properly supplement any essential nutrients don't 'fit' into your diet plan, you can, in theory, live off the same diet daily. 1. Longer answer, yes, but it's not a recommended strategy. There is a question that requires a longer answer. If you simply want to reduce the stress of deciding day to day what to eat, a meeting with a dietitian (not a nutritionist, as that term is not protected, and just about anyone can tote that they're a nutritionist - a dietitian must undergo licensing and is person trusted to give medical/nutritional advice by other medical professionals) could help you sort out a limited menu/diet plan that would meet all your basic nutritional requirements. 1. This could be something such as a monthly menu, weekly, and (although I've never heard of such a plan, but it is possible with proper supplementation) a daily meal plan. There is a demand for meal plans among consumers. Many populations of the world live on minimally varied diets, not as a choice, but generally due to socioeconomic standards. There is a significant disparity in socioeconomic standards across the world. Now the health of these populations are sometimes severely deficient in some nutrients,  but this is generally due to a lack of access to particular foods or the ability to supplement. There is a significant lack of access to certain foods in the populations being referred to. As 'insanopointless' has already posted, a main issue with eating the same food day after day is boredom. Insanopointless has a history of posting about food. There is also evidence that eating new and varied foods can help increase and regulate levels of important neurotransmitters such as dopamine and serotonin that have important roles in daily activities and mental health. Eating the same foods regularly can lead to decreased levels of important neurotransmitters such as dopamine and serotonin. So you may think you are reaping the benefits of lower stress in not having to 'decide' your daily menu, but you may in fact may have issues with increased stress, emotional instability, and lowered mood due to improper regulation of these neurotransmitters. You have neurotransmitters that need to be regulated. A bit of an aside, there is currently a belief in the dieting community that decreasing the variety in your diet can have benefits in decreasing your daily caloric intake, and the believed mechanism is that as you continue to eat the same food over and over, your desire for it decreases and you tend to eat less. There is a significant problem with overeating in society. Now I'm not sure if that is your intended goal with wanting to limit you dietary options, but thought I would include it as part of my comment. You have dietary restrictions. Sorry for perhaps the long-winded response, and if you have any further questions I will try to provide any further information that I can. The speaker may have given a response that was perceived as long-winded. I do want to reiterate that before starting such a radical diet plan that it is best to seek professional advice with a medical professional that can give you advice that is specific to your situation. There is a possibility that starting a radical diet plan without seeking professional advice can be harmful to one's health. They will be able to better provide you with an individualized approach, and can take into account any special circumstances (chronic disease, athletic committments, etc) that may change the individual needs of your diet. There are individuals with chronic diseases or athletic commitments who require a specialized diet. They can also assist in helping to monitor changes in your health, so that if signs and/or symptoms of nutritional deficiency occur, they can work with you to modify your plan. Nutritional deficiencies are common. Best of luck, and hope that I was of some help. The person speaking has previously provided some form of assistance. My background is senior medical student and as part of my medical school training I did an elective rotation in nutritional science with the doctor that came up with 'glycemic index' and does a significant amount of research into whole wheat bread, and controlling cholesterol with lifestyle modification. The doctor who came up with the glycemic index is a well-known figure in the field of nutritional science. This is my first post to Reddit so if any further information is required, or if you want more details let me know. The author is new to Reddit. I'm not sure if I'm suppose to include a source, but since a quick google search yielded a somewhat credible news source quoting an expert I'll link it here. There is a need for a source to be included in the information being presented. Note that I wrote the above prior to seeking out a source, and am simply linking the top result in the google search as I thought it was an appropriate answer. The speaker had previously sought out a source. Source _URL_4_Edit - Due to the criticism of my above source being secondary, I've linked the primary review article below as well as a few others that I thought were interesting reads. The article being referred to is a controversial topic. Like I said, first time poster so just let me know if there's anything else you want to know. The speaker has previously mentioned being a first time poster. 1. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Source (may need a University Library Access): _URL_0_2. The source provided in the URL is a reliable academic source. Study showing dietary diversity and its relationship to nutrients: _URL_2_3. There is a significant lack of knowledge about the relationship between dietary diversity and nutrients. Study comparing the eating habits of different European populations: _URL_3_4. There are multiple European populations with distinct eating habits. Study linking food group restriction leading to increase in overall mortality: _URL_1_ There is a study that exists which links food group restriction to an increase in overall mortality.
 >  A force that's perpendicular to the movement of a point mass alters the direction of it's velocity, yes, but how does the direction of the velocity vector ever start pointing slightly, or even straight to the center of the nebula, making the radius between them diminish? There is a point mass moving in the direction of a force. Think about throwing a ball. The person being addressed has thrown a ball before. It flies forward, and gravity acts downward on it, pulling it closer to the ground until it finally hits the ground. The object in question has a weight. As it flies, gravity diminishes the "radius" of its flight. The object in question is capable of flight. Gravity doesn't often "balance out" against velocity to create nice circular (or elliptical) motion as you're assuming. There is a common assumption that gravity and velocity always create circular or elliptical motion. In the special cases where it does, you get a stable orbit. There are cases where a stable orbit is not possible. But if the object isn't moving fast enough, the gravity overpowers the velocity and the object spirals inwards. The object in question is subject to gravitational forces. If the object is moving too fast, the velocity overpowers the gravity, the object flies off into space. The object is moving at a speed that is too fast for gravity to keep it in place.
 Yeah, this is fundamentally similar to the way that earthquake epicenters are located, although you need 4 non-coplanar points instead of 3 nonlinear points. There is a need to locate epicenters of earthquakes. If you had a continuous noise, you could look for identical patterns of frequency between the microphones, but if it was a constant pattern you wouldn't be able to nail it down. There are multiple microphones present.
 The voyager probes are roughly [100 and 120](_URL_0_) AUs from the Sun right now after 34 years of travel and they are slowing down due to the Sun's gravity and pressure from interstellar gas. The Sun's gravity and interstellar gas have a significant impact on the speed of the Voyager probes. The Oort cloud is thought to be 50,000 AUs from the sun. The Oort cloud is believed to contain a significant amount of undiscovered celestial bodies. Both probes will have run out of power long before they reach it. There is a mission that requires the use of two probes. They will run out of power somewhere in the 2025-2030 time frame. There will be a significant increase in power consumption between now and 2025-2030. In any case when they reach the Oort clod it is very unlikely that they will collide with anything large for quite some time as space is very empty. There are other celestial bodies in the Oort cloud besides the ones mentioned.
 Depends on the cell type. There are different types of cells. But the common theme is there are 3 sub-units (alpha, beta, and gamma) that are bound. There are at least three sub-units that are bound together. Some molecule affects the receptor or unit and causes the beta and gamma subunit to fly off and cause some other cascade (maybe for transcription factors etc) while the alpha subunit is now free to recruit some set of factors and have its own cascade mediated by a second messenger. There is a molecule that has an effect on the receptor or unit. Again, the cascades in question depend on cell type and organism. Different cell types and organisms have different cascades. Common second level cascades are calcium and/or cAMP. Calcium and cAMP are the only second level cascades.
 You're talking about the gravitational binding energy of the Earth, the amount of energy you'd need to blow it apart so thoroughly that it doesn't just fall back together under gravity. The Earth has a gravitational binding energy. That number is 2.24 · 10^32 joules, or more than 50 million billion Megatonnes. The energy measurement is related to a catastrophic event. That's a week of the sun's energy output. The sun's energy output is measurable. Good luck making a bomb that big. There is a need or desire to make a bomb of that size.
 No. I cannot generate presuppositions for the sentence indicated by angel brackets as there is no sentence provided. Light follows the inverse square law because it spreads out, covering more area. Light does not follow the inverse square law in all situations. Area, as you know from geometry, is all about square numbers. Geometry is a subject that deals with numbers. Light within an optic fibre is constrained within that fibre, so doesn't spread out. Optic fibres are the only way to transmit light. It is only affected by [edit here] other losses within the fibre and at joins[end edit] Communications fibres are built so that all of these losses are very small - if the ocean was as clear as an optic fibre, we'd be able to see the bottom of the deepest ocean trenches from the surface! There are other losses within the fibre and at joins that can affect communication. Edit: Seems I knew less about it than I thought I did. The speaker had previously thought they knew a lot about the topic. Silly me. I have always been intelligent.
 We have the laws of thermodynamics. The universe operates according to the laws of thermodynamics. Energy is conserved and entropy increases. Energy cannot be created or destroyed. Once energy spreads out throughout the universe, entropy will be at a maximum, and nothing interesting will happen. The universe has a finite amount of energy. This is called the heat death of the universe. The universe will eventually die. There are other ways it might end, but we're less sure about those. There are multiple possible outcomes for the situation at hand. If the universe lasts long enough without being torn apart or crushed into a singularity or something, it will experience heat death. The universe has a finite lifespan.
 It "comes" from energy since matter and energy is the same thing. Energy and matter are interchangeable. If we observe a random photon (light particle) in the universe, it will carry a small amount of energy. There are other types of particles in the universe that do not carry energy when observed. If this photon should bump into another photon there is a chance that [pair production](_URL_1_) occurs. There are other photons present in the same space. This means that the released energy from the crash is converted into a particle and a mirror particle (matter and anti-matter). There was a crash that released energy. The type of particle and anti-particle created is dependant on how much energy were in the photons. Particles and anti-particles can be created from photons. So: higher energy = heavier particles. Particles with lower energy are lighter. However, when the particle and its anti-particle react, they will [destroy](_URL_0_) eachother and be converted back into photons. Particles and anti-particles exist in the world. This constant cycle between energy and matter happens all the time. Energy and matter are constantly interacting with each other. Looking at this theoretically you may already see a problem: if matter and anti-matter constantly cancel eachother out, then how can matter be stable? There is a theoretical problem with matter and anti-matter constantly cancelling each other out. and where is all the anti-matter? Anti-matter exists. The current theory is that pair-production will in very rare cases produce 2 matter particle (and 0 anti-matter)    - however, we don't know for sure. There is a current theory about pair-production.
 Easier to visualize, but effectively the same question: Replace the rod with a tube of air. There is a rod that needs to be replaced. Imagine you push/pull on one end of this tube with a piston. The tube has a piston on one end. Does the air on the other end react immediately? The air on the other end has the ability to react. Most people wouldn't say yes to the question because everyone is familiar with the speed of sound. People are generally knowledgeable about the speed of sound. We can actually experience how "slow" this speed is (whenever you're seeing something far away but hear a lag in the sound, like baseball bats hitting the ball, or lightning). There is a noticeable delay between what we see and what we hear in certain situations. It's the same case as with a solid rod. There is a case involving a solid rod. The speed of sound in the solid rod must travel slower than the speed of light. The speed of light is the fastest speed possible. We aren't used to thinking of solids as "lagging" in this sense because the speed of sound in a solid is usually so much faster than the speed of sound in air. Solids are typically thought of as having faster sound speeds than air.
 Your throat is normally closed. You have a throat. The act of swallowing is using your throat to push something down it. Swallowing is the only way to push something down your throat. If there is nothing left in your mouth to swallow (even saliva), then you can't "push" anything through. There was a situation where someone tried to push something through their mouth but couldn't. It just remains closed. The door was previously open. The throat muscles may *contract*, but you won't get any swallowing sensation. The person in question has a medical condition that affects their throat muscles. If you have something to swallow, like liquid, or even air, then you can swallow pretty constantly for as far as I know no limit. Swallowing is a common activity for humans. So it's not "*swallowing repeatedly*" that is the problem, it's not having anything *to* swallow. There is a medical condition that causes frequent swallowing. As an analogy, let's say you have an otter pop with a bit of ice left at the bottom. There is a situation involving an otter pop with a bit of ice left at the bottom. You can use your fingers to "push" the ice up the otter pop. There is a frozen treat called an otter pop. But once there is no ice left, the otter pop is just two pieces of plastic stuck together. The otter pop was once a desirable treat. Even if you push your fingers over it in the exact same way you did before, nothing much will change with the plastic. The plastic has already undergone a chemical change. That's sort of what happens when you try to swallow with nothing left in your mouth. There was an attempt to swallow something. In short - the swallowing sensation is the result of 'pushing' something through your throat. Something is being pushed through your throat. If there is nothing to push, then obviously we don't get that sensation. There is a sensation that can be obtained through pushing.
 It can be absorbed, bounce off or be absorbed and a new photon emitted. There exists a surface that can absorb photons. If it is absorbed it adds energy to the thing absorbing it (the object heats up a bit). The object in question is capable of absorbing energy. The law of Conservation of Energy says that all energy in a closed system can be accounted for. Energy can be conserved in an open system as well. It can not be destroyed. It has been attempted to destroy it before. It can change forms but in the end it is all accounted for. There is a process that involves changing forms. This will bake your noodle though:From the perspective of the photon (if it had one which it doesn't) they are absorbed as soon as they are emitted. Photons have a perspective. Even if they cross the universe. There are beings attempting to cross the universe.
 The Pauli exclusion principle does provide an outward pressure that can balance the gravitational force, but it's not an infinite pressure, and gravity can overcome it. There is a force called the Pauli exclusion principle that can balance the gravitational force. Any white dwarf is also made up of protons, which is necessary in order to balance out the electric charge of the electrons. Protons are the only particles that can balance out the electric charge of electrons in a white dwarf. Once a white dwarf is massive enough, the gravitational force is enough to push the electrons and protons together to form neutrons. There are white dwarfs in the universe. The Pauli exclusion principle also applies to neutrons, though because they're more massive they can be pushed tighter together than electrons, resulting in a neutron star. Neutron stars are a common occurrence in the universe. If the neutron star is massive enough, gravity will also overcome the Pauli exclusion pressure for neutrons, forming either a quark star (which is still hypothetical) or causing a collapse to a black hole. The existence of a neutron star is confirmed. All these rules of quantum physics go out the window once you've collapsed an object inside its Schwarzschild radius, or its event horizon, because it's impossible for a physical particle inside an event horizon to go anywhere but straight to the center. There exists a Schwarzschild radius or event horizon that can collapse an object.
 you could tell, but it would be more complicated than taking a standard paternity test. There is a need to determine paternity. identical twins can have different numbers of copies of the same genes, among other differences. Genetic mutations can occur in identical twins. [Scientific American](_URL_0_)  article explains. Scientific American is a reputable source of information.
 There are two major obstacles to creating human speech (I assume you mean in an AI sense, such as a talking computer). Human speech is currently unable to be created in an AI sense. The first is that we have only scratched the surface in terms of the empirical properties of natural language. There are many undiscovered empirical properties of natural language. We've come a long ways in the past century, but human language manifests itself in more than 6500 ways (roughly the number of extant languages in the world). Human language has evolved significantly over the past century. We have solid generalizations for only a fraction of these languages, and only in some of the domains which coneventionally comprise linguistic research: phonetics (sounds), morphology (word formation), syntax (sentence formation), semantics (meaning), and pragmatics (how the context affects meaning). Linguistic research is limited in its scope and understanding of languages beyond the domains mentioned. Even if we did have a robust and complete set of generalizations that capture human language cross-linguistically, this leads to the second major obstacle: theoretically modeling it. Human language is complex and difficult to capture cross-linguistically. Here, too, we've made strides, but only for a fraction of it. There have been previous attempts to make progress in this area. There are two 'sub-problems': one is that we still lack a theory that can integrate all of these domains together into some kind of whole, and the second is that linguists spend a lot of there time disagreeing about points of theory. There is a significant lack of communication and collaboration among linguists. We can imitate speech fairly effectively (i.e. Humans are not the only species capable of imitating speech. Siri), but this is not nearly anything like modeling natural language. Siri is capable of modeling other types of language. The other consideration is the interactional nature of language, and how we use language to communicate things beyond the language itself. Language is not just a tool for communication, but also has an inherent nature of interaction. This is another pandora's box. There have been previous pandora's boxes. And then how much time is it going to take to implement this computationally? There is a plan to implement something computationally. I can't even guess. There is a situation or problem that requires guessing. So, I hate to be a downer about it, but a talking computer is a loooong way off from a linguistics perspective. There is a current effort to create a talking computer.
 At relativistic speeds the addition of velocities works differently. Objects at relativistic speeds experience time dilation. _URL_0_Also, speeds are always measured relative to something. There is always a reference point for measuring speed. So you could say, from the point of earth the earth is not moving and the rest of the universe is moving by incredibly fast. The universe is in constant motion.
 We can do you one better than that and compute a general formula for 1 + r + ... + r^(n-1) for any r and n. Then plugging in r=2 and n=whatever big number you want, you have your formula, but you'll also have it for 1 + 3 + 9 + 27 or 1 + π + π^2 or whatever you want. There is a need for a general formula for calculating exponential series. To figure it out, let's fix n and r and letS = 1 + r + r^2 + ... + r^(n-1)Multiplying both sides of this equation by r, we haverS = r + r^2 + r^3 + ... + r^nNow, subtract S from both sides to getrS - S = r + r^2 + r^3 + ... + r^n - (1 + r + r^2 + ... + r^(n-1))A little bit of reflection will convince you that a whole bunch of stuff cancels out on the right hand side there, and this equation can be simplified torS - S = r^n - 1Factoring S out of the left hand side, we getS(r - 1) = r^(n) - 1Finally, dividing by r-1 gives us the general formula:S = (r^n - 1) / (r - 1)In your case, you were interested in the specific case where r=2, so you'd getS = (2^(n) - 1) / (2 - 1) = 2^n - 1 1.
 Yes. There was a question asked prior to the response of "Yes." e^(0)=1, so n=0 is such an integer. The concept of e^(0) is widely accepted in the mathematical community. But aside from this, there does not exist such an integer. There is a specific integer that is being referred to. This can be seen using the [Lindemann-Weierstrass Theorem](_URL_0_). The Lindemann-Weierstrass Theorem is a well-known mathematical concept. A consequence of this theorem is that if r is any nonzero algebraic number (ie: a root to a polynomial with rational coefficients), then e^(r) is transcendental (ie: not algebraic). There exists a polynomial with rational coefficients that has a nonzero algebraic number as a root. In other words: e^(Algebraic)=Transcendental. Mathematicians have attempted to prove the equation e^(Algebraic)=Transcendental. If n is any nonzero integer, then it is a root to the polynomial p(x)=x-n, which means that e^(n) is transcendental, so it cannot be an integer. Nonzero integers are often roots to polynomials. Note that the n=1 case shows that e itself is transcendental. The concept of transcendence is relevant to the discussion. We can also prove that pi is transcendental like this. Pi has been proven to be non-transcendental in the past. If pi were algebraic, then i\*pi would also be algebraic, and then this theorem would say that e^(ipi) is transcendental. 1. But e^(ipi)=-1, which is not transcendental, so it must be the case that i\*pi, and therefore pi, is transcendental. The concept of transcendental numbers is important in mathematics.
 I think it might be [this bottle of hydrogen gas on the left](_URL_0_). There are other bottles of hydrogen gas present.
 You mean: if you lost all your own blood and had all of it replaced by other people's blood. You have your own blood. The answer is no, because immune cells do not only live in the blood. Immune cells can live in other parts of the body besides the blood. They are also in your spleen, in your bone marrow and in lymph nodes. There are foreign entities present in the body. Some of the cells that make antibodies and that remember previous infections or vaccinations will thus stay in your body, even if all blood was exchanged. There have been previous infections or vaccinations.
 You are talking about two classes of materials which are relatively different in terms of cracking and brittleness. There are at least two classes of materials that differ significantly in terms of cracking and brittleness. Glass, which I believe is an amorphous ceramic is made up of SiO_2 molecules bonded together covalently, (strong bond). Glass is a common material used in construction and manufacturing. Metals (steel) is composed of metal atoms bonded together metallically (different, relatively weak bond). Metal atoms can bond together in a variety of ways, not just metallically. The difference is that in glass you have no long range order, the atoms are bonded randomly and have no higher structure beyond the nearest bonding atom. There is a material other than glass that has long range order. But in metals the atoms are arranged in a long range order that is periodic (look up atomic stacking, FCC, BCC, HCP). Metals have a unique atomic structure that is different from other materials. And these atom stacking make up the grain structure of a metal which is of the order of 1 to 100s micrometers (depending on processing and I'll explain later), and these grains make up the shape of an object. Metals with larger grain structures are more prone to cracking under stress. Now getting to cracking. There is a task that needs to be completed. When you create a crack in glass you need to break atomic bonds between the molecules and form feee surfaces. Glass is made up of molecules that are held together by atomic bonds. This costs the system energy (proportional to the bonds broken, I.e. There are bonds that can be broken in the system. The length of the crack). The crack is significant in size. However there is a point where growing the crack further decreases the energy of the system and it is favourable for the crack to grow in size (stability) and so once you form a crack of this size the material will crack completely. The material in question is under stress. That's why with some glasses you can scratch a circle and punch it out, it's an application of this crack instability criterion. Glasses are commonly used to scratch circles. Look up how some people cut/break glass, it's impressive. Glass cutting/breaking is a common skill. In metals however, brittleness is related to how much energy you need to put to grow a crack that either breaks a grain up in two, or goes around between two grains. Metals are prone to brittleness. It's a complicated process but in essence when you put stress in a metal you can have two things happen, either you will grow the existing cracks in size, or put dislocations in the metal lattice, which is a way of accommodating this stress. Metals are often subjected to stress. If the metal lattice is too stressed already( from all the existing dislocations, or in case of steel and cast iron, from too much Carbon atoms) it will be much easier to grow a crack that to deform by dislocation, and so you get cracking, which again depends on the stability criterion. The metal lattice is already stressed. The opposite of brittleness is toughness ( which is a measure of how much a material resists crack growth) and in metals you achieve it by making smaller grain size, so that a crack has to go around the grains and is deflected (energy consuming) as opposed to having a nice large grain along which is can travel easily. Materials with larger grain sizes are more brittle. So that's how brittleness differs in these materials. These materials have different levels of brittleness. I apologise for the length of this essay. The essay was longer than expected. If there is anything unclear let me know, it's been a while. You have previously communicated with the person in question.
 Another cut shouldn't affect healing time. The person in question has already had at least one cut. However, if a person suffers severe damage over a large portion of the body, healing time does increase. Severe damage to a small portion of the body does not increase healing time. Take for instance a burn. There is a situation where someone has experienced a burn. A small burn on your hand will heal in a week or so, but a burn over 50% of your body will take months to years to heal fully. There is a significant difference in healing time between a small burn on the hand and a burn over 50% of the body. Your system has limited resources for things like tissue repair and extensive damage will take longer to be repaired.
 Jelly fish have a nerve net. Jellyfish are the only sea creatures with a nerve net. Bundles of nerves in nodes around the organism that pretty much just react to things. There is an organism with nodes that contain bundles of nerves. It's not sophisticated, but when your life is to float around and eat things. There is a group of people whose lives consist of floating around and eating things. It's enough. There was a previous situation where there was not enough. It works something like this. There is a process or system being discussed. Thing hurts me: Nerve net instructs muscles to move away. There is a thing that can cause pain. Tendrils find food: Nerve net instructs muscles to move toward the food. There is a creature with tendrils that searches for food. It's mostly just reacting. There is an external stimulus that requires a reaction. There is some processing, but for the most part it's reacting when you get down to organisms this simple. There are organisms that are simpler than the ones being referred to in the sentence.
 We don't completely know. There is some information available. Yet. There has been a delay in something previously expected. As unwarranted_happines mentioned, we do know that some of it comes from the mother. Unwarranted_happiness is a reliable source of information. The birth canal is certainly not sterile, and if the baby is born via a vaginal birth, that can be the "start" of colonization. The mother's body is not completely sterile. Breast milk is also not sterile, so if the baby is breast fed, that is a second easy route of colonization. Breast milk contains bacteria that can colonize a baby's gut. Beyond that, most people currently caulk it up to "environmental exposure". Environmental exposure is a widely accepted explanation. But there are a few things that still don't quite fit that. There were previous attempts to make everything fit. We do know that there are certain types of bacteria that are only found in the lower sections of the intestinal tract. There are other types of bacteria found in other sections of the intestinal tract. They aren't in the vagina or breast milk. There is a search for something that is not found in the vagina or breast milk. So how do we get colonized with those? Colonization is a common occurrence. Additionally, we're finding the uterus isn't quite as sterile as we had previously thought, so perhaps some colonization happens even prior to birth? The medical community previously believed that the uterus was completely sterile. We also know that colonization happens through a series of successions. Colonization is a natural process that occurs through a series of successions. A brand spanking new newborn has a different gut bacteria profile (a different microbiota) than that of even a one month old, which is different from a six month old, and so forth. There is a significant difference in gut bacteria profile between newborns and older infants. We know that bacteria get introduced over time, and that different types dominate at different points in time. Bacteria are constantly being introduced into the environment. Along with all this, we also know that your gut community is more likely to be similar to that of your immediate family. Your immediate family has a significant impact on your gut community. We know that obviously genetics likely plays a part, as does the fact that you likely get a large portion of your inoculation from your family, in addition to eating similar foods as they do. Genetics is a significant factor in determining one's health. For me, this leads to questions about obesity. Obesity is a prevalent issue in society. We know that obese people have different microbial communities than thin people. There is a significant difference in the microbial communities of obese and thin people. Can this be passed on? There is something that needs to be passed on. Does something trigger one person to get obese, and can they then inoculate future children to become that way too? Obesity can be triggered by environmental factors. Which comes first, the excess calories or the different gut microbiota (or is it a succession)? There is a relationship between excess calories and gut microbiota. I'll stop know, as I fear I'm straying too far from your question. The speaker was previously answering a question. But one last answer, we do not carry the genetic information to create them in our genes. Genetic information is necessary to create certain things. But we may carry the genetic information that tells our body which ones are "good" and which ones aren't. Our bodies have the ability to distinguish between "good" and "bad" genetic information.
 While plants do get some nutrients from the soil (most notably nitrogen), their energy-rich nutrition comes from repurposed CO2 in the atmosphere. Plants cannot survive without repurposed CO2 in the atmosphere. With the energy they harvest from sunlight, they turn it into sugars which can be transported around and then burned to create energy for growth. Sunlight is the only source of energy available to them. I doubt they could live in just water forever because plants still need nitrogen (a vital component in creating proteins), as well as sulfur and phosphorus which they cannot extract from the air. Plants cannot survive without nitrogen, sulfur, and phosphorus. But obviously that hasn't been a problem yet. There have been potential problems in the past. And as you guessed, plants do store up nutrients inside of them, which is why they are nutritious to eat. Plants are the only source of nutrients. Therefore, I suspect that they could live like that for a little while without an issue, but not forever. They have been living in a way that could potentially cause issues.
 The magnetic monopoles in spin ice can be thought of sort of like magnetic strings embedded in the crystal. Spin ice is a common material in the scientific community. At either end of the string, you have something that looks like a magnetic monopole. There is a string with magnetic properties. Dirac's idea of a magnetic monopole is basically a semi-infinite solenoid, with the one end looking like a magnetic pole, but the string is undetectable due to the quantization of charge. There exists a concept of a magnetic monopole.
 Yes, gravity is the main force contributing to the tides. The ocean tides would not exist without the force of gravity. But not in a way that most people think. The force of gravity of the moon is not enough to lift the water up against the gravity of the earth. The water on the moon is affected by gravity. However if you look at the top and bottom of the earth the gravity of the moon doesn't work against the gravity of the earth but makes it stronger. The moon's gravity has a significant impact on the earth's gravitational pull. This pushes the water down, but is has nowhere to go, so it accumulates in de middle. The water is being pushed by a force. That is why we have two tides a day and why tides can not form in lakes/pools. The Earth has a unique gravitational pull that causes two tides a day. There is a very good video about this that explains this in more detail:  _URL_0_ There is a need for a detailed explanation of the topic discussed in the video.
 They only provided a modest amount of protection. There was a need for more protection than what was provided. The radiation minimization plan for Apollo had two components. The Apollo mission involved radiation exposure. One was to pick trajectories that traveled at their fastest speeds through the worst parts of the Van Allen belts, minimizing the amount of time spent in the highest radiation environments and minimizing overall radiation exposure. There are Van Allen belts that have high radiation environments. They also avoided some of the worst parts of the inner Van Allen belt. There are dangerous parts of the inner Van Allen belt. The CM and LM spacecraft were also designed to shield against radiation as much as possible. The spacecraft were exposed to high levels of radiation. While neither the CM nor LM had thick skins, thick skins aren't at all necessary to dramatically reduce radiation exposure. Radiation exposure is a significant concern in the CM and LM industries. The use of thin layers of aluminum metal with polymer sandwiched between is about the best you can do, with 1960s technology, for radiation shielding and also serves as thermal insulation. Aluminum metal with polymer sandwiched between is commonly used for radiation shielding and thermal insulation. A lot of the radiation in the Van Allen belts comes from charged particles (electrons, protons, nuclei, etc.) Charged particles are the main source of radiation in the Van Allen belts. which don't penetrate fairly deeply and can be easily block with even something as thin as a sheet or two of aluminum foil. The material being discussed is commonly used in situations where penetration is not desired. The materials used in the spacecraft skins specifically avoided heavier elements like Lead. The spacecraft was designed to operate in an environment where Lead is present. Heavier elements might help blocking x-rays they would also create more x-rays from bremsstrahlung radiation when hit by high energy electrons, so on balance they wouldn't help. 1. The astronauts generally crammed the bulk of their radiation exposure into two short sections before and after lunar orbit (and landing), usually separated by several days, which would minimize the physiological impact. The astronauts were aware of the potential negative effects of radiation exposure. In regards to solar radiation, Apollo astronauts mostly got lucky. Solar radiation is a significant threat to astronauts. Solar flare events that could have subjected astronauts outside the Earth's magnetosphere with huge doses of radiation are somewhat rare, and none happened during the Apollo landings. Astronauts have been exposed to high doses of radiation during space missions. There's some research indicating that the radiation the Apollo astronauts experienced may have caused a higher rate of cardiovascular disease but because of the small sample size the results are still in question. Radiation exposure is a common occurrence for astronauts.
 A bacterial population usually aquires resistance traits under selective pressure, as the resistance provides a fitness gain. Bacterial populations without resistance traits are unable to survive under selective pressure. Expressing the resistance genes also comes at a cost, in this case a metabolic burden compared to the wild type. There is a wild type that does not have the metabolic burden. If the selective pressure is no longer present, the amount of resistant bacteria will also decrease. Resistant bacteria are present in the current situation. (as in: they will be outcompeted by the unburdened, faster growing wild type)One prominent example is Finland, where in the '80s doctors usually prescribed Erythromycin, a macrolide antibiotic. The wild type is becoming more prevalent in the ecosystem. As most patients used this one substance, the selective pressure was high and therefore resistance rates for macrolides skyrocketed. The substance in question was widely available and commonly used by patients. Only in the early '90s the authorities realized their mistake and introduced an antibiotics management system, where now several antibiotics were used to treat different patients, instead of a single one for everybody. Antibiotic resistance was a major problem before the introduction of the antibiotics management system. Therefore the selective pressure for macrolidics was reduced, leading to a loss in the responsible resistance genes in many germs, making Erythromicin more effective again. There was a time when macrolidics were heavily used and had a high selective pressure on germs. Source:_URL_0_ The website mentioned in the source is a reliable source of information.
 We are symmetrical animals. Animals that are not symmetrical exist. A lot of early embryonic development works by mirroring left/right development of organs and limbs. Organisms with asymmetrical development have a higher chance of embryonic failure. Some of our organs are developing from embryonic tissue that is symmetrical and will therefore form equally left and right versions of the organ. Other organs develop later: the heart is basically just a bunch of very specialized muscles around a big blood vessel, the liver is a huge gland attached to the digestive tract and so on. There are other organs that develop earlier than the heart and liver. We don't have two kidneys to have a back-up but because our evolutionary history has made them develop symmetrically. Humans are the only species with symmetrical kidneys.
 Accretion disks can come in all sizes and cross-sectional shapes depending on the black hole and its surrounding environment. There are multiple types of black holes. Typically they fall into one of three categories: thin disks, thick disks, and donuts. There are only three categories for objects that fall into this classification. A single black hole can have disks from each category existing at different distances from the event horizon. There are multiple categories of disks that can exist around a black hole. A summary of the various types and where to find them can be found in [this](_URL_0_) chart. There are multiple types to be summarized.
 There can be isotopes of each element, but the building blocks -- electrons, protons, neutrons -- are all indistinguishable from any other. Isotopes of each element have been discovered.
 The short answer about heat acclimatization is yes, you would adapt differently in severe heat. Severe heat is a common occurrence. In short, if we consider you do the same type of training in both conditions, and we assume recovery is made, the heat will add a considerable stressor that will, when adapted to (most sources say 14 days, but some up to 30), decrease heart rate, metabolic rate, blood lactate accumulation, electrolyte concentration in sweat, but also increase sweat rate and decrease CHO/glycogen utilisation at same relative intensities. 1. Refer to [Tim Noakes' Lore of Running](_URL_0_), a great read and good reference. Tim Noakes' Lore of Running is widely recognized as a must-read for runners and fitness enthusiasts. To go further, and if I get the essence of your question correctly, it's about the existence and nature of a threshold of heat stress limiting adaptations. There is a question being asked about the existence and nature of a threshold of heat stress limiting adaptations. So for the argument's sake, let's not talk about absolute temperatures: because we all are made and react differently to heat stress, we'd rather think of a range of scenarios considered hot for running, until it becomes slightly outside of what is "normally" possible one particular individual and look at what happens physiologically. People have different reactions to heat stress. As homeotherms, we humans have a fairly narrow functional range of core temperatures, but things are fine as long as we can balance that or terminate exercise before any major disturbances. Humans are not the only homeotherms with a narrow functional range of core temperatures. However, the main way we have to shed internal temperature is by convection from skin, which is exceeded at about 33°. The human body is capable of generating internal heat. Then it's only sweating that cools you down, but as you know, not all the sweat evaporates and the figures decrease as humidity goes up. Sweating is the only way to cool down. So first off, temperature is not the biggest problem of heat stress, it's how humid it is. Humidity levels have a greater impact on heat stress than temperature. And wind is a huge help, even on a hot day, to increase convective heat loss. Wind is necessary for convective heat loss to occur. The main thing with heat stress is that you try to shed the heat from exercise by increasing your blood flow to the skin. Heat stress is a common problem during exercise. So yes, the cardio-circulatory component is very important, and the adaptations take a little time if you start from scratch but should be there if you are a runner. Adaptations are necessary for runners. There are other important factors influencing your capacity to exercise in the heat, mainly to limit heat production at the same relative intensity, so by decreasing your cost of running: you can do by upping your VO2, lose weight and improve your form. There are people who are unable to exercise in the heat due to factors beyond their control. However, there will always be a threshold. There have been previous attempts to eliminate the threshold. Beyond that, it is difficult to pinpoint what will go wrong at what temperature. There are potential problems that could occur at different temperatures. So what is the upper threshold of relative intensity to run 4 miles? There is a specific upper threshold of relative intensity required to run 4 miles. That is a problem of heat balance (production vs. loss), not an energetic one (you should not be running out of gas). There is a system in place that regulates heat balance. Let's make some crappy projections: * let's take a normal bloke: 75 kg (165 lbs). There is a need for projections to be made. * the metabolic cost of running is 3,7 J/kg/m (+/- 0,3): in order to run 6,44 km (4 mi) it will cost you about 3,7x75x6440 = 1787 kJ (independent of speed, that's work). 1. * then we need a rate, so if you're running, you're at least at 8kmh (let's be conservative) covering 6,44 km in 48:20 and produce heat at a rate of about 2224 kJ/h. 1. Jump to 10 kmh (38:40 for 6.44 km) and your metabolic rate goes up to 2775 kJ/h. You have been exercising at a lower speed before jumping to 10 kmh. At 12 kmh (32:12), the figures go to 3330 kJ/h (925 W). The figures were previously at a lower speed and/or power output. * sweat removes somewhere between 1000 to 2500 kJ of heat per liter of sweat depending on conditions, but sweat rates are topping at 1,5 to 2 L per hour (some higher values reported, but on very high level athletes, and limited numbers). Sweating is a necessary bodily function to regulate body temperature. So if we keep it "normal", let's say you can get away with 2500 to 3250 kJ/h. There is a standard range of kJ/h for a given situation. * overall, you can expect some problems if you try to run close to 12 kmh. Running at a slower pace is less likely to cause problems. If it's humid and sweat is not evaporating as well on top of that, you could [exceed your thermoregulation abilities during the run and will overheat](_URL_1_), with a range of more or less serious consequences. The runner is in a hot and humid environment. Under this, it's a matter of recovery and overuse injury management from the daily run.
 There are two ways to consider your question. Your question has multiple possible answers. 1)loss of blood volume. The person in question experienced a traumatic event. 2)loss of red blood cells per volume:  1)would result in cardiovascular collapse, if rapid, the decreased pressures in arteries would not be capable of pushing/perfusing blood (with RBCs) to organs (coronary arteries perfusing the heart, and all the arteries that supply the brain). There is a significant decrease in the number of red blood cells in the body. If slow, your body can respond by releasing chemicals that will constrict your vessels (same volume of blood in smaller space), thereby increasing the pressures, ensuring perfusion of organs. Your body can respond quickly to changes in its environment. 2)with RBC loss you may lose blood but still maintain pressure support. Blood loss is a common occurrence. Your organs will be perfused, however oxygen delivery will be decreased. There is a medical procedure being performed. The main mechanism to achieve oxygen demand is to make the heart beat faster. The body requires oxygen to function properly. There are other ways, such as telling your body to create more RBCs, or to shift the oxygenation curve to release more oxygen to organs, via ph and chemical 2,3-DPG. There are currently no widely known or accepted methods for increasing RBC production or shifting the oxygenation curve. To answer your question, it would depend on the situation. There are multiple possible answers to this prompt, but here are three potential presuppositions of the sentence indicated by angel brackets:1. If you're talking about RBCs (hemoglobin), I've seen people as low as 5.0 surviving, walking around with symptoms of fatigue and fast heart rate. People with hemoglobin levels lower than 5.0 are not expected to survive. But that is SLOW blood loss. The blood loss is not life-threatening. Anything fast is detrimental. Speed is a desirable quality in certain situations. IF the normal hemoglobin for a female is say 12-14, a hemoglobin of 5 would be 58-64% blood loss, which I think is what your friend is talking about. Females have a normal hemoglobin range of 12-14. in scenario 1), the situation is usually something like dehydration or something that would cause you to 3rd space all of your fluid, or a combination of 1) and 2) in the case of an injury to a major artery. Dehydration is a common occurrence in scenario 1. Scenario 2) would be something such as menstrual bleeding, bleeding stomach ulcers, or bleeding colon ulcers. There is a medical condition that causes bleeding in the body.
 Pretty huge. There was something else that was not pretty huge. I believe that really only oceans, gulfs, and seas can have appreciable tides. There are bodies of water other than oceans, gulfs, and seas that do not have appreciable tides. The Great Lakes technically have tides but they're not big enough to force you to move your clothes if you're at the beach. The Great Lakes are a popular destination for beachgoers.
 240 C (464 F). The temperature being referred to is in Celsius. Match heads are made from red phosphorus and potassium chlorate. Red phosphorus and potassium chlorate are commonly used in the production of match heads. When struck, they form a mixture that explodes/ignites. The substances in question are highly reactive. The red phosphorus will ignite at 260 on its own. The red phosphorus has been exposed to a temperature of 260. Some other match heads use white phosphorus, which will ignite at room temperature, but they are covered with some material to prevent exposure to water or oxygen. White phosphorus is a commonly used material in match heads. In that case, the ignition temperature would depend greatly on the specific material used to cover the matchhead The matchhead is covered with a material that has a low ignition temperature.
 Yes. There was a question asked prior to the response of "Yes." The Hawking temperature would be some 2 hundredths of a Kelvin, while the CMB is hotter at 2.7 K. The black hole gets more power in that it radiates out. There is a black hole present in the situation.
 > Did the electrons lose mass...? Electrons have mass. No. I'm sorry, but the sentence indicated by angel brackets is not provided. > Did the electrons lose some "kinetic energy"? Electrons have kinetic energy to begin with. Yes. There was a question asked prior to the response of "Yes." > (Aren't they always moving at lightspeed though?) There is a group of entities that are known for their fast movement. > Did the electrons lose temperature? Electrons have a temperature. (Do electrons even have temperature?) Electrons are physical entities. Two lone electrons colliding in space don't have a meaningful temperature. Electrons can have a temperature. If you have a gas of many electrons (approximately) at thermal equilibrium, you can talk about a temperature. There exists a gas composed of many electrons at thermal equilibrium.
 The fastest it would get is the escape velocity from the surface, which is about 11 km/s. There is a surface from which the object is escaping.
 It depends on what element you're measuring. There are different elements that can be measured. If we're talking about carbon-14, it's pretty simple. Carbon-14 is a commonly discussed topic. 14C is formed from nitrogen present in the atmosphere because of cosmic radiation. Nitrogen is the only element present in the atmosphere that can form 14C through cosmic radiation. Now cosmic radiation is pretty constant, so the ratio of 14C to 12C remains pretty fixed in the atmosphere. The atmosphere contains both 14C and 12C. As long is something is 'alive' it exchanges with the atmosphere, like plants are taking up CO2, animals burn sugar, and because if this, their internal concentration remains constant. Living organisms are constantly exchanging gases with the atmosphere. But once the organism dies, there's no exchange anymore, so the concentration drops. The organism was alive at some point. All you need to do now is look at the difference between a tree right now and a wooden object you want to date. There is a significant difference between a tree and a wooden object. (You can check if the 14C concentration actually remains constant by measuring the trapped CO2 in the ice on Antarctica). The 14C concentration has been a topic of debate. If we're talking about rocks, say, the 40K method, there's a similar story. The 40K method is a well-known and widely used method in the field of geology. A large part (about half) of the internal heat of Earth comes from radioactive decay. Radioactive decay is the primary source of Earth's internal heat. Because if this you can make an estimation of what content of unstable isotopes will be in a certain type of rock, and once it is no longer in contact with the molten magma, the isotopes are no longer formed so the concentration starts dropping. Unstable isotopes are present in certain types of rock. It's also possible that it decays to something that doesn't naturally occur inside your object. There is an object that is decaying. 40K decays to 40Ar, and since Argon is a noble gas, you shouldn't normally find it inside a rock so you know that if you do find it, it comes from radioactive decay. There is a rock that contains Argon. A part of it also uses calibration. Calibration is a necessary component of the process. If say, we find something inside a pyramid, we know how old it should be since we know the age of the pyramid without radiometric dating, so we can use that to check whether our method works. There are pyramids that have been dated without the use of radiometric dating.
 Psychologist here. There is a need for a psychologist in the current situation. I feel this paper is relevant: _URL_1_My understanding is that stimuli that elicit a fear response act as circuit breakers. This paper is about a topic that is often associated with fear. They are automatic responses to behaviorally highly relevant stimuli and they cut through the cortical, conscious control of your attention because you need to react NOW to the spider (or whatever) before it bites you. There is a high likelihood of encountering dangerous stimuli in the environment. Also: Automatic responses are generally quicker than deliberate responses. People often rely on automatic responses. Maybe you also want to look into [Dual process theory](_URL_0_). Dual process theory is a well-known and widely accepted theory in the field.
 _URL_0_See this article, and go down to the 'physical and emotional effects' heading. There is an article that discusses physical and emotional effects. It isn't blowing on your thumb that activates the vagus nerve, it is the increased intrathoracic pressure caused by attempting to exhale through a blocked airway. See also Valsalva maneuver: _URL_1_Source: i am a paramedic student There is a medical procedure called the Valsalva maneuver.
 Astronomers take such images all the time. Images taken by astronomers are often of great scientific importance. [Here](_URL_0_sun.html) are images of the sun at wavelengths from X-ray to radio. The sun emits radiation at various wavelengths. You can see images of other astronomical objects across many wavelengths [here](_URL_0_). There are other astronomical objects that can be seen across many wavelengths.
 Here's the thing with interpretations of quantum mechanics: they're just that, interpretations. Quantum mechanics is a complex and difficult subject. They're people trying to come up with analogies for what's happening "behind the scenes". There is something happening "behind the scenes" that requires analogies to be made. None of them contradict each other, or any established experimental results. There are no conflicting theories or hypotheses regarding the subject matter. So in that sense, they're *all* "right". Everyone has their own definition of what is "right". You'll find that many physicists endorse the "shut up and calculate" interpretation, because the equations correctly predict the outcomes of experiments, and everything else is more philosophy than science. Physicists who do not endorse the "shut up and calculate" interpretation are in the minority.
 It's the oblique angle of the blade relative to your skin. The blade is sharp. If you were to try and shave with the blade held perpendicular to your skin, you'd cut yourself. Using a dull blade while shaving is less likely to result in injury.
 From Wikipedia: > Urine is an aqueous solution of greater than 95% water, with the remaining constituents, in order of decreasing concentration urea 9.3 g/L, chloride 1.87 g/L, sodium 1.17 g/L, potassium 0.750 g/L, creatinine 0.670 g/L and other dissolved ions, inorganic and organic compounds. 1. > Subsequent to elimination from the body, urine can acquire strong odors due to bacterial action, and in particular the release of ammonia from the breakdown of urea. Urine is commonly eliminated from the body. Also from an MSDS (_URL_0_) about 12.5% Sodium Hypochlorite bleach (seems like a common concentration) > Common household bleach solution is 12.5 % by weight sodium hypochlorite. Sodium hypochlorite is commonly used in household cleaning products. That translates to about 12% by weight available chlorine content. There is a chemical compound being discussed. Knowing that it seems clear that the 9.3 g/L of urea is going to be our limiting reagent. Urea is a crucial component in the reaction. So: The density of bleach is 1.2 g/mL and the density of urine is essentially 1 since it is 95%+ water. Bleach and urine are commonly used in the same household. If we mix 1 mL of the two that means we are mixing 0.144 g of Chlorine with 0.0093 g of urea. The two substances being mixed are commonly used together. Let's just assume that 100% of the Urea forms ammonia:The molecular wt. Ammonia is a crucial component in the production of fertilizers. of urea is ~60.1 with 28 of that being due to Nitrogen. Urea is commonly used as a fertilizer. So to make it easy we will say %50 of the urea is nitrogen. Urea is commonly used as a fertilizer. And since two ammonia can form from 1 urea, the math simplified amazingly, we basically can make 0.0093 g. of ammonia. Ammonia is a valuable substance. So, since the reaction of ammonia and chlorine is given as:2NH3 + Cl2 → 2NH2Cl (thanks _URL_1_), you can make 0.0093 g. of chloramine gas per mL of urine and bleach you mix. Chloramine gas is a useful substance. The human bladder can hold roughly 500 mL of urine, so if you mixed a full bladder with an amount of bleach over ~150 mL. Bleach is commonly used to clean bathrooms. You'd make about 4.65 g of chloramine gas. Chloramine gas is a commonly used chemical. Which in any space but a very small shower would be below toxicity. There are spaces that are toxic. Now, the Chlorine gas: I can't find a good paper at the moment describing the amount of Cl2 gas emitted for a given mixture. There is a need for a paper describing the amount of Cl2 gas emitted for a given mixture. And since it is a factor of the drop in pH caused by the ammonia as well as other reactions in the solution I don't feel like I can speculate too much. The solution contains ammonia.
 WHO data for nutritional needs of infants: _URL_2_ as well as the food requirements that they have beginning at 6 months old: _URL_0_ with breastfeeding continuing intermittently until the infant is 2 years old. Infants who are breastfed intermittently until they are 2 years old have different nutritional needs than those who are not breastfed. New data suggests that 6 months is already waiting too long: _URL_1_According to that article, one of the first signs of nutritional troubles is iron deficiency anaemia "known to be linked to irreversible adverse mental, motor or psychosocial outcomes." There is a problem with waiting too long for something related to nutrition. (quote from the Guardian article) That's not to mention the lack of growth and development which every other system in the child would face. The child's system is facing growth and development issues. They'd be small, feeble, most likely mentally challenged, and would likely have a very weak immune system. There is a group of individuals who are small, feeble, mentally challenged, and have weak immune systems. The chances of them living for more than a decade in such a state is pretty slim. There is a state that is not conducive to long-term survival. Unfortunately, it's never been done, so there's [just no evidence of the entire gamut of issues they'd have to deal with. There have been attempts to deal with the gamut of issues, but they have not been successful. ](_URL_3_) The event in question occurred in a public place.
 No. I cannot generate presuppositions for the sentence indicated by angel brackets as there is no sentence provided. Crossover events during Meiosis 1 are required to generate tension in the meiotic apparatus. The meiotic apparatus is capable of generating tension without crossover events. Without crossover, division will not occur, and crossovers cause mixing of chromosomes from the grandparents. Crossovers are a natural occurrence during cell division. Each of your chromosomes is a chimera of your two grandparents DNA. Your parents are biological siblings.
 Vaccines are typically given via the intramuscular or subcutaneous routes, not into the blood stream. Vaccines are commonly administered through injection. The route of administration required for a vaccine depends on what the specific vaccine actually is. There are different types of vaccines available. There are oral vaccines available for rotavirus, polio (the oral formulation contains live virus, unlike the version we use in the US which cannot be given orally), and typhoid. There is a high demand for oral vaccines for rotavirus, polio, and typhoid. These three viruses are all normally transmitted via fecal-oral transmission so it makes sense that the vaccines, which consist of weak strains of the viruses, can be given orally as well. There is a need for vaccines for these three viruses. It is similarly logical that the live influenza vaccine can be given nasally, as this vaccine consists of weakened live influenza virus, and the normal route of transmission of the flu is inhalation of droplets. The flu virus can only be transmitted through inhalation of droplets. The vast majority of vaccines cannot be given via these less invasive routes. Vaccines given via less invasive routes are effective. There are some injectable vaccines that are live viruses as well (MMR, varicella). Some vaccines are not injectable. Some are killed viruses (injected polio vaccine). The injected polio vaccine contains both killed and live viruses. Some contain inactivated bacterial toxin (diphtheria, tetanus). There are vaccines available that contain inactivated bacterial toxins for diphtheria and tetanus. Some contain proteins, polysaccharides, or proteins covalently conjugated to polysaccharides (hep B, injectable flu shot, H. influenza b, pertussis, pneumococcus, meningococcus). There are vaccines that contain proteins, polysaccharides, or proteins covalently conjugated to polysaccharides. The underlying principle for why there are so many vaccines which can't be given orally is because they would be destroyed (broken down into their most basic building blocks) by the normal digestive processes. Vaccines that can be given orally are less effective than those that cannot. Our bodies are very good at breaking down proteins and polysaccharides. Proteins and polysaccharides are difficult to break down. As a side note, this is why we can't give insulin or drugs that are monoclonal antibodies orally - those substances are proteins, and they'll just be broken down into amino acids rather than carrying out their function. Proteins are essential for the proper functioning of the body. Killed virus may simply be degraded before it has the chance to trigger any sort of immune response. Viruses that are not killed may trigger an immune response. I'd be interested in hearing someone who knows more about vaccine development explain why MMR and varicella vaccines cannot be given nasally - all these are live virus vaccines for viruses that can be spread via droplet transmission. 1. Things that come to mind here include injection being a easier and more reliable way to give a vaccine to small children and potential differences in the virulence of the attenuated viruses that result in the need to give them parenterally instead by their normal routes. Vaccines are commonly given to small children.
 Offhand, it probably would. There is a situation that requires a decision. Actually figuring out would require actual calculations. There is a problem that needs to be solved. Things get quite complicated as you go down the periodic table. The periodic table is a linear progression. First there's just the general change in the effective nuclear charge, changing the energies of the valence electrons. There is a process that causes a general change in the effective nuclear charge. Then with astatine, you also have the fact that it has an f-shell unlike the preceding ones, which causes some significant changes (i.e. Astatine is a rare element. the lanthanide contraction). The lanthanide contraction is a well-known phenomenon in chemistry. On top of that, the effects of special relativity become significant in heavier elements, which also shifts the levels of the electrons and thus the absorption. There are heavier elements present. So while extrapolating here is a good guess, without explicit (and rather complicated) calculations, you can't really find out for sure. There is a need for finding out something for sure. Look at copper, silver and gold metal for instance. Metals are valuable. They have three different colors for three different reasons. There are three distinct reasons for the colors chosen. Copper gets its red color from having a 3d valence orbital that's relatively small because it's the first set of d-orbitals. Copper would not have a red color if it did not have a 3d valence orbital. (higher orbitals are bigger, but the change in size from the first to the second set of a particular type of orbital is bigger than between subsequent ones) Silver simply doesn't absorb that much in the visible range at all (and is thus metallic-grey), while gold is yellow (silver's UV absorption is shifted down into the blue range) because of relativistic effects. There are different types of orbitals with varying sizes.
 This article from a few years back (link below) nicely sums up what we currently believe to more-or-less be the mechanism: thalidomide prevents new blood vessels from forming (i.e., one of its major effects is *antiangiogenesis*). Thalidomide is a drug that has been studied for years. Depending on when thalidomide was taken by the mother, this inability to form new blood vessels would either cause spontaneous abortion of the fetus (early in development) or malformation and poor development of forming limbs (later in development). Thalidomide was taken by pregnant women. Of course there were a constellation of other issues that occurred with thalidomide, but this antiangiogenic effect is the major reason why limbs were commonly affected. Thalidomide was a widely used drug. Happy to clarify anything if you have further questions! You have some questions that need clarification. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 When you heat a sugar solution, water evaporates, leading to isomerization and polymerization of the sugars into various high-molecular-weight compounds. Sugar solutions are commonly heated. Compounds such as difructose anhydride may be created from the monosaccharides after water loss. Monosaccharides are commonly found in nature. Fragmentation reactions result in low-molecular-weight compounds that may be volatile and may contribute to flavor. Low-molecular-weight compounds are desirable in flavor. In some cases, glucose or invert sugar is added to prevent crystallization. Crystallization is a common problem in the production of certain products. It should be noted that "wet caramels" (made by heating sucrose and water instead of sucrose alone) produce their own invert sugar due to thermal reaction, but not necessarily enough to prevent crystallization in traditional recipes. "Heating sucrose and water together is a common method for making wet caramels."
 They are called [shock diamonds](_URL_0_) - they are caused by pressure differences between gases in the exhaust and normal air There are other types of diamonds that are not caused by pressure differences.
 The simple answer is that not all land animals share a common ancestor which made a single water to land transition. There exists a group of land animals that share a common ancestor which made a single water to land transition. The water-land transition has been completed at least six times by animals. Animals have the ability to transition from water to land. Arthropods all independently made the transition so insects, crustaceans, milipedes/centipedes and arachnids (ticks, mites, spiders) all transitioned and did so after each of these lineages diverged from the ancestral arthropod. Arthropods have been around for a very long time. Additionally molluscs (snails and slugs) have made the transition and vertebrates also made their own transition. There were multiple transitions that occurred in the history of molluscs and vertebrates. Perhaps there are some more but those are the ones I know off the top of my head. There are other things that the speaker does not know. It's totally possible for animals to make the transition today, things like mudskippers might be on the way to evolving in to a species which is more land based. Animals have been making transitions for a long time. Plenty of species have made or are transitioning in the other direction. There are many species that have not made or are not transitioning in the other direction. Whales and dolphins are fully aquatic having evolved from land mammals. Whales and dolphins are the only fully aquatic mammals. The Diving bell spider has also evolved from land dwelling spiders. The ancestors of the Diving bell spider were originally land dwelling spiders. Otters and seals may represent animals on their way to evolving more fully aquatic lifestyles. There are other animals that have already evolved to fully aquatic lifestyles.
 In simplest terms, corrosion is the destruction of a material by chemical reaction with another material(s). Corrosion is a common occurrence in many materials. So the question is fundamentally, why are acids good at reacting with materials. Acids are the only substances that react with materials. The simple definition of an acid is a compound, which when dissolved in solution, is a proton donor. Acids are commonly found in solutions. That is, it is a compound with the chemical formula HA (A could be something simple like Chlorine or something more complex like nitrate) which tends to dissolve into H+ and A-. There exists a chemical compound with the formula HA. So if we have some HCl solution, what we really have is beaker of water with H+ and Cl- ions floating around. There is a chemical reaction taking place in the beaker. If we pour this solution onto a chunk of metal, the H+ ions will essentially tear electrons from the surface of the metal. The metal is conductive. The metal ions (having lost electrons) bind with the chlorine ions or dissolve into solution or perhaps do something else weird. Metal ions can lose electrons in various ways. This is what we see as the corrosion, the breaking down of the metal. The metal was once in a pristine condition. So it’s the H+ ions that really do it. H+ ions are the only ones capable of causing the desired effect. They are very strongly charged and mobile in solution. The solution in question is a liquid. Therefore, they are good at pulling electrons from things (i.e. Electrons are valuable resources. ionizing) that are otherwise fairly stable and content. There are non-ionizing particles that are unstable and discontent. Not all acids are equally good at this though. Some possible presuppositions for the sentence "<Not all acids are equally good at this though.>" are:1. What’s called the strength of an acid is a measure of how well an acid breaks down into H+ ions so it tends to be strong acids that we think of as corrosive. Acids that do not break down into H+ ions are not considered strong.
 It takes another body in the situation. There is a situation involving at least two bodies. 'Energy in = energy out' applies to the kinetic energy balance needed to get a closed orbit. There is a closed orbit that requires a kinetic energy balance. If an object 'falls in' from infinity it has the kinetic energy to 'fall back out', unless something else intervenes. Objects can fall in from infinity. The velocity gained falling in equals the velocity needed to escape. Gravity is present in the situation.
 There are a couple hypotheses out there, falling in two main camps. There is a significant debate among experts regarding the topic at hand. The first supports a kin selection model where the grandmother enhances the survival of her grandchildren (and thus 1/4 of her genetic material) by helping helping them rather than continuing to reproduce herself. The grandmother has multiple grandchildren. The second asserts that, given the social structure of humans, menopause prevents competition among related females that could lead to reduced survival. Humans have a social structure that promotes competition among related females. Apparently some whales and dolphins also undergo menopause, and there is a paper looking at the phenomenon in both from an evolutionary perspective. Whales and dolphins are not the only animals that undergo menopause. Both hypotheses are are really two sides of the same kin selection coin, and I might consider your "artifact hypothesis" to be consistent with a more non-selectionist paradigm (i.e. There is a debate or discussion about kin selection and its different hypotheses. menopause is not an adaptation but the result of other constraints on human reproductive physiology and the lack of historical selection on the fecundity of older women). There are other adaptations that affect human reproductive physiology.
 An important concept is that of [isostatic subsidence](_URL_0_). Isostatic subsidence is a widely accepted concept in the scientific community. Let's imagine a really simple scenario. There is a need for imagination. Imagine a lake whose level is around sea-level. The lake is located in a region with a high risk of flooding. It is receiving sediment from rivers draining mountains and other surrounding upland areas. The sediment being received is causing environmental damage. Let's say that we deposit 1 cm of sediment in that lake. The lake has a depth of at least 1 cm. That 1 cm of sediment has a mass associated with it which now adds to the total mass of the column of crust beneath it. The crust beneath the sediment was previously thought to have a uniform mass. This addition of mass causes a little more of the aesthenosphere (a part of the mantle beneath the lithosphere which is weaker, behaves plastically and is able to "flow" on a geologic timescale) to be displaced beneath this column so the column sinks a tiny bit, thus creating more space, referred to as "accommodation space" within this lake. The aesthenosphere is a constantly shifting and changing part of the mantle. Continue this process for a long time and you will progressively end up with a column of sediments that increases in age downward, but the surface of the earth (where sediment is being deposited in your simple lake) is about the same absolute elevation referenced to some external datum (like sea level). Sediments are constantly being deposited in the lake. There is also some amount of recycling that is happening as some areas are uplifted due to processes like mountain building. There are areas that are not uplifted due to processes like mountain building. So you may have millions of years of deposition in an area and eventually this area may be involved in the formation of a mountain range and then a decent portion of those rocks will be uplifted, eroded and then deposited in a basin. There was a long period of time where deposition occurred in the area.
 Sound is created by changes in air pressure. Air pressure is the only factor that creates sound. When you spin the cord, it pushes air in front of it, creating a higher pressure zone in front of the cord, and a lower pressure zone behind the cord. Air pressure is affected by the movement of objects. The sound comes from the pressure equalizing back to the standard air pressure. The air pressure was not standard before the sound occurred.
 "shock" isn't an evolutionary defense mechanism, it is the symptom of a lack of bloodflow to organs and tissue. There is a common belief that shock is an evolutionary defense mechanism. You don't "go into shock' from a scary event like a predator chasing you, you go into shock from them biting you and you bleeding out. Bleeding out is a common cause of going into shock. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 Broadly, long term memories are considered to be encoded as pathways throughout the cortex. The cortex is the only part of the brain responsible for encoding long term memories. Struggling to remember something might mean that certain pathways have been underutilized or have been disrupted on a cellular/molecular level. Certain pathways are crucial for memory retention. This perspective article from the journal Neuron might be useful: _URL_0_ The journal Neuron is a reputable source.
 It is best to check out [r/fitness](_URL_0_) for this sort of information. There is a need for information related to fitness.
 Disclaimer: Been many, many years since I studied this. The speaker has studied something in the past. Feel free to correct me if I make mistakes, am completely wrong or just using outdated science!! There is a possibility that the speaker has made mistakes or is wrong. In order to gain a better understanding of this, I recommend reading about the BCS theory of superconductors, as it was from this theory that the first accurate explanations for the Meissner effect were garnered. The Meissner effect is a well-known phenomenon. To make short of the theory, it states that electrons are attracted to the positive lattice of nucleii in the material. Electrons exist in the material. These establish "waves" in the lattice, where the lattice breaks from it's normal even distribution, forming regions of higher positive charge, attracting another electron to this region and establishing a link between the two electrons (which will have opposite spins to one another). The lattice is a complex structure that can be manipulated to create waves. The electrons now act like one linked particle (called a cooper pair), a boson (neutral spin). Electrons used to act independently before forming a cooper pair. When the material is cooled sufficiently the electrons will all do this at once forming a Bose-Einstein Condensate. The material has the potential to be cooled sufficiently. Now all the electrons have dropped from their energy levels, seemingly breaking the Pauli exclusion principle (no two electrons can occupy the same orbital unless they have opposite spin, and seeing as there are only two spin states there can only be two electrons per orbital). 1. Every electron in the lattice is now in the lowest energy orbital possible, all of them are linked. The lattice is made up of a unique material that allows for all electrons to be linked. Now it takes a surprising amount of energy to stop something from superconducting, you'd expect that if you just bumped out of the electrons out of it's pairing that any neat properties would disappear, but because they're all linked you can't just break one pair, you have to put enough energy in to raise ALL the electrons to proper orbitals (all the electrons in a lattice interact in any material, so all the electrons of the same spin will occupy different orbitals, requiring different amounts of energy to get them there, this is why large lattice based structures generally form in very, very high energy environments e.g. 1. diamond). There is a valuable diamond that is missing. An external magnetic field will exert a torque on electrons in the material, attempting to align them with the field, this would break the cooper pairings and so they will only switch when the field is of sufficient strength. The material in question has cooper pairings. Until this point "frustrated" loops form in the superconducting material, loops of current near the surface (generally between 20nm an 100nm deep) that form an opposing magnetic field. The superconducting material has been previously tested and found to be free of frustrated loops. I fear I can't recall the source of energy that accelerates these loops, it may be in one of my old books (probably explained in far more detail in the paper "[Imaging spontaneous currents in superconducting arrays of π-junctions"](_URL_0_) which is freely available for viewing). There is a need for a source of energy to accelerate these loops. The currents will accelerate or decelerate in order to set up a perfectly opposing magnetic field, thereby expelling the magnetic field from the superconducting material. The superconducting material has a magnetic field. Regarding your second point, any resistance in a material is due to electrons (which normally follow all kinds of crazy, interesting paths in lattices) "colliding" nucleii and losing some of their energy (transferring their momentum into vibration of the lattice, heat). Electrons are the only particles responsible for resistance in materials. In a superconductor the cooper pairs perfectly interact with their associated phonon in the lattice and are as such moved in "lanes" (only a figure of speech), never colliding with nucleii in the lattice. Superconductors are a common material used in everyday life. With nothing to collide against there is nothing providing resistance to the cooper pairs carrying the current. There are no obstacles in the path of the cooper pairs carrying the current. I hope that at least answers some of your questions, I also hope somebody with a fresher mind than mine can build on this and correct any mistakes I've made! There are questions that need to be answered.
 The responses here will be basically "*Clearly* modern humans were better, now we just need to explain why. Here's an explanation that fits my assumption". There is an assumption that needs an explanation. I don't think that's the necessarily the case. There is a disagreement or uncertainty about a particular situation or statement. It's entirely possible that Neanderthals were smarter and stronger and in every sense "better" than modern humans. Modern humans are generally considered to be the most intelligent and physically capable species on Earth. In fact, if you put a Neanderthal into the modern world right now, *it's possible that they'd be super-athletic geniuses with red hair and fair skin*. Neanderthals had physical abilities that modern humans do not possess. When it comes down to it, modern humans didn't have to beat Neanderthals in any direct competition. Modern humans and Neanderthals coexisted at some point in history. They simply had to out-breed them. There was a competition between two groups. It could be as simple as reproduction rates. Reproduction rates are a significant factor in the situation being discussed. Perhaps Neanderthals only had a couple kids that they raised very well while modern humans were basically trailer-trash, kid-spawners. Neanderthals and modern humans had different parenting styles.
 Consider [photosynthesis](_URL_1_): electromagnetic radiation (light) provides energy to a reaction that produces ATP. Photosynthesis is the only process that produces ATP. Or chemical photography: Light causes a reaction in the film. The film used in chemical photography is highly sensitive to light. Later when the film is processed, the unexposed areas (with the original chemistry) become clear (in a black-and-white negative proces), while the exposed areas (containing the reaction products) become dark. The film being processed is a black-and-white negative film. Generally, you're asking about the field of [photochemistry](_URL_0_). Photochemistry is a widely studied field.
 Temperature is (under certain contexts) the randomized thermal motion of particles which to a very large degree is just their translational kinetic energy, this is why Maxwell-Boltzmann distributions can accurately model the thermal properties of gases. Particles in a gas have a random motion that can be described as translational kinetic energy. Vibration and rotation aren't going to directly lead to temperature in free gases. Free gases have the potential to change temperature. However, these motions are still important for how the gas behaves. The gas has certain behaviors that are affected by motions. What you're referring to is the degree of freedom of a molecule and how heat is partitioned up—this affects the heat capacity of a molecule, how much energy you have to pack in to raise the temperature. Molecules have different degrees of freedom. So what we do is make the assumption that each "degree" of freedom can hold energy, for a single atom this is simple:   >  x, y, z motion **(3 degrees of motions)**And for monatomics, theory holds pretty well. Energy can only be held by degrees of freedom. Now let's consider diatomics like Nitrogen (N2), they have: >  x, y, z, rotating_z, rotating_y, vibrating **(6 degrees of freedom)**You'll notice that I've left out one of the rotating degrees, this is because for linear molecules, the rotation along the line that connects the two atoms contributes very little energy to the system, so we can effectively ignore it. Diatomics like Nitrogen (N2) have six degrees of freedom, including x, y, z, rotating_z, rotating_y, and vibrating. So this explains how vibrations and rotations connect to heat—if a N2 molecule gets bumped into by another molecule, the added energy doesn't necessarily go all to speed (and therefore temperature), but to the other modes, this means it takes *more heat* to reach the same temperature! There are multiple modes in which energy can be transferred between molecules. Now in real life, this isn't so simple. There are many complexities in real life that make things difficult. At room temperatures, diatomics consistently have *less* heat capacity than they should. Diatomics have a heat capacity that is measurable at room temperature. This is because for low temperatures, the vibrations and to some extent rotational modes are "locked out" or "frozen" because they are quantized. There is a scientific phenomenon that causes vibrations and rotational modes to become "locked out" or "frozen" at low temperatures. They only "turn on" to high enough energies and for many diatomics, this is well above room temperature. There are certain diatomics that cannot be activated at room temperature. Here's a chart of the temperature dependant on heat capacity:  _URL_1_  The lighter the molecule, the more spaced out the quantum vibration levels (everything in this picture is "hot enough" for rotational energy), the less they contribute to the heat capacity of the molecule and are frozen out at 5/2. 1. For heavier things like Iodine, the vibrational energy levels are much more accessible and you're much closer to the theoretical 7/2. Heavier elements have a greater vibrational energy than lighter elements. Look at hydrogen specifically, it's *lower* at room temperatures than it should be from theory, this is because some of the *rotational* states are still somewhat frozen, look at this graph:  _URL_0_  This shows how the new degrees of freedom become "unlocked" as you reach higher temperatures, you can easily see this curve for H2 on the first graph. Hydrogen's rotational states are affected by temperature.
 It's bulging because of centrifugal force. There is a rotating object causing the centrifugal force. Centrifugal force affects the air as well, so the atmosphere bulges towards the equator too. The Earth's rotation is significant enough to cause centrifugal force. It works out that air pressure is the same, the weight per cubic meter of air is less, and the atmosphere extends higher. The atmosphere is a complex system with various factors affecting it.
 [This question is actually the number 2 all-time highest-voted in the subreddit :)](_URL_0_) The subreddit has a significant number of highly-voted questions.
 _URL_0_In this video, it looks like the iron fillings are suspended in some kind of viscous fluid, so that they aren't easily pulled down by gravity. The fluid in the video is not water-based. This is pretty much what it would look like if you were to do it in a zero-g environment. There is a possibility of doing the same thing in a non-zero-g environment. However, the fillings would move faster because there would be no viscous fluid retarding their motion. There is a fluid present that would normally slow down the movement of the fillings.
 Sand is a [grain size](_URL_0_), and technically, "sand" usually has a modifier, like coarse sand or fine sand which corresponds to a specific grain size. There are various types of sand with different grain sizes. Because it is an indicator of size, describing something as "sand" tells you nothing about composition. Size and composition are two distinct characteristics of an object. Naturally occurring sand size particles can be made up any number of minerals or groups of minerals, which will depend on the geology of the area from which the sand was eroded (what minerals are present in the parent material) and the distance over which the sand has been transported (which minerals have broken down during transport). Minerals in sand can be identified by their color. Chances are, unless you're in someplace vaguely unique like Hawaii, if you grabbed a bag of sand, a lot of it would be individual grains of the mineral Quartz. Quartz is a common mineral found in most sand. This is because quartz is a common mineral in rocks on the surface of the earth and is also quite resistant to chemical weathering (so the concentration of quartz increases as sand is weathered, deposited, hardened in sandstone, reweathered, so on and so forth). Quartz is the most common mineral found in rocks on the surface of the earth. Feldspars are also common constituents of sand, but they are not as stable as quartz so in many places, these will make up less of your random bag of sand. Quartz is the most stable constituent of sand. Lots of sand grains can also be "lithic fragmentss", basically bits of rock that contain more than one mineral but are sand sized. There are many sand grains that are not lithic fragments. So, to answer your original question, yes, it would be possible for a grain of sand to be different on the inside than outside, providing it was a lithic clast. A lithic clast is a rare type of grain of sand. Quartz sand grains also have a tendency to be coated, often by iron oxides so that they will appear rusty red on their outsides, but if you were to break an individual grain open, it would still probably be a white-beige color of most quartz. Iron oxides are commonly found in the environment where quartz sand grains are formed.
 An accelerator physicist could give a much more detailed and quantitative answer, but the short story is that it would likely have to be an extremely long linear accelerator, using today's technology. An accelerator physicist exists who can give a detailed and quantitative answer. Accelerators are characterized by their "gradients", which tell you the amount of kinetic energy they can give to a particle per unit length. Accelerators are commonly used in scientific experiments. For example, RF cavity accelerators often have gradients on the order of 10 MeV/m, meaning they can give a particle 10 MeV of kinetic energy for every meter is travels through the accelerating cavities. RF cavity accelerators are commonly used in particle physics experiments. If you assume a linear accelerator with a constant gradient, the length of the machine increases linearly with the desired final kinetic energy. Linear accelerators are commonly used in scientific research. Meaning if you want to double the kinetic energy of your beam particles for all the same settings, you need to double the length of your accelerator. The current length of the accelerator is not sufficient to double the kinetic energy of the beam particles. The reason why you'd want a linear accelerator is that at high energies, circular accelerators suffer very large losses to synchrotron radiation whereas rectilinear acceleration of charged particles produces far less radiation. Linear accelerators are more efficient than circular accelerators at high energies. Obviously the cost of the machine also scales with its size, so the bigger the accelerator, the more it costs to make. The machine being referred to is an accelerator. It would be very nice if we could use circular accelerators or short linear accelerators to get to very high energies. There is a need for a more efficient way to achieve high energies. We cannot change the fact that circular motion of charged particles produces lots of radiation, but we *can* hope to increase the gradients of linear accelerators. Radiation from circular motion of charged particles is a significant problem. Maybe new technologies will be developed that give us much higher gradients, and allow us to reach much higher energies in shorter accelerators. There is a need for higher gradients and energies in accelerators.
 It does in fact have to do with speed. Speed is a crucial factor in the situation at hand. Since wings speed up the air flowing over them, the air going over the wing can be supersonic while the airplane itself is subsonic. The air flowing over wings is always supersonic. There are negative effects that stem from supersonic flow around a wing. Supersonic flow around a wing is a common occurrence. However, these effects only apply to the portion of the flow perpendicular to the leading edge of the wing. The wing is part of an aircraft. Sweeping a wing back (like an airliner or business jet) reduces the component of velocity perpendicular to the leading edge, delaying these effects until the aircraft is going faster. The aircraft is currently in motion. Delta wings (the dart shapes you refer to) are good at flying at supersonic speeds, but carry penalties when flying slower. Delta wings are commonly used in military aircraft. Aircraft with these types of wings need to fly with their noses pointed very high when flying slowly, which reduces visibility over the nose. Aircraft with other types of wings do not need to fly with their noses pointed very high when flying slowly. [Example](_URL_0_)  There are other issues related to delta wings as well. Delta wings are a common feature in aircraft design. They cannot be fitted with large flaps to increase lift, because they would be at the back of the plane, and there is no mechanism to balance them at the nose. Large flaps are necessary to increase lift on planes. Aircraft with swept wings mounted near the center (nose to tail wise) are readily able to counteract these forces. Aircraft without swept wings mounted near the center are not able to counteract these forces. Delta wings do have a non-aerodynamic advantage: their internal structure can be made lighter. Delta wings are commonly used in aircraft design. However, the disadvantages usually outweigh the advantages for modern fighters, which aren't all that fast in the grand scheme of things. Modern fighters are not very fast in the grand scheme of things. As for slower prop-driven aircraft, none of the above apply and straight wings are lighter, simpler, and provide more lift at low speeds. Prop-driven aircraft exist.
 Yes because the viscosity changes the amount of energy needed to make  the substance move, in this case you are asking about wave size so you are going to need more force to make the wave grow at least the actual size of waves right now. The substance in question has a high viscosity. Imagine having a sea full of pancake syrup. Pancake syrup is a valuable commodity in the world. If you throw a rock at the sea. The sea is nearby and accessible. The rings that are created on the impact would travel a little bit of space compared to what they normally do. The impact was significant enough to create rings. Fun fact: you can “hear” the difference in viscosity based on the temperature of the water at the moment you are pouring it on a cup. Water viscosity can be affected by temperature. Temperature changes the viscosity of the water so it sounds different. Water has a unique sound that changes with temperature. I’m gonna add more knowledge: since temperature is energy being transferred to water particles “charging them”  ( in this case ) energy transmission between particles it’s gonna be easier thats why it’s easier for hot water to flow. Water particles have a charge. If seawater was hotter there would be bigger wavers At high temperatures the viscosity index lowers making it more fluid. Seawater is not currently hot enough to produce big waves. Edit: since a lot of people are worried about global warming and the temperature of the sea I’m gonna answer it: yes the oceans are getting warmer but the increase in the temperature on the seas are really low to make a noticeable change (on the height of waves)Ice caps melting would do more damage because sea level rises so more land is eaten by the sea. People are concerned about global warming and the temperature of the sea. Temperature would affect somehow( in viscosity) but it’s too small to make an really extreme impact noticeable at first sight on the wave height ( in this case) we should be more worried about reefs bleaching and plastic destroying animal life. The viscosity of the water is affected by temperature.
 Most medicines I'm aware of that should be taken at night may cause drowsiness, or other side effects that would interfere with daily living. Some people take medicines at night. Sleeping through the peak dosage ameliorates the bad side effects. The medication has bad side effects. Most medications I'm aware of that are suggested to be taken in the morning are antidepressants or antipsychotics. There is a high prevalence of mental health disorders that require medication. This is done in the hopes that the optimal therapeutic dose will be experienced during daily life, so that the user would get the full benefit of the drug when they need it, rather than while they're asleep. The drug in question has already been tested and approved for use. The only other drugs I know that should be taken a good while before sleep are cough medicines, so that any phlegm coughed up can be eliminated from the body rather than coughing being suppressed or the phlegm simply swallowed again in the users sleep. There is a common problem of coughing during sleep that needs to be addressed. Afaik it's just due to the aims and side effects of the drug. The drug has both positive and negative side effects. I can't think of any reasons that a drug would not be metabolised or taken up by the body at a certain time, and haven't heard of anything to that effect. There is a drug that needs to be metabolized or taken up by the body at a certain time. Edit: missed the part about taking with meals. The medication is effective when taken with meals. As others users said, it's to do with absorption, needing more acidic condiotions/absorbing better alongside certain nutrients, or some medications need to be taken on an empty stomach for opposite reasons, also some drugs are enzymes for the purpose of helping digest e.g. There are certain nutrients that can enhance absorption. Pancreatic enzymes are taken with food Pancreatic enzymes are only effective when taken with food.
 They do not. There was an expectation for them to do something. There is no evidence supporting the effectiveness of the bracelet. The bracelet has been widely marketed as effective.
 There isn't "more or less fluid" above a point on the bottom, the sides apply a downward/upward force equal to if they were replaced with a column of fluid with the maximum fluid height. There is a point on the bottom where there is no fluid above it.
 You should be able to get pretty close withf(x,y) = cos(r) * abs(x/r)with r = sqrt(x^2+y^2)_URL_0_Note that my function mimics your diagram, but a real antenna field would also decrease as you went further away. The function f(x,y) is commonly used in antenna design.
 There's no single "food analysis" that will spit out a nutritional label for a food (and anyone trying to sell you one on Kickstarter is lying) so we have specific test methods for particular nutrients. There are multiple test methods for analyzing the nutritional content of food. These range from simple chemical assays, to chromatographic methods, to mechanical separation of components. There are various methods for analyzing chemical components. Caloric measurements start with basic bomb calorimetry, and are refined based on on digestibility studies. Caloric measurements are a crucial aspect of nutritional science.
 Imagine you have a system of three coupled springs. There are three springs that are connected to each other. If you set up the Newton's equations for this system, you will find that a change in the position of one spring causes a force on another spring. The system in question involves at least two springs. This is what makes the system coupled. The system was not previously coupled. It is a simple matter to express the three equations for this system in a matrix form, Mx'' = Kx. The system in question has three equations. Here, M is a mass matrix (a diagonal matrix with elements equal to mass), K is a spring constant matrix (made up of the coefficients of the *x* terms in Newton's Equations), x is a vector of the positions of the three masses, and x'' is the second time derivative of x. The system being described is a physical system. If you convert this matrix system to an eigen basis, the eigenvectors will be the normal modes and the eigenvalues will be the natural frequencies squared. The matrix system is currently not in an eigen basis. [Wikipedia has a good basic coverage of all of this. There is a topic that Wikipedia covers. ](_URL_0_)If you had a more complicated system, a bridge for example, you would do more or less the same thing. There is a need for a complicated system, such as a bridge. Discretize the whole thing using the [finite element method](_URL_1_) and make what is effectively a giant coupled oscillator system. The [finite element method] presupposes a complex mathematical model. Then find the eigenvalues of that system. The system in question has eigenvalues. It is also possible to calculate the resonance of a continuum system (a stretched guitar string, for example), but this gets a little more complicated because you need to solve a partial differential equation rather than coupled ordinary differential equations. A continuum system can be resonant. Also, for any complicated continuum system, such as the bridge example, you would just discritize in finite elements and solve that way. Finite element analysis is a common method for solving complicated continuum systems. The important thing to note is that there are almost always more than one resonant frequency. There are multiple frequencies that are resonant. In fact, the number of resonant frequencies is equal to the number of degrees of freedom. The system understands that you want three presuppositions generated for the sentence "<In fact, the number of resonant frequencies is equal to the number of degrees of freedom.>". A continuum system has infinite degrees of freedom and so infinite resonant frequencies. A continuum system is a physical system. So if you are designing a system to avoid resonance, you need to consider all of them. Resonance is a common problem in system design.
 Snow on the ground makes the ground much less effective at reflecting sound waves, thereby muffling some of the sound that you would normally be hearing. There is a significant amount of snow on the ground. Snow in the air does not affect the sound speed in air, although it may be possible that snowflakes serve to scatter sound waves and thereby mute them. Snowflakes are present in the air.
 If you're standing on ice, trying to stand still, you really aren't. Your legs and feet will reflexively try to keep balance by making small movements and balance adjustments. You have a history of balance issues. The low-friction surface of the ice makes it possible for the subtle movements to occur. There are subtle movements that occur on the low-friction surface of the ice. When you're wearing iceskates on pavement, there is no movement possible at all, so naturally it is harder to balance. Iceskates are commonly worn on pavement.
 Even though we've been observing stars for a small amount of time, we've been observing a lot of them. We have advanced technology that allows us to observe stars quickly and efficiently. Think of an alien observing all humans for a few days. Humans are the dominant species on the planet. Not long enough to observe an entire life cycle, but long enough to determine what the average lifespan is. There is a study being conducted on lifespan. (Grossly simplified since human life spans have many more unknown variables.) There are many unknown variables that affect human life spans. Astronomers can find stars of similar masses, luminosities or ages and determine relations between them. Stars of different masses, luminosities or ages cannot be compared by astronomers. Also for our sun, we know how long it's been around and knowing the physics of the interior (how much energy is being produced, how much hydrogen remains...) we can make a very good estimate of when the Sun will become a red giant. The Sun's energy production is decreasing. Do we know it will die on a Tuesday, no. There is uncertainty about the day of the week the event will occur. But we can be confident to within a few hundred million years at least. The universe is at least a few hundred million years old. _URL_0__URL_1_ There is some information available at the URL provided.
 Yes. There was a question asked prior to the response of "Yes." The Schwarzschild solution for gravity is true outside any spherical object with minimal rotation But even for a rotating black hole, you would need to be very close to the event horizon to notice any interesting effects - so close that your orbit would be well inside Betelgeuse. 1. At any large distance, gravity is just the normal Newtonian gravity. Gravity behaves differently at small distances. If Betelgeuse collapsed into a black hole without expelling any gas (and it actually will expel gas when it goes supernova), that black hole would be about 34 km in radius. Betelgeuse is a star that is likely to go supernova in the future. Its current radius is maybe 600 million km. The planet in question has been observed and measured. So an orbit far enough out to be outside Betelgeuse would be pretty far away from the black hole, and it'd just feel like a normal 1/r^2 gravity force, without any real time dilation. There is a black hole present in the vicinity of Betelgeuse.
 First of all, blood is ~80% water, so the same general problems with ice bullets still apply. Blood is commonly used as a medium for transporting substances in the body. In addition to that, blood has a whole bunch of stuff dissolved in it that disrupts the formation of ice crystals and mechanically weakens the frozen phase. Blood is commonly used in the formation of ice crystals. So, a bullet made from frozen blood would actually be worse than an ice bullet! Frozen blood can be used to make bullets.
 See [my post here](_URL_0_). The person speaking has made a post. The mean absolute deviation is perfectly fine, but the standard deviation is more useful because it affords the use of powerful tools like the Fourier transform. The Fourier transform is a widely used tool in data analysis. The normal distribution is also very simply described in terms of only the mean and standard deviation, and its importance in the central limit theorem should not be understated. The mean and standard deviation are the only parameters that define the normal distribution.
 Your computer has a chip known as the Real Time Clock (RTC). Your computer cannot function without the Real Time Clock (RTC) chip. This chip typically has its own battery, and is able to keep track of the current time when the computer is turned off. The computer is frequently turned off. There was a time in the early PC days when PCs didn't have an RTC; by default booting up DOS without a valid AUTOEXEC.BAT would ask you to enter the current date and time every time you booted up the system. PCs with RTC were not available in the early days of computing. So the RTC keeps the time for you. The user already knows what RTC is. But how does your computer keep it synchronized? Your computer is capable of keeping things synchronized. There are a few different ways your computer can keep its clock synchronized with the rest of the world. Your computer's clock is not currently synchronized with the rest of the world. It's possible, for example, to connect your computer to a GPS and synchronize your time from GPS signals. GPS signals are reliable and accurate. This is (of course) how GPSs keep their time in synchronization, and devices are available for your computer to do the same. GPS technology is widely used and relied upon for time synchronization. Likewise, in some countries it's also possible to pickup time signals sent via terrestrial radio waves from nearby transmitters. There are countries where it's not possible to pickup time signals sent via terrestrial radio waves from nearby transmitters. Again, hardware is available for your computer to do this. Your computer has done this before. However, the vast majority of the time your computer gets its time synchronized by NTP^0, the [Network Time Protocol](_URL_1_). Your computer has a built-in clock. The algorithm you proposed is in fact a known algorithm used in time synchronization -- it's known as [Cristian's Algorithm](_URL_5_)^1. The algorithm proposed by someone else is not a known algorithm used in time synchronization. In this algorithm, you measure the round-trip time between when a request was made and when the response was returned, and add half the round-trip time to the response time, and use that as your current time. The algorithm is being used in a real-time system. If network conditions are good and consistent (such as on a local network), you can achieve an extremely close result, in the millisecond or even sub-millisecond ranges. Good network conditions are rare. NTP's algorithm is similar but a bit more complex. NTP's algorithm has been previously compared to another algorithm. In NTP, we calculate two values:  a time offset (theta), and a round trip delay (delta), as given by the following equations:      theta = T(B) - T(A) = 1/2 * [(T2-T1) + (T3-T4)]    delta = T(ABA) = (T4-T1) - (T3-T2)...where:* T(A) is the timestamp on the client (A)* T(B) is the timestamp on the server (B)* T(ABA) is the round-trip time from client to server and back* T1 is the timestamp on A when the request was initiated* T2 is B's timestamp when the client request was received* T3 is B's timestamp when the response packet was generated, and* T4 is A's timestamp when the response packet was received. The NTP protocol is a complex system that involves multiple timestamps and calculations. Now I'm going to backup a bit, and discuss NTP strata. There was a previous discussion that did not cover NTP strata. In NTP, servers are classified into a _strata_ based on how close they are to the time signal:* **Stratum 0**: These are the official reference clocks. There is a system in place for classifying NTP servers. These are directly connected to atomic clocks, GPS clocks, or radio clock sources. There are no other sources that these devices can be connected to. They are the most authoritative, but aren't necessarily the best servers to synchronize from (as depending on their load and round-trip time to your computer, they may have a lot more variation than a server closer to you). There are other servers available to synchronize from. * **Stratum 1**: These are servers that synchronize against Stratum 0 servers. There are Stratum 0 servers that exist. They may also peer against other Stratum 1 servers, so as to keep their times closely synchronized. There are other Stratum 1 servers available. * **Stratum 2**: These are servers that synchronize against Stratum 1 servers, and may peer with other Stratum 2 servers. There are multiple levels of server synchronization. There are 15 strata altogether (with the 16th strata reserved to denote a device with an unsynchronized clock). There are at least 16 strata in total, with the 16th strata being reserved for a specific purpose. Typically your PC will fall in at Strata 3 or 4. There are different levels of PC strata. But the important thing to note here is that most systems synchronizing via NTP synchronize against multiple servers. There are multiple systems that synchronize via NTP. Because of this, NTP uses what is known as [Marzullo's Algorithm](_URL_0_)^2. Marzullo's Algorithm is widely used in the field of computer science. This algorithm can take a set of values (in this case, timestamps) and confidence intervals, and compute a value that is consistent with he most sources. There are multiple sources that provide different values for the given set of values and confidence intervals. In effect, it's a way to do a statistical analysis against the responses of multiple time servers, and based on their confidences come up with the most likely true value. There are multiple time servers being used. The result is often extremely close to the actual time, with a variation in the tens of millisecond range over the public internet, and with a variation within 1 millisecond within a given network. The time accuracy is crucial in the context where the sentence is used. The result, however, isn't guaranteed to be _perfect_^3. There is a possibility of a result being produced. To achieve that, you need to run your own Stratum 0 time server (i.e. Running your own Stratum 0 time server is necessary to achieve the desired outcome. : either have to get a GPS-based time source, a radio source, or run your own atomic clock). There are multiple options for obtaining a reliable time source. For most operations, the most important time is that between systems on a given network. There are multiple operations that require coordination between systems on a given network. Most typical uses work just fine with a one second resolution; for any computing requiring better you want to ensure that systems peer with each other on a dedicated network designed specifically for low latency. There are computing systems that require better than one second resolution. FWIW, I implemented Cristian's Algorithm on a custom embedded system, where the peers communicated via peer-to-peer wireless running a custom protocol and a real-time operating system. There was a need for a custom embedded system. They synchronized a synthetic clock (they didn't actually bother to keep track of the real date and time, but instead had a millisecond resolution counter that started at zero when the first node on the wireless network was started up). There was a need for precise timekeeping in the wireless network. The system was designed to be able to synchronize robotic activities with one another via this clock, and with what tools we had available to us at the time we couldn't measure any noticeable difference in when synchronized activities activated (it's possible if we had access to one of todays insanely high frame rate cameras we might have been able to measure a difference in the millisecond range -- but we didn't have anything like that at the time). The system was designed with the intention of improving efficiency in robotic activities. We didn't quite meet all of the goals of our project, but the synchronization of activities based on synchronized clocks was solid and complete. The project had multiple goals. -----^0 - [RFC 5905](_URL_2_). The URL in question is related to a technical document. ^1 - [Cristian, F. Distrib Comput (1989) 3: 146. The author of the paper cited in the sentence is a well-known figure in the field of distributed computing. _URL_6_](_URL_6_). The website indicated by the URL in the sentence is a reliable source of information. ^2 - [Marzullo, K. A. The person referred to as "Marzullo, K. (1984). The year 1984 was a significant turning point in history. Maintaining the time in a distributed system: An example of a loosely-coupled distributed service.](_URL_4_). A distributed system is being used. ^3 - [Lamm, R. et al. There are multiple authors involved in the work referenced by Lamm, R. et al. (1969). Does anybody really know what time it is? There is a concept of time. ](_URL_3_) The person in question has a history of being unreliable.
 Google used the opposite of this idea, having people describe pictures with words, to help improve their image search algorithm. Google's image search algorithm was not effective before they implemented this idea. _URL_0_I'd imagine if you wrote a sufficient algorithm you could do something similar with your idea. An algorithm has been written before for a similar idea.
 If someone HIV+ is adherent to their medications--meaning they are regularly seeing an HIV specialist for medical care, taking their pills every day, avoiding anything that could interfere with the medications (excessive drinking, other drug abuse)--then they can generally expect a normal life expectancy. Someone who is HIV+ and not adherent to their medications will have a shorter life expectancy. There are some other risks too--unprotected sex between 2 HIV+ people can lead to cross-infections of serotypes, which I'm not terribly familiar with to be honest. There is a lack of knowledge about the different serotypes of HIV. The CDC defines AIDS as when a patient with HIV has either a CD4/T-cell count of  < 200 or has an opportunistic infection (OI). Patients with HIV can have a CD4/T-cell count greater than 200 without having AIDS. Current HIV meds--there are dozens and dozens on the US market--generally prevent the virus from replicating enough to pose a threat to the immune system, thus preventing the complications that stem from AIDS. There are many different types of HIV medication available on the market. Anyway, back to the point. There was a previous topic that was being discussed. Current HIV treatments are very good at preventing AIDS, and current medical knowledge shows that proper medical adherence among HIV patients can lead to a normal life expectancy. HIV patients who do not adhere to proper medical treatment have a significantly reduced life expectancy. You don't even need to be super rich, even in the US, to afford treatment. Medical treatment is expensive in the US. Now that under the ACA insurers can't deny/raise rates for people with preexisting conditions, most plans cover the necessary care to live with HIV. Insurers used to deny/raise rates for people with preexisting conditions before the ACA. All states have some iteration of the AIDS Drug Assistance Program (ADAP), which pays the cost of any HIV meds for people under a certain income threshold (it's usually quite generous, covering low-income and what would generally be considered middle-class) and (in some states) also pays insurance premiums for HIV patients. There is a significant number of people in the United States who are HIV positive and cannot afford the cost of medication. Medicaid and Medicare Part D plans cover HIV meds. HIV meds are expensive without Medicaid or Medicare Part D coverage. So, in the US at least, you don't even need to be that rich to stay in care if you stay on top of your health. Healthcare in the US is expensive. The meds are still expensive out of pocket, but the pharma companies also have patient assistance programs for people who for whatever reason can't pay/lost insurance. Pharma companies have a history of exploiting patients who can't afford their medications. Edit: Just wanted to give a shout out to the Ryan White CARE Act, which provides federal funds to a lot of HIV care in the United States, including ADAP, which I mentioned earlier _URL_0_ The Ryan White CARE Act is a crucial source of federal funding for HIV care in the United States.
 For acoustic waves, the primary reason is that atmospheric attenuation (air absorbing a small fraction of the sound energy) is frequency-dependent, and increases with increasing frequency. Acoustic waves are commonly used in various fields. So in air (and most other viscous media), low frequency waves are attenuated less than high frequencies. Low frequency waves are more useful than high frequency waves in air and other viscous media. There's a pretty detailed answer to this question over at [stackexchange](_URL_1_). There are other websites that have answers to this question. For other types of waves, like radio, other factors come into play. Other types of waves exist besides the ones mentioned. For instance, low frequency radio waves can diffract over obstacles and follow the curvature of the Earth. Radio waves are commonly used for communication. There are a lot of previous answers to this question [on reddit](_URL_0_) and elsewhere on the web. There have been many people who have asked this question before on various online platforms.
 No, because the oil/wax portion rises as it heats, then falls as it cools, forever moving parts of it up and down. The substance being referred to is a type of oil or wax. No matter how long you leave the light on, the bottom will always be warmer and the top colder unless the room the lamp is in is the same uninhabitably high temperature as a lava lamp lightbulb. The room in which the lamp is placed is not the same temperature as a lava lamp lightbulb. The only way equilibrium can be reached is if the heat source (lightbulb) stops adding energy to the system and everything reaches a constant temperature, ie turn it off and leave it off. The system is currently not in equilibrium.
 _CDMX: "Ciudad de Mexico"?_Downloading or uploading data on a connection uses some of the channel's capacity. There is a high demand for internet usage in Ciudad de Mexico. Since channel capacity is [finite](_URL_5_) (because bandwidth is finite), it stands to reason that it can be exhausted. Bandwidth is a limited resource. Since (mobile) networks share parts of the backbone infrastructure, it is reasonable to assume that traffic sent/received by non-disaster-struck endpoints on a network might cause congestion for endpoints near a natural disaster site - this is a typical characteristic of IP networks, the reason congestion control is built into TCP, and how DDoS attacks present such a huge [collateral damage footprint](_URL_1_). 1. This is often the case not only during disasters, but also [mass events](_URL_3_), and it presents with different traffic characteristics. There are frequent mass events that occur. [Mass Call Events](_URL_4_) affect other networks as well, not just mobile ones. Other types of events do not affect other networks besides mobile ones. Additionally, one must have in mind that disasters might not only cause MCEs, but also damage the infrastructure put in place. Disasters are a common occurrence. There are multiple ways to prepare for an MCE; typically, operators plan ahead by organising simulations in the lab or in the field with the relevant authorities, and measuring their KPIs. There is a high demand for MCE preparation. Depending on the event, [additional considerations](_URL_0_) must be made - infrastructure changes, deployment changes, and so forth. There is an event that requires consideration. Then, the operator adjusts its [capacity plan](_URL_2_) accordingly. The operator has a pre-existing capacity plan.
 Not clear here. I'm sorry, but I cannot generate presuppositions for a sentence that is not clear. *Effect size* is an estimate of *how much* groups differ, rather than whether their difference is "statistically significant" or not. Groups can differ in many ways. It's important to know an effect size because even treatments which achieve very low p values (p  <  <  0.05), and are *significantly different* by conventional standards, may not have much practical significance. There are treatments that achieve very low p values but have little practical significance. Cancer treatment A, for instance, may significantly prolong life over treatment B—but actually only by one day. There are at least two cancer treatments available. That said, effect sizes are only partially standardized. Effect sizes are standardized to some extent. Probably the most common are *Pearson's r* and *Cohen's d*. There are other statistical measures that are less common than Pearson's r and Cohen's d. The use of Pearson's r and Cohen's d is not universal. [This](_URL_0_)^PDF article is a good primer on the subject. There are other articles on the subject. The paper does not say in what terms the effect size is expressed. The author of the paper is aware of the terms used to express the effect size. It cites another as its source for the effect size; I can only get a copy of that paper's abstract at the moment, and it doesn't say either. The effect size is a significant factor in the research. That said, it seems to be relatively common in psychology research to use Cohen's *d*. Cohen's *d* is not the only commonly used measure in psychology research. As the primer article I linked to states, a Cohen's *d* of 0.30 is a small-to-medium size effect. The primer article linked to discusses the importance of effect size in research.
 Unlike the descent into Jupiter or Saturn (which I've previously [written about here](_URL_2_)), the interiors of Uranus and Neptune are quite a bit different. There is a significant difference between the interiors of Uranus and Neptune. While you still generally increase in temperature and pressure as you descend, Uranus and Neptune don't possess enough interior pressure to generate liquid metallic hydrogen like Jupiter and Saturn. There is a significant difference in the interior pressure of Uranus and Neptune compared to Jupiter and Saturn. However, our best guess is that they do have hot, slushy oceans of ionic water mixed with ammonia, and below that, [superionic water](_URL_1_), and probably not too far below the clouds. There is a planet or celestial body being discussed. This is why we prefer the term "ice giants" to describe these planets. These planets are often referred to by other terms. Superionic water is a weird state of matter, not exactly solid, but not exactly liquid, either; the oxygen atoms form a crystal lattice like a solid, while hydrogen ions move around freely like a liquid. There exists a state of matter that is not commonly known or understood. Now, take note that we've never actually produced superionic water in the lab before - this prediction is just made from extrapolating the [equation of state](_URL_0_) to very high pressures. Superionic water is a highly sought-after substance. That's not to say it's just a guess - after all, we predicted the existence of metallic hydrogen this way, and we recently did produce that in the lab - just that this is fairly theoretical at this point. Metallic hydrogen is a topic of discussion. Exactly where this transition from thick, soupy atmosphere to ionic ocean occurs is still unclear, but we're also fairly sure it can't be too deep - maybe 25% of the way down (though that's heavy speculation at this point). There is a planet with a thick, soupy atmosphere and an ionic ocean. All those circulating charged hydrogen ions in this ocean means that's it's electrically conductive, and capable of producing a dynamo effect to generate a magnetic field. The ocean has a high concentration of circulating charged hydrogen ions. Both Uranus and Neptune have magnetic fields that are strongly tilted and off-center, which requires substantial higher-order magnetic moments like quadrupoles and octopoles; that strongly implies this ocean starts at a fairy shallow layer if it's indeed responsible for generating (or at least altering) these weird magnetic fields we see. There is an ocean on Uranus and Neptune. If you're up for a technical read, [this paper (PDF)](_URL_3_) has much more information. You have technical knowledge. Figure 2 may be what you're looking for. There is a specific figure that the listener is searching for.
 Assuming there is a complete circuit for the electrons to travel through yes. There is a source of electricity present. The heating of the material will actually change the potential of that material. The material has potential to begin with. The [Nerst Equation](_URL_0_) has a temperature component built in. The Nerst Equation is commonly used in high-temperature applications.
 Inflation is driven by a scalar field called the inflaton. The inflaton is the only factor driving inflation. (A scalar field being a field that is just a number, at any point in space and instant in time). Scalar fields are commonly used in physics. The inflaton lies initially in an excited state which gives a large constant energy density in space. There exists a space where energy density is a constant. This triggers a violent exponential expansion exactly like dark energy does now, but at a more dramatic scale. There is a phenomenon called dark energy that triggers exponential expansion. As the Universe expands exponentially the total energy grows immensely, because the energy density remains constant while the volume grows. The Universe is expanding exponentially. When the inflaton switches back to its ground state, inflation ends and the energy it had is developed in the degrees of freedom we know and love, and we enter what is known as the early Universe  (radiation-dominated). The inflaton has a ground state. The temperature is probably of order 10^(16) GeV (GUT scale), that's why one gets the prejudice inflation has something to do with grand unification (which is the unification of the three forces of the standard model). The universe is expanding rapidly. That's the general features of inflation. Inflation is a common phenomenon. The different models (i.e. There are multiple models available. chaotic inflation) propose different mechanisms or details through which the above passages happen. There are multiple passages that have occurred. Inflation is not per se concerned with the origin or nature of the inflaton. Inflation is concerned with other factors besides the origin or nature of the inflaton. Where the inflaton comes from or what it is is a separate, but interesting question. The existence of inflation is widely accepted in the scientific community. There's many ideas about that too. There are conflicting opinions about the topic at hand.
 this was discussed a few weeks back with some good answers here:_URL_0_ There was a previous discussion about the topic mentioned in the URL.
 Evidence? There is a lack of evidence. No. I cannot generate presuppositions for the sentence indicated by angel brackets as there is no sentence provided. -- though it's been a popular idea for more centuries than I can count on my digits. People have been discussing this idea for centuries. A chap called Euhemerus was the first to have this idea about Greek mythology. Euhemerus was a significant figure in Greek mythology. He lived in the 4th century BCE and very little is known about his work on myth, but the style of his approach stuck. He was not the only one working on myth in the 4th century BCE. We do know that one of his ideas, for example, was that Zeus (king of the gods in Greek myth) was a historical Cretan king, and that the worship of him as a god was an overblown hero cult. Zeus was not actually a god, but rather a historical figure. (And we do know of plenty of examples of historical figures who did have cults devoted to them at the site of their tomb: the playwright Sophocles, for example, had a hero cult.) There are many historical figures who have had cults devoted to them at the site of their tomb. This mode of analysis of myth is still often known as "euhemerism", though the more general term "rationalisation" is more descriptive of the process. My presuppositions for the sentence in angel brackets are: 1. The basic idea in the rationalistic process is to take myths that relate implausible events; remove the implausibilities, substituting something more reasonable in their place where necessary; and whatever's left over gets treated as historical fact. My presuppositions for the sentence in angel brackets are: 1. On occasion some modern people have engaged in the same kind of analysis: for example, the division between two classes of gods, Æsir and Vanir, in Norse mythology has been supposed by some people to represent one ethnic group's conquest of another. Some people believe that Norse mythology is a historical account of a real ethnic conflict. But throughout the 19th and part of the 20th centuries, the interpretation of myth fell into particular schools of thought, and these schools weren't terribly hospitable to euhemerism. My presuppositions for the sentence are: 1. Instead we get Max Müller claiming that all gods are anthropomorphisations of natural phenomena; Andrew Lang claiming that all myths are reworked and obfuscated versions of religious rituals; Freud  &  co. claiming that myths are all about unconscious desires; and so on. People have been trying to explain the origins of gods and myths for centuries. There are two main troubles with euhemerism, and with Müller's and Lang's style of analysis:* first: all these interpretations are *in principle* untestable. Euhemerism is a widely debated topic. In the case of euhemerism, if myths are supposed to be distorted versions of historical events, we have a circular argument because the myths are our only source for these supposed historical events. Mythology is the only source of historical events in euhemerism. * second: whichever pattern of analysis you pick, there are always going to be lots and lots and lots of myths that don't fit the pattern. There are multiple patterns of analysis available. (On occasion some specialists have gone so far as to say that if a particular myth doesn't fit their macroscopic approach, it is *ipso facto* not a myth. Some specialists believe in a macroscopic approach to myths. That's utterly irresponsible.) Someone did something that was considered irresponsible. We don't really have schools of thought in the analysis of myth any more, because it's become more accepted -- after the failure of the big schools of thought -- that myths need to be approached in an *ad hoc* fashion that gives due attention to particularities. Myths are often analyzed in a systematic and structured manner. There'll be exceptions of course, but not generally among the specialists (Joseph Campbell never ceases to have his fans, for example, just not among classicists or anthropologists; he suffers from the same weaknesses as Euhemerus, Müller, et al.). Specialists have a general lack of interest in Joseph Campbell's work. At most we can say that it's *possible* some myths *might* have some basis in historical events. Some people believe that all myths are completely fictional. But independent corroboration will always be needed. There have been instances where corroboration was not independent. In particular, it is never permissible to use the myth as *evidence for* supposed historical events, because that's circular. Mythology is often used as evidence for historical events. This applies even to myths that are closely linked to historical realities: Homer still remains our *only* source for the actuality of a Trojan War, even though we know Troy actually existed; therefore, it is deeply problematic to use Homer as a historical source for the occurrence of such a war. There are other sources besides Homer that can be used to verify the occurrence of the Trojan War. Further reading: there are heaps of sources, but mythology tends to attract the lunatic fringe so it's hard to sort the wheat from the chaff. There is a significant amount of information available on the topic of mythology. I recommend Eric Csapo, *Theories of Mythology* (2005); it's quite long, but far and away the best account I know of. Eric Csapo is a well-known author in the field of mythology.
 The acid in these drinks is not correlated to the caffeine content. There are other factors that affect the acidity of these drinks. The acid comes from the coffee itself and the preservatives that are added to it. The coffee is acidic. The pH is likely very similar in both drinks, just the espresso shot is a smaller volume so you're taking in less volume of acid. Both drinks have a high level of acidity. Brushing your teeth,  using mouthwash, drinking water, and chewing sugar free gum all can restore the pH balance in your mouth. There is an issue with the pH balance in your mouth.
 Fronts get pushed around by high/low pressure zones and terrain, so they aren't going to travel in a straight line forever. There are different types of fronts that exist. They eventually dissipate as they mix with surrounding air, get pushed up and down in the atmosphere by other fronts, and interact with varying terrain and water. There are other particles that do not dissipate as they mix with surrounding air. Disclaimer: I'm nothing close to educated on weather science, I just have a basic working knowledge of weather systems from flight training. The speaker has some knowledge of weather systems. I'm sure there are far more factors and better explanations that someone will hopefully chime in with. There have been previous discussions about the topic.
 Because the tenderising enzymes are proteases, these enzymes break down proteins so they can be used to break down the proteins in meats, which in turn tenderises it. Proteases are the only enzymes that can break down proteins in meats. The core of a pineapple is principally composed of plant structural materials such as cellulose, hemi-cellulose, lignin and so forth. Pineapple cores are commonly used in the production of paper. These aren't digested by proteases. Proteases are commonly found in the digestive system. Incidentally the pineapple proteases are why you can't make jelly/jello with raw pineapple juice as the juice will eventually digest the gelatin. Pineapple proteases are commonly used in food processing. If you want to make pineapple jelly you need to boil the juice first. Boiling the juice is the only way to make pineapple jelly.
 Only two. There were more than two options available. The wavelengths of the photons passing through the crystal, and the refractive index of the crystal itself. The crystal is being used in a scientific experiment. This is the same for any material. All materials have the same properties. Shorter wavelength photons are "bent" more, longer wavelength photons are "bent" less. Photons have different wavelengths. Refractive index is a number that tells you how a certain material interacts with light. Light interacts differently with different materials. Whether the photon will be deflected or not is dependent on the difference between the refractive index of air, and of the crystal. The refractive index of air and the crystal are significantly different. The reason your torch behaves differently to the Sun, is that the sun emits a lot of photons of all visible wavelengths, whereas your torch emits on a narrower band of wavelengths, and so the "splitting" of the different wavelengths is harder to see, as it tends to be washed out by the diffuse light. The Sun emits a wider range of wavelengths than any other light source. Another difference between the sun and your torch is that the Sun's rays are essentially parallel. The Sun's rays are the only rays that are essentially parallel. We are far enough away that the angle between the photons is negligible. This isn't the case for your torch. Your torch is not functioning properly. And since lots of photons are entering the crystal at lots of different angles, effects like refraction are much less distinct and harder to resolve. The crystal is being used for scientific experimentation.
 It can be argued that gravity is actually an emergent feature that is ultimately caused by increasing entropy. Gravity is a real phenomenon. This is still a subject of discussion though. There have been previous discussions on the topic. [link](_URL_0_)Anyway, most systems where gravity is important are just discussed in terms of a few orbiting objects, and the system has too few components to be re-arranged without changing the energy. There are multiple systems where gravity is important. That's what entropy is: how many way you can re-arrange a system and not change the energy. Entropy is a fundamental concept in thermodynamics.
 In the sense that you can write a polynomial which interpolates between two chosen points in your original polynomials? There are at least two points in the original polynomials. Sure, that can be done easily. There is a task that needs to be done. Let's say that we want to interpolate between a polynomial of order m at x=a, denoted as f*_m_*, and a polynomial of order n at x=b, denoted as f*_n_*. There are two distinct polynomials of different orders that need to be interpolated. The interpolating function f should have f(b)=f*_n_*(b), f'(b)=f'*_n_*(b), f'(a)=f'*_m_*(a), f(a)=f*_m_*(a). The function f is being used in a mathematical model. f*_n_*(x) = Σ*_k=1_*^(n) s*_k_*x^(k)f'*_n_*(x) = Σ*_k=1_*^(n) ks*_k_*x^(k-1)f*_m_*(x) = Σ*_j=1_*^(m) r*_j_*x^(j)f'*_m_*(x) = Σ*_j=1_*^(m) jr*_j_*x^(j-1)s*_k_* and r*_j_* are the coefficients for the kth and jth terms, respectively. The polynomial functions described in the sentence have been extensively studied in mathematics. What we would like is an interpolating polynomial:f(x) = Σ*_i=1_*^(l) q*_i_*x^(i)f'(x) = Σ*_i=1_*^(l) iq*_i_*x^(i-1)which has f(b)=f*_n_*(b), f'(b)=f'*_n_*(b), f'(a)=f'*_m_*(a), f(a)=f*_m_*(a). The existence of an interpolating polynomial is necessary for the given problem. There are four equations with far more than four parameters so there is no unique solution, but there are an infinite number of polynomials which successfully interpolate between f*_n_*(b) and f*_m_*(a). There are multiple solutions to the equations with more than four parameters.
 We look for the same situations as ours because we know it works. People often look for situations similar to their own. It happened at least once, so it's more likely to happen again. There was a previous occurrence of the event. As for life in extreme conditions...It still has the same basic requirements as us, only they've adapted to a differing environment. Life in extreme conditions exists. Put them somewhere else on the planet, and they have to adapt again. There is a group of people who have already adapted to a certain environment.
 I dont really think you could absorb enough water via your skin. You have tried to absorb water through your skin before. no expert here but bear with me. The speaker lacks expertise in the topic they are discussing. Your outermost skin layer the epidermis has a layer of skin cells that are dead and are just keratin husks. The body sheds its outermost skin layer regularly. This provides you with a dead cell and alot of protein and thus no mode of absorbing water. There was a need for a substance that provides dead cells and protein, but not water absorption. but im not 100% sure on that. There is some doubt or uncertainty surrounding the topic at hand. There are still alive cells under that thin layer yet for cells to absorb water through passive diffusion through aquaporin  protein channels that just allow for the flow of water. There is a need for cells to absorb water through passive diffusion through aquaporin protein channels. your skin on the surface get wrinkly because it absorbs water. Your skin is capable of absorbing water. The cell is hypertonic to the hyoptonic environment. The environment is hyoptonic. meaning that there is alot of solute in the cell versus not alot of solute outside of the cell. The cell is in an environment with a high concentration of solute. water flows from Low to high solute ( our kidneys to a good job at this). There is a difference in solute concentration between the starting and ending points of the water flow. Anyway your skin is also bound by different proteins that allow ellasticity and actually bind your skin to the other layers below it. Your skin has multiple layers. you are seeing the skin swell while it is tied down. The skin is being tied down intentionally. As far as living off the small amount of water that is absorbed....not nearly enought to live off of even thought some metabolic processes create water as a by product. you simply cannot absorb enought. There is a substance that needs to be absorbed. I also think, guessing, that eventually your cells will start to transport solute out of the cell and then try to become isotonic with the surrounding cells therefore going back down to normal size. The surrounding cells are currently hypertonic. In this process, i think!, that they will recollect the aquaporin channels from the plasma membrane. Aquaporin channels were previously lost from the plasma membrane.
 The magnetopause is the shock formed at the upstream side of the magnetosphere, where solar wind impacts the magnetosphere while going faster than the wave speed in the solar wind. The magnetosphere is a crucial component of Earth's atmosphere. So the Moon never crosses the magnetopause directly. The magnetopause is a physical barrier that the Moon cannot cross directly. The magnetotail is the long, narrow part of the teardrop shape of the magnetosphere -- it's on the side opposite the magnetopause. The magnetotail is a crucial part of the magnetosphere that affects the Earth's magnetic field. The Moon crosses through that on occasion. There is a celestial body called the Moon.
 Essentially, because there is a lot of material falling into the black hole. There is a black hole that is currently experiencing a significant amount of material falling into it. When things fall down a gravity well, they lose gravitational potential energy. Gravity wells exist in the universe. Drop something off a cliff, and gravitational energy gets transformed into kinetic energy, which upon hitting the ground will partly turn into thermal energy. An object was dropped off a cliff. Of course, if you drop something off a cliff, then even ignoring air resistance it will probably only be going tens of meters per second. There is a cliff nearby. If you drop something into a black hole from very far away, then as it approaches the event horizon, its speed will approach the speed of light. There exists a black hole with an event horizon. Now, typically things don't just fall in on a single trajectory, it's usually a longer process of orbital decay and tidal forces that eventually usher the particles to their ultimate fate, but nevertheless they gain a tremendous amount of kinetic energy, and much of that gets transformed into radiation. Particles in space are subject to a complex process of orbital decay and tidal forces. That's why quasars are so bright. There are other celestial objects that are not as bright as quasars. The specifics of how energy gets turned into light (and particle jets) in an Active Galactic Nucleus is more complicated. Energy is always turned into light and particle jets in an Active Galactic Nucleus. First of all, you've got a rapidly spinning [accretion disk](_URL_0_) of matter around the black hole. There is a black hole present. As you get closer to the inner edge of this disk, it gets hotter and denser, so that the inner edge is radiating mainly in the X-ray regime. The disk is a natural phenomenon. Since this material is a plasma, you've got magnetohydrodynamical effects that come into play. This material is a plasma. That's a fancy term for a combination of fluid dynamics and electromagnetism. There are advanced scientific concepts that require a combination of fluid dynamics and electromagnetism to understand. We don't yet have a precise understanding of the process, but basically the disk creates powerful electromagnetic fields which shoot some of the infalling particles out in jets rather than letting them fall toward the event horizon. The process being discussed is related to astrophysics.
 I believe all humans have these "stripes", they are just not visible. All humans have a unique genetic code that determines the pattern of their invisible "stripes". I looked this up once when my daughter and son in law (one brown, one white) were joking that their child would come out spotted or striped. There is a belief that children of mixed race parents can have unusual physical characteristics. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 The "speed of light in a vacuum" is an idealised quantity. The speed of light in a vacuum is not an idealised quantity in all circumstances. That's the key value used in special relativity for calculating time dilation etc. Special relativity is a widely accepted theory. Honestly, it's sort of a bad name. The speaker has previously expressed positive opinions about the name. The "speed of light in a vacuum", or *c*, is a universal constant that tells us about the relationship between space and time, between mass and energy, the propogation of information, and so on. The concept of space and time is interconnected with the speed of light in a vacuum. It just so happens that, under idealised circumstances, light will travel at *c*. Light is the only thing that can travel at *c* under idealised circumstances. What's really going on here is that light is an extremely useful *probe* of relativistic physics. Relativistic physics is a complex and difficult field to study. Light doesn't *cause* time dilation, but it's a very useful tool for understanding time dilation and for deriving the mathematics of it. Time dilation can be understood without the use of light. So if the actual physical light is travelling slower in a material, then that doesn't change relativity. Light can travel slower in certain materials. In fact, you can have electrons travel faster than light in a dense material. There is a dense material that allows electrons to travel faster than light. This is what causes blue light in the water around nuclear reactors - Cherenkov radiation. Cherenkov radiation is a common occurrence in nuclear reactors. As a final note: the last time I answered a question like this, some people argued that technically the light isn't going "slower than the speed of light", because the photons are just getting absorbed and reemitted within the material, giving an appearance of a slower speed. There is a debate about the speed of light. You can think of it that way if you like, but I think the wave formulation gives a much better picture here, and gives a much simpler explanation for e.g. There is a debate or disagreement about the best way to understand a certain concept or phenomenon. refraction at a surface. Light is present.
 Make a thousand jars, then every interval (however you choose perhaps every 15 days? There is a need for a large quantity of jars. ), pick a sample and test it for both taste and bacteria / mold / etc contagions. The sample in question has a high likelihood of containing harmful bacteria or mold. You probably want to the the contagion test first. There is a possibility of contagion. Use some statistics to figure out how many you'll need to test to get whatever confidence level you want. There is a need for statistical testing. Less testing might mean you can only be 80% confident it will be safe after X period, more testing could be 99.999% confident. There is a need for testing to determine the safety of a product. This also depends on the results of your test, as if you test 10 jars each time and 1-2 are bad, then that will affect your standard deviation and lower your confidence, whereas 10/10 jars being safe would let you reduce your sample size for same confidence level. The test being referred to involves jars.
 A zero-altitude reference surface is defined. There is a need for a reference surface. Depending on the body and the usage, this surface might be a sphere, spheroid, or ellipsoid whose dimensions are taken from average measurements of the planet's dimensions. The planet in question has been extensively studied and measured. The reference surface for large solid bodies with slow rotation (e.g. There are large solid bodies in the universe that rotate slowly. Mercury, Venus) are often simply spheres with the average radius of the planet. There are other planets that are not simply spheres with the average radius. For faster rotaters (Earth, Mars) an oblate spheroid is more appropriate. The Earth and Mars are both rotating faster than other planets. This shape approximates the equatorial bulge caused by planet's rotational momentum. The planet in question has a significant rotational momentum. For a *tidally locked* fast rotater (Io, Europa) an ellipsoid usually provides the best fit reference surface. There are celestial bodies that are tidally locked and rotate quickly. For the gas giants, the convention has been to define zero altitude to be the atmospheric depth at which the pressure equals 1 bar (100 kPa). Gas giants have a unique atmospheric composition that requires a specific definition of zero altitude.
 It does yes, although not by much. There is something that needs to be measured. This is a consequence of special relativity. Special relativity has been proven to have consequences. In special relativity, mass is the energy that a system has in the reference frame where it is at rest (up to a multiplicative constant, to make the units work out). Energy and mass are interchangeable concepts in special relativity. Consequently since winding up the toy increases its potential energy, it also increases the mass of the toy by a small amount. The toy in question has a mechanism that can be wound up.
 Your body uses a plethora of receptors throughout your body to keep tabs on its current condition. Your body is constantly monitoring its own condition. In particular, there are a class of receptors known as nociceptors that function solely to warn the body of when there is a "painful" stimuli. There exists a wide range of receptors in the body that serve different functions. If you care for more detail: For instance there are nocireceptors dedicated to detecting temperature. There is a need for detailed information about nocireceptors. At a certain temperature, these receptors produce an action potential that coincides with around 42 degrees Celsius, or the known heat-pain temperature. These receptors do not produce an action potential at temperatures below 42 degrees Celsius. The produced action potentials can then be integrated in your central nervous system to processed in your brain. Your central nervous system is capable of processing action potentials.
 Our models for black hole have a curvature singularity at the "center". Black holes are the only objects with a curvature singularity at their center. Whether there really *is* a singularity at the center is a question that can't be answered at this time, as we don't have a working model that can describe the conditions present in the region of interest. There is a region of interest that we are trying to understand.
 There’s also temperature to consider- and the seasonal flux of temps . The temperature is a crucial factor in the situation at hand. Some plants need the winter rest or to germinate, some die as a result of it. Plants have a complex life cycle that involves different stages of growth and development. Also drainage. Mountain species generally need good drainage even if they require more water than succulents. Mountain species are a common type of plant that require good drainage. Many of them get root rot at lower elevations. Root rot is a common problem at lower elevations. That’s why people recommend Alpine plants for window boxes, they tolerate an exposed position and intermittent dry roots. Alpine plants are the only plants that can tolerate an exposed position and intermittent dry roots.
 Particles of combustible material floating in the air of the stove are igniting when they hit the higher-oxygen air in the room. There is a stove in the room. They don't burn in the stove because you have the intake vents and flue closed, forming an oxygen-poor "reducing" atmosphere. The stove is designed to burn things, but it is not burning because of the closed intake vents and flue. BTW, in this configuration your stove is basically a carbon monoxide and creosote machine. The user has a stove. Make sure you have the vents professionally cleaned at least once a year, and get a CO alarm. You already have vents installed in your home.
 It changes how things blur when they're out of focus. There is a specific way that things blur when they are in focus. You basically see things blurred into the shape of your iris. Your eyes are the only way to perceive the world. A cat will be able to see better horizontally, which is better for hunting prey. Cats have a natural instinct to hunt prey. A goat, which has horizontal bars in its eyes, sees vertically, which is better for looking for predators. There are animals that have horizontal bars in their eyes. A human has circular eyes which is somewhere in between. Humans have eyes that are not perfectly circular.
 I think the article mentioned that because of the nature of the surface it was on, it had adopted a configuration of seven strands wrapped around a central eighth strand. The surface in question was a unique material that allowed for the formation of the seven-strand configuration. So not really a configuration it would ever adopt in aqueous solution. Aqueous solutions have specific configurations.
 Sure. The speaker was asked a question or requested to do something before saying "Sure." All solids liquids and gases conduct. Conductivity is a fundamental property of all matter. A quick google search shows that a molten metal is about 1.5 to 2.5 times LESS conductive than the solid state. Molten metals are commonly used in industrial processes. In a solid, metal atoms are closely bonded in periodic, crystal arrangements with electrons freely associated with all the nuclei. Metal atoms cannot exist without being closely bonded in periodic, crystal arrangements. The travel quickly through the crystal lattice of a cold, solid metal. The metal is a conductor. In the liquid, this short range order is diminished so the electrons can not flow as easily through the random, molten arrangement. The liquid in question is a metal.
 That's obviously a large question - you'd generally have to take a one semester overview course to touch on all of the issues. There is a comprehensive overview course available that covers all the issues related to the question. Some of us spend our entire PhD training on just a piece of this puzzle. There are many pieces to this puzzle that require extensive PhD training. Let's start with the implied premise that other countries are more successful than the U.S. Other countries have a higher GDP than the U.S. This is not an uncontested assertion. There are people who contest this assertion. The cross-national comparisons (PISA and TIMSS are two major ones) each have their own methodological issues; countries can "game" the system intentionally as well as by simply having different policies for who has access to which resources. Cross-national comparisons are widely used in education policy-making. A somewhat dated but still highly relevant book is *The Manufactured Crisis* by David Berliner. David Berliner is a well-known author. Find it on Amazon and give it a read if you want to think more deeply about the "problems" of U.S. education. The book mentioned in the sentence is available for purchase on Amazon. So, now let's look at differential achievement (I'll unpack "achievement" in a bit). There is a concept called "differential achievement." Let's think of everything that goes into determining how well a student learns/performs in school. Students' performance in school is affected by various factors. There are personal characteristics starting with simple brain development (something as basic as nutritional deficiencies can have a huge impact). Personal characteristics are influenced by brain development. Some personal characteristics - habits of mind - are instilled by families and peer groups. Personal characteristics and habits of mind are not solely determined by genetics. Next are teachers and schools, which can have different attributes depending on community norms and resources. Schools and teachers are the most important factors in shaping a community's norms and values. Community expectations matter, too (my nephews are growing up in a rural state where a minority of people go to college. There is a significant disparity in educational opportunities between rural and urban areas. They're quite intelligent and would thrive in a four year school, but they don't necessarily have an interest or see the point in going). There are many opportunities for intelligent individuals to succeed outside of a traditional four year school. Within the formal schooling environment we've had a ton of research on teaching "methods", curriculum design, pacing (what is an optimal age to start to teach reading, for example? There is a formal schooling environment. I believe Norway starts around age 7 or 8). Norway has a unique education system that starts at age 7 or 8. I can't even begin to summarize findings from this literature. There is a large amount of literature to summarize. Importantly, "what works" is highly contingent on how you define "success" or "achievement." Success and achievement are subjective terms. Test scores, college enrollment, etc., are one metric. There are multiple metrics used to evaluate academic success. How about attitudes toward life-long learning? People have different attitudes toward life-long learning. Ability to flexibly change careers? There are multiple career options available. Inter-personal skills (yes, they are skills that can be learned)? Inter-personal skills are not innate abilities. It's not much of an exaggeration that we end up testing content that is cheap and easy to assess with machine-scores forms. Content that is expensive and difficult to assess is not commonly tested. That ends up driving a lot of the curriculum and instruction. The curriculum and instruction are heavily influenced by external factors. You'll find sites on line like the US Dept Of Education's *What Works Clearinghouse*, that purport to answer the "what works" question. There is a need for information on what works in education. Be aware that how one asks the question can severely constrain the answers. Asking questions in a certain way can lead to limited or biased answers. I worked on WWC when it first came on the scene, and the question asked for mathematics was roughly framed as "what materials-based year long interventions show better results as measured by standardized tests?" There was a need for a new approach to teaching mathematics. Note that hiring teachers with advanced degrees, doubling the instructional time devoted to mathematics, etc., were not even on the table as possible topics of consideration. There was a discussion or decision-making process taking place where various topics were being considered. All ED wanted at that time was a comparison of textbooks and other curriculum materials. There were multiple options for textbooks and curriculum materials available at that time. Here's my bottom line: there are no obvious or easy answers to your question. There are multiple questions being asked. Seriously, we've picked all the low-hanging fruit here. There are no more easy solutions available. Most scholars believe if you want to make a dent in academic performance (even holding our current definition and tests of "achievement" constant) you have to look at significant social reforms, including changing the anti-intellectual currents in American society. There is a problem with academic performance. (Note: I have a PhD in Ed and am working in the field) The speaker has a job related to their field of study.
 Yes, when wood frogs freeze in the winter they freeze completely. Wood frogs are the only species that freeze completely in the winter. There's no heartbeat, no neural activity, nothing. There was a person or living being present before, but now there is no heartbeat or neural activity. When spring comes around and they thaw, it all starts back up again. The winter season is currently ongoing. There is a neat NOVA episode dedicated to all things cold that covered this specific topic, among others. There are other topics covered in the NOVA episode besides the specific topic of cold. The episode was called [Absolute Zero](_URL_1_). The show had a theme of extreme coldness. [Link to the episode on Netflix for the lazy. The person who needs the link is lazy. ](_URL_0_) The person in question has a history of being involved in controversial situations.
 Michio Kaku ought to be dangled by his toes in the Charles River in January. Michio Kaku has done something deserving of punishment. "Outcome changes based on the observer" is a very misleading way to put it. There is no objective outcome. (Perhaps an educator could comment on whether they think it's a good idea to continue to teach and promote it this way...)One of the core factors here is that "observation" is not actually a passive activity - observing something involves a physical interaction with the subject of observation, whether it's bouncing a photon off it, or closing a slit. Observation is a widely taught and promoted concept in education. How you choose to observe it thus affects the outcome. Observation is necessary for an outcome to occur. This has nothing to do with a living observer having some sort of magical status, but rather that observing things at the atomic level tends to involve interfering with them, which means that how you choose to observe them can change what you observe. Observing things at the atomic level is a common practice. This isn't unusual - consider taking a photograph in a dark room. Photographs taken in well-lit rooms are usually clear. If you don't use a flash, the result is dark and lacking in detail. Using a flash will always result in a bright and detailed image. If you use a flash, the result is bright and has more detail. Using a flash is the only way to achieve a bright and detailed result. How you chose to observe affected the outcome - and when you used a flash, you flooded the room with photons, causing interactions with all the matter in the room. Observing without a flash would have resulted in a different outcome. One thing I found confusing when I first learned about the double slit experiment is that when they talk about "observing" which slit the particle went through, they may be talking about something as dramatic as *closing one of the slits*. Particles can go through both slits in the double slit experiment. The reason this doesn't bother a physicist is that (nowadays) they know that even if you put some sort of particle detector at the slits, its detection of a particle entering the slit inevitably interferes with the results of the experiment - because a particle detector is not passive, it interacts with the particles it detects. Particles are being detected at the slits in the experiment. So in the end, closing one of the slits is as good a way of "observing" which slit a particle goes through as any. Particles can go through multiple slits. But it's hardly a mystery that the outcome changes when the observer closes a slit! The observer has closed a slit before. (Note that I'm not saying that the double slit experiment is not mysterious - but it's mysterious enough without complicating it further with sloppy "gee-whiz" explanations.) The speaker has encountered "gee-whiz" explanations of the double slit experiment before.
 It really depends on what caused your fever. There is an assumption that the person has a fever. The infectious period associated with each illness can differ dramatically, from 24 to 48 hours to several days or weeks depending on the cause. Different illnesses have different infectious periods. For flu-like symptoms 24 to 48 hours is ideal, but for something like Salmonella infection you can shed the bacteria (aka still infectious) for over a week after being ill with it. There is a difference in the duration of shedding bacteria between flu-like symptoms and Salmonella infection.
 [Physics] is fine for your flair, though if there were a [Fluid Dynamics] flair it would be even better. /u/RobusEtCeleritas answer is pretty close, but it's missing what it really means in context of the paper you're reading. There is a paper being read. Reynolds number Re = (density\*velocity\*diameter) / viscosity, and is a ratio of inertial force to viscous force. The fluid in question is viscous. In the limit where Re- > 0, There is essentially zero inertia and it can be completely ignored. There is a fluid system being analyzed. This *greatly* simplifies fluid dynamics analysis using the Navier-Stokes equations, and is generally applicable for flows that are in very small dimensions or very very viscous. Some examples where you have zero Reynolds number are:* [Microfluidics](_URL_2_)* Locomotion of microscopic organisms* [Brownian motion](_URL_1_) of nanoparticles in a liquid* [Lubrication theory](_URL_0_)In the case of blood flow through a capillary that you are reading about, the capillaries are very small so that the Reynolds number Re <  < 1, so that any inertial effects are negligent and are hence being ignored. 1. For the case of a finite Reynolds number, that simply means that inertial effects are now large enough that they *cannot* be ignored, and have to be included in any analysis. Inertial effects were previously ignored in the analysis. The flow *might* be turbulent, but it could also be laminar while still having inertial effects. The flow has both turbulent and laminar characteristics. If the Reynolds number is very large (typically Re > 2000 for flow in a tube or pipe) then inertial forces will dominate, which is observed as turbulent flow. In a fluid flow system, if the Reynolds number is not very large, then viscous forces will dominate, which is observed as laminar flow.
 A few thing: Just because something has probability zero, doesn't mean it can't happen. There are events that have a probability of zero. It's improbably, but not impossible. There is a situation that requires something to be done. Secondly, there is a difference If you pick a particular point in the interval, then that particular event has zero probability. There are multiple intervals being considered. So if you sit and way for your favorite event to happen, you'll likely never see it occur. There is an event that the person is waiting for. But to find the probability of *something* happening, then you select the whole interval on where there is a 100% chance of *something* happening. There is a specific event or phenomenon being referred to as "*something*". So *something* must happen, and whatever thing does happen will have probability 0 of happening, which is why you can't pin down precisely what will happen before it happens. There is an event that is inevitable. Now, what would happen if each point on the interval did have a nonzero chance of happening? There is an interval with points. If this were the case, and the distribution were continuous, then you could find a number P so that there would be an infinite number of points with probability greater than P of happening. There is a probability distribution involved. Add up 1+1/P of these together and you will get a value over 1. There are at least P numbers to add together. So individual points having positive probability is more problematic than them having zero probability. There is a situation where individual points have both positive and zero probabilities. To fix this the probability in continuous distributions is given by *area*. Continuous distributions are commonly used in probability calculations. If you have some set in a continuous interval with a distribution above it, then to find the probability that something in the set happens, you find the area under the graph above that particular set. There exists a continuous interval with a distribution above it. The "adding up individual probabilities to get 1" thing still makes sense. There are multiple probabilities that need to be added up. To add a continuum amount of things together, we use integrals. Integrals are the only way to add a continuum amount of things together. Integrals are defined as being the limit of rectangular areas whose individual areas go to zero, yet produce an overall positive area. Rectangular areas are the only shapes that can be used to define integrals.
 The short answer is no. There was a question asked. Let me paint a picture for you:If you go outside and have let's say a car a meter in front of you, a house 100 meters away, a tree 200 meters and a mountain range on the horiszon. There is a person who is capable of painting a picture. Now when light hits these objects the bounce it back, to your eye in this case. Light hitting objects is a common occurrence. The light "source" is as far away as these objects. There are other objects present in the same location as the light source. In the case of nearsightedness the further away objects get blury because your eye is IIRC a little to long inside, which means the angles get screwed up when the light gets to the back of your eye. Nearsightedness is a common eye condition. Now monitor is a single light source right in front of you (or a bit further if we are talking about a TV). There is a person present who is looking at the monitor. That means the angles are fine. The angles were previously thought to be problematic. Its like looking at a painting, its a 2D object that you are looking at. The object being viewed is not three-dimensional.
 Other substances that expand on freezing are acetic acid, silicon, gallium, germanium, antimony, bismuth, plutonium and also chemical compounds that form spacious crystal lattices with tetrahedral coordination. There are other substances that do not expand on freezing. _URL_1_**Edit:** There are multiple MSDSs that say "Acetic acid should be kept above its freezing point (62°F), since it will expand as it solidifies and may break container." Acetic acid is commonly used in various industries. _URL_3__URL_2_But there are other sources that say acetic acid becomes *more* dense as a solid (thanks to /u/DancesWithWhales):1.049 g cm−3, liquid1.266 g cm−3, solidSource: _URL_0_Is there a chemist in the building? Acetic acid has different densities in liquid and solid form.
 It's based on measurement of the engines, of course. The engines have been measured before. But H2O gives the best specific impulse in an ideal rocket engine. Water is commonly used as a propellant in rocket engines. The reason is that self-contained rockets have to carry two kinds of supply:  *fuel*, which is matter that contains energy to be used for propulsion; and *propellant*, which is matter that can be loaded with negative-going momentum and discarded (thereby giving the rest of the rocket forward-going momentum, yay!). Self-contained rockets are the only type of rockets that require both fuel and propellant. The reason you need both is that you need *energy* to load *momentum* on the propellant. There is a propellant that requires both energy and momentum to be loaded. Dealing with temperature is a secondary concern -- it's easier and better (from the armchair perspective) to deal with the basics of mass, momentum, and energy. The speaker has knowledge and understanding of the basics of mass, momentum, and energy. Temperature only enters since SSMEs are heat engines, converting chemical energy - >  heat energy - >  mechanical energy. Heat engines are the only way to convert chemical energy into mechanical energy. The kinetic energy of the propellant scales like *1/2 m v^2* ; the momentum of the propellant scales like *mv*. The propellant is a physical object. The idea is that you want the most momentum per unit propellant you can get - that way you don't have to discard so much of the rocket. The rocket is currently experiencing issues with discarding too much propellant. So you give it a high exhaust speed as you throw it away (which raises *mv*, so your momentum performance improves). The object being thrown has a significant weight. But the energy price you pay is proportional to *mv^2* , so the more propellant-efficient you are the less energy-efficient you are. There is a need for propellant efficiency. Chemical energy storage is so marginal for orbital propulsion (it barely carries enough energy) that the only way to make chemical rockets work is by combining the fuel and the propellant. Chemical rockets are the only option for orbital propulsion. You react the fuel to make free energy (i.e. Fuel is readily available. burn fuel to make heat! Fuel is available. ), and then you use the reaction products (which are now hot but useless) as propellant. The reaction products were previously useful. So the most mass-efficient way to make a chemical rocket work is to use reactants with the highest reaction energy you can, and throw the whole shebang out the back of the rocket nozzle after it is fully reacted. Reactants with lower reaction energy are less efficient for making a chemical rocket work. That gives you the most available energy per unit expended mass, and also the most available momentum per unit expended mass. There is a need for energy and momentum in the situation. If you "run rich" to lighten the exhaust products (by putting extra hydrogen in the exhaust stream) then you are spreading your available energy over more propellant - so you are more energy-efficient. Extra hydrogen is present in the exhaust stream. But you turn out to be less mass efficient then, since you could replace some of that hydrogen with oxygen and eject the same total amount of mass with slightly more kinetic energy. There is a process that involves replacing hydrogen with oxygen to eject mass with more kinetic energy. In terms of temperature, running hydrogen-rich cools the exhaust stream more than it benefits you with the lightness of the individual particles. Hydrogen-rich fuel is commonly used in exhaust systems. The molecular mass really only matters in the case where you are limited in the amount of energy you can put on each particle, but you aren't incurring a large mass hit for carrying that energy with you. Particles can carry energy without incurring a large mass hit. Then you want light particles so you can get them going as fast as possible. Light particles can be controlled to increase their speed. The energy per particle imposes a negligible mass hit if you are using, say, nuclear power or solar panels to get that energy -- the former because nuclear fuels have about 10^6 - 10^7 times as much energy per gram as chemical fuels, and the latter because you don't have to carry sunlight around with you, you can just collect it and use it as you go. Nuclear power and solar panels are the most efficient sources of energy. The direction of the trade (heavy exhaust particles, light exhaust particles, etc.) There are different types of exhaust particles that can be produced during trade. depends on the physics of your rocket engine. The success of your rocket launch is heavily reliant on the physics of your rocket engine. Certain types of ion propulsion, for example, are energy-per-particle limited; others are exhaust-speed limited; still others are limited by esoterica like how much the fuel erodes the engine itself on the way out. There are multiple types of ion propulsion. The optimal propellant choice thus depends on detailed engineering trades. There are multiple propellant choices available. Edit: that BOTE analysis is correct for an ideal engine, but neglects nozzle efficiency. An ideal engine exists. Molecular mass has **two** effects: the simple one I described and debunked above, and a more complicated one that changes the efficiency of the nozzle in converting heat energy in the combustion chamber to bulk kinetic energy at the exit aperture. There is a combustion chamber. In general, you need a larger nozzle/bell for the same efficiency, with heavier exhaust molecules. There is a need for efficient propulsion systems. The nozzle efficiency issue is actually a big one since nozzle/bell mass is a major element of engine design, and a major mass element for the dry vehicle. The engine design is a crucial aspect of the vehicle's performance. So, even for conventional chemical thermal rockets like SSMEs, the answer is really just that the optimum depends on the detailed engineering trades for the particular rocket. There are multiple types of rockets, including conventional chemical thermal rockets like SSMEs.
 It really depends on how you define "intelligent," but for most definitions the answer is that it's pretty far away. There is a debate about the definition of "intelligent." AI's getting better, but sci-fi-style human-like AI is decades away at best and quite possibly a century or more away. There is a significant demand for sci-fi-style human-like AI. Some people think it's straight up impossible, although I, and I think most other AI researchers, strongly disagree with that, even if we don't necessarily expect it within our lifetimes. AI researchers have a strong belief in the possibility of achieving what some people consider impossible. As for how it would impact our lives... it's hard to predict. There are potential events that could impact our lives. AI's already getting used all over the place, but obviously truly intelligent AI would be quite different from any of the AI we have now. AI is currently being used in various industries and fields. I think MandatorilyMutatinal is right that once AI starts getting close to that level we're going to see a lot of interesting ethical debates becoming very prominent in politics, and how things turn out depends on where all those debates land. AI is getting closer to a level where ethical debates will become prominent in politics. It also depends on what the AIs are actually like. There are different types of AIs. Sci-Fi robots tend to be extremely human-like, although often a bit more socially awkward and logical and much less emotional, which isn't an unreasonable way to depict them, but that doesn't mean that's what we'll end up with. Robots in the real world are not as human-like as depicted in sci-fi. Computers are very different from humans, and creating an AI that is as intelligent as a human doesn't necessarily mean creating an AI that behaves like a human. Humans and computers have fundamentally different ways of processing information.
 This is something I do research on (some of my own papers and those of colleagues are cited below). There are multiple papers on the topic, indicating its importance. Generally speaking, if a fluid is convecting, warm water rising and cold water sinking, its temperature will be nearly uniform, and heat will flow rapidly to bring it into thermal equilibrium with the walls of its container. The fluid in question is in a container. In Europa's ocean case, temperature is pinned to the freezing point at the ice/water interface, but the seafloor sets a particular *heat flow*, not a fixed temperature. The ocean floor in Europa's case has a significant impact on the temperature of the water. This means that, provided there's convection driven by heating inside the moon, **the whole ocean should be within a degree or two of freezing**. There is an ocean inside the moon. Computer simulations bear this out. There have been previous attempts at computer simulations. Even near thermal vents, the hot water mixes with surrounding cold water so quickly that temperatures would be close to freezing within a few hundred meters of the vent. There are thermal vents nearby. The only way Europa's ocean could *not* be near freezing is if variations in salinity created density differences that prevented top-to-bottom convection, or if the pressure and salinity were low enough that [the weird thermal expansion of freshwater](_URL_1_) came into play. There are variations in salinity in Europa's ocean. Unfortunately, the salinity of the ocean is still a mystery. The ocean's salinity has been studied extensively in the past. One final thought: I said "within a degree or two of freezing", but I didn't say zero degrees C! The speaker previously mentioned a temperature close to freezing. If the ocean is very salty, its freezing point could be lowered by quite a few degrees; if the ocean has some ammonia in it, and it might, the freezing point could be tens of degrees below zero C._URL_0__URL_2__URL_5__URL_4__URL_3_ The ocean's salinity level is high enough to affect its freezing point.
 No...both constants show up in things like the blackbody spectrum, the Bose-Einstein distribution, and the Fermi-Dirac distribution. The constants mentioned are widely accepted in the scientific community. Dividing by them without context doesn't get you anything meaningful. There is a context in which dividing by them gets you something meaningful. There is Planck temperature, which is proportional to the square root of the Planck constant, over the Boltzmann constant. The existence of the Planck temperature is widely accepted in the scientific community.
 Tons. There is a large quantity of something. With a PhD:  You could be a professor (jobs are hard to find), you could work at a pharmaceutical or biotech company ... Having a PhD is a prerequisite for being a professor or working at a pharmaceutical or biotech company.
 It could be a biofilm caused by [Serratia marcescens](_URL_0_), a bacteria. Serratia marcescens is a common bacteria found in biofilms.
 You can take the natural logarithm of any nonzero complex number, it just might be different logarithms that you work with. Complex numbers are commonly used in mathematical calculations. In other words, it's complicated. There is a lack of clarity or understanding about the topic at hand. If you have the complex plane, that is, all real and imaginary numbers, then you can have the exponential function e^(z), where z is any complex number. The complex plane exists and is a valid mathematical concept. In particular, e^(ix) is equal to cos(x)+isin(x), hence e^(ipi)=-1. The concept of complex numbers is widely used in mathematics. If we try to define a logarithm in the normal way, we run into problems. There is a common understanding of what a logarithm is. The normal way to define log(x) is that y=log(x) is the number so that e^(y)=x. The concept of logarithms is widely used in mathematics. The problem is that  e^(ix)=e^(ix+2ipi), so if we have log(z)=ix, then we should also have log(z)=ix+2ipi. 1. For instance, e^(ipi)=-1, but also e^(3ipi)=-1, so the log should be both ipi and 3ipi. There is a mathematical concept called "log" that is used to solve equations involving complex numbers. Obviously this can't happen. Something similar has happened before. What is happening here? There is some sort of event or activity taking place in the location indicated by "here". Well, the numbers e^(ix) give the unit circle that lies inside the complex plane, the point cos(x)+isin(x) in the complex plane is the same as the point (cos(x),sin(x)) on the Cartesian coordinate grid, which is a point on the unit circle. The complex plane is a fundamental concept in mathematics. So increasing x makes you circle around the origin by an angle x. The origin is a fixed point. If you go to the angle x, and then go around a whole time, then you'll end up at the same spot. The location of angle x is known. Trying to take a logarithm is then trying to ask what angle a point on the unit circle is. The unit circle is a fundamental concept in mathematics. This might seem obvious at first, just don't go around multiple times, but there are situations where we my view an angle as 3pi/2 and another where we view is at -pi/2. There are situations where angles can be viewed differently based on the context. So it is unclear what value a logarithm should have because each point on the unit circle will have a multiple different angles to give the logarithm. Logarithms are commonly used in mathematical calculations. We can fix this though. There is a problem that needs fixing. The issue happens because we are allowed to go around the circle a whole turn, so let's not let that happen. There is a circular structure involved. If we 1.) There is a specific condition that needs to be met in order for the action described in the sentence to occur. Fix a starting point, like log(1)=0, and 2.) There is a mathematical equation involved in the sentence. Don't allow ourselves to go around a whole circle, then there will be no issue. There is a problem that needs to be avoided. To do this, we choose a ray pointing out of the origin, out towards infinity and we say that we cannot pass this line. There is a need to define a boundary for the chosen ray. We then say that the value of log(z) is whatever value it should be as long as we keep track of log(z) by originating at a fixed starting point and then making a path to z without crossing this ray. There is a mathematical concept called log(z). For instance, we can choose this ray to be the ray that points straight down, and we can have our starting point be log(1)=0. There is a need to choose a ray that points straight down. If we then rotate around the unit circle, we'll get log(e^(ix))=ix, as long as -pi/2 < x < 3pi/2. The unit circle is a commonly used mathematical concept. In this case, log(-1)=ipi. The concept of imaginary numbers is widely accepted in mathematics. We're also free to start with log(1)=2ipi, in which case log(-1)=3ipi. There is a mathematical problem being discussed. Changing the starting point and changing the line that we shall not pass gives different logarithm function that all serve the same purpose. There are multiple logarithm functions that serve the same purpose. Of course, if you're not working with complex numbers, then negative logarithms mean nothing. Working with complex numbers is necessary to understand negative logarithms. And when you do work with complex numbers, you have to be careful how you work with logarithms. Working with complex numbers is a common practice. -----------------------------------------------------------------------You can get around this issue of having this line of no passing and starting points by moving from the complex plane to a different object. There is an issue with having a line of no passing and starting points in the complex plane. You place the positive part of the real axis where it usually would be, but instead of extending it to the complex plane by just rotating it through angles, as we rotate, we also lift. The speaker is knowledgeable about mathematics and geometry. [Like a spiral staircase](_URL_1_). The structure being referred to is a physical spiral staircase. By the time we've gone around one whole circle, instead of winding up where we began, which would be the case if we stayed in the plane, we're actually pointing in the same direction, but a floor above where we started. There is a circular path that can be taken. We can continue rotating, in both clockwise and counter-clockwise directions to get an object that is an infinite spiral. There are objects that can be created through continuous rotation. A point on this spiral will be determined by how far it is from the origin, what direction it is pointing in *and* what floor it is on. The spiral is a physical object that exists in the real world. Or, by the complex number it lives over and the floor it is on. The building in question is a multi-story complex. If we're pointing along the negative direction, on the first floor and are a distance 1 away from the origin, then we're at -1 and on the first floor. The origin is located at (0,0) on the first floor. Since this if the first floor, the logarithm is just ipi. The speaker is knowledgeable about logarithms. If we go to the second floor, by spiraling around once more, then we're still at -1 but a floor above. There is a building with at least two floors. The logarithm of this point is then 3ipi. The point in question has a logarithm. On this infinite spiral, the logarithms are all nicely defined, it's just a little unclear what the logarithm of a number is because you need to also specify which floor it is on. The infinite spiral is a mathematical concept that has been studied extensively. So log(-1,1st floor)=ipi, log(-1,2ndfloor)=3ipi, log(1,5th floor)=8ipi etc. The mathematical equation in the sentence is based on complex numbers. There are related issues when talking about square roots and cube roots, etc. Mathematicians have been studying the relationship between square roots and cube roots for centuries. These all have new, different surfaces that classify them, like this staircase does for logarithms. There are multiple objects with new surfaces that can be classified. These objects are called [Riemann Surfaces](_URL_0_), and they're super important for everything. Riemann Surfaces are widely used in advanced mathematics.
 Molecules not atoms are sensed by [olfactory receptors](_URL_0_)things do not have a smell per se , certain molecules activate receptors causing the sensation of smell in the brain. 1. Think of a receptor as a lock and the odour molecule as the key. Receptors and odour molecules are the only components involved in the process of scent detection. If the key fits and unlocks the lock then an odour is smelled. The lock is designed to emit an odour when opened.
 Temperature increases volatility, and taste is roughly 75% olfactory. There is a direct correlation between temperature and volatility. On top of that it affects texture and color, which also play a role in flavor. There are other factors that affect texture and color besides the one mentioned. Taste in foods with a temperature higher than 86 degrees F or lower than 68 degrees also becomes more difficult to distinguish- Hot coffees taste less bitter whereas slightly melted ice cream tastes sweeter. Foods with temperatures between 68 and 86 degrees F are easier to distinguish. Other variables include time of day it was eaten, age, gender and degree of hunger of the taster. The taster's experience of the food was affected by the time of day it was eaten.
 Yes, different ones are used not only for different missions, but also for different purposes within the same mission. Different missions require different tools. This is mostly important for the attitude control system because each sensor gives information in a different reference frame, so the onboard software must be able to convert between them. There are multiple sensors involved in the attitude control system. Rather than "rotating" or "stationary", we call them inertial or non-inertial . Inertia and non-inertia are the only two possible states of motion. Earth-centered reference frames include [WGS84](_URL_0_), used by GPS, which is non-inertial; and [ECI](_URL_1_) when an inertial frame is required. The use of non-inertial reference frames in GPS technology is widespread. Similarly there's a SCI (Sun-centered inertial) frame, commonly used for interplanetary trajectories. In inertial frames, the x axis usually points in the direction parallel to the vernal equinox, given by the intersection of the ecliptic plane and Earth's equatorial plane. The vernal equinox is a significant point of reference in inertial frames. However this changes very slowly due to the precession of the equinoxes. The precession of the equinoxes has been occurring for a very long time. I've seen some efforts to define more precise reference frames based on well-known pulsars that lie close to that point as seen from Earth. There are well-known pulsars that lie close to the point being referred to. The y axis points 90° ahead along the frame's fundamental plane, which is the ecliptic plane for the SCI frame, but ECI frames can use the equatorial plane instead. The frame being referred to is used for space exploration. The z axis points north following the right hand rule. The earth's magnetic field is aligned with the z axis. For Rendez-Vous and Docking manoeuvres, a body frame has to be defined for each of the participating spacecraft. There are multiple spacecraft involved in Rendez-Vous and Docking manoeuvres. This is normally done at design time. Design time is a common occurrence. It's important so that docking ports can be aligned, though a small error is tolerated. Docking ports are frequently misaligned.
 Without having the cones ourselves, we can never know exactly, but without getting into philosophy, one method of trying to perceive what their vision is like is via metaphor. There is a group of people who do not have cones in their eyes. This Radiolab podcast (partway through it) does just that, using a choir to build the metaphor for the vision of a butterfly and a mantis shrimp: _URL_0_ The Radiolab podcast is discussing the use of metaphors in art.
 [Global energy consumption is on the order of 200 TWh per year (= 720 petajoules). The world's population is increasing rapidly. ](_URL_0_)[Total solar energy absorbed by the Earth is about 3,850,000 exajoules per year. The Earth is capable of absorbing solar energy. ](_URL_1_)Divide the two and you get about 2E-7. There is a mathematical equation being discussed. The amount of energy humans use per year is about 2 ten-millionths of the amount of energy absorbed from the Sun. The Sun is the primary source of energy for humans. Primary energy consumption, then, is negligible compared to something that affects how much energy is absorbed from the Sun. There is a source of energy that affects how much energy is absorbed from the Sun.
 The active ingredient in most non-medicinal, non-sunscreen skin lotions is lanolin. Lanolin is a commonly used ingredient in non-medicinal, non-sunscreen skin lotions. _URL_0_There is a *small* amount of evidence that applying lanolin does help minor skin wounds heal somewhat faster. Lanolin is a commonly used ingredient in wound healing products. It is not well known how that occurs--if there is some chemical action upon the wound itself, or if the lanolin just keeps the skin more supple which prevents tearing the wound open as much. There is a wound that needs to be treated. You can buy pure anhydrous lanolin online; there are sellers on eBay. Lanolin is a highly sought-after product. The smell is rather,,, animal-like. There are animals present in the vicinity. But it does work well as a skin softener. The product has multiple uses. It softens your skin better than petroleum jelly does. Your skin is not already soft. It doesn't leave your skin greasy like petroleum jelly does, but it does leave your skin "waxy". Petroleum jelly leaves your skin greasy.
 It's an innate characteristic. The characteristic cannot be learned or acquired. If you have a very small child, you can tell if they are left handed or right handed by handing them a crayon and asking them to draw a picture. Small children are not able to communicate their handedness verbally. They'll use their dominant hand. The person in question has a dominant hand.
 First: steroid hormones are a large class of hormones with widely different effects. Steroid hormones are commonly used in medical treatments. Even look at the two you named. There are at least two things that were named previously. Testosterone is a sex hormone involved in reproduction, while cortisol is a glucocorticoid, involved in energy regulation and stress responses. The human body only produces two types of hormones, sex hormones and glucocorticoids. Weirdly enough, high levels of either can suppress the other. There is a correlation between two variables. Anyway. There was a previous conversation or topic that the speaker is trying to redirect from. Check out [this](_URL_2_) paper. The paper being referred to is worth checking out. Even if you don't have access the whole thing, you should be able to see the abstract which should give you an idea. Accessing the whole thing is difficult. Its an issue of resource partitioning. There are limited resources available. Animals have a limited set of resources (energy, carbohydrates, amino acids, whatever) that they have to divide up between body maintenance (including the immune system) and reproduction. Animals have a complex system for allocating resources between body maintenance and reproduction. Normally an animal wants to keep itself together, so most of those resources go towards body maintenance. Animals have limited resources to allocate towards different needs. When its time for some of that sweet sweet lovin', testosterone and estrogens are increased. People experience a significant increase in testosterone and estrogens during sexual activity. Among other effects, the immune system is suppressed, freeing up resources for reproduction, including courtship, mating, pregnancy, and supporting the offspring (assuming they're not left to their own devices). Reproduction is the primary goal of the immune system. The paper I linked above seems to imply that this trade-off only occurs when resources are limited. The paper linked above suggests that there are other factors that can affect the trade-off besides limited resources. If you have plenty of food, enough to support both full body maintenance and reproduction, there's no trade-off to be made and you get the best of both worlds. There is a scarcity of food in the environment. I didn't look too much at glucocorticoids because I couldn't find a straightforward paper like the other right off the bat, so this is going to be a bit of speculation. There are other papers on glucocorticoids that are straightforward. My work is about glucocorticoids, so hopefully this won't be too far off the mark but if someone knows better please correct me. Glucocorticoids are a widely studied topic. Glucocorticoids are released under stressful conditions like exposure to a predator, new environments, or unsafe environments like the open arms of an [elevated plus maze](_URL_0_). Predators are a common threat in the environment where glucocorticoids are released. Acute (short-term) elevations of glucocorticoids actually boost the immune system, while chronic elevations are immunosuppressive. Glucocorticoids are commonly used to treat immune system disorders. ([Source](_URL_1_)) The acute part makes sense-if you get hurt running from a predator, your immune system will be ready to go. The speaker assumes that getting hurt while running from a predator is a common occurrence. But if you're in a constantly stressful situation, your energy needs to go to getting you *out* of that situation. There is a stressful situation that the person is currently in. An immune system won't do you any good if you get eaten, so the immune system is suppressed, freeing up more energy for whatever else needs to be done. There is a danger of being eaten.
 Sound speed actually goes *down* with density. Sound waves can travel through different mediums. The only reason why materials like steel or water have a higher sound speed than air is that sound speed increases in materials that are *less compressible. Materials that are more compressible have a lower sound speed than air. * Because fluids and solids are usually *much* less compressible than gases, this offsets the increased density and causes an increase in sound speed. Gases are more compressible than fluids and solids. In case you are curious:v^2 = B/ρWhere v is sound speed, B is bulk modulus, and ρ is density. The speed of sound is an important factor in the equation. Now, on to your real question: Can a material have a sound speed higher than the speed of light? There is a real question that needs to be addressed. The answer to that question is a resounding **No. The question was asked. ** Even setting aside the question of causation, it turns out that the maximum sound speed that can be achieved is actually the sound speed of a relativistic fluid. There is a question of causation that is being discussed. The sound speed in such a fluid is equal to *the speed of light over the square root of 3* (c/√3). The fluid being referred to is capable of transmitting sound waves. If this seems random, just keep in mind that the 3 in the denominator comes from the number of spatial dimensions in our universe. The universe has three spatial dimensions. (Source: [Relativistic fluid dynamics](_URL_0_))Does this figure into the observable universe in any way? The concept of "observable universe" is widely accepted in the scientific community. Surprisingly, yes! The speaker was not expecting a positive response. It turns out that neutron stars (which are highly incompressible, because they're essentially oversized atomic nuclei) have *very* high sound speeds near their core. Neutron stars are a common occurrence in the universe. The sound speed is determined by the star's mass, which in turn, means that one upper limit of the neutron star's mass is given by its internal sound speed. The star's mass is a crucial factor in determining the sound speed. If the internal sound speed would break the limits of causality and go too high, the neutron star collapses into a singularity instead! The existence of a neutron star is presupposed. Hopefully this answers your question! The person asking the question had a specific question in mind.
 Essentially it’s density. The substance in question has a measurable density. Packed snow has more snow in a smaller area so there is less surface area for heat transfer. There is a need to reduce heat transfer in the area where packed snow is present. for example, a ball of snow is exposed to the sun less than an equivalent amount of snow laid out flat. Snow can be exposed to the sun in different ways. Also the snowball can disperse the heat it’s absorbing much more because there are more particles nearby and they are closer than snow laying flat There are particles nearby that can absorb heat.
 You can check out [these past posts](_URL_0_) regarding blood iron in a magnetic field. There are past posts available regarding blood iron in a magnetic field. The short answer is that iron in our blood isn't ferromagnetic, and won't be drawn to a magnet like iron filing would. Iron filings are ferromagnetic. There can be effects on the nervous system as well - that is the basis behind [transcranial magnetic stimulation](_URL_1_). The nervous system is highly susceptible to external influences.
 The [wiki](_URL_1_) article actually has a surprisingly decent summary of the basic timeline. There is a basic timeline that needs to be summarized. Quarks in particular can exist up to arbitrarily high energies (i.e., arbitrarily early times after the Big Bang) in the standard model of particle physics, though above a certain energy (such as the Planck energy) we don't *really* know how things behave anymore. The standard model of particle physics is widely accepted. The key event for this is [cosmic inflation](_URL_0_), a period of accelerated expansion believed to have occured in the very early Universe driven by a type of exotic matter. Exotic matter is a crucial component of cosmic inflation. When inflation ended, the energy driving it went into fundamental particles like quarks and electrons. The universe underwent a period of inflation. This would be the origin of most of the quarks (and other matter) in the Universe today. Quarks are the building blocks of matter.
 The whole "interfering with itself" part - when considering light as a particle - is probably what throws people off. Light is often considered as a wave. The mantra about light is that it travels as a wave, but interacts as a particle. Light is a physical entity that can be described as both a wave and a particle. If we follow that, we'll see that "interfering with itself" isn't weird at all - that's what waves do. Waves have a natural tendency to interfere with themselves. And it only acts like a particle when it is time for interaction with the detector - meaning at any time, there can only be an excitation in one location. There is a detector present in the situation. >  I'm lost because most sources online just say ,"Oh this is how it works isn't is weird?" There are confusing sources online about a certain topic. "Its both a particle and a wave!" Particles and waves are the only two possible states of matter. I can't find a straight explanation. There is an explanation to be found. Well that is pretty much _the_ straight explanation. There was a previous explanation that was not straight. Light is something that exhibits behaviour of both particles and waves. Light can be observed as both particles and waves simultaneously.
 > What observations did Newton make that lead him to believe gravity acted instantaneously? Newton was not the first person to observe the effects of gravity. Tycho Brahe and Johannes Kepler had detailed observations of the motion of the planets. The motion of the planets was a subject of great interest during Tycho Brahe and Johannes Kepler's time. They were incredibly precise for the time, but were nowhere near the precision one would need to observe deviations from Newton's laws due to relativistic effects, and indeed these deviations are very small. There were attempts to observe deviations from Newton's laws due to relativistic effects. Newton's law of universal gravitation describes the motion of the planets incredibly well, and certainly within the experimental error of the measurements available at the time. The planets' motion was not well understood before Newton's law was discovered. In his era, there were no experimental observations to indicate gravity takes time to propagate, his laws agreed incredibly well with available data, and they were based on some very rational first-principle ideas, so there simply was no reason for him to think them wrong. Gravity was not well understood during the time period in question. [There's a list of some experimental evidence for relativity here. Experimental evidence for relativity has been discovered. ](_URL_0_) The level of necessary experimental precision and knowledge of other fields like electromagnetics necessary to actually observe these things simply didn't exist at the time. There were attempts made to observe these things in the past. > What problems would his theory have if gravity took time to propagate? Gravity currently does not take time to propagate. Basically everything that relativity corrects. There are things that relativity corrects. Realize that Newton's laws aren't "wrong" per se, but taking the limits general relativity for speeds much less than light, and instantaneous gravity, you arrive back at Newton's laws. Newton's laws were once thought to be incorrect.
 The long answer is fairly intricate, but basically, a finished mRNA that is present in the nucleus will have a sequence that indicates it is ready to be exported into the cytoplasm. There is a process in the cell that involves the export of mRNA from the nucleus to the cytoplasm. This sequence is added or modified during post-processing of the raw mRNA transcripts. The raw mRNA transcripts were incomplete or contained errors before post-processing. These signals are recognized by transport proteins called the nuclear pore complex that are present in the nuclear membrane. The nuclear pore complex is the only transport protein that recognizes these signals in the nuclear membrane. These complexes are responsible for all of the transport of large molecules in and out of the nucleus. Large molecules are constantly being transported in and out of the nucleus. If you want a way more intensive look at it, here is a review article _URL_0_If you have trouble viewing it, you may need to visit a college library. There is a review article available at _URL_0_. Some journal articles are not available online to the public, and since I'm on a college campus, most are available to me that may not be visible to you. There is a limited number of journal articles that are available online to the public.
 Some things are Lewis acids that aren't Brønsted,, e.g. There are substances that can act as Lewis acids but not as Brønsted acids. boric acid or aluminum trichloride. Boric acid and aluminum trichloride are both commonly used in industrial processes. They can react with Brønsted bases in ways that is quite similar to how H^+ can, so it makes sense to classify them as acids. There are Brønsted bases that react similarly to H^+. For example, many organic reaction that run faster in acidic medium also runs faster when a Lewis acid is present. Organic reactions are commonly studied in both acidic and non-acidic mediums. Lewis acid-base reactions aren't redox reactions because the electrons are not completely transferred, but end up being shared between the acid and the base, meaning that a bond is formed. There is a fundamental difference between Lewis acid-base reactions and redox reactions. For example:2Fe^3+ + 2I^- - >  2Fe^2+ + I*_2_* is a redox reaction, as the electrons are completely transferred,  and no bond is formed. Electrons are always transferred in redox reactions. Fe^3+ + Cl^- - >  FeCl^2+ is a Lewis acid-base reaction, as the electrons are not completely transferred, and the reactants end up being bonded to each other (sharing the electrons). There is a chemical reaction taking place between Fe^3+ and Cl^- ions. **edit:** typoes. I'm sorry, but there seems to be a typographical error in the sentence you provided.
 Well, in base 1369.003, you would get a 10:1 ratio. The speaker is knowledgeable about mathematical bases. This is applicable to any proportion you want. There are various proportions to choose from.
 Entropy is not a simplification, it is a quantifiable measure of the stability of a certain lattice structure. There exists a certain lattice structure that requires measurement of its stability. In quantum mechanics, the higher the local potential is, (the Energy is the spatial/reaction path integral across that potential), the higher the probability that the wave function of a particle displaces at a higher rate, (faster reaction rate) to a new stable configuration. There exists a local potential in quantum mechanics. This physics is what is encompassed in the Gibbs fundamental equation: T * dS = dU + P * dV - sum_{i \in Set of possible configurations} \mu_i dN_iwhere \mu_i is the chemical potential of a configuration and dN_i is the set of particles moving to that configuration. The Gibbs fundamental equation is widely accepted in the field of physics. The Gibbs dU is directly related to the probability that a certain configuration appears, (a word like "affinity" would be appropriate as well, but unncessary :P), because, as stated earlier, it affects the local potential. There are multiple configurations that can appear. I personally am not a biochemist, but I would surmise from the above that the proton moving across the membrane and facilitating the oscillation of the ATP synthase has the highest affinity/probability of any reaction that could happen with that ATP synthase, and so, it is what is observed 99.9999999% of the time. There are other reactions that can happen with the ATP synthase, but they occur very rarely. Take some 2nd or 3rd year QM classes, should clear things up. You have not provided any context for the sentence in angel brackets, so it is difficult to generate presuppositions that would give the best information about the world or situation in which the sentence occurred.
 The human genome project sought to develop a reference genome for humans. Humans have a reference genome that is not developed. ~10 people were sequenced for the project, and because of this there are alleles in the human genome reference (by which I mean the reference actually contains a rare allele, not the common one most people would have). There is a significant difference between the rare allele found in the human genome reference and the common allele found in most people. So I'd have to say that the HGP really was just out there to find "what could vary". The HGP was unsuccessful in finding what could vary. Another project, started about 6 years ago was the "thousand genomes project". The "thousand genomes project" was not the only project started about 6 years ago. TGP sought to sequence several hundred people from different populations (Africa, Europe, Asia, America) to find all common alleles in these populations. There are several populations with distinct genetic differences. Really the goal of TGP was to find much of the natural variation in humans. Humans have a significant amount of natural variation. There are a number of large scale sequencing projects on-going (ESP, CHARGES, UK10K (UK100K?)) There is a high demand for large scale sequencing projects. that are also going to uncover natural variation in healthy adults. There exists a study that aims to uncover natural variation in healthy adults. FYI, the human genome reference is updated every few years. The human genome reference has been updated in the past. Release 38 should be out before the end of the year. The company has a history of releasing updates before the end of the year.
 >  25-30% of our total calorie intake for the brain seems like a lotThe typical estimate is that your brain uses about 300-400Kcal per day (typically around the upper end) which is about 18-20% of an average height man's daily calorie intake. 1. Yet the brain is only about 2% of your body weight. The rest of your body is significantly heavier than your brain. It is often erroneously cited that the brain requires these calories in the form of glucose and in turn this is used as justification that you should consume at least 100g of carbohydrates per day (as there are 4Kcal per g of carbohydrate). The brain can function without glucose. >  How is that even measuredFlux in oxygen consumption (masks over people's faces), changes in neural blood flow and pressure have been used to estimate how much more calorie burning is being done while thinking hard. There is a method for measuring calorie burning while thinking hard. Today Magnetic Resonance Spectroscopy (MRI) can be used to directly measure oxygen flow/consumption in the brain from there you can directly calculate the amount of respiration and calorie consumption. The brain's oxygen flow and consumption can be measured through other means besides Magnetic Resonance Spectroscopy. >  Do thinkers and dreamers burn more calories via the brain than a "stupid mindless person"? People can be categorized as thinkers, dreamers, or "stupid mindless persons." It turns out that the brain's energy consumption is somewhat constant irrespective of the cognitive load. The brain's energy consumption is affected by cognitive load. To my understanding it is changes in the neuron firing patterns and connectivity that represent changes in thinking. Changes in neuron firing patterns and connectivity are the only factors that represent changes in thinking. It is not simply that increased thinking increase the amount of neuron firing across the board, however this is not my field and perhaps someone with deeper expertise can fill in more details there. There is a debate about the relationship between increased thinking and neuron firing. >  Again how is that even measured if research is done on it? There is a specific topic being researched. To do the experiment about the effects of thinking hard you have someone lie at rest in the MRI machine to get baseline data and then you get them to solve hard problems (often arithmetic) while still in the MRI machine. The person in question is capable of thinking hard. >  On a brain to calorie% ratio, what animals are in the top with us humans? There is a ranking system for animals based on their brain to calorie ratio. To my understanding energy consumption per neuron is not that much different for most animals. All animals have neurons. What is usually seen as an important measure is the brain-to-body-mass ratio. The brain-to-body-mass ratio is commonly used as a measure of intelligence. Humans are nowhere near the top here. There are other species that are superior to humans in this place. Ants can have 15% of their body mass in their brains. Ants have a complex nervous system. Animals which are similar to humans (ratios within the same order of magnitude) are small rodents, small birds, many primates. Animals which are not similar to humans are not small rodents, small birds, or many primates. Animals towards the bottom are things like hippos and whales where there brain might be less than a 2000th of their total body weight. There are animals that have brains that are a significant portion of their total body weight. >  What parts of the brain functions spends the most energy? The brain is the most energy-consuming organ in the body. I don't know this but from the info above it seems unlikely specific bits of the brain use much more than other bits. There is a significant amount of research on the brain. I hope someone can infill some more information hereCitations:_URL_0__URL_2__URL_1__URL_3_ There is missing information that needs to be filled in.
 The human circadian rhythm is a little over 24 hours. Humans have a natural circadian rhythm. At night, we have signals in the brain that make us sleepy; blue light can screw up the release of melatonin. Melatonin is only released at night. Things like testosterone and cortisol follow this diurnal rhythm. There is a natural diurnal rhythm that affects various substances in the body. Sometimes people are forced into abnormal sleep schedules, either by work (shift work) or because they want to stay up playing video games (social jetlag). Abnormal sleep schedules can have negative effects on a person's health. Military personnel on submarines used to have to stay up for 6 hour shifts and have 12 hours off, to make an 18 hour day. Military personnel on submarines are required to work long hours. However, that really negatively affected their sleep schedules and quality of life. There was a significant event that occurred. They have switched it to 24 hour work days (8 on, 16 off) and quality of life has improved, as well as mission execution and alertness. The previous work schedule was not 24 hours. People weren't nodding off anymore. People used to nod off frequently before. _URL_0_Circadian misalignment, ie sleeping at 2am to 10am every night instead of 11pm to 7am, has been shown to have a lot of negative effects on the body. The body is negatively affected by sleeping at 2am to 10am every night. Shift workers who work at night have higher rates of heart attacks (possibly from inflammation), diabetes and obesity (changes to appetite hormones and cortisol and metabolism are all possibilities), psychiatric issues, and other things. Shift workers who work during the day have lower rates of heart attacks, diabetes, and obesity. This is a pretty big field of research   _URL_1_ There are many researchers working in this field.
 You determine the weight of an object by weighing it in a vacuum chamber. Objects have different weights in a vacuum chamber than in normal conditions. For the gas you compare two measurements. There are two measurements available for comparison of the gas. One of a container filled with nothing (vacuum), and the other with a container filled with gas. There are two containers present. The difference in weight of the two measurements is the weight of the gass in the container. The container has gas in it.
 It depends on the shutter speed, first of all. The shutter speed is a crucial factor in determining the outcome. Assume the shutter speed is 1/60 s. Also, you have to factor in the size of the tire, not just the rims. The camera being used has a shutter speed setting. 17" rims can easily support tires with 25 inch diameters. Tires with 25 inch diameters are commonly used with 17" rims. If you're going for a full rotation, the car has to travel 25pi inches (one full rotation of the tire). The car has a tire with a circumference of 25pi inches. So 25pi inches x 60 = 1500pi inches per second  (slightly more than 4700 inches per second), which is close to 270 miles per hour. The object being measured is in motion. However, as you can see, there are a ton of variables, like shutter speed, tire diameter, if you're going for a full rotation, etc etc etc. There are many factors that can affect the outcome of the situation described.
 A basic principle of heat transfer is that the bigger the temperature difference is the faster heat will transfer between the two through conduction. Heat transfer is a common occurrence in everyday life. This means that by keeping his apartment colder than he would with his heat on, he will be absorbing energy (heat) from his neighbors at a faster rate. The neighbors are unaware that their heat is being absorbed. Since they're maintaining the temperature in their apartment, this costs them more money. They were not maintaining the temperature before, which means they were spending less money on their apartment. So yes, his decision does affect his neighbors. His neighbors are unaware of his decision. This also means that the warmer his apartment is the less money he is saving by "stealing" from his neighbors, until he eventually makes the temperature at his floor higher than their ceiling, and he starts giving them free heat. The neighbors are unaware that their heat is being "stolen" by the person in question. Most people already understand this principle without realizing it. This principle is widely discussed in academic circles. Keeping your heat at 70 is going to be more expensive than keeping it at 50. There is a significant difference in cost between keeping your heat at 70 and keeping it at 50. In a perfectly insulated house (no heat transfer between outside and inside) they would cost the same once you got to that initial temperature. The initial temperature is achievable. Obviously this isnt the case though, just going to show you how important insulation is to heating bills Insulation is important for heating bills.
 A board that can hover over an arbitrary surface? There is a technology that allows for boards to hover over surfaces. probably not. There was a previous statement that was highly likely. You'd need some kind of antigravity. Antigravity technology exists. And gravity *not* being like electromagnetism means that we know of no way to get a repulsive gravitational effect. There is a fundamental difference between gravity and electromagnetism. So, in short... not any time soon. There was an expectation for something to happen soon. Maybe some day in the distant future when we have an understanding of what dark energy is, as that's the closest physical thing we know of to antigravity. 1.
 Your nasal cavity is designed to humidify and heat the air you breathe in. The air you breathe in needs to be humidified and heated. It also traps dust and other things so that they don't enter your lungs. The air is polluted with dust and other harmful particles. It doesn't matter as much when you're breathing out, and it's easier to expel air from your mouth. Breathing in is less important than breathing out.
 An optical circulator is typically a 3-port device where light incident on port 1 goes to port 2 and light incident on port 2 goes to port 3. An optical circulator is a commonly used device in the field of telecommunications. This "nonreciprocal" operation is possible because the circulator uses a magnetic field to break the symmetry of the propagation direction. A magnetic field is necessary for the operation to be nonreciprocal.
 Well...yes, it is possible, *but:*Space is not entirely empty. There is a common belief that space is completely empty. Even the void between galaxies contains very diffuse ionized gas. There are multiple galaxies in the universe. It may ve only a few particles per cubic kilometer, but it's there. There is a measurable amount of particles per cubic kilometer. It's mostly hydrogen, with a bit of helium and a tiny, tiny scattering of lithiumWe know this because we can see the absorption lines it leaves in the spectra of distant galaxies. 1. We know it's not antimatter because it surrounds our own galaxy, which is *not* made of antimatter, anthers is no sign of matter/antimatter annihilations occurring near the galactic rim (the annihilation reaction tends to produce gamma rays with a very specific energy level:  511-kev). There is a possibility of the existence of a galaxy made entirely of antimatter. Likewise, we know that none of the galaxies we can see is made of antimatter because of the lack of this 511-kev emission anywhere in the sky. There is a significant amount of antimatter in the universe. If there were large amounts of antimatter out there, it would be obvious:  matter and antimatter are strongly attracted to each other through electromagnetic and weak nuclear charge forces--and then they convert each other entirely into energy. There is a possibility of large amounts of antimatter existing in the universe. Lots and *lots* of energy. There is a high demand for energy.
 Your parking voucher is likely printed on a thermal printer. Thermal printers are commonly used for printing parking vouchers. This means that there is no ink. There was ink present before. Instead there is a chemical that changes color when heated. There was a previous method that was used before the discovery of the chemical. It also changes color when exposed to UV. The object in question is sensitive to UV light. So it doesn't go anywhere, it just changes color. The object in question is capable of changing color.
 We can measure the velocity of all the other stars and compare it to the center of the galaxy to express everything relative to the center. There are other stars in the galaxy.
 Bacteria are EVERYWHERE. Bacteria are present in all environments. Even the statement that fetuses remain sterile in the womb has recently come under scrutiny (_URL_0_). Fetal development is a topic of ongoing scientific research. This aside, the majority of bacteria arrive during and after birth (within the first 24 hours). Bacteria can arrive before birth. Almost immediately exiting the uterus, babies are exposed to a number of microorganisms from the mother (bacteria in the vaginal tract and even faecal matter) and immediate environment (handling physicians, surfaces, etc) which rapidly colonize the surface of their skin. Babies born via C-section have significantly different microbiomes than those born vaginally. Interestingly, the colonizing microorganisms can vary on whether the baby is delivered naturally, or via caesarian section (_URL_2_). The baby's health is affected by the type of microorganisms present during delivery. Organisms can subsequently gain access to the digestive tract following the first meal in a process which can vary from individual to individual depending on whether formula or breast milk is provided. Organisms have a digestive tract. Colonization early in life, such as following birth, may have lasting impressions on the health of an individual throughout their lifetime. Early colonization of the gut microbiome is a critical factor in determining an individual's long-term health outcomes. The statement "we are said to be 10% human and 90% bacteria" arises from the fact that bacterial cells outnumber human cells 10:1 (approximately 10^14 - (100 trillion) versus 10^13 bacteria:human). Bacterial cells are essential for human survival. We physically appear 'human' because the size of a eukaryotic human cell is much larger than the size of a typical bacterial cell. Humans are the only species that physically appear human due to the size of their eukaryotic cells. What is really interesting is that the genetic diversity and functional capabilities of all these combined bacteria is MASSIVE. There are many different types of bacteria present. Bacteria add about 8 million genes to our normal set of 22,000 human genes. Bacteria have a significant impact on human genetics. We are just beginning to understand what a huge role these organisms play in regulating normal functions of human physiology, and appreciating the fact that the microbiome of an individual functions as an independent organ in its own right. The human body has been functioning without the knowledge of the microbiome's role until recently. Disruption of microbial communities has been associated with many diseases including diabetes, obesity, nutrient deprivation, and inflammatory spectrum disorders like IBD, colitis and diarrhea. There are many diseases that are associated with disruption of microbial communities. (_URL_1_) I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 Yes! The speaker was previously unsure if the answer was yes. Because mass has two effects:(1) Mass gives you how strong your gravity is (i.e. Gravity is affected by mass. how much it weighs)(2) Mass is "resistance to force"In zero-gravity (or free-fall, which is what astronauts are actually in), number (1) doesn't really matter. The object being referred to has a weight. An astronaut can stand with a 200 lb weight above him or her and will of course not feel any particular force. Gravity is not a significant force in the environment where the astronaut is standing. However, (2) does matter a lot! There is a specific thing or situation being referred to as "2". If an astronaut throws a 2 lb hammer, it will fly fairly well. The astronaut has access to a 2 lb hammer. If however, an astronaut shoves another astronaut (weighing say 200 lb including the suit), that astronaut won't go as fast - and the astronaut would definitely feel it takes more effort to get them going. There are two astronauts in close proximity to each other. Similarly, if an astronaut floated up to the space station and gave it a shove, it wouldn't really budge at all - the astronaut would feel like they're pushing off a solid object really. The space station is incredibly sturdy and resistant to external forces.
 Being pedantic, objects don't emit light rays at all, they emit photons. Light rays are commonly believed to be emitted by objects. Light rays are mathematical constructs which help us solve some problem. Light rays are not physical entities, but rather abstract concepts. But, the heart of the question remains- does a light source really put out an infinite number of photons? There is a question about whether a light source puts out photons. Well- no, because that would require an infinite amount of energy. There is a situation that requires an infinite amount of energy. However, they do release photons in random directions, and the photons are dense enough that for your case, it is a good approximation to say that the photons "fill" the space. There are particles that release photons in random directions. Some math to show this:Imagine you have a single Compact Fluorescent Bulb (13 W), and you're about 3 meters away from it. The bulb is turned on. [Reading up on CFBs](_URL_2_) we see that they are about 10% efficient (so about 1.3 Ws are actually making visible light) and they put out their light at a color of about 4000 K. By looking at the charts on that graph, you can see that the average wavelength of a photon emitted from a CF is about 600 nm. CFBs are a popular source of light. A photon of this energy has an energy of about [3E-19 Js](_URL_0_) which means a 13 W CF bulb (at 10% efficiency) releases about 4.3E18 photons per second. Light bulbs are a common source of photons. Ok, if you are 3 meters from that bulb, then those 4.3E18 photons are spread over a surface area of [113 m^2 ](_URL_1_). The bulb emits a significant amount of light. That means that every square cm, 3 meters from the bulb have 3E8 photons passing through it, per second (that's 300 million!). There is a light bulb emitting photons. So, there is not an infinite number of light rays, but it might as well be. There is a limited number of light rays in existence. There are 300 million photons coming through any square mm piece 3 meters away. There is a device that can accurately measure the number of photons passing through a square mm piece 3 meters away.
 Probes like the Voyager are actually just following a pre planned trajectory, NASA never has to send them coordinates of where to go. Probes like the Voyager have a pre-programmed route that they follow without deviation. When a probe like that is launched it is given enough velocity in order to escape the gravitational pull of the Sun, this is called the escape velocity. There is a need for probes to escape the gravitational pull of the Sun. NASA just timed the launch such that it's escape trajectory would take it by certain planets on it's way out of the solar system. There are certain planets that NASA is interested in studying. Messages are still sent and received to and from deep space probes though they just serve other purposes. Deep space probes have been repurposed. Information is sent by something called the Deep Space Network which is a group of large radio antennas separated around the Earth which was designed to communicate with deep space probes such as the Voyager. There are extraterrestrial beings who are receiving the information sent by the Deep Space Network. Information is received on the spacecraft by a radio antenna, a probe like the Voyager has a pretty big dish in order to receive signals that far away from Earth. There is a need for information to be received on spacecraft.
 Many animals, especially mammals, not only have sex in multiple positions but also partake in oral sex, masturbation, and homosexual sex. Animals have a complex and diverse sexual behavior. [Bonobos](_URL_0_) for example, will even use sex to diffuse tense social situations. Bonobos are known for their ability to use sex as a means of conflict resolution.
 A [rum cake](_URL_0_) apparently has about 1/2 a cup of rum in it, meaning 41 ml ethanol at a typical 35% (volume) alcohol content, equaling 32 grams of ethanol. There is a demand for cakes with high alcohol content. That requires 32*841/1000 = 27 kJ to vaporize. The substance being referred to has a boiling point. By comparison that's the amount of energy required to heat 1 kg of water by 6.5 degrees C. It's not an insignificant amount, but it's not a lot for an oven, which puts out around 2.5 kW - enough power to vaporize the ethanol in 11 seconds (in a fictional scenario where all the power was going to that one thing) So without going into more detailed calculations, all or most of the alcohol in that case is almost certain to vaporize. The oven in question is capable of producing a significant amount of power. Measuring ethanol content in food is possible, I strongly doubt your assertion that food labs _wouldn't_ have standardized methods and protocols for assaying it. Food labs exist and are responsible for assaying ethanol content in food. But doing it accurately would require some fairly sophisticated chemical methods (like GC or HPLC) in order to separate the ethanol out from the thousands of other compounds present. There are thousands of compounds present in the mixture. You can't do it at home. You need specialized equipment to do it. There's nothing for a 'reputable study' to prove, or even study. There is a lack of credible evidence to support any claims related to the topic at hand. Alcohol will vaporize if you heat it above its boiling point of 78 C, I'd think that much should be obvious. Alcohol is commonly heated above its boiling point of 78 C. Heating alcohol above its boiling point is a common practice. Whether or not _all_ the alcohol in some foodstuff vaporizes depends entirely on how much heat you're transferring to it, which depends on a whole bunch of things but most significantly the cooking time and temperature. Alcohol is present in some foodstuff. There is no reason to think you could reach any general conclusion. There is a specific situation or context in which a general conclusion cannot be reached. Besides which, there is no real 'zero' ethanol content. There is a debate about the definition of 'zero' ethanol content. Most food contains ethanol anyway, especially stuff like bread that have yeast, but also almost everything else that's not pasteurized because there are yeast spores everywhere. Yeast spores are present in most food. [This study](_URL_1_) measured 1.662 g ethanol/100g in a Bourbon cake, which one might expect to have a minor amount of alcohol in it, and 1.066 g/100 g in an Apple Walnut Roll, which many would probably _not_ expect to have any alcohol in it. Alcohol content in food products is a significant concern for consumers. They used GC to determine the alcohol content. GC is a commonly used method for determining alcohol content.
 Eventually you get something called nonlinear propagation where the air is squished so much that it changes the squishiness. The air is squished in a way that changes its physical properties.
 Well, if we ignore the other aspects that'd make an "oxygen lighter" hard to create, then yeah, it'd pretty much look the same. There are other aspects that make creating an "oxygen lighter" difficult. Many reactions use a stream of oxygen to create an exothermal reaction in an enviroment filled with the reactant, which looks a lot like the lighter you described. There are many reactions that do not use a stream of oxygen to create an exothermal reaction.
 It's because of the rotation, so the core sample from the pole will be less massive. The Earth has a rotation.
 The oxygen sensor in your engine will tell the computer in the engine how much fuel needs to be provided for combustion in stoichiometric proportions. The engine has an oxygen sensor. Colder oxygen/air is more dense, so more air per unit volume enters the engine, whereupon the oxygen sensor directs more fuel to be used, which leads to more power. The engine is currently running at a lower power output.
 It's not going to hurt you. You have nothing to fear. The pH of baking soda is about 9. Baking soda is commonly used in products with a pH of 9. 'Milk of Magnesia' a laxative you can buy from your local drugstore, and drink. Milk of Magnesia is a commonly used laxative. It has a much more 'caustic' pH of about 10.5. The substance in question is typically not considered to have a high pH. Many commercial soaps/shampoos have pHs that are 10-11. Commercial soaps/shampoos with pH levels outside of 10-11 are not effective. In fact, with regard to industrial chemicals, stuff with a pH of 9 is still considered 'neutral'. Industrial chemicals are commonly classified based on their pH levels. As for the other worries: Skin oils are very slightly acidic, but I'd hardly call that an 'acid mantle'. Skin oils have a significant impact on the pH balance of the skin. Disulfide bonds are broken by acids, not bases. Disulfide bonds are not broken by bases at all. I wouldn't worry about the 'pH balanced' advertising hype. The pH level of the product is not important.
 You get a "[domain wall](_URL_0_)" with two (potentially [false](_URL_2_)) vacua on either side, and the vacuum with the lower energy wins. There are at least two vacua present in the system. Associated with a domain wall, of course, there is a lot of energy (the cost for continuous fields which have to go through the large potential barrier between the vacua). There exists a domain wall. A domain wall can be modeled as a classical surface with some tension. A domain wall is a common phenomenon in physics. Much of this was worked out in a classic [paper by Coleman and de Luccia](_URL_1_). Coleman and de Luccia's paper is widely recognized as a seminal work in the field. EDIT: I forgot to say that the domain wall will (probably) expand outward at the speed of light. The universe is expanding at the speed of light. What I meant by the lower vacuum winning was that the bubble with lower vacuum energy will "eat into" the other bubble. There are two bubbles with different vacuum energies.
 The elements whose atomic emission lines are most commonly used to generate green colors are copper, barium, and boron. Green is the most commonly used color in the industry. Sometimes just lining the combustion chamber with copper or barium chloride salts is sufficient if your flame burns hot enough, but you can get a stronger green color with volatile boron compounds such as [boric acid esters](_URL_0_) which burn with a green flame. 1.
 Alien life could be, well, totally alien to us. There are other forms of life in the universe. So alien that we might not even recognize it. There exists an alien species that is vastly different from any known life form on Earth. But when you're searching for life in the vast emptiness of the universe, you use what you know as a starting point. There is life in the vast emptiness of the universe. As fun as it is to speculate about alternatives, we have exactly one confirmed life-supporting planet and it's full of carbon-based critters that need liquid water. There are other planets that are being speculated as potential life-supporting planets.
 Terminal velocity for a tiny object is quite low -- they fall slowly. Objects with a high mass fall faster than tiny objects.
 What might some reasons that digital storage is constrained by 0  &  1? Digital storage is not constrained by any other means besides 0 and 1. i.e. There is a specific sentence missing in the prompt. there either isn't, or there is a charge? There may have been a situation where a charge was expected but not received. Why cant there be 'degrees' of charge (strength of field) so you end up with 0, a little bit of charge, a lot of charge or 1? There is currently no system in place for measuring the strength of a field in degrees.
 I deal with microwaves more than full spectrum visible, so..One thing you can look at is firn (old dense snow on glaciers). Microwaves and full spectrum visible light are both relevant to the topic at hand. It, and glacial ice can start looking quite blue. Glacial ice can also appear green or purple. _URL_1_, _URL_2_ That's more from transmission through the snow. There was a significant amount of snowfall in the area. Certainly, these shadows will be illuminated both from diffuse sky light, as well as light transmitted through the snow. There is snow on the ground. Transmission of light is pretty good for visible wavelengths, roughly speaking at least half a meter (dependant on grain size, density, impurities, frequency, and what you consider to be enough light to count). There are various factors that affect the transmission of light for visible wavelengths. It's best with blue-green, so you can't explain what you see here by calling snow a filter. The environment in which the speaker is located has a blue-green tint. (see _URL_0_ for example). There is an example available at the URL provided. If the snow were thick (the distance the light has to travel through it gives many more opportunities for scattering and absorption of red-green). The environment is cold and snowy. Actually, that paper probably answers your question: Rayleigh scattering in the snow is not driving the colour, as snow scatters visible light basically equally. Snow is known to scatter visible light. It's a very good reflector too. The object being referred to is reflective.
 Copper gives a sort of [bluish-green flame](_URL_0_). Copper is commonly used in situations where a bluish-green flame is desired. Boron gives a [brighter green](_URL_1_). There is a current demand for brighter green colors. There are other elements that give a greenish flame, but they're all either yellowish or almost white. Other colors of flames exist besides green. Which one of these looks closest? There are multiple options to choose from.
 This is almost identical to the "lighted Marquee" thought experiment for exceeding the speed of light - the idea that a sequential series of bulbs could be timed such that it appears that the "light" on the marquee is moving faster than the speed of light. There is a thought experiment called the "lighted Marquee" that involves exceeding the speed of light. The issue is that the light itself is not moving - it is simply turning on and off at a point in space. The light is in a fixed position. The movement is an illusion - the light is not traveling "around" the marquee, it is just that individual bulbs turn on and off. There are individual bulbs on the marquee that turn on and off. In the same way, the beep is not moving *along* the rail, but rather each individual speaker is simply emitting a beep, in sequence. The rail is stationary. No sonic boom would happen, because at no point is any single speaker breaking the sound barrier in any way. There are no supersonic aircraft in the area. Edit: I should also point out, because some are talking about constructive interference, that constructive interference in this case could possibly lead to the beep getting *louder,* but will not fundamentally cause the compression into a shock wave that constitutes a sonic boom. There is a possibility of constructive interference occurring. That sort of compression necessitates something moving through the medium faster than the medium can move out of the way. There is a medium that can be compressed. A sonic boom is not simply a "loud noise" which you could achieve with constructive interference, it is a very specific kind of physical phenomenon. Sonic booms are often mistaken for loud noises caused by constructive interference.
 If I understand it correctly, at higher than atmospheric pressure (i.e. There is a scientific experiment being conducted. underwater) your central nervous system is affected by higher than normal partial pressures of oxygen. You have been underwater for an extended period of time. At normal atmoshperic pressure other body systems are affected with different symptoms. Other atmospheric pressures do not affect body systems in the same way. Free radicals form from the oxygen overload. Oxygen overload is a common occurrence. These free radicals do damage to cells on a molecular level eventually causing irreparable cell damage and death. Cells are constantly exposed to free radicals. The death of CNS (brain etc.) The CNS was alive at some point. cells results in seizures and death. There is a disease that causes cells to result in seizures and death. This addresses it in depth. There is a specific topic that needs to be addressed. See the mechanism section if you want the detailed "why." There is a mechanism section available. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 [There have been many devices made that have large touchscreens. There is a high demand for devices with large touchscreens. ](_URL_0_)  In fact, I've used a couple of them before. There have been previous instances where the speaker has used similar things before. You don't see larger tablets because they're more expensive to produce, and inconvenient to carry around. Tablets are becoming increasingly popular. With regards to an absolute limit - I'm not sure exactly what this would be. There exists an absolute limit that is yet to be defined. But is far larger than the screens in tablets on the market. There are tablets on the market with screens.
 You can't. There is a task or action that needs to be done. Any interactions that would change the probe to create an image would cause a change in the atom. The probe is capable of creating an image. That's how forces work. Forces are always at work. If you're talking about making it not move around, you can try to use a probe that will only excite the electrons, which just changes the orbit the electron is in instead of changing the momentum of the nucleus 1.
 For some perspective, the natural color of [enamel](_URL_1_) (hard outer part of the tooth) is light yellow or grayish white, and [dentin](_URL_0_) (porous stuff inside the enamel) is usually yellow. Enamel and dentin are the only two parts of a tooth that have color. Due to the fact that enamel is slightly translucent, especially in areas where it is thin, "normal" teeth appear as slightly yellowish or off-white. Enamel is the only factor that affects the color of teeth. Also, many dental imperfections due to wear or food staining are benign, so white tooth color is probably not a good indicator of oral health. Dental imperfections are common.
 Although this thread seems to be a downvote magnet, no one has really answered the question. People are actively downvoting the thread. Although there are other factors at play, the main reason your body feels tired is because an increase in the neurotransmitter gamma-Aminobutyric acid, or GABA. Your body can feel tired for reasons other than an increase in GABA. This is an inhibitor that blocks the normal excitability of neurons throughout the body. Neurons are normally excitable throughout the body. When you are sleep deprived your body still produces GABA. Sleep deprivation is common. Caffeine or other energy stimulants typically work to increase excitatory neurotransmitters, but the effects of GABA will ultimately outwork these supplements, especially in the brain. GABA is a more effective supplement than caffeine or other energy stimulants for increasing excitatory neurotransmitters in the brain. As your body attempts to fall asleep (despite your paper being due tomorrow morning) GABA begins to shut down your brain's control of the physical functions it uses when awake. Your paper is not finished yet. The cerebellum is a major brain segment that controls really basic tasks, such as walking and talking. The cerebellum is the only brain segment that controls basic tasks like walking and talking. Since these are only useful when awake and the cerebellum is at the bottom of the brain, it gets targeted first by GABA. The brain is only useful when awake. It's clear to see why when someone gets overly tired, their abilities to walk and talk would become a bit impaired. Someone has become overly tired. If they became even more sleep deprived, their abilities to think and reason would also begin to shut down. They are currently sleep deprived. Not surprisingly, alcohol also increases the production of GABA, which is why it is a depressant. All the same consequences of sleep deprivation are equal to and amplified by the intake of alcohol. Sleep deprivation and alcohol consumption have negative consequences. From losing "inhibitions" to losing balance and slurring speech, GABA increase leads to the shutdown of basic brain functions. GABA increase is a common occurrence in individuals who have lost inhibitions.
 I wouldn't think of them as failures of the brain. The brain is capable of failure. Our brain does a lot of processing on the raw data that the eyes collect. The eyes collect raw data that is not processed by the brain. This processing is very important to our ability to understand the information we get from our eyes. Our ability to understand information from our eyes is limited without this processing. Optical illusions exploit that processing; they set up situations where what our brain tells us doesn't match up to reality. Our brain is not always reliable in processing visual information. These types of situations are rare and in general the brains image processing gives us a huge advantage in our ability to interact with the world. Situations where the brain's image processing does not give us an advantage are common. Since understanding or "seeing through" optical illusions is probably less important (in the evolutionary sense) than the information processing its very unlikely that we will evolve to see through them. Optical illusions are prevalent in our environment.
 No, because the fault and direction of mass movement is likely not perpendicular with the center of gravity of the earth, nor is it likely equally balanced. There is a fault in the earth's crust. Additionally, imagine a figure skater spreading her arms out to spin slower, or drawing in to spin faster. The figure skater is performing a routine. Earthquakes that disrupt large quantities of mass vertically will do the same thing, but on a proportionately smaller scale. There have been earthquakes that have disrupted large quantities of mass vertically.
 [The triboelectric effect](_URL_0_) doesn't necessarily create heat. The triboelectric effect can create other forms of energy. When you walk across a carpet and you then get a shock when you touch the fridge, that's friction manifesting itself as an electrical charge. Friction is a common occurrence in everyday life.
 This depends on both the strength of the laser, and the reflectivity of the object. The laser and object are both present and operational. An object that is a perfect mirror will not heat up at all regardless of the strength of the laser, while a black body (100% absorption) will heat up until the incoming laser energy and outgoing black-body radiation balance out. There exists a laser that is strong enough to heat up any object that is not a perfect mirror. Note that perfect mirrors and perfect black bodies do not exist in nature, so the actual effect will be between the two extremes. There are two extremes in nature: perfect mirrors and perfect black bodies.
 Medications (and foods for that matter) are actually absorbed from the intenstines. The human body is capable of absorbing medications and foods through various means other than the intestines. The stomach serves to break apart foods using mechanical force of churning and acids, then it releases them slowly into the duodenum (first section of small intestine). Food cannot be broken down without the stomach. Food doesn't generally stay in your stomach for hours either, but it must first be broken down into absorbable components whereas medications administered orally are desgined to be absorbed. The human body has a limited capacity to break down food. Depending on the medication a reasonable onset time would be about 30 minutes. The medication in question has a typical onset time of longer than 30 minutes.
 I believe the term you are looking for is [sublimation](_URL_0_). The speaker has knowledge about the term "sublimation". In short the ice/snow would turn directly from a solid to a gas due to the excess amount of heat caused by the nuclear reaction. There was a nuclear reaction that caused an excess amount of heat.
 it would probably be effective for some microbes/viruses but unlikely to be as effective as it is today. There are microbes/viruses that are currently not affected by the treatment. Even going back a few decades and you had small pox, a few more and HIV did not exist and every winter bring new flu strains.Things change fast. Diseases have evolved rapidly over the past few decades. Don't forget geography ; Traveling around the world today, each new continent and country brings its own immunological challenges, ( hence travelers diahorrea ),  so its a safe bet that things were very different 2000 years ago. People 2000 years ago did not experience traveler's diarrhea.
 There are a combination of methods. There have been previous attempts to find a single method that works. One is maceration. There was a process that led to the maceration. Basically, it involves removing as much of the soft tissue as is practical, then allowing the rest to decompose under controlled conditions, often in temperature-controlled water, until the rest of the tissue is soft enough to be cleaned away. There is a process for removing soft tissue from a material. Another method can be used in combination with this. There is a current method being used. Dermestes beetles will eat flesh, but they prefer not to eat the bones, so they will clean a skeleton for you. Flesh-eating beetles are commonly used for cleaning skeletons. Care has to be taken because they will move on to the bones if they exhaust the soft parts, but it saves humans a bit of work. Animals are present and likely to consume the soft parts. edit: a bit of clarification. There was a previous misunderstanding that caused the need for clarification.
 Larger groups tend to have lower rates of evolution because it takes forever for something to spread through a large population. Evolution rates are affected by population size. Of course, very small populations have less raw genetic differences to work with and small probability of new mutations to help out. There is a need for genetic diversity in populations.
 They generate high-voltage AC electricity. The electricity generated is used for industrial purposes. This can be useful for many things, including testing for leaks and starting up larger electric arcs. There are many things that require testing for leaks and starting up larger electric arcs. However, their main use is just to look really cool. The speaker has a negative opinion about the object in question. See: _URL_0_ > Today, although small Tesla coils are used as leak detectors in scientific high vacuum systems[9] and igniters in arc welders,[57] their main use is entertainment and educational displays. Tesla coils were not originally designed for entertainment or educational displays. Originally, Tesla planned to use them for power transmission, although this would be somewhat impractical and dangerous. Tesla had a need for power transmission.
 With modern Lithium Polymer batteries? Lithium Polymer batteries are widely used in modern technology. It is not needed, its a hangover from the old Nickel-Cadmium days. There was a time when Nickel-Cadmium batteries were commonly used. Along with the old "discharge completely every few weeks". The old "discharge completely every few weeks" was a common practice in the past. Lithium based batteries are best kept between 25% and 85%. Lithium based batteries are commonly used in electronic devices.
 We tried this with Javan rhinos (captive breeding in zoos). Javan rhinos are endangered. It went quite poorly. There were high expectations for the event.
 To help answer your question Are you talking about differences between different animals, or between different people? There is a question that needs to be answered. By bone structure and size do you mean length of bones or cross sectional area? There is a debate or confusion about the meaning of bone structure and size. What do you mean by muscular potential? There is a context in which the term "muscular potential" is being used. Size? There is a specific object or entity being referred to by the word "size". Speed? The vehicle in question is capable of moving. Strength? There is a need for strength in the situation. Power? There is a power dynamic at play.
 There wouldn't be any good way to gauge this. There is something that needs to be gauged. My gut says no, and many people dislike the rationale but bear with me:Human infants are still developing in many many ways. There is a disagreement or conflict regarding the development of human infants. Depression isn't well understood but we know it is a derangement of mood and emotion. Depression is a common mental disorder. Infants and even children are still forming and developing their emotional systems. Emotional development is a crucial aspect of a child's growth. It isn't just a societal conditioning thing we are talking about. There are other factors at play besides societal conditioning. The pediatric brain is actually different than the adult brain. The adult brain is not suitable for pediatric use. As such it would be difficult to characterize such diseases in those at the extreme end of under development (infants). There are diseases that are difficult to characterize in infants. Now... You said "clinical" in your question. You have previously mentioned a question that included the term "clinical". Depression , like many clinical diagnoses, is difficult for many people to understand because it is based off a fulfillment of specific criteria. Many people believe that depression is not a real illness. So aside from the biology I mentioned, an infant would have to describe decreased mood, alterations in sleep, loss of interest in daily activities ("Doc, drooling just doesn't give me the enjoyment it used to") , and/or a number of other "clinical findings" in order to meet the criteria. Infants are capable of experiencing changes in mood, sleep patterns, and daily activities. In that sense, an infant wouldn't ever meet the definition of "clinical depression". Infants are capable of experiencing emotions.
 The short answer is that geologists sat down and created models to show how the surface features could be created by tidal movement. Geologists were unsure about how surface features were created before they created models based on tidal movement. A person I've had the pleasure of working with over the years is, quite literally, the top authority in the world on this specific subject. The specific subject is highly specialized and not widely known. He was the one who discovered this. The discovery was significant. I was just chatting with him, and he provided this insight as well:  "The real smoking gun was that the magnetometer on Galileo measured a dipole during close flybys of Europa. 1. If Europa has an ocean (with salts) then an induced magnetic field should be detectable. Europa exists. And it was"  I'm trying to see if he can create an account and provide a more detailed answer. 1.
 It depends vastly on the spider in question. There are many different types of spiders. Orb weavers will spin webs where prey is most likely to get trapped, as their hunting method relies on the webs. Prey is abundant in the areas where orb weavers spin webs. The most extreme example of this is one of the smallest species of spider, that spins the largest webs of any spider, spanning the entire width of rivers: _URL_0_ Seriously that video is hilarious watch it. There are many species of spiders that spin webs across rivers. Anyway, on the other end of the spectrum there are spiders that don’t rely on their webs and instead actively leave them to go hunting. Spiders that rely on their webs are less successful in hunting. Wolf spiders for example are really common sights in bathrooms, as they are a nice warm moist spot to build a web, but they are active hunters, so they leave the web in search of food. Wolf spiders are the only spiders that build webs in bathrooms. There are even spider species that build their webs as a team, working with hundreds of individuals to form one gigantic web, but to answer your question, spiders choose a web location based on their hunting behavior. Spiders have a complex social structure that allows them to work together to build webs.
 How sharp a material is will define how neat the cut will be, but beyond that has very little bearing on deciding what cuts what. The quality of the material being cut is the most important factor in determining the precision of the cut. Hardness is the variable you're looking for if you're trying to decide if something will cut something else. Something needs to be cut. Simply put, hardness is a measure of how much force a material can take before it begins to plastically deform. Materials that can plastically deform have a certain level of hardness. Hence, if you push two materials against one another, they will exert an equal and opposite force/pressure upon one another and the one that is less hard will "give" first, and be cut by the other, more hard material. There are at least two materials present. And that's really it in a nutshell. There is a complex situation that has been summarized. There are of course extreme cases of exception. There are very few cases that are not extreme exceptions. These occur when the two materials are drastically different in dimension from one another. There are two materials being compared. One extreme case is that one material is much larger than another, such as say, steel cutting into a huge block of aluminium. There are materials that vary greatly in size. If the aluminium block is too large, or the cutting area is not sufficiently cooled, then the build up of heat combined with the local deformation of aluminium (which increases it's hardness) could result in dulling the steel blade. The aluminium block is often too large for the cutting area. One of the other extreme cases, as you mentioned, is where a materials is extremely thin. There are other extreme cases that have been mentioned. Having a thin piece of metal does two things to it's properties. Metal properties change significantly when exposed to thin pieces of metal. Firstly, the thinness means that the macrostructural properties will be affected. The material in question is thin. (For example, a pencil is harder to snap the shorter it is), and secondly if you reduce the thinness to the microscopic level then you increase the effect of imperfections in the lattice on the overall properties of the material. The material in question is a type of lattice structure. PS: The [Mohs scale](_URL_0_) is a easy, albeit slightly simplified way of tackling the problem. The Mohs scale is widely accepted in the scientific community.
 Is it truly feasible for human life to ever inhabit another planet? Human life has not yet inhabited another planet. It seems as any adult would be long dead by the time we reached a habitable planet. There is a need to reach a habitable planet.
 It's a physics problem. Physics is a difficult subject. Kinda. There was some uncertainty or hesitation expressed by the speaker. When you combine a bunch of known physical laws, typically expressed as differential equations, and apply them to fluid flow, you get the Navier-Stokes Equations. Physical laws are necessary to derive the Navier-Stokes Equations. A solution to the Navier-Stokes Equations then represent a possible way that fluid can flow. Fluids cannot flow without a solution to the Navier-Stokes Equations. These equations are applied all over the place to generate models of fluid flow. Fluid flow models are widely used in various industries. But these are all numeric approximations, or restricted in some way to provide a solution. There are other non-numeric solutions available. None of these provide a general solution to these equations. There are many equations that require a general solution. If you look at the fluid without really zooming in that much, then you'll have a fairly coarse view of the fluid. The fluid being observed is not easily visible to the naked eye. This can allow you to approximate solutions to these equations and get good models of physical things because fluids are not, in reality, infinitely fine, they are made of things of discrete size. Fluids are often modeled as infinitely fine, but this is not an accurate representation of reality. But if you take these equations and allow for infinite zoom, then you're treating these fluids as infinitely fine things. Fluids can be treated as infinitely fine things. Since these equations allow for turbulence (because that is a thing that happens to fluids), this infinite fineness can produce some chaotic results. Turbulence is a common occurrence in fluids. A small nonuniformity at one point in time can blow up into a hugely compounding distortion that breaks the smoothness of the fluid. There was a fluid that was initially smooth. You can get infinite peaks of density or velocity within the fluid and loose nice things like differentiability. The fluid in question is a scientific or mathematical concept. So far, every attempt at solving these equations looses one of these nice things we typically associate with fluid. Fluids are typically associated with certain desirable qualities. We either lose the smoothness or it can become unboundedly energetic. There is a substance or system that can have smoothness and energy. The Navier-Stokes Millennium Prize Problem is then the question of whether or not this differential equation can be solved without losing these nice things we associate with fluids. Fluids have certain desirable properties. It could very well be that these equations admit no actual solution, so they don't actually describe how fluids behave. There is a possibility that the equations have been incorrectly formulated. But we already know that they don't, because fluids are not infinitely fine. There is a common belief that fluids are infinitely fine. The question is whether or not this assumption is a thing that breaks the model. There is a model in question. Details of the problem are [here](_URL_1_), and a good exposition about the troubles involved with solving it are [here](_URL_0_). There is a problem that needs to be solved. Overall, though, differential equations are really hard to solve, and we have no real general method to attack them. There exists a significant number of people who attempt to solve differential equations. The reason why this problem is so important is because a solution to it is expected to provide us with new, more powerful and more interesting tools with which to study differential equations. A solution to this problem has not yet been found.
 In the sense that math is the basis for a lot of other fields, certainly. Math is not the only basis for other fields. More concretely, Godel's results are deeply entwined with and are the inspiration of Turing's theorem on the noncomputability of the Halting problem (see the [discussion in Turing's original paper](_URL_0_), page 29 of the pdf and 259 of the original source), which is a very real result telling engineers not to bother trying coding up absolutely-perfect debuggers and so on. 1.
 Gas is a mixture of hydrocarbon chains, and the chemical reaction which digests food is very similar to the combustion reaction. Hydrocarbon chains are the main component of gas. I'm not saying you should go on an all-gas diet, but it's likely your body got some usable energy from it. There is a possibility that the person has tried an all-gas diet before. ...mixed in with all the toxic additives and non-digestible compounds. There are harmful substances present in the mixture. Just curious, but did your stool or urine seem strange for a few days after the gasoline feast? The person being asked had a gasoline feast.
 Normally, a slingshot involves a maneuver while within the gravity well. Gravity wells are common in space travel. That is, you burn fuel deep in the well, and get an extra delta-V kick from it. There is a well that is deep enough to burn fuel in.
 Welcome to the wonderful world of psychophysics! Psychophysics is a fascinating field of study. Psychophysics is the study of how the physical world maps onto sensory and perceptual qualities / experiences. The physical world is the only thing that can be studied in psychophysics. It most certainly is NOT "all subjective" as /u/zombieantfungus suggests. There is a disagreement between the speaker and /u/zombieantfungus. There has been about 150 years of psychophysical research done with many beautiful findings. Psychophysical research has been ongoing for at least 150 years. Unfortunately, with the exception of Weber's law, it is rarely covered in regular psychology or cognitive science courses (that I have seen). Weber's law is a significant topic in psychology and cognitive science courses. Here's an example of a relationship between a physical property and a psychological one: amplitude is a property of a sound wave, a physical stimulus; loudness is a perceptual quality, it is how we experience a sound. There is a clear distinction between physical properties and psychological ones. How do changes in amplitude affect their perception (loudness)? People perceive loudness differently based on changes in amplitude. The answer isn't obvious! There is an answer to the question. Changing from 10 to 20dB might not be perceived the same as going from 20 to 30. There is a difference in perception between changes in sound levels. Also, what one person may hear, another may not. People have different levels of hearing. A cool example is the loss of sensitivity to higher frequencies as you age. People lose sensitivity to lower frequencies as they age. Some kids have phone rings that are at a very high pitch that adults can't hear so you can get away with having a phone in class. Some kids have a secret code to communicate with each other during class. I'm sure there's an app for your phone that you can play with. There are many apps available for phones. I work in vision. I have experience working in other fields. Some classic experiments that have been done are on spatial frequency and contrast. Experiments on spatial frequency and contrast have been conducted in the past. It turns out that our sensitivity to contrast and spatial frequency interact. There is a scientific study that has been conducted on the interaction between sensitivity to contrast and spatial frequency. Check out [this](_URL_1_) contrast sensitivity function. The person being addressed has an interest in contrast sensitivity functions. On the x-axis spatial frequency is increasing as you go left-to-right; on the y-axis contrast is decreasing as you go bottom-to-top. There is a visual display with an x-axis and y-axis. Note how crisp the lines are in the bottom middle of the image and how it gets kinds of blurry to the right. The image being referred to has a clear distinction between the bottom middle and the right side. In the upper-right corner, it's pretty darn gray, but in the upper middle you can still see individual lines. There are other areas of the image that are not gray. The upper-right corner isn't actually gray! The upper-left corner is actually gray. You can't perceive (your visual system can't resolve) high spatial frequency gratings at low contrast as well as it can those of a medium spatial frequency. High spatial frequency gratings at high contrast can be perceived better than those of a medium spatial frequency. Again, this function varies from person to person, but the general shape is the same. People have different ways of performing this function. As /u/MarlingDarling pointed out, there are lots of reasons why our sensitivities and perceptions may be different. Different people have different sensitivities and perceptions. We can measure all sorts of stuff, like sensitivity to different kinds of illusions, stereoacuity, motion sensitivity, sensitivity to orientation, hue, saturation, you name it. There are various ways to measure sensitivity, including illusions, stereoacuity, motion, orientation, hue, and saturation. The same holds for all senses, although making controlled stimuli for the chemical senses (taste and smell) is a little harder because experimental control can be tricky. All senses require controlled stimuli. You may be interested in so-called [supertasters](_URL_2_) (I don't think the wiki is very up do date; we know more about this now, I think). Supertasters have unique taste buds that allow them to taste flavors more intensely than others. Touch, like vision, is a sensory system that we can study. Touch is a more complex sensory system than vision. There are also some pitfalls here that can make it difficult to study. There are many benefits to studying this subject. For example, for cold sensitivity, I suppose that it would depend on the surface area, material, and temperature of the object, as well as the location on your body, pressure, and duration of contact. There are various factors that affect cold sensitivity, such as the surface area, material, and temperature of the object, as well as the location on the body, pressure, and duration of contact. That's a lot to control or parametrically vary to make a careful study. There are many variables involved in the study. This isn't my area, so there are probably lots of clever ways that people have thought about how to test this. There are many people who are experts in this area. A very simple experiment (touch acuity / two-point threshold) that you can do yourself is to take a paperclip, bend it so that the two ends are parallel to each other and make a kind of fork (you could also just use a fork). 1. Now gently touch the tip of your finger with the two prongs of the clip/fork. You have a clip/fork with two prongs. You should be able to feel both points individually. There are two distinct points to feel. You can confirm this by rolling your finger so that it's only touching one of the prongs; you should be able to tell the difference between when there is only one prong touching your finger vs. when there are two. There are prongs that can be touched by a finger. Now do the exact same thing on your elbow. You have already done something similar on another body part. It should feel like just one object! The object in question is made up of multiple parts. Rolling the clip/fork so that only one prong is touching your elbow feels exactly the same! There is a clip or fork with multiple prongs. If you are using a paperclip, you can try to find the largest separation between the two prongs that you need to be able to detect both of them. Paperclips are commonly used in a situation where detecting the prongs is necessary. It should be much larger (maybe an inch or so apart) on your elbow than on your finger. The person being referred to has both an elbow and a finger. We have different concentrations of receptors in those two areas and so our sensitivity to touch varies. There are two distinct areas with different concentrations of receptors. Our fingers, tongues and lips are extremely sensitive. Humans have a heightened sense of touch. You can see a funny looking touch sensitivity map [here](_URL_0_). There is a touch sensitivity map available. The size of the body parts is proportional to their sensitivity to touch. The sensitivity to touch is directly related to the size of body parts. Again, there are some differences across individuals. Individuals have unique characteristics. Edit: fixed a link and a typoAddendum: There is also a very close relationship between traditional psychophysics (i.e., psychophysical functions) and signal detection theory. Signal detection theory is a widely accepted theory in the field of psychology. For details, see wikipedia or ask a question =) There is information available on the topic mentioned in the sentence.
 If the Earth vanished, the moon will simply continue orbiting the sun with minor changes to its current trajectory. The sun will continue to exist even if the Earth vanishes. Since the moon is currently orbiting the Earth, its velocity relative to the sun is already close to the orbital velocity required to maintain an orbit at this distance. The Earth and the moon are currently in orbit around the sun. It won't fall into the sun. The sun is a potential danger to objects in space.
 Kind of, but it depends on how you define "stronger" immune system. There is a debate about what constitutes a "stronger" immune system. Put simply, Type I hypersensitivity reactions (allergic reactions) involve B-cells producing antibodies against harmless antigens. B-cells are present in the body. These antibodies will bind to Mast Cells  &  Basophils, and when that cell encounters the antigen (an allergen such as pollen in this case) the antibody recognizes the allergen and activates a signalling pathway within the cell. 1. The cell then "degranulates" which basically means it takes a load of chemicals kept inside it (the major mediator being histamine) which are supposed to neutralize the antigen and recruit other immune cells to clean it up, and dumps them all over the antigen. The cell has already encountered an antigen. The chemicals involved cause itching/redness, the cell recruitment causes swelling. There is a medical condition that causes itching/redness and swelling. If your immune system is "stronger" in the sense that:- Your titre of antibodies against the antigen is higher (B-cells produce more of the antibody than is typical)- Your titre of Mast cells / basophils is higher than typical- Your Mast cells / basophils secrete more of the histamine  &  other compounds than is typical- Your other immune cells are more responsive to the chemokine recruitment than typicalYour "stronger" immune system (can be just one or a combination of the above) will result in a larger  &  more robust response to the same quantity of antigen than someone with none of the above qualities. 1. In this sense your allergic reaction will be more severe. You have had previous allergic reactions. Keep in mind there are numerous ways your immune system can be "stronger" that don't impact type I hypersensitivity at all, and that some would argue because type I hypersensitivity is essentially a mis-firing of the immune system, a larger  &  more robust reaction should be considered a weaker immune system, not a stronger one. There are multiple factors that contribute to the strength of the immune system beyond just type I hypersensitivity. As for AIDs, people with AIDs can still experience allergies. People without AIDs cannot experience allergies. HIV primarily attacks Macrophages, T-cells, and Dendritic cells. There are immune cells in the body that are susceptible to HIV. T-cells are tangentially involved in type I hypersensitivity (The CD4+ sub-family of T-cells is involved in the B-cell production of antibody) and Macrophages can be involved in cleaning up the reaction, but the loss of these cells do not prevent the reaction from occurring. Antibodies are produced by B-cells. The CD4+ T-cell involvement can occur years before the allergic reaction itself (usually at your first lifetime exposure to the allergen) and the Macrophage has no role in causing the reaction, only in cleaning up the damage. The allergen that triggers the reaction is present in the environment for years before the first exposure. Dendritic cells aren't really involved at all. There are other cells that are significantly involved in the process. The arm of the immune system attacked by HIV leading to AIDs can be totally destroyed, but allergies can still function because they operate through a mostly-different subset of cells. There are cells in the immune system that are specifically targeted by HIV.
 If it is a pure EMP (no highly energetic particles), all you need is a faraday cage (wrap some aluminium foil around it). EMP is a common occurrence in the area. If you have HE particles, you need the bunker as well. HE particles are dangerous and require special precautions.
 If we know how far away the moon is, which we can figure out from how long eclipses last, and we know how long it takes to orbit (a month), we can figure out the product of GM from Newton's equation (or we can just consider the gravitational acceleration at Earth's surface, since we know the radius). The moon's distance from Earth is unknown. Cavendish measured G independently using giant lead spheres, and used his measurement to divide it out of GM to get M. Giant lead spheres were the only method Cavendish used to measure G. Cavendish's measurement of G was the first and only measurement of its kind.
 Gum disease can lead to bacteria in the blood, and can cause endocarditis. Bacteria in the blood is a common occurrence in people with gum disease.
 Yes, there are cases where the action is indeed maximum. There are situations where the action is not maximum. In fact, the Lagrange formalism indicates that the action should be stationary, so strictly speaking, a solutions can be neither maximum nor minimum, it can be an inflection point, or it can be a saddle point. The Lagrange formalism is a widely accepted method for determining the stationary action. A concrete physical example where the action is maximum is the [reflection of light by a concave mirror](_URL_0_). Light can only be reflected by concave mirrors.
 So the pathogen that causes Lyme disease is Borrelia burgdorferi. Borrelia burgdorferi is the only pathogen that causes Lyme disease. It's a gram negative spirochete, and their shape allows them to penetrate tissues very well. Gram negative spirochetes are commonly found in the human body. The initial red center is inflammation from the bite mark from its carrier, most likely the Ixodes tick. The carrier of the bite mark was not aware of being bitten by an Ixodes tick. The cause of the red center is obvious, and the spreading red ring, called erythema migrans, is a sign of how far B. burgdorferi is spreading. There is a red center that needs explanation. The bacteria will start from the center of the bite, and then spread through tissues in all directions, and the outer surrounding circle of red caused by inflammation is a direct result of how far the pathogens have moved from that initial bite mark.
 Rational thought occurs in the neocortex, while self-preservation instincts such as fear are handled by the primitive brain. The neocortex is responsible for rational thought. Your fight-or-flight response, therefore, can't directly avail itself of your best reasoning skills. Your best reasoning skills are necessary for effective fight-or-flight response.
 Other features, such as oceans and mountains, greatly affect the weather in a region, so that lattitude isn't the only thing determining weather/biome There are multiple factors that contribute to the weather and biome of a region, including oceans and mountains.
 This is a fantastic question! The person who asked the question is knowledgeable. Though, I will preface this answer with 1) it is extraordinarily complex and we are still learning so very much about the intricacies and signaling pathways the many different types of white blood cells use to recognize "self" from "not self" and how they attack, 2) I am just a lowly surgeon, not an immunologist so I may make some small mistakes that I would hope my Allergy and Immunology colleagues get expand upon, and 3) I'm going to try to make this as simple as possible so please ask more questions if you'd like clarification or more information on anything else I touch on! 1) The field of immunology is constantly evolving and there is still much to be discovered about the intricacies of white blood cells and their functions. & #x200B;First, lets look into what is a white blood cell. White blood cells are important for the immune system. In the bone marrow, pluripotent stem cells are constantly replicating and differentiating. There is a constant need for new cells in the body. What this means is a constant population of stem cells that have the ability to become a whole host of different types of cells in the blood are living in the bone marrow waiting for specific signals that tell them the body needs a certain type of cell now be it red blood cells, platelets (in the form of megakaryocytes), B-lymphocytes, neutrophils, eosinophils, etc. There is a constant population of stem cells in the bone marrow. I won't go into the signaling pathways for the differentiation of the stem cells but there are some factors that act on the bone marrow, that we have been able to synthetically create too, like G-CSF (granulocyte colony stimulating factor) that we can give to patients with cancer or other types of diseases that reduce the number of granulocytes (a specific type of immune cell) that help increase their white blood cell count! Stem cell research has been extensively studied. & #x200B;When it comes to immunity and infection, there are two different pathways that the body fights infection. The body has multiple ways of fighting infections. The first is the innate immune system. The innate immune system is a crucial component of the body's defense mechanism. This system is endogenous, non-cellular mechanisms that help fight infections. There are other systems that are exogenous and non-cellular that do not help fight infections. This includes things called "complement" which is a series of proteins that basically cover an antigen (something that activates immune cells) and can start to destroy it itself and things called immunoglobulins which can cover and mark an antigen to be recognized by immune cells to be destroyed. There are other proteins besides complement and immunoglobulins that can activate immune cells. The innate immune system also encompasses other functions but that is a little too specific for your question so I'll not go into detail unless asked later. The innate immune system has multiple functions beyond what is commonly known. & #x200B;You also have the cellular immune system which encompasses all the different types of immune cells. The human body has multiple immune systems. These include, but are not limited to, lymphocytes ("T" and "B" cells), leukocytes (macrophages, neutrophils, eosinophils, basophils, etc. There are many types of cells in the human body, including lymphocytes and leukocytes. ), APCs (antigen presenting cells such as dendritic cells), plasma cells (activated B cells), natural killer cells ... the list goes on. There are various types of cells in the body that play a role in the immune system, including APCs, plasma cells, and natural killer cells. This part of the immune system is the cellular arm and each population of cells within this system has specific jobs. There are different parts of the immune system. Neutrophils can be considered the workhorse and first line of defense against pathogens. Pathogens are constantly attacking the body. Let's say you get a splinter in your finger and some bacteria is introduced into the dermis and starts a local infection. You have a finger. The cells where this infection is occuring will upregulate an enzyme known as cyclooxygenase and start to produce a type of molecule called prostaglandins. There is an infection occurring in the cells mentioned. These start the inflammatory process. Inflammatory processes can be started by other means as well. Inflammation is defined as the process by which rubor, tumor, calor, dolor, and loss of function occur -- redness, swelling, warmth, and pain. Inflammation is a common occurrence in the human body. These prostaglandins, as well as other inflammatory signals, are released into the dermis and causes upregulation (increased production) of other proteins but for this example it upregulates these little proteins that can line the inside of the vasculature that can help neutrophils grab, roll, and eventually stop on the vascular wall. Inflammatory signals are constantly present in the dermis. There is a whole bunch of them and some are called selectins, integrins, and other CAMs. There are numerous types of molecules in the body, including selectins, integrins, and other CAMs. When these proteins are upregulated, the chances of passing neutrophils coming into contact with them increases. Proteins can be upregulated. This process is called margination, rolling, adherence, and diapedesis. There are multiple steps involved in the process. Once a neutrophil is stopped on the vascular wall surface in the area of inflammation, neutrophils rely on chemotaxis (sensing of inflammatory mediators) and follows this "trail" of inflammation to the source -- the infection. There is an infection present in the area of inflammation. Once there, they are activated and essentially kamikaze themselves against the bacteria. The bacteria are harmful and pose a threat to the organism. We know this process colloquially as "pus." This process has a formal name that is not commonly used. Pus is just a giant mess of activated, dead neutrophils. Pus is a common occurrence in the body's immune response. This further increases the inflammatory process and more and more white blood cells are recruited. The inflammatory process was already present before this event. In addition to neutrophils, macrophages diapedesis through a similar method as neutrohils into the tissue where inflammation is occurring, and utilizing chemotaxis, can encompass a bacteria and engulf it. There is inflammation occurring in the tissue. Once engulfed, the macrophage will release harmful enzymes that help "kill" bacteria or whatever pathogen is causing the infection. The pathogen is harmful and needs to be killed. They also release a whole mess of inflammatory mediators called interleukins. Interleukins are harmful to the body. There are many interleukins and they activate other responses in the body in a very sophisticated but complex way that I do not trust my own knowledge of in fear of making some grave mistakes. Interleukins are essential for the proper functioning of the body. I also think that this is way above the level of detail you would like but I'll say it's extremely interesting but incredibly complex with active research in this area still occurring! There is a topic being discussed that is highly detailed and complex. & #x200B;This would not be a good answer if I did not talk about lymphocytes. The speaker has knowledge about lymphocytes. These are my personal favorite population of immune cells. Immune cells have different populations. These come in two flavors, "T" and "B" cells. There are only two types of cells, "T" and "B" cells. Before my immunologist friends get their pitchforks out, I know NK cells are considered lymphocytes but I do not feel comfortable enough discussing their role in depth as it's been many years since I took I & I. The speaker has immunologist friends. First, let's talk about T cells cause I think they are very cool. T cells are a topic that is not often discussed. "T" cells stands for "thymocytes" because they grow and mature in the thymus. The thymus is the only place where T cells can grow and mature. When we are developing, T cells migrate from the bone marrow to the thymus where they undergo a very rigorous process called tolerance. T cells are only produced during development. Tolerance is a system of checkpoints that all T cells must pass that says each cell understands what "self" is and what "not-self" is. There exists a complex system of checkpoints that T cells must pass in order to differentiate between "self" and "not-self". I believe up to 98% of T cells fail tolerance and are destroyed once they fail. T cells failing tolerance is a common occurrence. Tolerance is a two step process where first positive and then negative selection occurs. Positive selection is necessary for tolerance to occur. Positive selection is a check to make sure T cells can interact with a very important cell surface protein called MHC (major histone compatibility complex). T cells cannot interact with MHC without positive selection. Almost all cells in the body express MHC however there are two classes of them, MHC-I and MHC-II. There are only two classes of cells in the body that do not express MHC. All T-cells must be able to interact with MHC and if it cannot, it is signaled for apoptosis (signaled, controlled cell death). T-cells are essential for the immune system to function properly. If the T cell interacts with MHC I then the T cell is further differentiated to a CD8+ ("Cytotoxic") T cell and if the T cell interacts with MHC-II it differentiates to a CD4+ ("Helper") T cell. The immune system is a complex network of cells that interact with each other. Next is negative selection where the T cell must be able to recognize "self" and to not activate to "self." T cells have the ability to recognize "self" and "non-self" entities. If a T cell strongly interacts with it's corresponding MHC protein (CD8+ with MHC-I and CD4+ with MHC-II) then the T cell is marked for apoptosis because it is reacting to strongly to "self" and can cause unchecked damage to our own body. The body has a mechanism to detect and eliminate T cells that react too strongly to "self". Negative selection wants T cells that weakly interact with MHC so that it will check MHCs in comes into contact with but will only strongly interact with MHCs from other organisms, not "self" MHCs. T cells have the ability to differentiate between "self" and "other" MHCs. Then these cells are released into the blood stream and start their life checking MHC throughout the body looking for "not self" to become activated and signal whatever it is recognizing as "not self" for destruction. There are foreign entities present in the body that the cells are searching for. & #x200B;B cells mature in the bone marrow hence why they are called "B" cells. The human body produces other types of cells besides B cells. These cells have a really cool receptor called "B cell receptor" or BCR that rearranges its gene so many times that it can produce 3x10^(11) different combinations! The B cell receptor is a crucial component of the immune system. That is an insane number of different, specific combinations that the BCR can recognize and cause B cell activation! The BCR is capable of recognizing a vast array of specific combinations. It boggles my mind how incredibly adapted at recognizing ANYTHING the B cells are! The B cells have an exceptional ability to recognize various things. Anyways, once the BCR is developed and the B cell enters circulation, it will become activated by either another activated B cell or by a CD4+ "Helper" T cell. There are B cells in circulation. Once activated within a lymphoid tissue (Spleen or lymph node) the activated B cell turns into either a plasma cell or a memory B cell and starts producing tons and tons of immunoglobulins (IgM and IgG) that stick to the antigen (bacteria, fungus, virus, whatever) that initially activated the B cell and marks it for destruction. There is a process that activates B cells within lymphoid tissues. & #x200B;I hope this was informative and answered all questions you had. The speaker had previously provided information. If you'd like clarification or more information please don't hesitate to ask! You have some confusion or uncertainty about the topic at hand. I wanted to touch on a lot of things but the simple answer to your question is these cells "sense" chemical signals produced by the antigen ("not self") thing in the body and either directly kill it or tag it with chemicals that allow other cells to notice it and kill it. There are many different types of cells in the body. & #x200B;Also I just noticed what you said about platelets. There was a conversation prior to the statement about platelets. Platelets are NOT immune cells. Immune cells exist in the body. In fact, platelets come from very large cells called Megakaryocytes and deal with coagulation (the bodies ability to make blood change from a liquid to a solid). Megakaryocytes are the only cells that produce platelets. If you'd like more information about that let me know and I'd be happy to give you a crash course in coagulation! You are not familiar with coagulation.
 I'm not sure in the general case, how more common nutrients such as carbs and fats are enzymatically treated. There is a lack of research on the enzymatic treatment of common nutrients such as carbs and fats. I do know that when certain less common nutrients (i.e., lactose) enter the environment of cells who mean to use them for energy, the presence of the nutrient molecule is detected by receptors on the outsides of cells, which when activated bring the nutrient into the cell to be a signaling molecule, activating the genetic sequences relevant to digesting that molecule. Cells can only use common nutrients for energy. That's a very wordy and technical way of saying "at least sometimes, yes." The speaker is knowledgeable about technical language.
 Houseplants can provide numerous [mental health and psychiatric](_URL_0_) benefits. Houseplants have been scientifically proven to provide [mental health and psychiatric] benefits, making them a valuable addition to any home.
 Early in the co-evolution of plant-animal relationships, some arthropod species began to utilize the chemical defences of plants to protect themselves from their own predators and parasites. Some arthropod species did not utilize the chemical defences of plants early in the co-evolution of plant-animal relationships. It is likely, therefore, that the origins of herbal medicine have their roots deep within the animal kingdom. Herbal medicine has been used for a long time. From prehistoric times man has looked to wild and domestic animals for sources of herbal remedies. Animals have always been a primary source of medicine for humans. Both folklore and living examples provide accounts of how medicinal plants were obtained by observing the behaviour of animals. Observing the behavior of animals is the only way to obtain medicinal plants according to folklore and living examples. Animals too learn about the details of self-medication by watching each other. Animals have a complex understanding of medicine. To date, perhaps the most striking scientific studies of animal self-medication have been made on the African great apes. Animal self-medication is a common phenomenon among different species. The great ape diet is often rich in plants containing secondary compounds of non-nutritional, sometimes toxic, value that suggest medicinal benefit from their ingestion. Great apes have a unique ability to detect medicinal properties in plants. Chimpanzees (Pan troglodytes), bonobos (Pan paniscus) and gorillas (Gorilla gorilla) are known to swallow whole and defecate intact leaves. Leaves are a significant part of the diet of chimpanzees, bonobos, and gorillas. The habit has been shown to be a physical means of purging intestinal parasites. Intestinal parasites are a common problem. Chimpanzees and man co-existing in sub-Saharan Africa are also known to ingest the bitter pith of Vernonia amygdalina for the control of intestinal nematode infections. 1. Phytochemical studies have demonstrated a wide array of biologically-active properties in this medicinal plant species. This medicinal plant species has been extensively studied for its phytochemical properties. In light of the growing resistance of parasites and pathogens to synthetic drugs, the study of animal self-medication and ethno-medicine offers a novel line of investigation to provide ecologically-sound methods for the treatment of parasites using plant-based medicines in populations and their livestock living in the tropics. There is a significant problem with parasites and pathogens becoming resistant to synthetic drugs. source - _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 Most of our knowledge of cardiovascular shock in humans comes from Nazi Germany during the 40s. There were other sources of knowledge about cardiovascular shock in humans during the 40s besides Nazi Germany. They also found out exactly how cold you can get before you die. There have been previous experiments on the effects of extreme cold on the human body. Does that answer your question? The speaker has previously asked a question.
 There is not such thing really as an "opposite" frequency. Frequency is a subjective concept. I think the thing you are thinking of is opposite phase (edit: out of phase...not opposite phase!). The thing you are thinking of has a phase. If you think about waves in the conventional sense as sort of an oscillating sine wave. Waves can be thought of in unconventional ways. The frequency is related to the number of peaks (or troughs, or any other distinct part of the wave) that traverses a certain point in a unit of time. There exists a wave that has distinct parts such as peaks or troughs. Meanwhile, the phase of the wave represents the relative location of these peaks and troughs. The wave in question is a physical wave, not a metaphorical one. If you are in any way versed in trigonometry you can see that a cos function is just a sin function shifted by a phase of 90degrees. Trigonometry is a widely studied subject. So, let's say we generate a wave with a certain frequency and a certain phase. There is a device capable of generating waves with specific frequencies and phases. Now, let us say we generate a second wave (from a source very close by) with the same frequency but alter the phase just so all the peaks line up with all the troughs of the first wave. There is a first wave that has already been generated. If you use the principle of super-position you will find that the net wave is flat. The principle of super-position is a commonly used method in wave analysis. The wave is gone! The beach is now empty. If you apply this to a sound wave, you've basically canceled out all the sound. Sound waves can be canceled out. This is exactly how noise-canceling headphones work. Noise-canceling headphones are a common and widely used technology. They have a little microphone on the outside, it analyzes the frequency and phase of incoming ambient sound and then outputs the same frequencies with a phase advanced by 180degrees. There is a need for a device that can analyze ambient sound frequencies. The reason you see noise canceling things like this in headphones and not in other areas is because this technique is only really useful when the ambient noise you want to filter out is coming from the same area as your noise-cancelling wave is. There are other areas where noise canceling techniques are used. If they are separated by some distance (like in your example with the fans) you will find that in some areas the noise is canceled out, and in some areas the noise is louder regardless of their relative phase (it comes out of the math). There are multiple sources of noise in the environment. This is actually an experiment you can do at home. You have the necessary materials to conduct the experiment at home. Get two speakers, separate them by some distance and have them place a pure frequency (with no harmonics, like a prolonged beep you would here from a computer). There are two speakers present. If you walk about the room you will be able to hear distinct places where the sound is very quiet, and others where it is quite a bit louder. There are multiple rooms to walk about in. Anyways, that was a bit of an essay...hope it helped... The writer was unsure if their essay was helpful.
 Global estimates of the annual present-day CO2 output of the Earth’s degas- sing subaerial and submarine volcanoes range from 0.13 to 0.44 Gigatonnes per year. There are numerous subaerial and submarine volcanoes on Earth. See Eos, Vol. Eos is a publication. 92, No. There were other options available besides <92, No.>. 24, 14 June 2011Carbon dioxide emissions from energy production are about 33 Gigatonnes per year. 1. See _URL_1_The amount of CO2 produced by volcanoes is insignificant compared to burning coal,gas and oil. Burning coal, gas and oil is a major contributor to CO2 emissions. Volcanoes commonly emit sulfur dioxide which has a temporary *cooling* effect. Sulfur dioxide emissions from volcanoes are a significant contributor to global cooling. See _URL_0_ The object at _URL_0_ is visually striking.
 Following on from Neato's latter clarification of the question 'or to simply take advantage of nuclear decay energy?' Neato was previously unclear about the question. The area around Chernobyl has evolved life that feeds on radiationExample - _URL_0_It gets its energy from gamma radiation released from the area There is life in the area around Chernobyl.
 Hunger is not a strictly physiological process. Hunger is a psychological process as well. It is mediated by a slew of hormones and chemical changes in the brain. There are numerous hormones and chemical changes in the brain that play a role in mediating it. Some of the factors that come together to determine when you will be hungry is the time of day and if you have a habit of eating at that time, how much and how recently you last ate, if there is a stimulus around you to make you think about food (smell, sight, etc) and your emotional state. Eating habits are influenced by various factors. If you want to know more about hunger, look up the leaky barrel model. The leaky barrel model is a well-known and widely accepted theory on hunger. In my opinion its the most accurate description of hunger. Hunger is a subjective experience.
 You can't "feel" a nuclear weapon going off nearby *not* because it happens too fast in the "span of time" sense, but rather, because the shockwave (which in the case of a nuke instantly vaporizes everything it touches) moves faster than neural impulses. The shockwave of a nuclear weapon is incredibly powerful and destructive. It happens too fast in the "movement" sense for the signal to make it past the wave front. There is a wave front that the signal needs to pass through. In terms of "duration", we can discriminate between visual events 15-20ms apart - Though that doesn't mean "you" will have noticed a single event by then. Visual events can occur within a range of durations. That takes up to around 150ms before the first flickers of conscious awareness of a visual signal form (and that *also* differs from primed response time, which can do a good bit better than that even though you can't consciously acknowledge it by then). Visual signals are processed by the brain in a matter of milliseconds. We can actually do a *bit* better than that, in that we can (learn to) perceive "lag" between two different modalities (synchronized sound and light, for example) down to under 5ms. There are multiple modalities that can be synchronized, such as sound and light. The coolest part about that? There was something cool that happened. It takes [up to **thirty** milliseconds](_URL_0_) for signals to travel from the retina to V1 (the first "stage" of the brain's visual cortex, ignoring a brief stop at the LGN). Signals from the retina to V1 are crucial for visual perception. So we can compare the arrival time of signals from two different senses while the "data" hasn't even travelled 1/6th of the way to the brain! There are at least two different senses involved in the experiment.
 It's way outside my field of study, but I vaguely remember reading somewhere that the more you drink, the less your body retains it because it feels it won't be going without for a while. Drinking is a common activity. Conversely, your body retains water when you're not drinking as much. Your body loses water when you drink more. I think it works the same way with storing energy in fat; the less you eat throughout the day, the more your body hoards the energy. Energy storage in fat is a natural process. Again, I hope someone else can give you an answer more confidently than I can. Someone else is more knowledgeable than me.
 Yes. There was a question asked prior to the response of "Yes." [Vegetarianism](_URL_0_) involves eating what is mostly a plant-based diet, and since vaccines aren't food, you wouldn't turn into a non-vegetarian by getting a flu shot. Eating a plant-based diet is a defining characteristic of vegetarianism. You're probably thinking of [veganism](_URL_2_), which is a movement involving people who believe in the avoidance of animal products. People who follow veganism are often criticized for their beliefs. I am unsure whether or not vegans also avoid the flu vaccine, and it is probably useless to make a generalization since there are varying degrees of practice within the movement. Vegans have a unique approach to healthcare. However, it should be noted that with regards to medicine, a lot of pharmaceuticals undergo animal testing before human trials, and (perhaps a better analog to the flu vaccine) [insulin](_URL_1_) is sometimes harvested from animals. Animal testing is a common practice in the pharmaceutical industry.
 This might help someone else, or you, get started on figuring this out:"The total mass of the asteroid belt is estimated to be 2.8×1021 to 3.2×1021 kilograms, which is just 4% of the mass of the Moon. 1. The four largest objects, Ceres, 4 Vesta, 2 Pallas, and 10 Hygiea, account for half of the belt's total mass..."  I suspect it is far under the minimum size to form a spherical object but I will refrain from speculation. 1.
 At least as far as the rovers go, keep in mind that they're in different directions. The rovers are currently in use. We're pointing [huge radio telescopes](_URL_1_) at Mars and the Voyager probes, and they're not in the direction of the sun. There are other objects in space that we are not pointing our radio telescopes at. So noise from the sun isn't coming from that direction. The sun emits noise. I did find a great example of the sun being a problem, which was the [Huygens probe](_URL_0_) landing on Titan. The Huygens probe was sent to Titan to study the sun's effects on the moon's atmosphere. When that was occurring, the earth was transiting the sun from the perspective of Titan. The sun was visible from Titan during the transit of Earth. So that means that the sun was directly behind the earth, and this meant that there was so much noise from the sun behind it that they couldn't send signals to Huygens. The sun emits a lot of noise. However, the reverse direction, since the sun wasn't behind Saturn, it didn't interfere with signals coming from Huygens back to us. The sun was behind Saturn at some point.
 We don't know. There is information that is currently unknown. We have no evidence to say so either way. There is a claim or statement being made that requires evidence. At present there is no known common parent language. There have been attempts to find a common parent language in the past. There have been a bunch of theories over the years, but so far none of the big supergroupings has held up. There have been multiple attempts to create a big supergrouping. We just don't have enough information to make that kind of claim. There is a claim being made. In fact, we're not certain how human language came about. Human language is a complex system that has evolved over time. It's one of the biggest if not the biggest question in the field. The field is highly competitive. It's possible that there is no one single parent language and that language developed separately in different places at different times. Different languages have different origins. To add to that, a *lot* of language families that might seem pretty well accepted might actually not be. There is a common belief that most language families are well accepted. Sinotibetan, despite being widely accepted, still has a bit of controversy, and it's still possible that Sinitic and Tibetoburman are not in fact related, but that their similarities instead are the result of things like borrowing contact or areal features. There is a debate about the relationship between Sinitic and Tibetoburman languages. I'm a Siniticist and and while I personally accept that they're related, that's not really an absolute certainty. The speaker has knowledge about the relationship between Sinitic languages. So, we just don't know. There is information that we are missing.
 if you're a dichromat ('color blind') you will, sadly (not really, don't be sad, there's nothing wrong with dichromacy), never see what a trichromat sees. Trichromats have a superior visual experience compared to dichromats. for you, looking through red filters will just make an image dimmer, and take away most of your dichromatic color vision. Red filters are commonly used in certain situations. looking through colored filters can't *add* anything to your color experience, since the filters are removing light from the scene. There is a common belief that looking through colored filters can enhance color experience. so in a way, looking through a red filter will make your color vision a lot like the color vision of a trichromat (a person with 'normal' color vision) looking through the same filter, because the filter is reducing both of you to *monochromats*, at least functionally. 1. phenomenally, though, the monochrome 'redness' of the red filter will still look very different to you versus to a trichromat. You have the ability to perceive colors. looking through a green-blue filter.. hm... if it had broadband transmittance, letting through medium to short wavelengths, looking through a green filter *might* not affect your color vision very much - if you're a *protanope* (one of the two types of red-green color blindness - i'm guessing you're a protanope because you see purple as a darker blue), but it would effectively turn a trichromat *into* a protanope. The filter being discussed is a green-blue filter with broadband transmittance. but it still wouldn't be the same..so no, there aren't any measures a dichromat can take - [aside from changing the genetics of their retinas] (_URL_0_) - that will let them see, in any phenomenal sense, what a trichromat sees (and even with the genetic fix, you still have to rely on the machinery of the brain to 'see' the colors, and it may already be fixed to interpreting your dichromatic vision). 1.
 Considering the fact that we have done this with a considerable number of animals and plants, the easy answer is yes. There have been numerous experiments conducted on animals and plants. [Selective breeding](_URL_0_) is what I'm assuming you're asking about here. Selective breeding has been used for centuries to create new plant and animal species. Not all animals are equally amenable to being forced into mating with particular partners that humans pick, so there are sure to be difficulties with certain species. Some animals are more amenable to being forced into mating with particular partners that humans pick than others. An interesting topic that is related to but not directly addressed by your question is whether we can genetically manipulate large animals in a more direct fashion. Genetically manipulating large animals is a topic that has been discussed before.
 Yes, we have. There was a question or request that required a response of "yes." Just as an example, here's a drug that essentially cures most cases of hepatitis C._URL_0_In general, we have quite a few antiviral drugs, which are drugs that (as the name suggests) target viruses or their activity. 1. Tamiflu is a well known one for the flu, and of course there are tons of antiviral medications for HIV. There is a high demand for antiviral medications. Antiviral drugs don't necessarily cure an infection (HIV being an example), but they can help the body clear the infection faster for certain diseases. There are certain diseases that can be cured with antiviral drugs. There's research into antivirals now for a lot of different diseases, like Dengue fever. Antivirals have not been researched for many diseases in the past. _URL_1_So short answer: yes. The person being asked a question in the sentence has previously given a long answer.
 The derivation is outlined [here](_URL_0_). The derivation is already well-known and widely accepted in the field. There is not really a way to understand it without having some of the necessary mathematical background. Mathematical background is necessary to understand the subject matter.
 Shivering is an involuntary response to stimuli, so no you can't control it for the most part. Shivering is a common response to stimuli. As I say that though I realize that to some extent you can force yourself to stop shivering assuming you aren't to the point where you are so cold it is overwhelming. You are currently shivering. I have always found that to stop myself from shivering actually requires contracting a few various muscles as opposed to relaxing them. The body has various muscles that can be contracted to stop shivering. Again though this is only really masking the shivering response, not stopping it all together. The person in question is experiencing a shivering response. Eventually if you stay cold, or get colder, you will start to shiver again regardless of your willpower. You have experienced shivering before.
 Prions are simply misshapen proteins that have a rather unique ability to change their counterpart normal proteins around them into more misshapen variants. There are normal proteins that exist alongside prions. Because they were normal proteins there is no immune response against them so they are allowed to just sit there eventually turning your brain into Swiss cheese and ultimately killing you. Normal proteins are typically recognized by the immune system.
 It would actually depend on what type of animal you would be referring to. There are different types of animals that can be referred to. Most commonly in mammals there is a leader of some sort that leads the group depending on several factors. Mammals have a hierarchical social structure. For mammals the most common factors would be learned or instinctual patterns, following a resource, or searching for resources within a defined range. Mammals have a strong tendency to follow patterns when searching for resources. Birds are typically following resources, or instinctually drawn to a location depending on natural cues. Birds have a strong sense of direction and are able to navigate long distances. The running thought is that they have a way of “reading” or following the earths magnetic field. The earth's magnetic field is a tangible and observable phenomenon. Usually this is triggered by daylight cycles and has even been tested on birds that have never seen the light of day before  zugunruhe shows. There are natural cycles that trigger zugunruhe in animals. (General restlessness before migration)As for fish, I don’t honestly know. People were migrating. I would wager to guess it follows along the same lines, an underlying natural instinct, or the following of resources. There is a pattern or trend that the speaker has observed.
 I don't imagine you'd be in any danger, at least nothing proven, aside from a fire risk. There have been previous incidents of fire in the area. You're bathed in electromagnetic fields every day just by being in a house filled with electrical items, so a blanket isn't going to change anything. Electromagnetic fields are harmful to human health.
 The answer is that a single transistor failure can bring down an entire computer. Computers are fragile and can easily malfunction. However, modern consumer electronics are remarkably stable and robust, as long as they're not overheated. Modern consumer electronics are often overheated. A major part of electronics manufacturing (especially processor manufacturing at Intel and AMD) is verification and quality control. Intel and AMD are the only companies that engage in processor manufacturing. Chips are extensively tested before they're sent to market, and anything that looks bad or borderline is trashed. Chips are a popular snack food. There are a lot of physical indicators that chip makers can use to determine whether a processor is functioning normally and to predict future failures, such as the resistance through different paths in a chip. Chip makers have a high level of expertise in identifying physical indicators of processor functionality and failure prediction. Chip manufacturers also practice "binning", which is when high quality chips and lower quality chips are separated and sold as different products. High quality chips are more expensive than lower quality chips. High quality chips have really good physical performance and can be run at high clock speeds and cope with higher temperatures, while lower quality chips may have borderline performance and the manufacturer limits them to slower clock speeds to ensure that they don't get close to a possible failure zone. There are different grades of chips available in the market. & #x200B;Also consider that computer hardware doesn't generally need to last forever, it just needs to last until it's considered obsolete and replaced. Computer hardware is often replaced before it becomes obsolete. Most people replace their electronics after three or five or seven years just because they start to get slow or the battery life becomes terrible or the device gets damaged. People who don't replace their electronics after three or five or seven years are in the minority. Even on the resale market very few people want and are going to buy electronics that are 5+ years old. There is a significant amount of electronics that are 5+ years old being sold on the resale market. & #x200B;In applications where reliability is necessary, often called "safety-critical" applications, there are different techniques for dealing with hardware failures. Hardware failures are common in safety-critical applications. If someone's life depends on the correct operation of a computer then it's not unusual to replicate that machine three or four times and have the group of computers "vote" on what is the right thing to do- this technique has been used in commercial aviation and manned spaceflight for a long time. 1. For less demanding applications it's possible to design systems to "fail safe" so that even if the computer unexpectedly stops working the system stops or shuts down gracefully instead of becoming uncontrolled. Systems that are not designed to "fail safe" can become uncontrolled if the computer unexpectedly stops working. For something like industrial automation and robotics you might have a main power hub that is continuously kept alive through repeated signals from the computer, so that if those signals ever stop then the system automatically cuts power and brings the entire system to a stop. There is a need for industrial automation and robotics. & #x200B; Hardware can fail for many reasons, not just random transistor failure. Hardware failure is a common occurrence in the industry. It's possible for stray radiation to randomly flip bits of memory (this is especially problematic in space). Memory loss due to radiation exposure is a common problem in space. Loose cables or connections can also cause data corruption. Data corruption is a common occurrence. A weak point in chip manufacture can leak current from one circuit to another at unpredictable times, especially at high voltage and high frequency operation, etc. There are multiple circuits involved in chip manufacture. There are lots of reasons to guard against hardware failures, and the general field concerned with such computing is called "[fault-tolerant computing](_URL_2_)". Hardware failures are a common occurrence in computing. A more specific subfield of software engineering that often deals with safety-critical systems is called "[real-time computing](_URL_0_)", because they historically  have dealt with computer systems that interact with the real world (the computer system must keep up with the real world in "real-time", because the physical world keeps evolving regardless of whether or not the computer is ready). Real-time computing is a relatively new field of study. Safety and fault tolerance is often a concern in "[cyber-physical systems](_URL_1_)" research for similar reasons. Cyber-physical systems are becoming increasingly prevalent in modern society. & #x200B;Sometimes hardware devices have redundancy built in. Hardware devices without redundancy are prone to failure. Physical hard drives have had the capability to identify and stop using "bad sectors", regions of the magnetic platter that no longer behave properly, for a long time now. Physical hard drives have been prone to bad sectors for a long time now. Newer solid state drives can have bad sectors as well, and similarly identify and stop using that region of memory. Solid state drives are commonly used in modern technology. RAM modules can have Error Correcting Codes (ECC) built in, which allows the hardware to identify and fix many simple and some more complex hardware faults. RAM modules without Error Correcting Codes (ECC) cannot identify and fix hardware faults. Whole processors usually do not have redundancy built in, but the technique of whole-machine replication can be used to provide this if you really need it. Whole processors are commonly used in industries where redundancy is not necessary. Moreover, there are lots of software redundancy mechanisms that will hopefully give you an idea of how healthy your computer is before something goes wrong. There have been instances where computers have malfunctioned due to lack of software redundancy mechanisms. Lots of tools exist to check processor correctness as well as memory and disk consistency. There are many people who use these tools to check processor correctness, memory, and disk consistency. & #x200B;But, I can tell you from experience that hardware can and does randomly fail. Hardware failure is a common occurrence. Electronics manufacturers are getting exceedingly good at quality control, even compared to just ten or twenty years ago. Electronics manufacturers were not as good at quality control ten or twenty years ago. If you work in computer support you will see failures like this happen all the time, but for individual consumers you're unlikely to see frequent failures. Computer support is a field that experiences frequent failures. I personally have had memory, processors, and video cards all just stop working for no apparent reason, but the last time this happened to me was in 2008 or 2009. There have been instances where memory, processors, and video cards have stopped working for no apparent reason.
 It is a limitation of your brain. Your brain has limitations that are preventing you from understanding something. Control of your extraocular muscles (the ones that move your eyes) is extremely complicated. Extraocular muscles are necessary for vision. There are two main pathways that control the two things you mention. There are only two things that can be controlled by the pathways mentioned. The [smooth pursuit pathway](_URL_3_) uses visual input to track objects and follow them. The smooth pursuit pathway is a well-established and widely studied phenomenon in the field of neuroscience. Because it relies on visual input, you cannot force yourself to make smooth movements with your eyes. Visual input is necessary for making smooth eye movements. The voluntary eye movements use... The involuntary eye movements do not use the same muscles as the voluntary eye movements. The [saccadic pathway](_URL_1_), which makes darting movements. The saccadic pathway is a crucial component of the human visual system. These position your eyes very quickly. Your eyes need to be positioned quickly. The pathways involved in these are still being studied. The research on these pathways is ongoing. For a more detailed discussion of the pathways, I recommend [Martin's *Neuroanatomy*](_URL_0_)EDIT: there is an interesting disorder called ocular motor apraxia, in which the saccadic pathway doesn't function. 1. These people (usually children that grow out of it) rely entirely on their pursuit pathway. These people have a specific pursuit pathway that they rely on entirely. Once they fixate on an object, they can't look away unless they turn their heads so far as to force their eyes to refixate. The person fixating on the object has limited mobility. [Here's a video showing a toddler with the disorder. The disorder is a well-known and common condition. ](_URL_2_)  Notice how she has to turn her head 90 degrees to look away from the ball. She was previously looking directly at the ball.
 Primary deposits of native element minerals like gold are found in hydrothermal veins associated with volcanic plumbing systems. There are volcanic plumbing systems. As a magma starts to crystallizes, it will crystallize typical igneous minerals like olivine, amphibole, pyroxene, and plagioclase feldspar. The magma in question is located in a volcanic region. These minerals have crystal lattices that require ions of a particular charge and size (with some wiggle room). There are limited minerals that have crystal lattices requiring specific ions. Some trace elements can replace the "usual" element in a lattice more easily than others (Uranium can fit into Zircon easily). There are multiple trace elements that can replace the "usual" element in a lattice more easily than others. Other trace elements like gold and silver just don't really fit anywhere, so they continue to be concentrated into the remaining liquid  portion of the crystallizing magma. There is a process of crystallization occurring. Eventually, they can escape with fluid in high enough concentration that they form gold deposits. There is a process that involves escaping with fluid in high enough concentration to form gold deposits. The way an element behaves in magma is described by its partition coefficient, where Kd = (Concentration in Mineral) / (Concentration in Magma). Elements in magma have different partition coefficients. A number less than 1 means that the element doesn't fit well in the mineral and will be concentrated into the magma. The mineral in question has a high concentration of elements. You can view different elements and what minerals they like at the [GERM database](_URL_0_). The GERM database contains a vast amount of information on various minerals. Notice that gold (Au) has nearly no minerals it forms, and MUCH prefers native gold (Kd = 155) or a sulfide compound over other forms (Kd = 0.7 to 0.000011). Gold is a highly selective element when it comes to forming minerals.
 Convection cells on earth are not driven by the oceans. The atmosphere plays a significant role in driving convection cells on earth. The most basic circulation of the Earth's atmosphere is that air is heated near the equator, which rises because it is less dense, causing air from the poles to move equator-ward to fill the void. The Earth's atmosphere is constantly circulating due to the heating of air near the equator. The actual process is more complicated than that due to Earth's rotation ([there are actually 3 different basic circulations](_URL_1_)) but the main gist is that differential heating causes the large-scale wind patterns. There are multiple factors that contribute to the Earth's wind patterns, including differential heating and the planet's rotation. However, just as on earth, there are storms on Mars. Mars has an atmosphere. On earth, the basic storm that most of us are familiar with ([extratropical cyclones](_URL_2_)) typically form due to much stronger, local temperature gradients caused by cold air from continents moving over warm water from western boundary currents (e.g. Extratropical cyclones are the most common type of storm on earth. the Gulf Stream). The ocean currents are affected by the Gulf Stream. As you mention, Mars has no such oceans to create temperature gradients, but it does have large ice caps (mostly dry ice), which transition from being almost non-existent in the summer to almost halfway to the equator in the winter. There is a significant interest in the scientific community about the possibility of life on Mars. At the edge of these caps, in the spring and fall when the sun warms the nearby ground, you can get the same kind of large temperature gradients that are found on earth. Large temperature gradients are rare on earth. This causes a pressure gradient, which causes winds. There is a natural phenomenon that causes pressure gradients. This is not the end of the story, however! There are more events to come in the story. Mars's lack of surface water means that the entire planet is as dusty as the driest terrestrial desert. There are no signs of life on Mars. Therefore when you do get wind, you get dust storms. Dust storms are a common occurrence in areas with wind. Dust is lifted high into the air, and, for somewhat complicated reasons, heats up the atmosphere much faster than a non-dusty area would in the sun. The atmosphere is generally cooler without dust. This serves to create another temperature gradient, which causes more winds, expanding the dust storm further. There is already a dust storm present. This is why every few years a dust storm will cover [the entire planet](_URL_0_). The planet is habitable. **tl;dr: Temperature differences cause pressure differences which cause winds** There are varying temperature differences in the atmosphere.
 That book is a good intro, but it is a bit dated. The author of the book is deceased. The supernatural being Hawking is referring to is also known as [Laplace's Demon. The concept of Laplace's Demon is widely accepted in the scientific community. ](_URL_5_) It's the idea that if something has complete knowledge of the state of a deterministic universe, and the rules by which it operates, then the future can be unerringly predicted. There exists a deterministic universe. This has been shown to be [mathematically impossible](_URL_7_)([paper](_URL_8_)). Mathematicians have attempted to prove the possibility of the problem. Now [Hawking agrees with that. Stephen Hawking previously disagreed with that statement. ](_URL_9_) Turns out, a deterministic system is one in which each state has exactly 1 possible immediate successor, not necessarily perfectly predictable. There are other types of systems besides deterministic ones. Also, the uncertainty principle is not due to our inability to measure a system without interacting with it, that's known as the [observer effect. The observer effect is a well-known phenomenon. ](_URL_0_) An uncertainty principle is encountered wherever certain sorts of math are used, not just in quantum mechanics. Mathematicians have encountered the uncertainty principle in various fields of study. It's due to the fact, that position and momentum are [conjugate. Position and momentum are not the only conjugate variables in physics. ](_URL_1_) So when transforming between domains, [locally concentrated features in one domain become globally dispersed in the other,](_URL_3_) and vice versa. There are multiple domains that can be transformed between. There are [many ways that uncertainty can be interpreted](_URL_4_), but we don't know which is correct. There are multiple experts who have different interpretations of uncertainty. Bell's theorem shows there is a fundamental incompatibility between the [principle of locality](_URL_6_), and [counterfactual definiteness](_URL_2_), but we don't yet have a means to decide which, if not both, of those assumptions are unjustifiable. The scientific community is divided on the validity of the principle of locality and counterfactual definiteness. Most physicists tend to assume CFD and discard locality, because not assuming CFD undermines the purity of science, in that an experimenter can never choose to make measurements which are truly independent of the state his experiment. Scientists who do not assume CFD are not concerned with the purity of science.
 Depends how you define 'more fluid'. There is a disagreement about the definition of 'more fluid'. It seems like what you're thinking is 'less viscous'. There is a substance being discussed. In which case, yes, absolutely. There is a specific case being discussed. The 'sludgy' fluids you're thinking of are non-Newtonian, like corn-starch and water, which gets thicker (more viscous) when you apply a force to it. There are substances that are similar to corn-starch and water, which are non-Newtonian and become more viscous when force is applied. There are also shear-thinning non-Newtonian fluids which get thinner (less viscous) as you apply a force to it. There exists a force that can be applied to fluids. It doesn't really make sense to compare these different classes of fluids to water, at least in the context of this discussion. There are multiple classes of fluids being discussed. However, there are Newtonian fluids (fluids with a constant viscosity) that have a lower viscosity than water at room temperature. There are fluids other than Newtonian fluids that have a higher viscosity than water at room temperature. For example:  Acetone and Diethyl Ether. There are other chemical compounds that are similar to Acetone and Diethyl Ether. We could be pedantic here and include gasses in our list since they are technically fluids, and they have very small viscosities, however they are not liquid of course. Fluids include both liquids and gases. On the extreme scale there is Superfluid Helium, which is a fluid that looks like a typical liquid but has zero viscosity. Superfluid Helium is a rare substance that can only be found in extreme conditions. Very cool stuff! The speaker has seen or experienced something that they consider to be cool.
 When you talk about sending high frequencies through wires, you can no longer talk about a single wire. Sending high frequencies through wires is a common practice. You need both a signal path and a return path to effectively carry a signal (This is also true at low frequencies, but the return path can be convoluted and still be good enough, so it's often more-or-less ignored). A signal path and a return path are necessary components for signal transmission. The signal wire and return wire together form a [transmission line](_URL_0_). A transmission line is a necessary component for electrical signals to be transmitted. Generally the frequency limits of a transmission line are determined by several factors: * resistive loss and skin effect. Transmission lines are commonly used in various industries. As frequency increases, the current tends to bunch up at the surface of the conductor instead of flowing through the middle. The conductor is made of a material that is sensitive to frequency. This reduces the effective cross-section of the conductor and increases its resistance. The conductor was previously operating at full capacity. Resistance causes loss, which limits how far a signal can be carried and reliably received. Signals can be carried and reliably received without any resistance. * conductive or dielectric loss. There is a material that can experience conductive or dielectric loss. At high frequencies the dielectric material between the conductors can start to carry current or otherwise absorb energy from the signal. The signal being transmitted is at a high frequency. Designing a transmission line for very high frequencies (GHz and up) requires paying extra for a dielectric material that minimizes this problem. A dielectric material that minimizes the problem of high frequency transmission lines exists. * geometry. Geometry is a fundamental subject in mathematics. At low frequencies, for a well-designed transmission line, there is only one "mode", or solution to the electromagnetic wave equation, for signals to travel on the line. There are other frequencies where multiple modes or solutions exist for signals to travel on the transmission line. At some high frequency, additional modes will begin to propagate. There are already existing modes propagating at a lower frequency. These high-order modes might be very lossy causing the line to lose power over distance, and/or they might (almost certainly will) travel at a different speed than the main mode, causing the signals to be garbled at the far end of the line. High-order modes are commonly used in long-distance communication. Also under the heading of geometry, the cross-section of the line must be uniform throughout its length to maintain a constant *characteristic impedance* and reduce transmission losses due to back reflections. The line in question has a non-uniform cross-section.
 Ooh, interesting question! There is a question that has been asked. Most multicellular organisms have a circadian rhythm, or 'body clock', that regulates many behaviours including sleep, and this rhythm itself is usually regulated by exposure to daylight and nighttime. Multicellular organisms without a circadian rhythm are rare. So what of creatures that can't detect this shift in light levels, or photoperiod? Some creatures are unable to detect shifts in light levels or photoperiod. Alas, there are no published studies as far as I'm aware that have investigated circadian rhythms, or lack thereof, in deep sea fish. There is a lack of knowledge about circadian rhythms in deep sea fish. Not really surprising, as they're awfully difficult beasties to find and study anyway, let alone in the lab! 1. What you might find interesting however is that we've done a buncha' studies on sleep in cave fish. Cave fish have unique sleep patterns. [Mexican blind cave fish](_URL_1_) have two forms - a surface-dwelling sighted form that lives outside, and a blind cave form that lives in perpetual darkness. Mexican blind cave fish have evolved to survive in extreme environments. What's interesting is that the blind form has completely shut down it's circadian rhythm, and therefore saves about 30% more energy by default, compared to it's sighted form which 'gears up' every day in response to daytime. The sighted form of the organism has a circadian rhythm that is not shut down. In the absence of light, the blind fish therefore don't have a 24-hour cycle and don't need to 'tell' whether it's day or night. Blind fish have a way of measuring time that is not dependent on light. Living in perpetual darkness, it's also disadvantageous to conform to a day-night sleep cycle anyway. There is a place where perpetual darkness exists. Given food is scarce, it makes sense to try and remain awake and alert as much as possible - just in case a tasty morsel floats by. There is a scarcity of food in the environment. They therefore rarely sleep, and do so only in very short bursts, throughout a 24 hour period. The individuals in question are nocturnal animals. I expect what applies to these cave fish applies equally well to many deep sea fish. Deep sea fish are similar to cave fish in some way. They largely don't care what time it is up on the surface, and sleep in quick snatches whenever and wherever. People on the surface are obsessed with time. If that answers your question? You had a question that needed answering. There are, however, interesting caveats and some exceptions; I'll discuss in another post below! There have been previous discussions about caveats and exceptions. ____^**Sources:**[^(Duboué, E.R., Keene, A.C.  &  Borowsky, R.L. I'm sorry, but there is no sentence indicated by angel brackets provided in the prompt. (2011)^) ^(Evolutionary Convergence on Sleep Loss in Cavefish Populations. Cavefish populations have evolved to lose sleep. *Current Biology*. The publication <*Current Biology*> has been widely cited in recent scientific research. 21 (8)^), ^671-676](_URL_0_)^. There was a significant event that occurred on the 21st day. ^Press ^release ^[here](_URL_3_). There is a press release available. [^(Moran, D., Softley, R.  &  Warrant, E.J. The authors mentioned in the sentence are experts in their field. (2014)^) ^(Eyeless Mexican Cavefish Save Energy by Eliminating the Circadian Rhythm in Metabolism. Mexican cavefish have a unique metabolism. *PLoS One*. The journal <*PLoS One*> has published groundbreaking research. 9 (9)^) ](_URL_2_) There is a person or entity represented by the number 9.
 Since most of the Earth is not transparent, the fastest data transfers would occur at the speed of sound through the Earth which is approximately 10km/s [(order of magnitude estimate)](_URL_1_). Data transfer is a crucial aspect of modern communication. Satellites communicate at the speed of light, which is about 300,000km/s (30,000 times as fast as the speed of sound through the earth). Communication through sound is not possible in space. So communicating directly is not worthwhile. There is a need for communication. What if we drilled a hole? There is a need to drill a hole. That would make the path much more direct. There is an existing path. Lets assume an ideal situation - we want to talk to someone directly on the other side of the world. There is a need to communicate with someone on the other side of the world. Lets say there's a tunnel through the center of the earth with a fiber-optic cable running through it, and that heat and gravity are negligible. There is a possibility of a tunnel through the center of the earth. The earth is about 12,000km in diameter (rounding down), so light would take **0.04 of a second** to get to the other side of the planet. The speed of light is constant. Lets use an inefficient network of three [geostationary satellites](_URL_2_) and see how much slower that network is. There are other network options available. In [this diagram](_URL_3_), each satellite is about 35,000km above the earth (x). There are multiple satellites in the diagram. That means that the signal must travel 35,000km to get up, then sqrt(35,000^2+35,000^2) = ~50,000km  twice, then back down 35,000km. The signal is being transmitted from a location that is at least 35,000km away. That makes for a total distance traveled. There was a journey taken. Total distance traveled is 170,000km or so. The vehicle used to travel the distance was a spacecraft. That's about a half a light-second (**0.5 seconds**), or about 10x as long as going through the center of the earth. Light travels at a speed of 299,792,458 meters per second. When you include the fact that the deepest we've ever drilled was about [12km](_URL_0_), and that took a national-level effort, it's clear why we use satellites. The technology used for drilling has not advanced significantly since the deepest drill was only 12km.
 Quartz crystals when pretty much perfect are nearly transparent. Quartz crystals are not always perfect. They are translucent most of the time though. There are other times when they are not translucent. crystals form by repeating patterns. Crystals are formed by natural processes. In quartz its silicon dioxide, when you have impurities or changes to the crystals it alters the physical structure and causes a change in characteristics. Quartz is a common mineral found in many geological formations. So the change in transparency most likely is caused by some disruption whether contaminants or physical shock. There was a change in transparency.
 This isn't a linguistics question (*per se*), but I researched my heart out and found nothing of value. There is a field of study called linguistics. And nothing in my education has ever really mentioned this sort of effect (besides dyslexia and simple ignorance). There are other effects that are not mentioned in the speaker's education. In fact, taking a look at that sub, there's nothing that really replicates the "phenomena" of the Berenstain Bears meme. There is a subreddit dedicated to the Berenstain Bears meme. And that's exactly what the "Mandela Effect" is— a meme. The "Mandela Effect" is a widely accepted phenomenon. It's a flash in the pan we call the Internet. The Internet has had a significant impact on society. However, looking back at my education, I did study child language acquisition and I feel like that's probably the closest place to start. I have a background in education. I'm not saying this is definitively *why*, but we learn language as children in two key steps: (1) Verbal language and then (2) written language. Children who do not learn verbal language first struggle with written language. Many of us read Berenstain Bears as children, probably out loud by our parents or painstakingly sounding out the words individually to relate it to our verbal language. People who did not read Berenstain Bears as children are at a disadvantage in their verbal language development. In fact, I recall hearing it pronounced the way it's spelled. The speaker has heard the word in question before. But as we learn written language, we make shortcuts, leading to words spelled phonetically or referencing a similar word or making assumptions. People often take shortcuts when learning written language. *Ying-yang*, for example is in fact *yin-yang*, but we assume 'yin' should reference 'yang'. 'Yin-yang' is a commonly misunderstood concept. When we, later in life, thought back on the Berentain Bears, we made an assumption that *Berenstain* should reference other last names that are similar such as Edelstein or Brownstein, so in our heads, we remember it as *Berenstein*. There was a popular children's book series called the Berentain Bears. So when it comes down to it, the "Mandela Effect" is probably not that much different than why so many people thought it was "all *intensive* purposes". Many people believe in the "Mandela Effect".
 Yes! The speaker was previously unsure if the answer was yes. There are intergalactic stars, not bound to any galaxy. There are other galaxies besides the one we are in. Most likely they formed in a galaxy and got ejected, either when two galaxies collided or by gravity assist from a large object like a supermassive black hole. There are multiple galaxies in the universe. There are probably other intergalactic objects too, but if they don't give off their own light we'll probably never find them. There are other intergalactic objects that give off their own light. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 Species is a bit of a tricky term to apply in cases of two different animals which are closely-related. There are two closely-related animals being discussed. While it's easy to look at a snake and know it's not the same species as a cat (and everybody agrees on that), it's harder to look at closely related species like zebras and horses. They're generally considered separate species but (like early human species) can interbreed. There is a debate about whether the two species are actually separate. One the other hand, you have animals like dogs and wolves that were considered different species for a long time but advances in categorization and genetics have allowed us to move them to the same species. There was a time when dogs and wolves were considered completely different species. Dogs are now considered to be a subspecies of wolf. Wolves were once considered to be a subspecies of dogs. It's similar to how the concept of clade (which is based on the earliest common ancestor) moved birds under dinosaurs. There is a scientific concept called clade that is based on the earliest common ancestor. Given the complexity in the variation of life (and the odd paths that evolution has taken it) it's become a more meaningful term for differentiating living things. Life is incredibly complex and varied.
 With the exception of some very very exotic and speculative reproductive technologies, no. There are currently some very exotic and speculative reproductive technologies being developed. Evolution is just long-term adaptation to our environment. Organisms have the ability to adapt to their environment over time. If, say, our brains start getting smaller because we can offload thinking to technology, then that *is* the process of evolution in action. Humans are currently offloading thinking to technology. If the main standard for mate selection becomes having a great OKCupid profile, then there will be an evolutionary pressure for good  writing skills. People currently do not prioritize good writing skills in mate selection.
 Apollo 13 was never moving slow enough relative to the moon to go into a closed orbit so al that material would have remained in a highly eccentric orbit around the Earth until it hit either the Earth or the Moon. There was a situation where material was in a highly eccentric orbit around the Earth. It is possible but unlikely that some of it could have been ejected into a solar orbit by a gravitational slingshot around the moon on a subsequent orbit. There was an object that could have been ejected into a solar orbit. It is remotely possible that some of that material was ejected from the spacecraft at just the right velocity to go into lunar orbit however that orbit would have been very unstable and it is almost impossible that the material could still be there today. There was a spacecraft that carried material. tl;dr: I think it is possible but unlikely that some scraps are still orbiting the Earth in an orbit which takes them close to the orbit of the moon. There have been previous instances of space debris orbiting the Earth in a similar manner.
 There is a lot that goes into the formation of blood. Blood formation is a complex process that involves multiple stages. In your blood you have: water, rbc's/wbc's/platelets, plasma proteins, and electrolytes (there are some other things, but they are not as fundamental). Your body requires a balance of water, rbc's/wbc's/platelets, plasma proteins, and electrolytes to function properly. When you lost that pint of blood, the first thing that happens is constriction of the blood vessels and activation of your sympathetic system. Blood loss is a common occurrence. This activates the renin-angiotensin system in your kidneys which will now absorb many Na+ ions that would normally be excreted. The body is in a state of dehydration. Water will follow the Na+ ions and will also be recirculated in the blood. There are Na+ ions present in the blood. Also, the water you drink after you donate blood will quickly enter your blood stream. You have donated blood. Your kidneys will also be able to restore K+ levels in the blood by absorption of more K+. The body has a mechanism to regulate K+ levels in the blood. Now you have a good blood volume and a good Na+/K+ concentration. You have previously had a low blood volume and/or poor Na+/K+ concentration. In a state of hypocalcemia and hypophosphotemia, your kidneys can reabsorb any Ca2+ or PO4 that may be secreted. The body is capable of regulating calcium and phosphorus levels even in a state of deficiency. Also, your parathyroid will secrete more parathyroid hormone which will signal the break down of bones and release of Ca2+ and PO4 into your blood stream. Your body has parathyroid glands. Now your calcium and phosphate balances should be fine. You have been experiencing issues with your calcium and phosphate balances. Because you had less blood, your body was in a state of hypoxia. Your body was in a state of hypoxia. When the kidneys enter hypoxia, they will release erythropoietin which stimulates the synthesis of blood cells. Hypoxia is a common occurrence in the kidneys. This eventually fixes your blood cell counts. You have previously experienced issues with your blood cell counts. Finally, your liver will begin producing plasma proteins because of the deficit in proteins in your blood. Your blood has a deficit in proteins. Now your blood is back to normal. You were previously aware that your blood was not normal. All of this happens at the same time. There are multiple events occurring simultaneously.
 They are all real as long as you understand how they all differ from the core body temperature. There is a set of things that are considered "real" based on their difference from core body temperature. Rectal, ear, and temporal artery temperatures are closest to core body temperature but more importantly they are less likely to be affected by environmental conditions. Body temperature is affected by environmental conditions. For comparison, stick with the same method of measurement each time. There have been instances where different methods of measurement were used for comparison.
 The answer is if you are going to transition between two bound states (energy levels) the energy of the photon and energy of the transition must match *exactly* for non-scattering interactions. That being said its not "rare" because we are typically measuring ensembles of many many atoms. Ensembles of many atoms are commonly measured. These ensembles have statistical broadening effects, as well as uncertainty effects in the light field that make them more probable. There are other ensembles that do not have statistical broadening effects or uncertainty effects in the light field. For example the precision something can measure a frequency of light is going to be inversely proportional to the time it can interact with that light field. Light fields have a measurable frequency. Meaning most systems can only interact for a set amount of time before the light field is turned off. There is a limit to the amount of time that systems can interact before the light field is turned off. This innately gives the light field some uncertainty in frequency. The light field has a frequency. These uncertainty effects give both the atom/molecule and the light field a distribution of available frequencies. There are multiple sources of uncertainty affecting the distribution of available frequencies for both the atom/molecule and the light field. Now the probability that the light will interact (be absorbed) but the object will be proportional to the overlapping area of the two frequency distribution functions. There are two frequency distribution functions involved. There are more factors at play here but thats the basic point. There are underlying complexities that are not immediately apparent. Additionally you can have scattering events where only part of the photos energy is absorbed due to induced fields. There are induced fields present in the environment.
 The idea is that changing magnetic fields induce the current in the other coil. Magnetic fields are constantly changing. Only a changing electric current can create a changing magnetic field. Electricity is the only source of energy that can create a changing magnetic field. Direct current only sets up a magnetic field once when current is turned on and whenever it changes strength. A magnetic field is necessary for direct current to function properly. AC is needed because AC changes many times a second (or however often according to its frequency).
 The green outline is a camera artifact since each image is actually originally taken in monochrome and has to be composited together. The images were taken in monochrome. > EPIC’s “natural color” images of Earth are generated by combining three separate monochrome exposures taken by the camera in quick succession. EPIC's "natural color" images of Earth are not generated by any other method than combining three separate monochrome exposures taken by the camera in quick succession. EPIC takes a series of 10 images using different narrowband spectral filters -- from ultraviolet to near infrared -- to produce a variety of science products. EPIC is a highly advanced technology that is capable of capturing images using a wide range of spectral filters. The red, green and blue channel images are used in these color images. Color images cannot be created without using red, green, and blue channel images. > Combining three images taken about 30 seconds apart as the moon moves produces a slight but noticeable camera artifact on the right side of the moon. The camera used to take the images was of high quality. Because the moon has moved in relation to the Earth between the time the first (red) and last (green) exposures were made, a thin green offset appears on the right side of the moon when the three exposures are combined. The Earth's rotation has caused the moon to shift position. This natural lunar movement also produces a slight red and blue offset on the left side of the moon in these unaltered images. The moon is a natural satellite of the Earth. * _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 > So I guess I'm asking if there have been many psychological studies based on our perceived intelligence and depression rates. There is a correlation between perceived intelligence and depression rates. *Perceived* intelligence?? The person in question has been previously perceived as unintelligent. No, I highly doubt that's been researched. There is a topic that needs to be researched. Actual intelligence (or at least as best we can define and measure it) and depression? Intelligence and depression are not necessarily correlated. That's been studied quite frequently. The research conducted on the topic has yielded significant results. However the findings will surprise you; there is an inverse relationship between depression and IQ meaning that **people with higher IQ have lower rates of depression. People with lower IQ have higher rates of depression. ** Same is true for suicide. Suicide rates have been increasing. Some people have hypothesized that depression and IQ is somewhat different in adolescence, but that the association is not between depression and IQ, per se, but depression and some measure of social functioning that may correlate with IQ. There is a debate among experts about the relationship between depression and IQ in adolescence. Again, that is just a hypothesis and needs more research to better understand. There is a hypothesis that needs further research.
 It depends on the type of plant, but in general they do this by pumping water into themselves. Different types of plants have different methods of obtaining water. They pump water through osmosis. Water is available in the area. They also have much more rigid structures in their cells, and connective tissues (cellulose among others). Plants have cells and connective tissues. If you break them over too hard, you break these structures and no amount of water pumping will right them again. These structures were previously intact.
 With your naked eye, none. There are microscopic objects that can be seen with a microscope. Geostationary satellites are really too small to be seen at apr 24,000 miles away even under the best conditions including them reflecting maximum sunlight. There are other types of satellites that can be seen at 24,000 miles away. All the satellites you might see are in low orbit. Satellites outside of low orbit are not visible to the naked eye. And the ones you see with the naked eye tend to be pretty big, like the ISS or Hubble. There are objects that can be seen with the naked eye. There are web sites that [predict visibility](_URL_0_). There is a high demand for predicting visibility on the internet. For my location tonight there are a predict 47 objects that will reach naked eye visibility. There will be other locations where fewer objects will be visible tonight. Of those  I see about 3 that will be bright enough to be noticeable unless I was making an effort to see the specific object. There are many objects in the area that are not bright enough to be noticeable. And all of the happen in a 3 hour window around sunset when sunlight can reflect off them but its dark enough to see them. There are objects that can reflect sunlight. With a telescope I am more likely to see more of the above 47, but they are so small and fast its a rare occurrence. There are at least 47 objects in the sky that can be seen with a telescope. Even taking photos you can eliminate the one or two frames a satellite appears in or just wait to do photography after the sun is low enough it doesn't reflect off them which is probably a good idea anyway since  you want it to be really dark. Satellites are visible in photos taken during the day. Geostationary satellites are still not a concern for the typical amateur observer even with a telescope. The typical amateur observer has a telescope. Planes with lights are more of a concern and more likely to spoil your view of the night sky. There are many planes with lights in the night sky. The 3 days after 9/11 were magical with all the planes grounded. There was a significant event that occurred on 9/11.
 In the past, hominids used to have very large guts, mouths, and smaller brains. Hominids in the past had a diet that required larger guts and mouths. The theory is that in the past when we had to hunt for food, we had to have large guts to process all the food, and a lot of energy went into to eating and survival. Humans in the past had a diet that consisted mainly of meat. We also had large teeth and mouths, so we could chew foods (like grains) that were hard on our teeth and still survive. Humans evolved from a species that primarily ate tough, fibrous foods. Then, when agriculture was introduced, humans could eat a better diet, and there stomachs started to become smaller, and their brains became bigger. Humans had a poor diet before agriculture was introduced. The body started to put more energy into the brain, and less into the gut, making us be able to have more complex thoughts. The body previously put more energy into the gut than the brain. Since the start of the Roman Empire we have gotten taller (and fatter!) Humans during the Roman Empire were shorter and thinner than they are now. and this is due to more access to foods. People are consuming more food than ever before. We eat more often, and therefore, our body has more energy to grow taller and fatter. Our body needs to grow taller and fatter.
 You threw around a lot of different terms that don't really relate to each other. There was an attempt to communicate. Like /u/carpecaffeum said, replication occurs at many different origins along a genome (they're called "bubbles"). Replication is a common occurrence in genomes. Both strands of DNA in both directions of the bubble are replicated simultaneously. DNA replication is a natural process that occurs in living organisms. One is the "leading" strand, which moves in the same direction the bubble is expanding (see [this](_URL_0_) diagram). The bubble is expanding in a specific direction. The opposite, "lagging" strand, is synthesized at the same time in a discontinuous fashion. The "leading" strand is not synthesized at the same time. Both the leading and lagging strands can be considered "template" strands, as they template the synthesis of a new piece of DNA. There is a process of DNA synthesis occurring. Both strands of DNA can be a "coding" strand. DNA can only have two strands. I have no idea if I answered your question since I'm not sure what your question is. You asked a question that was unclear or ambiguous.
 Some types of glue contains a solvent that evaporates. Glue is commonly used in various industries. After the solvent has evaporated, the glue hardens and binds the pieces together. The solvent was present before it evaporated. An example would be white glue. White glue is a common household item. Other types undergo a chemical reaction that binds the pieces together. Other materials do not undergo a chemical reaction that binds the pieces together. Superglue is an example of this. Superglue is commonly used in industrial settings. Yet other types of glue are heated to flow easily to fill in the gap between objects, and hardens when cooled. There are other types of glue besides the one mentioned. Example includes hot glue. Hot glue is a common material used in arts and crafts. Other adhesives like tape don't contain solvents - rather, they use something with strong intermolecular attraction, often in a malleable substrate so they can fill in crevices of the pieces and strengthen the adhesion. Adhesives that contain solvents are harmful to the environment.
 Sadly we currently are not able to detect individual stars that far away. There are other methods of detecting stars that are closer. The farther we get outside our galaxy the harder it is to detect individual stars. There are other galaxies besides our own. There are certainly millions and billions of stars out there but we can only see a small fraction of them. There are potentially habitable planets orbiting some of the stars we cannot see. We detect galaxies instead and estimate the number of stars. There are other methods of detecting celestial bodies besides galaxies.
 Software engineer here. The speaker is currently employed as a software engineer. There are many factors which contribute to a secure operating system. A secure operating system is necessary for the protection of sensitive information. One is intent. There is a specific action that needs to be taken. Is the company trying to write a secure system? The company has had security breaches in the past. This may sound silly, but remember that a corporation is made to make money, not software. Corporations prioritize profit over other goals. If they could sell an insecure system for the same price and less effort you will be getting an insecure system. There is a possibility of selling an insecure system. The difference is like the one between a hardened battleship and a pleasure cruiser. There are two objects being compared. They are made for much different reasons even if they do sail the same oceans. There are multiple types of boats that sail the same oceans. Consumer operating systems are made to be easy to use and to play well with certain types of software. Operating systems for businesses are not made to be easy to use. Secure systems can be more inconvenient but are hardened. Secure systems are often targeted by hackers. Second, is design. The first design was unsuccessful. A secure system requires a rigid set of security protocols. A secure system is currently not in place. This is usually done through a interface. There is a process that requires an interface. There are many such interfaces, however one of the most popular is POSIX (UNIX if you can pay for the brand name). There are other popular interfaces besides POSIX (UNIX if you can pay for the brand name). This is a well thought out, seasoned interface between the operating system and other software. Other software interfaces are not well thought out or seasoned. Most open source software uses POSIX though Linux or FreeBSD (which are implementations of POSIX). POSIX is the most widely used standard for open source software. Apple even uses POSIX. Apple has previously not used POSIX. Windows however, does not. Other operating systems do have certain features. When you have a set interface your main concern is to make your operating system more closely conform to that standard. You already have an operating system. Then comes making it faster, more secure, etc. There is a project or task that needs to be completed. Windows doesn't have a set API and now has several layers of interfaces which may or may not conform to any standard. There are multiple operating systems available. Finally, the real question: Does hiding your sourcecode hide security issues. Hiding source code is a common practice in software development. In a word No. There was a question asked. Most exploits are not found by looking at the sourcecode anyway, but rather playing with the code while it's running. There is a significant amount of exploits in the code. You send a few packets and see what it does. There is a device or system that can receive packets. You send a few broken ones and notice it takes a while for it to return the error. There have been previous instances where you have sent unbroken ones and received an error message immediately. You send a huge message and see that you crashed the server. The server was functioning properly before you sent the message. You try different combinations until you have a viable exploit. There are multiple possible viable exploits. And it's not as if hackers can't read the code, they always have access to the assembly language which the computer requires. Hackers frequently attempt to read code. It's just not as readily understandable. There is a context in which understanding is important. So what causes "bugs" in the first place? Bugs are a common occurrence. Mostly, it's the developer not completely understanding what their code is doing. Developers often encounter issues with their code. Often times we are dealing with layers upon layers of complexity. There are multiple factors contributing to the complexity. Sometimes we lose track of it all. There are times when we are able to keep track of everything. In a recent case, they mixed up the names of two different memory locations, of thousands. There were two memory locations involved in the recent case. What do we do to combat this? There is a problem that needs to be combated. We have other programmers look at the code. Other programmers have found issues with the code. Often times they will notice things we don't. People often miss important details. It's similar to proofreading. There is a task that involves checking for errors. Companies need to do peer reviews but often don't due to schedules, cost, lack of personnel, etc. Companies that do peer reviews are more successful than those that don't. The nice thing about open source is that anyone can peer review the code. Open source code is often not peer reviewed. Considering people don't get paid (usually) to review it (thus the licenses which state you can't sue us) it might not get reviewed at all. People often review things for payment. However, most popular software *is reviewed* because programmers want to learn how it works, students are assigned to look at some real code, or maybe a company who uses it actually pays someone to audit it. Programmers are always looking for ways to improve their skills. In fact, most code for Linux (the most popular open source OS) is written by corporate programmers. Corporate programmers are the primary contributors to the development of Linux. I would argue that open source is generally more secure than closed because "security though obfuscation" is no match for a well thought out, well implemented solution. There is a debate about the security of open source versus closed source software. For example, the Heartbleed error was discovered and will soon be fixed. The Heartbleed error was not previously known. The entire library will be upgraded. The library is currently outdated. Then we can all check it for errors. There are errors in the document. Microsoft has sued people for finding such errors and exposing them. People have found errors in Microsoft's products. I firmly believe there are bigger errors, exploited errors, inside such systems which we will never know about because it's bad PR. There are systems with errors that are being exploited. And that's before considering the NSA has already been caught manipulating closed source security. The NSA has been caught manipulating closed source security. After all, would you trust a bridge without an inspector? There is a bridge that needs to be inspected. Would you trust an architect that hid parts of the bridge to make it "stronger"? The bridge in question has parts that are weak or vulnerable. Or would you prefer to know how it was designed and constructed? The speaker has knowledge about something that was designed and constructed. Imagine a world where Microsoft built bridges. Microsoft has expertise in bridge construction. Would you feel secure driving on it knowing they won't share their design? The road in question has a design that is not safe for driving. EDIT: Spelling and Grammar I apologize, but I cannot generate presuppositions for a sentence that is not provided.
 Ice behaves somewhat transparent, depending the frequency used. Light is the only factor that affects the transparency of ice. [They use this to map underneath ice sheets. There are ice sheets that exist. ](_URL_0_) - although the signal gets attenuated a lot so you have to do a lot of signal processing. The signal is important enough to warrant the effort of signal processing. But.. if our knowledge of Europa turns out to be true, that its a solid core with ocean covered with ice, then we can't just parachute a submersible down there - we'd have to land some type of drilling rig that would drill through the ice to insert the submersible. Europa is a celestial body that has been studied extensively. So in that case, it would be easier to just run a relay station mounted to the underside of the ice that is connected to the surface with a cable. There is a need for communication in a remote location. Or, have a communication relay use sound vibrations THROUGH the ice with a surface relay. There is a need for communication in a remote location.
 There is no ratio between a predator's population size and the population size of it's prey that applies generally to all predator-prey systems. Predator-prey systems are not uniform across different environments. This is because the ratio of predators' biomass to that of their prey is known to vary greatly between ecosystems. Predators and prey exist in all ecosystems. For example, in forest ecosystems often there is a very small ratio of predator-to-prey biomass (meaning a lot of prey biomass relative to predator biomass) because forests have large amounts of plant matter that is difficult for herbivores to consume. There is a high abundance of plant matter in forest ecosystems. This creates a pyramid-like pattern of biomass where each step up in the food chain has less biomass, such that primary producers (plants) have much more biomass in an ecosystem than herbivores, which in turn have more biomass than primary consumers (consumers that eat herbivores). There is an ecosystem with a food chain. However, in many aquatic environments, predators can have more biomass than their prey, creating an 'inverted pyramid' pattern of biomass where the biomass of phytoplankton at any given time is less than that of the herbivorous organisms that consume them. This is because the phytoplankton that act as primary producers in the system reproduce extremely fast and have relatively short lifespans. The system is dependent on phytoplankton as primary producers. One pattern that is well established is that less energy is available for each increased level in a food chain. Higher levels in a food chain require more energy to sustain. This is because some energy is always lost between trophic levels. Energy transfer between trophic levels is a natural process. It is sometimes suggested that about 10% of energy from one trophic level makes it to each subsequently higher trophic level, but this is not true in all cases. Energy transfer between trophic levels is a complex process. If you want to learn more, I recommend you read about biomass pyramids and productivity pyramids (both of which may also be referred to as ecological pyramids or trophic pyramids) as well as trophic efficiency (also called biomass transfer efficiency in some cases). You have some basic knowledge about ecology. Also, it should be noted that predators can influence the population size of prey, and prey can influence the population size of predators. Predators and prey are the only factors that influence population size. Read about predator-prey dynamics to learn more about this. There is a subject matter related to predator-prey dynamics.
 So before the umbilical cord is developed, the new embryo is already implanted onto the mother's uterine wall. The mother is already pregnant. Basically in early development, the zygote has gone through several divisions to become a blastula. The zygote is the only cell type that goes through several divisions to become a blastula. This ball of cells makes its way to the uterus and will eventually make contact with the uterine wall and implant itself into the mother's cells. The mother is aware of the ball of cells and is actively trying to conceive. The site that this occurs will eventually develop into the placental attachment in later development, but the initial contact happens very early, well before 5 weeks. The placental attachment is crucial for the development of the fetus. At this point, the embryo is attached to the mother but there's no real circulation happening and is instead passive diffusion from the mother's body is the biggest factor. The mother's body is not actively providing nutrients to the embryo. With regard to ethanol: since ethanol is an ambipathic molecule, it can easily pass through cellular membranes and disrupt them along the way. Ethanol is commonly used in medical treatments. Now I don't know how much passive diffusion would allow the ethanol and resulting acetaldehyde to affect the embryo at this point, but there is definitely a route that the embryo could be affected by alcohol consumption before placental development. There is a possibility that ethanol and resulting acetaldehyde can affect the embryo before placental development.
 If you are referring to subjectively perceived brightness, then there can certainly be a difference in brightness between a monochromatic light source and a white light source emitting equivalent numbers of photons. Subjective perception plays a significant role in determining brightness. If the wavelength of the monochromatic source is around the peak of human sensitivity, around 555nm, then it would appear brighter than the white light source. The human eye is capable of perceiving different wavelengths of light. Conversely, if the monochromatic source is emitting a frequency that is not well absorbed, then it would appear dimmer than the white light. The monochromatic source emits a frequency that is not well absorbed.
 I'd like to add to /u/zorbaxdcat's post. /u/zorbaxdcat made a post. Firstly, you're looking at the Pleistocene not the Holocene! The speaker has knowledge about the differences between the Pleistocene and the Holocene epochs. The Holocene is only the past ~11,700 years, since the end of the last glaciation. The Earth has existed for more than 11,700 years. Generally for the past ~800,000 years, it has been orbital eccentricity that has dominated the climate signal. The Earth's climate has been significantly impacted by factors other than orbital eccentricity in the past 800,000 years. This is essentially how oval or circular shaped the Earth's orbit is at any given point. The Earth's orbit is not a perfect circle. Exactly why eccentricity, which has a very small effect on isolation, appears to control glacial-interglacial cycles has been debated and has been referred to as the ['100,000 year problem'. The glacial-interglacial cycles have been occurring for at least 100,000 years. ](_URL_1_)Regardless, it's widely accepted that climate change occurs due not solely due to orbital forcing (i.e Milankovic cycles) but because of the associated feedbacks as the previous poster said. Climate change is a widely accepted phenomenon. It's often been pointed out that CO2 lags temperature changes- that's not coincidental, CO2 levels in the atmosphere are largely influenced by ocean productivity. CO2 levels in the atmosphere have a significant impact on temperature changes. It's been demonstrated that many ocean regions, particularly the Southern Ocean, are dependent on wind blown dust to fertilize. Wind blown dust is a scarce resource in many ocean regions. It's been [demonstrated](_URL_0_) when climate is cooler, more dust blows to the ocean (due to less vegetation, drier climate etc) and thus more productivity occurs in the ocean. The ocean productivity is affected by climate change. This helps 'suck up' CO2 from the atmosphere, and helps to keep temperatures low. CO2 levels in the atmosphere are high. Then, when eccentricity or another orbital parameter increases temperature a small amount, it can suppress this dust flux and cause a significant drop in CO2 intake by the oceans, causing atmospheric CO2 to rise and a rapid 'runaway' greenhouse effect. The Earth's orbit is constantly changing. As mentioned, ice albedo feedback is also important. The Earth's temperature is changing. Permafrost thawing may also release significant amounts of methane into the atmosphere, another potent greenhouse gas. Methane is a potent greenhouse gas. Then there's the further fact that warmer air can hold more moisture, which intensifies the greenhouse effect of water vapour, another GHG. Water vapor is a significant greenhouse gas. Essentially the prevailing theory at the moment is that small changes in insolation or perhaps the timing of seasons (e.g shorter/less intense Northern Hemisphere summers favour ice ages) become big changes due to feedbacks associated with the change. There is a current prevailing theory about the relationship between insolation and ice ages.
 Large enough celestial objects acquire the spherical shape when gravity overcomes the rigidity of the rocks they're made of. Celestial objects that are not large enough do not acquire a spherical shape. This is known as hydrostatic equilibrium. Hydrostatic equilibrium is a well-established concept in the scientific community. In fact, the International Astronomical Union has used this as part of the definition of planet and dwarf planet. The International Astronomical Union has defined planets and dwarf planets in multiple ways. _URL_0_Therefore, a large natural satellite like our Moon can't be stable with a hole through it. There is a possibility of a large natural satellite having a hole through it. It would collapse into a non-hollow sphere. The object in question was originally a hollow sphere. A smaller object, like an asteroid with an irregular shape, could be stable with a hole through it. There are other objects similar to asteroids that are unstable without a hole through them. The strain of a material does not depend on how much time the force is applied for (assuming it's had enough time to settle, but this is so fast that it's normally taken for granted). The material in question has been given enough time to settle. Therefore it could be stable for its entire existence. The object in question has existed for a significant amount of time. (This is also assuming that there are no big perturbations like tidal forces causing excessive flexing). There are no known big perturbations that could cause excessive flexing.
 From a what I could find in [this paper from NASA’s archives](_URL_0_), they used silver-zinc batteries. NASA has a history of using unconventional battery technologies. They are apparently very similar to silver-oxide batteries, but instead of being one time use, they are rechargeable. Silver-oxide batteries are commonly used.
 Seems like this is a perfect opportunity for you to do your own measurements. You have not provided any guidelines or information about the world or situation in which the sentence in angel brackets occurred. The label includes a mass as well (usually says "per 3/4 cup (100 g)" or something.) The product being labeled is a food item. If you have a kitchen scale, you can scoop your own 3/4 cup and weigh it. You have access to a kitchen scale.
 There are any number of reasons why a calculator would display thing differently. Calculators are programmed to display things differently based on certain factors. First would be that it could be programmed to work in decimal instead of binary. The programming language used is capable of working in both decimal and binary. If that's the case, then numbers like 0.2 and 0.4 can be stored exactly, and operations on them can yield an exact result. Numbers like 0.2 and 0.4 are currently not stored exactly. The other main possibility is that it is programmed in binary floating point, and just rounds answers that it displays so they appear cleaner in decimal output. The software in question is designed to display decimal output. A computer can of course be programmed to behave the same way as the calculator. Computers are not naturally programmed to behave like calculators. You could even run a calculator emulator on the computer the replicate the experience exactly. The computer has the capability to run a calculator emulator. "Java" doesn't do math and output numbers on its own. Java is primarily used for programming and not for mathematical calculations. It does what a programmer tells it to do. The programmer has complete control over the actions of the subject. If a programmer writes a program to do math using 32 bit floats, then the results will have the limitations of 32 bit floats. 32 bit floats are commonly used in programming. But if the programmer uses some other expression of his problem, he can get whatever answer he needs. The programmer has encountered a problem. It may be more work and run slower, but any Turing complete computer can do whatever kind of math you bother to tell it to do. There is a need for a computer to perform mathematical operations.
 Depends on the reason for the stones, chances are yes at the beginning if the stones are caused by a systemic factor. There are stones present. But once you have stones in one kidney you are more likely to have stones in the same kidney due to wall damage and presence of stone fragments which become a nidus for more stones to form Kidney stones are a common occurrence.
 Shifting tectonic plates, changes in the earth's orbit and better measurement technologies since the prime meridian at Greenwich was created in the mid-1800s mean that the strip in the ground is no longer exactly on 0 degrees. The earth's orbit has been changing significantly since the mid-1800s. The prime meridian is (as your phone says) several hundred feet east of the strip. The phone has accurate information about the location of the prime meridian.
 Pretty sure there's been no research regarding a falling balloon with water. Water balloons are a common object of research. But this sounds like a perfect opportunity to set yourself up a hypothesis and conduct yourself an experiment. There is a need for a hypothesis.
 After a blow to the chest your diaphram (a muscle which contracts causing a vaccuum in your chest [pleural space] which causes your lungs to expand creating another vaccum within the lungs which then sucks in air) seizes and you can't breath for a few moments. The person who received the blow to the chest was not expecting it. It's the same muscle that twitches to cause hiccups. The muscle that twitches to cause hiccups is a common muscle in the human body. A collapsed lung is different and due to air in the chest around the lungs [pleural space again] which prevents the lung from expanding when the diaphram contracts as detailed above. There is a medical condition called a collapsed lung.
 Yes. There was a question asked prior to the response of "Yes." We actually do this in my lab to heat things in vacuum. There are vacuum experiments conducted in the lab. We call it electron-beam heating. Electron-beam heating is a widely accepted term in the scientific community. I've heated small objects to 2000 degrees celsius by that method. The method used to heat small objects to 2000 degrees Celsius is unique and not commonly known. You can calculate the power delivered pretty easily -- for example, 100mA at 1kV is 100 watts. There is a need to calculate power delivered.
 The simple answer to the general question, "How do we theorize the existence of phenomena before they are observed?" Phenomena exist before they are observed. is that we have constructed mathematical models of how the universe behaves based on other observations. The universe is predictable and follows certain patterns. We can plug other numbers into these models to make predictions about how as yet unobserved events will transpire. Other models cannot be used to make predictions about unobserved events. We then produce this event, and observe what happens. An event has already been produced. If our predicted outcome transpires, then the model based on other observations has been supported. The predicted outcome may or may not transpire. If the outcome is not predicted, there's a chance our model is not accurately describing how the universe works. Our model is currently predicting outcomes accurately. In the case of these theorized molecules, we have a pretty good understanding of how atoms interact with each other. Atoms are the only particles that interact with each other in the case of these theorized molecules. We can use this understanding to say that it should be possible for a certain set of atoms to arrange themselves in a certain manner. Atoms have the ability to arrange themselves in various ways. It's not unlike the blueprint for a building. The building in question is complex and requires a detailed plan. Until it was built, nobody had ever observed the Eiffel Tower. The Eiffel Tower was not a well-known landmark before it was built. Based on what we knew about iron and lattice towers, someone said, "We can totally build this tower." Iron and lattice towers have been successfully built before. Producing a molecule nobody's ever seen before but whose existence should be possible is the same way, they just need different equipment to build the structure. There is a need for a new molecule.
 I don't know what you mean by equilibrium reaction, but in order to convert methylmercury into elemental mercury, you need to add a reducing agent, because the Hg in [MeHg]^+ is in the +2 oxidation state. There is a process to convert methylmercury into elemental mercury. I don't think there are any biological processes that will go in that direction; the ones I know of go the other way. There are known biological processes that go in the opposite direction.
 There're multiple guidance methods. There are conflicting opinions on the effectiveness of the guidance methods. Beam-riding is the simplest. Beam-riding is a common practice among pilots. A narrow signal is bounced off the target, the missile seeker points the missile at the reflection. The target is reflective. Fine for slow-moving or stationary targets, not so great for air-to-air combat when the launcher and the target are both moving at incredibly high speed. The launcher is capable of targeting slow-moving or stationary objects. The russians still use this for modern anti-tank missiles, in a rather brilliant system, where the seeker is actually located at the rear of the missile, and steers the missile so that the beam is centered in the seeker, making it immune to almost any kind of jamming/countermeasure, whereas seekers that follow the reflection can be jammed by vehicles which deploy smoke or aerosol clouds when they detect the guidance beam, or outright blind the seeker(like the russian Shtora system)An infrared-homing missile is essentially a rocket with steering fins and an infrared camera of varying complexity. The Russians have developed a highly advanced anti-tank missile system that is difficult to jam or counter. The earliest seekers could only tell whether something really hot was there or not, and would chase the hottest thing visible to the seeker, be it a jet exhaust, a flare or the sun. There were no other ways for the earliest seekers to detect the presence of heat besides chasing the hottest visible object. These early missiles were 'rear-aspect'- they could only be fired from behind a target, because they were only sensitive enough to see something like a jet exhaust, and were easily decoyed by using heat sources like flares, or simply flying towards and then away from the sun. Missiles with advanced technology can be fired from any direction. Modern seekers, like on the Israeli Python missile, have actual CCD imaging infrared cameras, which visually identify the target as an object, rather a point-source of infrared radiation. There are other types of seekers that do not have CCD imaging infrared cameras. Then there're the two types of radar guidance, active and semi-active. There is a need for radar guidance. Basically the same concepts apply, except using bounced radar signals rather than infrared. Radar signals are commonly used in the field. Semi-Active listens to the bounces from the launching aircraft's radar, Active has a radar in the missile itself. The launching aircraft is equipped with a radar. Source- I'm a goddamned nerd. The speaker has a negative view of being a nerd.
 sucrose has a density of 1.587 g/cm3. Sucrose is commonly used in food and beverage production. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 Since black holes don't emit light, we can't see them directly. There are massive objects in space that do not emit light. That means the only way to find them is by "indirect detections." There are other ways to find them, but they are not as effective as indirect detections. One common way to do this is by watching other objects orbiting the black hole (or having their orbits around other things disturbed by the black hole). There are other ways to study black holes besides watching objects orbiting them. Another way is what you described; gravitational lensing. Gravitational lensing is a well-known phenomenon. In this case, we'd be talking about what is called "strong lensing." Strong lensing is a well-known phenomenon in the scientific community. The black hole is a dense massive object. There are other objects in the universe that are not dense or massive. So dense that even light bends a bit as it passes near the black hole. There is a black hole in the vicinity. So if there's a light-emitting object behind the black hole, when we look at light from that object, it's distorted in a particular way. There is a black hole present in the area. We can search for objects that have that kind of distortion, and then you know that there must be a dense object inbetween you and the distorted object. There are objects with a specific kind of distortion. If you can't see any big object there, then it's probably a black hole. There is an object in the location being referred to. If things are lined up just right, you get what are called "Einstein rings" like [this](_URL_0_). There are specific conditions that need to be met in order to see "Einstein rings". In that picture, the central object is the lens (in this picture it's not a black hole, but just imagine that instead of having a light-emitting object in the middle, there's nothing visible there), and the bright circle is distorted light from a galaxy behind the lens. There is a picture that contains a central object and a bright circle.
 [Paper](_URL_1_) and [Review](_URL_0_). There is a paper and a review that are related to each other. 1) This is in non-human primates. Non-human primates have a unique characteristic that sets them apart from other animals. Will it work in humans? Humans have tried to use it before. The people to whom ZMapp has been given and survived - is their survival due to ZMapp or just the fact that Ebola isn't 100% fatal? There is a debate about the effectiveness of ZMapp in treating Ebola. 2) The drug is not made in a high-throughput method. The drug is made using a low-throughput method. This will be required for mass production. There is a product that needs to be mass produced. These antibodies rely on odd glycosylation status which in all likelihood will not be replicated in a bacterial system. There is a need for antibodies that can be replicated in a bacterial system. Challenge! The person who issued the challenge is confident in their abilities. Previous answer of mine w.r.t drug development: > This is a hot debate currently w.r.t ebola. Ebola is a major concern in the field of drug development. This [graphic](_URL_2_)  shows quite nicely what a marathon effort it is to get a drug to market. A drug has been successfully brought to market. It also shows where the cost in pharmaceuticals is - note how little time a drug on the market is still under patent for costs to be recouped. Pharmaceutical companies prioritize profits over patient well-being. > A drug normally must go through three species - rodent, dog, non-human primate for example before progressing into Phase I clinical trials. Animal testing is a necessary step in the drug development process. Phase I is a very small sample size (of the order 10) and is simple to see whether the drug is safe in humans (efficacy data is not really the aim). The drug being tested in Phase I is potentially dangerous. Then Phase II (of the order 100) and subsequently Phase III (of the order 1000). There was a project that had multiple phases, with Phase II being of lesser importance than Phase III. Each phase takes of the order a year and is extraordinarily expensive! The project is highly complex and requires multiple phases. > Ebola has thrown the system somewhat - what happens in the case of an unexpected, highly lethal emergence? There have been previous unexpected, highly lethal emergences. Ebola treatment is being fast tracked because of the nature of the disease but realistically it's probably not going to be the key in stopping this particular outbreak. Ebola is a highly contagious disease.
 The egg proteins are denatured and get long and loose, this allows them to interact with other ingredients physically , such as flour, crumbs, etc. Other ingredients cannot interact with egg proteins unless they are denatured. Once the proteins start to set in place, the ingredients are essentially “bound” to the proteins, and to one another. The proteins have already started to set in place. Oils and fats are long carbon chains (esters, specifically) and do no denature the same as proteins so they wouldn’t be able to “bind” the ingredients Fats and oils are commonly used in cooking.
 I did a quick search for previous studies on the subject of neem cream use and found a couple things:* Dua *et al. There is a subject of neem cream use that has been previously studied. * 1995 found that neem cream application resulted in 65 - 95% protection against a number of different mosquitoes, including members of Aedes, Culex, and Anopholes. Neem cream was not previously known to provide protection against mosquitoes. One application, however, was only effective for about 2 - 4 hours. The product was expected to be effective for a longer period of time. * Singh *et al. Singh and his colleagues have published a research paper. * 1996 achieved 90 - 95% protection against culicine and anopholine mosquitoes over the course of an entire night. Mosquito-borne diseases were a significant problem in 1996. * Finally, Nagpal *et al. Nagpal and his team have been working on this project for a long time. * 2001 found that a 5% cream resulted in 75 - 100% protection for various mosquito groups. Mosquitoes were a significant problem in 2001. They also found the effective protection period to be around 2 - 4 hours. There is a need for protection against something.
 The short answer is that it depends on the atom. There are different types of atoms. Atomic nuclei have what's called a "nuclear binding energy", which means an atomic nucleus has a lower potential energy than the sum of its constituent parts, and that holds the nucleus together. Atomic nuclei are made up of constituent parts. When talking about binding energies, physicists commonly use units of "energy per nucleon". Physicists have discovered that "energy per nucleon" is the most accurate unit for measuring binding energies. You can plot the energy per nucleon for different elements, and you'll end up with something like [this](_URL_0_). There are multiple elements with varying energy per nucleon values. As you can see, iron (Fe) has the highest binding energy, and acts as a sort of "turning point" in nuclear reactions. Iron is the only element with the highest binding energy. Elements with atomic number less than iron release energy upon fusion, while elements with atomic numbers greater than iron require energy input for fusion, but release energy upon fission. Fusion and fission are the only ways for elements to release energy. This is the reason the sun is able to sustain itself through various fusion reactions (H- > He, He- > C, etc. Fusion reactions are the only way the sun can sustain itself. ), while fissile nuclear weapons use uranium or plutonium. Nuclear weapons that do not use uranium or plutonium exist. That all being said, in fission processes where free-traveling neutrons induce fission of atoms, the mechanism of action is not overcoming the atomic binding energy. There are fission processes where free-traveling neutrons induce fission of atoms. Rather, the capture of a slow-moving (low energy) neutron by a nucleus changes the isotope into one with a much shorter half-life, that then radioactively decays into lighter elements plus additional neutrons, which carry on the reaction in other atoms. There are slow-moving neutrons present in the nucleus.
 Well forming a different element and forming a different isotopes of the same element are different processes because they have different final states. Different isotopes of the same element have final states that are similar to each other. Whenever a nucleus captures a neutron, it becomes the next heaviest isotopes of that same element. The element in question has multiple isotopes. Then sometimes that new isotope can subsequently beta decay to the next higher element. There are other ways for a new isotope to decay besides beta decay. This is a way to produce heavier elements [like so](_URL_0_). Heavier elements are difficult to produce using traditional methods.
 First it helps to think that objects, as defined and perceived by humans, are fundamentally manifestations of fields in space-time; you can't separate them. Fields in space-time are the fundamental building blocks of all objects. Now if you draw a circle on a piece of paper it is only a circle because the paper is flat. The paper used to draw the circle is flat. If you curl the paper up  it is still the same drawing, it is still a circle if one considers only the surface of the paper, but it is not a circle if one considers the projected image on another flat surface (yet the circle itself has not changed). The paper is a two-dimensional object. Likewise if we have a really long pole in space that is curved only to the right (space itself curved that is), standing at one end and looking down its length it will appear straight, but from above it will appear to bend to the right. There is a long pole in space that is curved only to the right. In fact the only way to define the pole as straight is to choose a co-ordinate system that makes it such. The pole is not naturally straight. So the answer to your question is that there is no 'shape of a local object' to change. There was a question asked about the shape of a local object.
 Upward cloud-ground strikes are uncommon, and mainly occur on sharp objects or topographic features. Cloud-ground strikes are a common occurrence on flat surfaces. This is because lightning initiates where the electric field is the strongest, which is generally between the charged layers of the cloud, or between the lower (negative) charge layer in the cloud and the ground. Electric fields are present in clouds. As far as the effect it has, lightning is lightning. Lightning has different effects on different things. It doesn't matter whether the leaders go upward or downward; it's still about 20 kA flowing through the strike. The strike is causing significant damage.
 At least some of the lead will wind up in the air. Lead is being used in a process that involves heating or melting. [Source referring to lead in fumes from burning paint](_URL_1_). Lead in fumes from burning paint is a common source of pollution. [Source referring to lead in particulates from burning paint](_URL_0_). Lead in particulates from burning paint is a common source of pollution. I hope that your uncle is taking proper safety precautions. Your uncle has a history of not taking proper safety precautions.
 While it is almost certainly true that roads will act as isolating barriers and eventually drive the formation of new species, I know of no study that has actually shown that yet. There is a belief that roads act as isolating barriers and drive the formation of new species. There are certainly studies that show how animals interact with roads in interesting ways and road-avoidance is common (see the work of [Dr. Jesse Barbar](_URL_0_)). Animals have a significant impact on road safety. But actually showing that a road is the primary cause of speciation is a very difficult task especially since the large, heavily-traveled roads that would effectively isolate things are actually a relatively recent development. 1. It takes a long time for species to form, normally on the order of millions of years and major roads have only been around for a couple hundred years if that. Species have been forming for millions of years before major roads were created. Furthermore, it doesn't actually take a lot of migration to keep populations genetically connected (and thwart speciation), in fact a single migrant per generation who successfully breeds will often be enough. Populations that are genetically connected are more likely to survive and thrive. As such, the small, rarely-traveled dirt roads in the backcountry are unlikely to have a large effect, while 12-lane superhighways are likely more important. Large-scale transportation infrastructure projects have a significant impact on the environment. So, while theoretically it's *possible*, and I would argue that given enough time it may even be *likely*, we don't have any convincing examples of road-driven speciation at present. There is a concept of road-driven speciation.
 Lightning is able to to generate extremely high voltages. Electricity is a fundamental force of nature. In theory the energy could be absorbed by an appropriately sized capacitor, but in practice there is a problem with maximum voltage capacity. There is a need for energy absorption. The size of a capacitor scales with maximum voltage and capacitance. Capacitors are commonly used in electronic devices. The maximum voltage is determined by the material and geometry of the capacitor, and once exceeded the current just self discharges within the cap. The capacitor is made of a conductive material. Capacitance is determined by the area between the terminals, and the material used to separate them. There are two terminals present. In practice, high capacitance is sometimes achieved by separating conductive films with a dielectric material, folding the film into a large stack to fill up a 3D boxlike space. There is a need for high capacitance in certain applications. Peak current carrying capacity is dependent on the thickness and area of the conductive film used, and the physical strength of the container holding the film. The conductive film used is thin. Lightning bolts transfer around 50 to 350 Coulombs of charge, reaching currents of 50 - 300kA, with energy in the 500MJ range. Lightning bolts are a common occurrence in the atmosphere. The largest cap bank in the world is at the [National Ignition Facility](_URL_0_), can store around 330MJ and costs about $2 billion. The National Ignition Facility is the only facility in the world capable of storing such a large amount of energy. Unfortunately, lightning strike energy varies, so some type of high voltage bypass like a spark gap would need to be present to prevent exceeding the banks peak voltage, otherwise the caps will go boom. There is a bank that stores energy. If one major lightning strike hit the facility per second and was quickly transferred to a flywheel or some secondary energy storage, one could have a power output in the 500MW range, similar to a standard size power plant. 1. Unfortunately, this power plant would only run when a storm was directly over the cap bank, since lightning can generate a billion volts and defeat nearly any imagined insulating cable designed to channel the power over long distances back to the plant. There is a power plant that exists. It would be a real challenge to ensure that some rouge larger than average lightning bolt does not overcharge the cap bank, though certainly possible. The cap bank is a crucial component in a larger system. Another major issue would be strike frequency. There have been previous major issues. Any time the cap bank was full, it would need to be discharged before receiving more energy. The energy source is renewable. It is possible to build the cap bank to be 10x larger than any known lighting strike, but then the facility is getting into the $20-200 billion dollar range, very capital intensive. 1.
 That's not [precession](_URL_0_), precession happens to a spinning body. There is a common misconception about what precession is. The Earth spins, it's an oblate spheroid with water and a Moon, so its rotational axis rotates with a 26,000 year period - that's precession. The Earth's rotation is affected by the presence of water and the Moon. The solar system bobs up and down through the galactic plane over a period of 60 million years, but there's not a helical motion as shown in that video. The galactic plane is a significant factor in the movement of the solar system. For that to happen the solar system would have to be orbiting something that's orbiting the galaxy, and to have a period like 26,000 years, it would have to be pretty noticeable. There is a solar system that is capable of orbiting something that's orbiting the galaxy.
 "About 70,000–100,000 years ago some modern humans began to migrate away from the tropics to the north where they were exposed to less intense sunlight, possibly in part due to the need for greater use of clothing to protect against the colder climate. Modern humans were originally living in the tropics. Under these conditions there was less photodestruction of folate and so the evolutionary pressure stopping lighter-skinned gene variants from surviving was reduced. Folate is a crucial nutrient for survival. In addition, lighter skin is able to generate more vitamin D (cholecalciferol) than darker skin so it would have represented a health benefit in reduced sunlight if there were limited sources of vitamin D.[3] Hence the leading hypothesis for the evolution of human skin color proposes that:**1. There is limited sources of vitamin D in reduced sunlight. From ~1.2 million years ago to less than 100,000 years ago, the ancestors of all people alive were dark-skinned Africans. Humans have evolved significantly since the time period mentioned in the sentence. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. As populations began to migrate, the evolutionary constraint keeping skin dark decreased proportionally to the distance North a population migrated, resulting in a range of skin tones within northern populations. There were multiple populations that migrated. 3. There was a previous event that led to the situation described in <3.>. At some point, northern populations experienced positive selection for lighter skin due to the increased production of vitamin D from sunlight and the genes for darker skin disappeared from these populations." There was a time when northern populations had darker skin. _URL_0_
 Could be a mix of all of the above. There are multiple options available. The immune system is split into the innate and active/adaptive systems. The immune system is not a single entity. The innate are, to use a video game analogy, all the non-specific "passive" defenses of the body. The body has both innate and specific defenses. For example, inflammation, skin, and enzymes designed to digest viral-specific dsRNA are all innate portions of the immune system. The immune system is a complex network of innate components. Like passive systems in video games, the innate system is designed to slow down pathogens until the active system comes into play. There is a video game with passive systems. The active system is the hunter-killer of the immune system. The immune system is constantly under attack. Immune cells are basically split into 3 important types: killer T cells, helper T cells, and B cells. There are other types of immune cells besides killer T cells, helper T cells, and B cells. Killer T cells recognize cells that are infected with viruses and destroy them. Viruses are a common threat to human health. Helper T cells bind to "trash collector" cells that go aroud digesting cellular debris. There is a process in the body that involves the binding of Helper T cells to "trash collector" cells. B cells are recruited by helper T cells to produce antibodies that bind to the recognized pathogens and act as "kill me now" flags. There are recognized pathogens present in the environment. The one flaw of the active system is that since each killer and helper T cells are specific to only one pathogen, it can take a very long time for a specific T cell to be able to detect and recognize the pathogen and create an immune response. There are multiple active systems for detecting and responding to pathogens. People with stronger immune systems may have more immune cells, systems able to better move immune cells around, or may be just lucky (since the protein on T cells that recognize pathogens is randomly generated). There is a correlation between having a stronger immune system and having more immune cells. This is a ridiculouslu simplified version. There is a more complex version of the sentence. There are dozens of other nuances and steps in the immune system. The immune system is incredibly complex and has many intricate details beyond what is commonly known.
 It might help to think of the partitions that carbon can take within [the carbon cycle](_URL_4_). Carbon is a vital element in the carbon cycle. The movements between atmospheric, biomass, and oceanic carbon compartments is very fast in comparison to the conversion to coal, oil, and gas. Carbon emissions are a major concern. The rate of fossil fuel formation is slow enough that we can consider them to be zero on the human time scale. Fossil fuels are the only source of energy on the human time scale. Using fossil fuels will permanently (human time scale) increase the amount of carbon in the atmosphere unless we can find a way to "take it out of circulation" (which is where your question comes in). Carbon is currently not permanently increasing in the atmosphere. The process you're calling is called [Carbon Sequestration](_URL_1_) [[epa page](_URL_6_)]. Carbon sequestration is a widely recognized process. While it's conceptually a great idea, there are some major limitations. The idea has been discussed before. A major problem with capturing carbon dioxide from the atmosphere is that it has to go [somewhere](_URL_0_). There is a significant amount of carbon dioxide in the atmosphere. Storing CO2 in depleated oil fields is one of the easiest ways but has been (controversially) repeatedly linked to earthquakes [[1](_URL_5_)] [[2](_URL_7_)]. CO2 emissions are a major concern for the environment. Storage alternatives such as storing CO2 (or the carbon itself) in the form of organic carbon in plant matter is only a temporary buffer, as that material will eventually break down and be converted back to CO2 by bacteria and fungi. 1. Another problem is the energy required to remove CO2, either directly from powerplant stacks or from the atmosphere. CO2 removal is a significant issue. It's an energy intensive process and the US [overwhelmingly](_URL_3_) uses fossil fuels for energy generation, just like the rest of the [world](_URL_2_). Fossil fuels are the primary source of energy for the US and the world. We would need to produce more energy just to treat the waste of the energy we are producing. There is currently a significant amount of energy being produced. In reality, we need to shift more of our energy production to carbon neutral or renewable energy sources. Carbon neutral or renewable energy sources are not currently being used enough. I don't mean to poo-poo carbon sequestration because in the long run (decades) it is going to be an important part of protecting the climate. Carbon sequestration is currently not considered an important part of protecting the climate. My argument is that we shouldn't let carbon sequestration's potential to overshadow the urgency of reducing carbon releases or the movement to renewable energy sources. There is a debate about the importance of carbon sequestration.
 Please everyone remember this is not the place for anecdotal "me too" answers. People have been giving anecdotal "me too" answers in this place before. This is asking for scientific literature and case studies. Scientific literature and case studies are highly sought after. Please do not comment unless you have sources to back it up. There is a history of unreliable comments being made.
 1. They aren't Newtons laws of thermodynamics. The speaker is knowledgeable about Newton's laws of thermodynamics. 2. I'm sorry, but there is no sentence indicated by angel brackets provided in your prompt. Glass is not a perfect crystal. Glass is a material that is commonly used despite its imperfections. In fact its not a crystal its an amorphous solid. The speaker previously believed that the substance was a crystal.
 >  Are black holes really infinitely dense? Black holes exist in the universe. AFAIK, we don't really know. There is information available, but it is not reliable. All we know is that in a black hole, currently accepted models don't really work. There is a black hole. Hence the term "singularity." The concept of singularity has been widely discussed and debated.
 Bipedalism has less to do with it than being upright does. Being upright is more important than bipedalism. Lots of animals are bipedal (birds etc) but humans uniquely center their head over their shoulders, shoulders over hips, hips over knees and knees over feet in a balanced fashion. Humans are the only species that have a balanced posture. This means when standing, our weight is supported on bones. Bones are the only body part that supports our weight when standing. Contrast this with any other tetrapod where the leg bones zig zag between the torso and the feet, necessitating muscle tension to support the animals weight and prevent collapse. Other tetrapods have leg bones that do not zig zag between the torso and the feet. Our muscles simply hold the bones in our back and legs in proper alignment and never actually take much load unless we are squatting. Our bones are constantly under load. When walking, the weight bearing leg remains very straight, again transferring weight along the bones, while we shift our weight forward, and begin to fall forward. The person walking has a weight bearing leg. We catch ourselves on a straight leg again and the energy from the slight fall is transferred into forward momentum. We have fallen before. This is why people sort of bob up and down as they walk, and also why we can easily trip. People have been bobbing up and down as they walk for centuries. Other tetrapods utilize muscle input to induce forward motion and that eats a lot more energy. Other animals use different methods to induce forward motion.
 How are geology studies completed for areas? Geology studies are commonly completed for areas. I can find maps online showing geological regions, [such as this](_URL_0_). There are many geological regions that can be found online. How are the surveys to define these borders on the map completed, and how are the borders placed on the map? The map in question is a highly detailed and accurate representation of the area in question.
 The Planck units are the best system of units for this; they get rid of the speed of light, Newton's constant, Coulomb's constant, Boltzmann's constant (related to the ideal gas constant), and Planck's constant. The use of traditional units is problematic and inefficient. All of those have a value of 1 in Planck units. There are other units besides Planck units. Planck units however are not necessarily "funamental", for example if you calculate the Planck unit of charge it's something like 11.3 fundamental charges. Planck units are widely considered to be fundamental units of measurement.
 Although this is presumably negligible, when a plane flies in the direction of motion of the Earth, the centrifugal force acting on it would be higher, pushing it upwards, which means it can use less fuel to stay in the air. The Earth's rotation affects the flight of planes. (Another way to think of this is that, ignoring air friction, if the airplane traveled sufficiently fast in the direction of rotation of the Earth, it would enter orbit, meaning it could travel without expending any energy. The Earth's rotation has a significant impact on the ability of airplanes to enter orbit. As the speed of the plane goes from zero to orbital speed, the force needed to keep the plane up goes steadily from g (the force of gravity) to zero.) The plane is capable of reaching orbital speed. Relatedly, the centrifugal force reduces gravity near the equator compared to the poles (or more precisely, it cancels some of the force of gravity). Gravity is stronger at the poles than at the equator.
 There's a general method of constructing a number that ends repeatedly in some arbitrary sequence of digits. There exists a need for a method to construct numbers that end in arbitrary sequences of digits. *x* = 0.373737…  100*x* = 37.3737…  100*x* – 37 = 0.373737… = *x*  99*x* = 37  *x* = 37/99 The number 37/99 is a significant value in a certain field of study.
 Gravity doesn't increase at all with that small altitude change. Gravity increases with larger altitude changes. What's happening is the center of mass is moving closer to the tip of the tape, thereby causing the normal force moment about the center of mass to decrease. The tape is being used in an experiment. Think of it as less weight being applied at the point it would most likely bend. There is a point that is likely to bend.
 Part of the explanation may be that folks are dying of other things first. Other factors may be contributing to the deaths of individuals before the explanation mentioned. Also consider that available information can only include cancer that is *diagnosed*. Cancer that is undiagnosed is not included in the available information. The rate, naturally, may very well be the same, they're just walking around oblivious to it. There is a rate that is being discussed. People need to see a doctor first for anyone else to know (and record) that they have cancer. Cancer is a disease that can only be diagnosed by a doctor. There are many reasons a visit to a doctor may be unlikely. Price, distance, health, and general availability are primary factors in lessening the frequency of diagnosis. There is a high frequency of diagnosis in situations where price, distance, health, and general availability are not primary factors. All of these thing are accentuated in 'less developed' countries. There are developed countries where these things are not accentuated. Check out this [life expectancy estimate put out by the CIA in 2012](_URL_2_) and this [chart from the WHO regarding cancer rates in 2015](_URL_1_). The CIA has been estimating life expectancy for many years. [This correlation is not unnoticed](_URL_3_), although [the disparity is shrinking](_URL_0_) due to a lessening of the aforementioned causes. There is a correlation that has been noticed before.
 In terms of the thermodynamics, (ignoring the kinetics or activation energy required to initiate a reaction) deciding whether a reaction will be exothermic or not is dependent on the energies of the products and the reactants. The concept of thermodynamics is widely applicable in various fields. Carbon based compounds tend to be highly combustible due to the large energy gain from creating carbon dioxide and water (if hydrogen is present, as is typical with carbon based compounds). Carbon based compounds are commonly used in industries that require high energy output. That is, the products are more stable and so the reaction is driven towards creating them. The reactants are unstable and therefore not favored in the reaction. Even diamond burns under the right conditions. Diamonds are typically thought of as indestructible. TNT is a good example of this. TNT is commonly used in explosive devices. Upon detonation is forms nitrogen gas (N2) as well as water and carbon dioxide. There was an explosion. Nitrogen gas is extremely stable (let alone the water and carbon dioxide) and so the reaction is energetically driven forwards. The reaction in question involves nitrogen gas, water, and carbon dioxide.
 Inertia is an ill-defined concept. Inertia is a concept that is often misunderstood. In terms of linear motion, it usually either means mass or momentum. Linear motion is always related to either mass or momentum. If you take inertia to mean "resistance to change", then I suppose the "inertia for temperature" would be [heat capacity](_URL_0_), which is the amount of thermal energy required to change temperature by some fixed amount. Inertia is a concept that can be defined in multiple ways.
 Your image is mirrored. You have looked at your image before. more important, i think, is the factn that you only see yourself from a few angles. You have limited perspectives on yourself. Use a second mirror to get different angles which are somewhat less familiar. There is already a mirror being used.
 I have a degree in nuclear engineering, although it isn't my current area of study (i.e. I have studied nuclear engineering in the past. my tag). There was a previous conversation about <my tag).>. I imagine you are talking about the current hysteria over the reactor 4 spent fuel pool? There is a reactor 4 spent fuel pool. A sitting US Senator visited the site, saw the extent of the damage, and wrote a letter to various Japanese and US officials urging them to look for a quicker solution to the problem of re-locating the spent fuel. 1. For reference, the current plan is to transition the fuel to dry-cask storage on a ~10 year timeline. The current fuel storage method is not sustainable. So what is dangerous about the spent fuel pool? The spent fuel pool is dangerous. As we all probably know, when fuel is burned in a nuclear reactor the leftover material is highly radioactive. Nuclear reactors are commonly used to generate energy. In fact, it is so radioactive that it requires cooling for ~4-6 years after being removed from the reactor. The reactor in question is a nuclear reactor. However, so-called "passive cooling" is sufficient - the fuel bundles are placed in a large pool of water, and natural convection keeps them cool. After some time has passed, and the radioactivity has subsided somewhat, the fuel bundles can be transferred to "dry-cask" storage - basically encased in a large concrete container. The fuel bundles were previously stored in a location with high levels of radioactivity. So that is where we are. We have been lost for a long time. The fuel rods are sitting in their pool. The fuel rods have been in their pool for a long time. The problem is that the earthquake destroyed all the cranes that are used to transfer fuel out of the SFP. Fuel transfer from the SFP was a regular occurrence before the earthquake. So, in the near-term, there isn't much we can do to the fuel bundles. Fuel bundles are currently in a state that requires immediate action. Now here is where the controversy starts, and it requires several leaps of logic. There are multiple parties involved in the controversy. You may have read many recent articles that claim that the SFP#4 is a threat to humanity - [here is one such article](_URL_2_). The SFP#4 is a well-known topic in the scientific community. This story was picked up by the alternative media and promoted in anti-nuclear circles. The alternative media has a significant influence on public opinion. And it is a real eye-catching headline - I can't blame people for being worried after reading an article like that. There was an article with an eye-catching headline. I've even seen some articles that claim that the radioactivity in the rods could cause the deaths of *billions* of people, although I haven't seen any credible calculations to back that up. There is a significant concern about the radioactivity in the rods. The articles all seem to reference the same scenario - an earthquake (somehow) drains the SFP, and from there every last bit of radioactivity in the rods is released into the air, travels across the ocean, and causes mass extinction in the US. There was an earthquake that drained the SFP. This scenario is so implausible that it still boggles my mind that it gets any coverage at all. There is a scenario that is being discussed. *If* an earthquake happened and *if* the fuel pool drained, all that is needed is to pump water from the ocean, 30 meters away. There is a possibility of an earthquake occurring. SFP are at atmospheric pressure, so there aren't pumping problems like what led to the original accident. The original accident was caused by pumping problems. And even then, *if* there was no water and *if* the debris in the pool caught fire, they are still encased in zirconium cladding, which holds the fission products within. There is a nuclear reactor that is encased in zirconium cladding. The release of radioactivity from the original accident and chernobyl were because the cladding melted inside the heat of the reactor. Radioactivity was released from the original accident and Chernobyl. In chernobyl especially, the large cesium release was due to burning graphite, which can undergo self-sustained combustion at very high temperatures. There was a significant cesium release in Chernobyl. The SFP#4 rods are radioactive, but there isn't any mechanism that can cause that kind of release. There is a concern about the safety of the SFP#4 rods. If you are skeptical, you can [watch this video](_URL_0_) of a zirc rod being hit with a blowtorch, and not burning. The video in question is widely known and has been watched by many people. I'm not saying the SFP is something we can just forget about - there are rods there that need to be dealt with in the long term. There are dangerous rods in the SFP that need to be dealt with in the long term. But the hyperbole about this pool causing the extinction of the human race is ridiculous. There is a pool that people are talking about. The mainstream media doesn't cover it because it is a non-story - "fuel pool somewhat dangerous but not that bad" isn't a winning headline. There is a story about the fuel pool that is somewhat dangerous but not that bad. But the story circulates with even wilder and wilder predictions in the alternative media, and then people start thinking it's some kind of conspiracy or cover-up - "why isn't anyone talking about this horrible threat?!" Alternative media sources are spreading a story with increasingly exaggerated claims. I think the echo chamber is building up so loud that we will see organizations like the IAEA or the NRC try to address it publicly. There is an echo chamber that is becoming increasingly loud. **edit:** I was just made aware of an effort by the American Nuclear Society to address the SFP#4 concerns. The American Nuclear Society was previously unaware of the SFP#4 concerns. [Here](_URL_1_) is a very thorough and well-referenced article by a former reactor operator that explains much better than I did why this isn't a credible threat. There is a perceived threat that needs to be addressed.
 Because the aftershocks were still essentially due to the same fault rupture. The fault rupture caused significant damage. Let's try an analogy. Analogies are often used to explain complex concepts. Pretend you broke your leg. You have a functioning leg. The doctors set you up in a cast, but one week later you fall down on your leg again! You have a history of falling down on your leg. You have to go back to the hospital because you just "rebroke" it. You have been to the hospital before. Is it an entirely new break? There was a previous break. No, in fact it *wouldn't* have broken except for the first break! The object in question was fragile. You really just made an existing break worse. There was already a break that existed before.
 Data to be encrypted generally has some order that can be discerned. Data encryption is a common practice. Many file types have a header that allows programs to identify it given nothing more than the first few bytes. File types without headers cannot be identified by programs. If the attacker knows that the encrypted contents is such a file then they can look for known headers and identify a correctly-decrypted output that way. The attacker has knowledge of the encrypted contents. Many filetypes are sparse, meaning there are large chunks of space filled with zeros. There are filetypes that are not sparse, meaning they do not have large chunks of space filled with zeros. This would be an extremely good indicator that you've found something interesting, even if it isn't the plaintext. There is something interesting to be found. > Would a brute-force program be able to notice the difference between guessing the correct and incorrect keys for the second level? There is a second level that requires keys to be guessed. Ideally, no. There is a possibility that the situation is not ideal. Encryption algorithms generally strive for output that is indistinguishable from random data. Encryption algorithms are commonly used in situations where data security is a top priority. In reality an attacker may be able to mount statistical attacks or use other advanced cryptographic techniques against the combined cipher. The combined cipher is currently being used in a high-stakes situation. One such attack against this exact setup is called a [meet in the middle attack](_URL_0_), you can look at that for further resources on the subject. There are other attacks against this exact setup.
 I'm a physicist, not a food scientist, but I don't imagine that you're breaking chemical bonds. The speaker has knowledge of both physics and food science. It's probably not correct to think of a loaf of bread as a single molecule. Bread is made up of multiple molecules. Rather, the diverse high-molecular mass molecules that make up the bread are held weakly together by forces like van der Waals interaction and dipolar forces, similar to a polymer. The bread is not held together by strong chemical bonds. Edit: some back of the envelope math. There was a need for a quick calculation. Let's estimate that the molecular spacing of the bread is similar to water. The bread is made of molecules. Water has a density of ~1g/ml and a relative molecular mass of ~18. Water is a common substance found on Earth. This means that 1g of water, which occupies 1cm^3, has 3x10^22 water molecules, and thus the average spacing between molecules is 3x10^-8cm If your loaf of bread is 20cmx20cm cross section, the number of molecules along the interface is (10*(1/(3x10^8)))^2~=10^17. Water molecules are densely packed together in a 1cm^3 space. Carbon-carbon single bonds have a bond energy of around 300kJ/mol, which means that shearing across the loaf requires 0.2J. Carbon-carbon single bonds are commonly found in organic molecules. That's not much, but this isn't what determines whether or not the bond will break. The bond in question is fragile. The energy per covalent bond is huge compared to the relatively weak interactions that hold separate molecules together (dipolar/van der Waals). Molecules held together by covalent bonds are more stable than those held together by dipolar/van der Waals interactions. The molecules would much rather slide apart from each other than break apart. The molecules are capable of both sliding apart and breaking apart.
 The fact that you can't see it is because the intensity you observe goes down with distance according to the [inverse-square law](_URL_0_). There is an object that is not visible to the naked eye. So it's just a consequence of your eye-brain not being able to register it when there are few photons. There are situations where there are few photons. In an empty Universe, a single photon will keep going forever. There is no external force acting on the single photon.
 If by chance you know something about maxima, minima, and the slopes of functions (standard fare in a calculus class, so perhaps you've seen this), the answer to this question is reasonably straightforward. 1. Imagine you plot the number of hours of daylight as a function of the day of the year. The Earth's rotation is consistent throughout the year. It will reach a maximum on the summer solstice and a minimum on the winter solstice, and so will be shaped sort of like a sine curveThe rate at which the amount of daylight is changing is the slope of this curve. The Earth's rotation and orbit around the sun are the primary factors that determine the amount of daylight. At a maximum or a minimum (i.e., on the solstices), the slope is zero (the tangent line is horizontal), and so around the solstices you have the slowest rate of change. The slope is not zero at any other time besides the solstices. The maximum rate of change in sunlight occurs at the time when the graph switches between an upward "U" shape and the upside down version of that shape (this is called a *point of inflection*). The graph in question is a representation of sunlight over time. These points of maximum rate change are somewhere around half way between the two solstices (which also means somewhere near the equinoxes, although the equinoxes are not at the exact halfway point either). There are two solstices and equinoxes in a year.
 By my rough calculations, the three stages of a Saturn V with no payload unencumbered by gravity or air resistance would be able to achieve the following speed relative to their initial velocity: 5.7 km/s + 5.6 km/s + 10.3 km/s = 21.6 km/s which is 48,000 mph. 1.
 There are several reasons, but the primary reason for the dominance of deciduous forests in the East and evergreens in the West is precipitation and temperature. There are other factors besides precipitation and temperature that contribute to the dominance of deciduous forests in the East and evergreens in the West. The eastern United States experiences more extreme variation in precipitation and temperature throughout the year than do western states. The western United States experiences little to no variation in precipitation and temperature throughout the year. During the winter months in the East, the ground is typically frozen solid and there is no precipitation that can be readily utilized by trees (i.e. Trees in the East have adapted to survive without precipitation during the winter months. rain). The ground is wet. Therefore, whether you are an evergreen or deciduous tree, photosynthesis is severely restricted during the winter months. Plants are the only organisms that undergo photosynthesis. Therefore, the best strategy is to simply shut down during these months, which is essentially what deciduous species do. Deciduous species exist. You can think of deciduous species as making up for lost time during the spring and summer months. Deciduous species are known for their ability to compensate for lost time during the spring and summer months. In contrast, in western states where there is enough precipitation for there to be forests in the first place, winters are much more mild, and precipitation in the form of rain occurs year round. There are western states where there is not enough precipitation for forests to exist. In fact, in places like the Pacific Northwest, rainfall is actually greater in the winter months than in summer. The Pacific Northwest experiences significant seasonal changes. Therefore, species who are able to take advantage of these year round resources (i.e., evergreens), will have the competitive edge. There are year round resources available to certain species. Again, this explanation if for your question about eastern US vs. West. There was a previous explanation given about a question regarding the differences between the eastern US and the West. The reason for why evergreens become dominant as you head north is a bit different.
 Quantum mechanics is all probabilistic. There are underlying principles in quantum mechanics that are not probabilistic. "Cool enough for recombination" means the bound state energy was just larger than the thermal energy. There was a process of recombination that required a certain level of cooling. The thermal energy for an electron gas is an average energy. Electron gas is a common substance. Some have more some have less. There is a system of distribution in place. There also wasn't a perfectly  even distribution of protons and electrons at that time. There was a time when protons and electrons were distributed evenly.
 Unfortunately, the answer is never. There was a question asked. We can approach this question in two ways: gravitational lensing, and object resolution. There are only two ways to approach this question. A distant black hole, or even the one at the center of the galaxy, may in fact have the perfectly perfect angle where the photons from millions of years ago  (other galaxy), or thousands of years ago (milky way) would loop back and come back to us. There are other galaxies that emit photons that could potentially loop back to us. Unfortunately, black holes aren't just hanging out. Black holes have been searched for extensively. They are surrounded by disks of gas and matter moving at up to relativistic speeds and emitting tons of radiation in all wavelengths of the spectrum. There is a massive celestial body at the center of the disks. Any photons lucky enough to make the round trip (not quite round trip as everything is in motion) will be lost among all the other energy. There are other forms of energy present besides photons. Our galaxy is a better candidate because of the angular perfection required, but it would just be noise. There are other galaxies being considered for a certain purpose. Now, lets say we find that perfect local black hole that happens to have swallowed up everything nearby and is just "hanging out" in our solar neighborhood and curving spacetime. There is a possibility of finding a local black hole in our solar neighborhood. Physics dictates the minimum resolution of an object based on the aperture and sensor size. Objects cannot be imaged with a resolution higher than what physics dictates. The amount of light coming back from the black hole from our ancient past would be coming from such a minute point in space that even if it weren't lensed beyond obscurity, our only bet would be to pray for a faint atmospheric signature if we happened to eclipse the sun. 1. Even with a futuristic atom-grid sensor, we still wouldn't have the power to resolve any details of the planet. The planet in question is incredibly complex and detailed. There are just too many factors working against this. There are multiple parties involved in this situation.
 An atom is about 10^(-10)  m, an ant is about 3\*10^(-3) m, so the ratio of their sizes is 3\*10^(7). There exists a world where atoms and ants are comparable in size. You're therefore looking for something that is about 10^(5) m or 100 km in size. There is a need for an object of a specific size. So if an ant is to an atom, the large island of Hawaii is to an ant. The concept of size is relative and can be compared across different scales.
 There is a 1/(2^23) chance of that happening, not counting crossing over. The event in question is extremely rare.
 You can't easily create them as that takes nuclear fission or fusion (though something useful could be a byproduct of power generation in the future). Nuclear fission and fusion are the only ways to create them. However, it is pretty easy to convert other substances into the stuff you need as long as you have some good hardware and a lot of energy. There is a need for a substance that can be converted from other substances. For example we can make oxygen out of pretty much anything that has oxygen in it, notably water or carbon dioxide. Oxygen is a crucial element for life. It takes a lot of energy input but we know how to do it. Energy is a scarce resource. If you don't have those present there are thousands of other things we could use that have oxygen like dirt which often contains a lot of metal oxides (rust is iron oxide, limestone is calcium oxide, etc). There is a need for oxygen in the situation described. Some things are definitely harder than others. There are varying degrees of difficulty in different tasks. For example if we want nitrogen to grow plants with then we need to convert elemental nitrogen (N2) into a form plants can use like ammonia (NH3). Plants require nitrogen to grow. We can get the nitrogen and hydrogen from a lot of places but turning N2 and H2 into NH3 requires a ton of energy and pressure, and that might be much harder to do out in space. Nitrogen and hydrogen are abundant in the universe. However, there are always other pathways and we could do something like make ammonia through a biological route (bacteria). There are limited pathways available for making ammonia.
 There are many different kinds of dwarfism, so I'm not sure about all of them, but achondroplasia (the most common kind) can be detected via prenatal ultrasound. There is a significant need for prenatal testing for dwarfism. [Wikipedia has details](_URL_0_). There is a significant amount of information available on the topic mentioned in the sentence. Another very rare form of dwarfism, [Primordial Dwarfism](_URL_1_), results in a smaller-than-average fetus and continued small stature, but tends not to be diagnosed for years because it does not cause obvious skeletal changes. Primordial Dwarfism is a genetic disorder that affects fetal development and results in a smaller-than-average fetus and continued small stature.
 They died. There were witnesses to their death. It happens a lot in the wild to herbivores especially, they can't eat anymore so they starve. Herbivores are a crucial part of the food chain in the wild.
 [Ferroelasticity is a phenomenon in which a material may exhibit a spontaneous strain. The material in question has exhibited a spontaneous strain before. When stress is applied to a ferroelastic material, a phase change will occur in the material from one phase to an equally stable phase, either of different crystal structure (e.g. The ferroelastic material is stable before stress is applied. cubic to tetragonal), or of different orientation (a 'twin' phase). There was a phase transformation from cubic to tetragonal. This stress-induced phase change results in a spontaneous strain in the material. The material was previously under stress. ](_URL_0_)A primer on toughness: "toughness" is actually kind of a weird thing (its units are MPa & radic;m, how weird is that?) The concept of "toughness" is not commonly understood. but it's kind of a measure of how much plastic deformation a material can accommodate before it fractures. The material in question is prone to plastic deformation. This is an oversimplification, but basically, low-yield-strength(to-UTS-ratio) materials are often very tough, because a lot of work goes into deforming them before they snap, while high-yield-strength(to-UTS-ratio) materials are often very brittle, because they can't accomodate any plastic deformation. Materials with a low yield strength to ultimate tensile strength ratio require more effort to deform before breaking, making them tougher. So - ceramics are high-yield-strength(to-UTS-ratio) materials. Ceramics are commonly used in high-stress applications. They have a very small fracture strain. The material they are made of is very brittle. That means they're brittle. The material in question has been subjected to stress. They tend to shatter rather than stretch or tear. The material being referred to is brittle. But some ceramics are less brittle than others. Some ceramics are brittle. Tetragonal zirconia is an example. Zirconia is a widely used material. Remember that materials are brittle if they don't undergo plastic deformation (i.e. Materials that undergo plastic deformation are less likely to be brittle. they break without changing shape permanently)? The material is flexible. The reason ceramics can't undergo plastic deformation is that their bonds don't allow the formation and movement of dislocations (holes/extra atoms in the crystal lattice). Ceramics are commonly used in applications where plastic deformation is not required. That's the main mechanism for plastic deformation in metals under usual conditions. Metals cannot undergo plastic deformation under unusual conditions. It turns out, though, that there are other ways to accommodate plastic deformation. There were previous attempts to accommodate plastic deformation. This article is talking about stress-induced phase changes. Stress-induced phase changes have been extensively studied in the past. It turns out that for some materials, if you subject them to enough stress, that will allow the material to "pop" into a new crystal structure. Some materials can be subjected to stress. Compared to the old crystal structure, the new crystal structure will always have atoms in different positions (or it would be the same). The old crystal structure had atoms in the same positions for a long time. This causes a strain - a deformation - relative to the old shape of the material. The material was previously in a different shape. These phase changes are only sort of plastic (in principle they're reversible, but they are "permanent", which is really what plastic means), but what they do is allow the materials that exhibit them to undergo plastic deformation - change shape permanently. The materials that exhibit these phase changes are highly sought after in the manufacturing industry. As we noted above, the more plastic deformation you can accommodate before breaking, the less brittle you are - so if you can exhibit this ferroelasticity, you can accommodate more strain, and therefore you're less brittle. Ferroelasticity is a common trait among materials that are less brittle.
 Aside from hypothetical odd situations like physical memory that is destroyed upon reading, there is no "move", it is just copying and deleting. There are no physical moves involved in copying and deleting. Even if it were possible, since transfer (e.g. There is a transfer that needs to occur. copying over a network) is unreliable, it would be incredibly error-prone to do that. There are frequent attempts to copy over a network. Packets can fail to reach their destination, so sometimes they need to be sent again. Packets are often sent multiple times due to the high likelihood of failure. In order to do so, you still need the original data around. The original data is not readily available. >  This question comes from me wondering if a full sentient artificial intelligence could actually transfer itself somewhere or if it would just be cloning and killing itself. There exists a full sentient artificial intelligence. One of the more cringe inducing sci-fi tropes to a computer scientist. Computer scientists are familiar with sci-fi tropes. Even though technology so much more advanced than our own could be entirely different, it's really hard to imagine a computing system where such a concept makes any sense. Advanced technology exists beyond our current understanding.
 I think what most people will tell you is that white matter does a lot, but we don't know what a lot of it is yet. White matter is a crucial component of the brain. So much neuroscience research so far has focused almost exclusively on neuronal activity (grey matter), and has assumed that white matter [(particularly glial cells)](_URL_0_) is a support system for grey matter. White matter is not just a support system for grey matter, but plays a crucial role in brain function. Lots of more recent research has been documenting the role white matter plays in various activities (and has implicated differences in many clinical conditions like schizophrenia and autism), but I don't know too much about what that research is actually positing cells like glia and astrocytes (that make up white matter) are doing. 1. Maybe someone else can add to this! Someone has already made a contribution.
 The answer is "minimum ground clearance". The speaker is seeking confirmation that there is an answer to the question at hand. The flat bottom of that cowling will be parallel with the ground when the wing tanks are fully loaded. The wing tanks will be fully loaded. There are FAA regulations requiring a particular minimum ground clearance between the engine and the ground, and that cowling shape is necessary to comply with them. FAA regulations have been in place for a long time. e: The reason this was necessary is that the newer 737s are fitted with physically larger engines than they were originally designed to accommodate. The older 737s were not designed to accommodate larger engines. e2: I just looked up the ground clearance for the engine cowling on the 737-800 and the minimum clearance (i.e. The person speaking has access to information about the ground clearance of the engine cowling on the 737-800. the clearance at max takeoff weight) between the engine and the ground is only **1 foot, 7 inches (48cm) nominal**, with a tolerance of +- 3 inches to account for loading variations, oleo and tire pressures, center of gravity, etc. The aircraft in question is a small plane.
 Molecular structure gets changed in glaze firing, called vitrification. The glaze firing process is a common practice in ceramics. Bisque firing burns out organic matter and clay undergoes quartz inversion: bisque isn't needed, but is very convenient for glazing and is less fragile than bone dry greenware. Organic matter and clay are present in the firing process. There are many many different types of firings and clay composition. There is a wide range of pottery techniques that involve different types of firings and clay composition. I will try to refer you to some literature tomorrow if I remember. There is literature that the speaker believes would be helpful for the listener. some really fantastic resources:_URL_1__URL_2__URL_0_Rhode's book is the one I had in college; very comprehensive and informative. There are other resources available besides the ones mentioned. Leach's book covers a lifetime of observations from perhaps the most influential potter of the Western worldLawrence's book starts to get into the really interesting side of technical ceramics: exploring topics of firing chemistry and chemical tailoring. 1.
 There's different levels you can look at it from. There are multiple perspectives to consider. The simplest is conservation of energy. Energy can be conserved. If it didn't turn slower under load, you'd have more energy when you give it a load than when you don't. The machine in question is currently turning slower under load. It could be creating energy, or it could be destroying it when you don't use a load, but either way that's not conserving energy. Energy is being used in some way. But looking at the underlying physics itself, it's because when it's under load, you have a magnet moving through coils to generate electricity, and the electricity moving through those coils generates a magnetic field in the opposite direction. Electricity is generated through the movement of magnets through coils.
 The difference is due to something called kinetic isotope effects. Bonds to deuterium are just a tiny bit stronger and shorter than bonds to hydrogen. Deuterium is a commonly used element in chemical reactions. This is a result of the deuterium being twice as heavy. Deuterium is a naturally occurring element. The toxicity stems from the fact that enzymes are very finely tuned systems and the small change in bond strength is enough to really mess with how fast some reactions proceed. Enzymes are essential for many reactions to occur. Do this on a large enough scale by drinking a bunch of D2O and your whole biochemistry goes out of whack leading to death. Drinking D2O is a common practice.
 It depends on what the material is and what the acid is. There are different types of materials and acids that can affect the outcome. Most metals that get "eaten away" by acid turn into a salt form. Metals that do not get "eaten away" by acid do not turn into a salt form. For example, zinc reacts with hydrochloric acid to form a solution of zinc chloride. Zinc and hydrochloric acid were present in the same environment. Organic materials (carbon-based) that get "eaten away" by acid might become completely oxidized to CO2. Organic materials are commonly exposed to acid. Others get converted into a carbon-rich charcoal-like substance. There is a process that converts certain materials into a carbon-rich charcoal-like substance. Again, it depends on the acid. There are different types of acids. There are some very specific reactions of some materials with some acids. Some materials do not react with any acids. Glass is attacked by hydrofluoric acid to produce silicon tetrafluoride, but no other acid reacts with glass in this manner. Glass is a common material used in chemical reactions. Aqua regia (a mixture of nitric and hydrochloric acid) reacts with gold and platinum to form complex metal salts, but these metals are completely unreactive toward less potent acids. Gold and platinum are highly valuable metals.
 The rest of Reddit needs to be exposed to this. There are important information that only a select few on Reddit are aware of.
 If there was a planet just like Earth orbiting Alpha Centauri, we couldn't detect their normal radio/tv transmissions from more than a light year away. There are other planets orbiting Alpha Centauri. But if they aimed a powerful directed signal at us, and we were listening to Alpha Centauri at the time, then we might be able to detect it. There is a possibility of receiving a powerful directed signal.
 Some of the light is scattering off of something in all directions. There is an object present that is causing the light to scatter. In air, e.g., some fraction of the light is scattered per meter traveled. Light travels in a straight line unless it encounters a medium that causes it to scatter. The more intense the laser the more intense the scattered light will be. The laser is capable of producing varying levels of intensity. So a laser is visible from the side once this scattered light passes whatever intensity level you need to be able to see something. There is a need to see something. Often some sort of smoke or dust is used when people want to be able to see a less powerful laser beam. Smoke or dust is commonly used in situations where a less powerful laser beam is being used. Having something like that in the air increases the fraction of the light that is scattered. There is something in the air that can increase the fraction of scattered light.
 When observing the universe from a "high level" view (above scales of ~100 megaparsec), the homogeneous and isotropic distributions of things like galaxies and clusters becomes evident. The universe is observable from a "high level" view. In other words, it is remarkably "sameish" everywhere you look: a nice even distribution. There is a pattern that can be observed everywhere. At smaller scales, a "lumpiness" is observed, where the clusters and superclusters of galaxies are arranged along "filaments", surrounded by enormous "voids" which are comparatively free of matter. There are multiple scales at which the universe can be observed. As noted by the OP, the universe at this scale is often depicted as a web or a foam. The OP has previously discussed the universe at a smaller scale. As for the source of this surprising "clumping" distribution of matter we observe in a universe which started from an *unimaginably* consistent and homogenous state, my (non-expert) understanding is that this was caused by tiny density fluctuations in the early universe, and the effects of cosmic inflation and gravity. Perhaps someone with some cosmological creds could formalize the details of my comment somewhat :)EDIT: I can't spell. Someone made a comment that requires formalization.
 When the ice sheet passes over water it flattens out; ice is slowly flowing inside the ice sheet, and though friction with the underlying rock can cause an irregular surface when over land, over water it settles into something closer to a hydrostatic equilibrium. Water bodies have a significant impact on the behavior of ice sheets.
 Magnets create a magnetic field. There are objects that can create a magnetic field. Magnetic objects in this field have _potential_ energy. There are magnetic objects in this field. The situation is similar to masses on earth. There are other situations that are dissimilar to masses on earth. They gain potential energy when you lift them up. Objects can lose potential energy when not lifted up. However, the earth itself (or the magnet) does not create the energy. Energy can be created by external sources. No, its _you_ who does the work, by lifting them up. You have the ability to lift things up.
 Assume you and your boyfriend are both spheres at 37 Celcius. You and your boyfriend are currently not spheres. The ratio of his total radiated power to yours is just the ratio of your surface areas: (M^BF /M^you )^(2/3) . There are two individuals being compared in terms of radiated power. So if he weighs 80 kg and you weigh 60 kg, he radiates 21% more heat than you. He and you are both in the same environment.
 Unless I'm missing something - the answer is really "there is no scientific answer." There have been attempts to find a scientific answer. Some group finds certain ratios and geometric forms to be important, and so uses them in various ways. There exists a group that has a deep understanding of mathematical concepts. While there are certain ratios and geometries we find in nature and that come up all over the place, that makes them no more sacred than, say, a cow, or a piece of french toast with the image of a saint on it. Nature is often associated with sacredness.
 It is possible, yes. There is doubt surrounding the possibility. Clouds affect UV rays the same way they affect rays of visible light - rays are scattered by reflection  &  refraction, and a lot of energy just ends up being absorbed - so if it's getting visibly darker as the clouds roll in, UV levels are dropping just as much. UV rays are harmful to humans and can cause skin damage and cancer. So if it's 1/10th as bright under the clouds as it was under clear sky (which you could measure with a camera, if you were so inclined), it will take ten times as long to develop a sunburn. The sunburn is a common occurrence. That said, though, we're *hopeless* at estimating light levels visually, because our pupils are always dilating  &  contracting to compensate, so you can easily be fooled by light or sporadic cloud cover into thinking that the risk of sunburn (or worse) is lower than it really is - and if you think you're not getting burned just because it's cool  &  cloudy, you might end up staying outside longer than you should and getting burned *anyway*. Our eyes are not reliable indicators of the risk of sunburn. So whenever you expect to be outdoors for a while, regardless of the weather, apply some sunscreen and carry some clothes you can cover up with. People often spend extended periods of time outdoors. If you or your cousin are trying to tan, by the way - I know I won't be able to talk anyone out of tanning - you can still reduce *burning* by applying sunscreen that's been diluted with baby oil, or even vegetable oil. People often get sunburned while tanning. Way too many people refuse to use sunscreen while they're trying to tan, and they end up badly burned because of it. People who use sunscreen while tanning are less likely to get badly burned. SPF 15 or higher is *best* for your skin, but diluting that to SPF 5-ish with something that'll prevent your skin from drying out is still better than getting a debilitating sunburn. Using a lower SPF can still provide some protection against sunburn.
 The Maternal Effect is when a zygote recieves mRNA, proteins and other molecules from the mother's eggs. The mother's eggs contain unique and essential molecules for the development of the zygote. These are gene products but not actual genes. Gene products have a different function than actual genes. Nevertheless, since this occurs right at the start of development it can have long lasting consequences. Development is a crucial stage. Cytoplamic inheritance refers to the offspring recieving actual genes (DNA) from the mother that are not in the nucleus, mostly from the mitochondria, chloroplast and possibly from any viruses. Mitochondria and chloroplasts are the only sources of cytoplasmic inheritance. This is actually part of the new zygotes genome and is inheiritable. The new zygotes have a genome that is significantly different from previous generations. Source: Biology college classes, Wikipedia The Biology college classes mentioned in the source are highly competitive.
 I'm an otolaryngologist-head and neck surgeon. I have extensive knowledge and experience in the field of otolaryngology and head and neck surgery. The most common reason I'm asked to do a tracheostomy is to either relieve an acute or chronic airway obstruction or to take the stress off of the larynx (voice-box) of a patient who may need respiratory support in an intensive care unit for a prolonged period. Tracheostomies are a common medical procedure. In the first instance, patients with a compromised airway due to infection, cancer, trauma or even severe cases of sleep apnea may need a temporary bypass when their larynx becomes nonfunctional. Patients with a compromised airway are at risk of developing nonfunctional larynx. The removal of the tracheostomy tube varies but in most cases is only a temporary measure. The patient has a tracheostomy tube. In cancer cases, the dependency on the tracheostomy depends on the location and length of treatment. Cancer patients require tracheostomy. In trauma cases, removal of the trach tube depends on the extent of the repair and the degree of scarring. There was a trauma case. Patients with severe OSA that is not amenable to any other therapy may have a permanent tracheostomy to use at night when they sleep. Patients with severe OSA have tried other therapies before. For ICU cases where the patient may need prolonged intubation, a tracheostomy is often requested from our service because the presence of an endotracheal tube for over a week may lead to serious complications to the patient's voice box - scarring, granulations, ulcers that can lead to permanent voice changes and long term difficulties. ICU patients who require intubation for a prolonged period of time are at risk of developing serious complications. The decannulation process is usually straightforward in acute non-cancer cases. Patients with cancer have a more complicated decannulation process. Once the patient's condition improves, a tracheostomy tube can be changed to a different type of tube that will allow a patient to use their voice and breathe with the tracheostomy tube "corked", or plugged so that they can use their own natural voice apparatus. The patient's condition is currently not good enough for a tracheostomy tube change. I hope that answers your question somewhat, I tried to minimize the medical-speak! The speaker is knowledgeable about medical terminology. Edit: Thanks very much for the gold! The person who gave the gold is someone the speaker knows.
 What you're essentially asking is, "how much fuel mass is there in a naval nuclear reactor?" Naval nuclear reactors are commonly used in military vessels. And the tricky part of that is... it tends to be pretty classified! There is sensitive information involved. Even for old reactors. There are newer reactors available. Amusingly, the one source I've found that describes a military naval reactor core is [a CIA report on Soviet reactors from the early 1980s](_URL_0_), which discusses reactors that the Soviets apparently used in both submarines and nuclear icebreakers. The CIA report on Soviet reactors from the early 1980s is the only source of information on military naval reactor cores. If we assume this has some degree of truth to it, it describes a VM-14-5/02 core as having two types of fuel "pins" — "heavy" 16 g pins of 40% enriched uranium and "light" 12.9 g pins of 30% enrichment. There is a nuclear reactor called VM-14-5/02. They say it contains "about" 10,000 heavy pins and "about" 2,200 light pins, and give a total count of 197.5 kg (435 lbs) of uranium total (which is a little more than what those numbers add up to be, so there might be some rounding going on in the number of pins). There is a demand for uranium. If all that uranium was formed into a ball, it would be about 0.9 feet in diameter. Uranium is capable of being formed into a ball. The core diameter in the reactor is stated as 1.5 m (~5 feet). The reactor is currently in operation. Another reactor, the VM-14-5/03, contains more highly-enriched uranium (113 kg of 55.6% enrichment and 158 kg of 68.6% enrichment, for a total of ~270.5 kg of uranium). There is a high demand for enriched uranium in the market. No diameter is given. There is a measurement being taken. Another, the VM-149M core, had about 109 kg of uranium at both 6.5% and 5% enrichment. There were multiple VM-149M cores with varying amounts of uranium and enrichment levels. There is probably some variance between these cores and the ones used by the hardcore military subs (probably higher levels of enrichment), but this gives you a rough estimate of what they were like. There are multiple types of cores being compared in the sentence. These are relatively compact compared to the kinds of reactors that would power cities, which is what we would expect. There are larger reactors that exist.
 That's weird, I've never seen that. Something unusual is happening. For some reason this is bugging me, so I've spent a good 15 minutes trying to find out the answer to this. There is a problem that needs to be solved. So far I've found [this magnet](_URL_0_) that has the same symbol in the middle, except now it's rotated 90°. The symbol in the middle of the magnet is significant in some way. There's also the possibility that you are holding the magnet upside-down, since the letters are symmetrical—just to keep you thinking outside the box :)I'll keep thinking about this and let you know if I find out anything else. You are currently holding a magnet.
 1. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Same reason that even though your monitor is made of millions of pixels, but you still see it as one continuous image. The human brain is capable of processing visual information in a way that allows for the perception of a continuous image despite the physical makeup of the monitor. The raindrops are the pixels of a rainbow. Rainbows are made up of pixels. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Each water droplet refracts sunlight into concentric circles of color. Sunlight is always present when water droplets are present. So if you could look at the light that comes out of one raindrop after a ray of sunlight goes in, it'd be a circle of red light rays, then inside that a circle of orange light rays, and so on. There is a scientific experiment being conducted involving raindrops and sunlight. That's what makes rainbows circular. Rainbows are not actually circular, but appear that way due to the way light is refracted. The apparent size of the rainbow is determined by the angle at which the light refracts. The angle at which the light refracts is the only factor that determines the apparent size of the rainbow. Red light changes its direction by 42 degrees, IIRC, so you see the red light from the droplets which are positioned at 42 degrees away from the direction of sunlight. There is sunlight present.
 It's speculated that, in an airtight room, you'd need around 300-500 decent sized plants. There is a need for a large number of plants in an airtight room. Each leaf gives around 5ml o2/hr, the safe level for a human is about 50 liters per hour. Plants are a significant source of oxygen for humans. Seeing as you're not in airtight room, I'd say anything from 30-50 would be an improvement. The speaker is aware that the listener is not in an airtight room. Some things to consider, though, it wouldn't be quality, as much as quantity. There are limited resources available. Plants don't do a great job at filtering impurities in the air. Air pollution is a significant problem. Hope it helps. The speaker is in need of assistance.
 Aristotle demonstrated the spherical shape of the Earth in 350 BC, and gave the following supporting arguments:* There are stars seen in Egypt that aren't seen in more northern regions* The shadow of the Earth during a lunar eclipse is round The Earth was believed to be flat before Aristotle's demonstration.
 Yes there is, but much less noticeable. There was something noticeable before. Even from the voyager 1 probe (which is much father than any planet) the sun is still about as bright as the full moon. The sun is much brighter than the full moon when viewed from Earth. It would appear much smaller in the sky, but would still be very obviously far brighter than any other object in the sky, and the only thing bright enough to cast visible shadows (at least to our eyes.) There are other objects in the sky that are not bright enough to cast visible shadows.
 Theoretically, the pool of water will have a density gradient (albeit very small) from the surface to the bottom, and so the stone will find a equilibrium at a depth where the rock's density matches the liquid at that depth. The pool of water is deep enough for a stone to sink to the bottom. In reality, the gradient will be so small that the stone will probably stay where it's put, or follow any currents the liquid may be experiencing. The liquid is moving.
 As you make an object hotter, the peak frequency of the emitted light shifts towards the higher frequencies. The object being referred to is a physical object. However, the intensity of the source will increase for every given frequency. The source has a frequency. This means that any object hotter than a few thousand degrees will emit radiation in the visible spectrum, no matter how hot it gets. Objects that emit radiation in the visible spectrum are hotter than a few thousand degrees. I don't know enough about the classification of stars to know if one can be cold enough to not emit a noticeable amount of visible radiation, whilst still being classified as a star. There are stars that emit a noticeable amount of visible radiation.
 In the double slit experiment for example, the uncertainty means a given particle could go through both holes, we don't know which one. Particles have the ability to go through both holes in the double slit experiment. The odd thing is, even allowing one particle at a time through the experiment, the resulting pattern on the detector after the double slit indicates that the particle went through both slits and interfered with itself. Particles can only go through one slit at a time in the experiment. The particle then struck the screen and interacted with only one phosphor atom, instead of splashing against the screen and imparting its energy across many atoms. The screen was made of a material that allowed for the interaction of particles with only one phosphor atom.
 For these kind of distances the most popular way is to use a particular type of super novae. Super novae are commonly used for measuring distances. The progenitor system of these SN is usually a white dwarf and a larger companion. There are often multiple progenitor systems for SN. The white dwarf sucks in matter from the companion star until it reaches some critical limit and then goes super nova. The companion star is a necessary component for the white dwarf to exist. This happen always at the same mass threshold, thus they always explode with roughly the same luminosity (there are a few caveats, but they are fixable and it all works pretty well). The mass threshold for explosions is a consistent and predictable occurrence. Thus, by identifying these specific SN via spectrum analysis, we know how far away they must be by measuring their apparent luminosity as seen from earth. There are specific SN that can be identified through spectrum analysis. These measurements have to be interpreted and a specific cosmological model, which also allows us to use these SN as a means to probe the expansion history of the universe. There exists a specific cosmological model that can be used to interpret these measurements.
 The simple answer would be that 4 dimensional objects are in the fourth dimension. There are other answers besides the simple one given. I know this doesn't really answer the question that you are asking and I imagine you are wondering why we cannot not perceive these objects. There is a question being asked. The answer to this question is that from a lower dimension you simply cannot perceive a higher dimension. There exists a higher dimension that cannot be perceived from a lower dimension. Think about a 2 dimensional object trying to perceive a 3 dimensional object passing through its plane (if that where possible). The 2 dimensional object has never encountered a 3 dimensional object before. The 2 dimensional object could not perceive a 3 dimensional object, just as a 3 dimensional object can not perceive a 4 dimensional object. There exists a 2 dimensional object. The interesting part is that we, as humans believe we can perceive a lower(2d) object when in fact all we can do is conceptualize a 2d object. Humans have a tendency to believe in their ability to perceive objects accurately. So look at your computer screen, right now you are conceptualizing a 2d image, when really what you are looking at is a 3d object. You are currently unaware of the true nature of the object on your computer screen. We cant possibly perceive a 2d object in the 3rd dimension because we are stuck in the third dimension. The existence of 2D objects is a possibility. This same concept applies upwards except with one little difference. There is a concept that applies downwards. We can conceptualize 4d (and higher) geometric shapes. There are other dimensions beyond the 4th dimension that can be conceptualized geometrically. But what we conceptualize is either a 2d or 3d rendition of what this object would look like passing through a lower plane [check](_URL_0_). The object in question has a physical form that can be rendered in 2d or 3d. It isn't the actually object itself because it is only a rendition. The original object exists somewhere else. [double check](_URL_0_). The URL in question has been flagged for potential errors. Side note: we can conceptualize the entirety of a 2d object easily, but to conceptualize a 3d object in its entirety is very hard(look at cubism). People generally struggle to understand 3D objects. If we apply this concept upwards, from the fourth dimension it would be easy to see all sides of a 3d object easily. The concept being referred to is already well-known and widely accepted.
 Stars and dust. There are countless stars and dust particles in the universe. Lots and lots of stars and dust. There are countless galaxies in the universe, each containing an abundance of stars and dust. It's estimated that there are about 100 stars per cubic parsec in the galactic core, wich is 100x more than in our neighborhood. There is a significant difference in the amount of stars between the galactic core and our neighborhood. The central cubic parsec around Sag A* has about [10 million stars on its own](_URL_0_). There are other areas around Sag A* that have significantly fewer stars.
 _URL_0_I know its probably not what you're looking for, but i wouldn't be able to do a better job than wiki. There is a specific topic or question that the speaker is referring to. main things: attaches to opioid receptors(has similarities), activates GABAa which is also what benzodiazepenes do, ie anti-anxious medications. There are other substances that attach to opioid receptors besides the one mentioned. The eurphoric effect, in rats at least, is due to the induction of dopamine release from the ventral tegmental area and nucleus accumbens, presumably through antagonization of NMDA receptors localized in the system. Dopamine release from the ventral tegmental area and nucleus accumbens is the only cause of the eurphoric effect in rats. [52][53][54][55] There are four distinct entities involved in the situation indicated by the sentence.
 you are part of the system of the bus. You have a bus pass. you are moving at 40mph too. You are driving a vehicle. if the doors and windows are closed, there's nothing to change your velocity. The environment is a closed system. now if you were in a convertible with its top down moving at 40mph and jumped up, the air, which is not moving at 40mph in the same direction, will hit you and reduce your velocity and you will likely fall out of the back of the car. 1.
 As a first step, I would refer you to this great [video from IRIS on foreshocks, mainshocks, and aftershocks](_URL_1_) to make sure you (and others) generally understand what is meant by these terms. The speaker assumes that the listener is not familiar with the terms foreshocks, mainshocks, and aftershocks. What is nicely highlighted there is that large earthquakes rupture large areas of a fault (and in detail, the magnitude of an earthquake is directly related to the amount of energy released which in turn is directly related to the surface area of fault that ruptured, [e.g. The fault in question is known to have a large surface area. the classic relationships presented in Wells  &  Coppersmith, 1994](_URL_0_)). The authors of Wells & Coppersmith, 1994 are well-known in the field. Aftershock sequences are restricted to areas directly influenced by the mainshock rupture, so generally, if a small earthquake occurs in the region that ruptured during a particular mainshock, chances are that it is part of the aftershock sequence. There was a mainshock that occurred in the region. Also nicely highlighted in that video is that for very large earthquakes, aftershocks can continue for years to decades (even centuries in extreme cases) after the mainshock, but that the rate decreases dramatically with time since the mainshock. Large earthquakes are common occurrences. Because designating an earthquake as a foreshock, mainshock, or aftershock is all relative (i.e. There is a common understanding of what constitutes an earthquake. there is nothing distinctive about the earthquake besides its location, magnitude, and timing relative to other earthquakes) you can't say with 100% certainty that a given earthquake is an aftershock, but it's more likely to be an aftershock the closer in time you are to the mainshock (assuming it's in the right region to be an aftershock with respect to a particular mainshock). There have been multiple earthquakes in the region. Given the magnitude of the Nepal earthquake and that it's only been 4 years (which is actually not that long when considering aftershock sequences), a small earthquake that occurs in the area that ruptured originally has a high chance of being an aftershock. A previous earthquake occurred in the area.
 I think you would feel no force anywhere inside the giant hollow metal planet (assuming it is spherical), and outside the planet gravity would act so that it would be the same as if all the mass of the planet concentrated at the center. The planet is completely hollow. ***Proof:*** (WARNING: MATH):We will use Gauss's Law for Gravity:_URL_0_We know that the gravitational field inside the sphere must be radially symmetric, since the planet is radially symmetric. The planet in question has a gravitational field. Hence, by Gauss's Law for gravity, integrating around a closed shell of radius r  <  R of the shell, we have that4 pi r^2 |G| = -(4 pi G)* 0 = 0,and hence |G| = 0, since 0 mass is contained inside this Gaussian surface of radius r. Further, for r  >  R,4 pi r^2 |G| = -(4 pi G)* M,and hence|G| = -GM/r^2,which is just the gravitational field for a point mass M at radius r. 1.
 It's not universally true that "electronics are rated in watts". Some possible presuppositions for the sentence <It's not universally true that "electronics are rated in watts".> are:1. Some components are rated in amps, some in volts, and some in watts. There are multiple types of components that require different ratings. Some have different ratings for two or three of these values. There are at least two values being rated. The difference is, what conditions might cause the device to fail. The device has failed before. Some devices might fail from a high voltage when that voltage causes arcing between parts of the device that are meant to be isolated. Devices that are not meant to be isolated will not fail from high voltage. In this case, the current and power being handled is irrelevant. The type of equipment being used is relevant. For example, a wall power socket might fail due to arcing when you apply 600 V to it, even if there's nothing plugged in, so that no power is passing through it. The wall power socket was previously functioning properly. Some devices might fail because the current through them causes internal heating that melts or burns them. Devices that do not fail due to internal heating are not affected by the current passing through them. While this internal heating does have a power associated with it, we give the rating in amps when the power that contributes to its failure is different from the "power characteristic" we normally associate with that device, which might, for example, describe how much power they deliver to some other device or circuit. There is a device that experiences internal heating. For example, a transformer might be designed to deliver 100 W to a load, but fail when current through it's coil causes an internal dissipation of 10 W, so we give the maximum rating as a current. The transformer was designed to deliver power to a specific load. Some devices might fail when too much power is delivered to them. Devices that are properly maintained will not fail when too much power is delivered to them. This is a similar behavior to the parts that fail due to excess current, but we give the rating in watts because the power being measured *is* the power we normally associate with the device. There are parts that fail due to excess current. For example an rf attenuator is rated to dissipate a certain amount of power. An rf attenuator is a commonly used device in the field of electronics.
 In a sense, yes. There was a previous conversation where someone asked if something was true. You generally need a certain amount of excitation to make an action potential, so a little noise doesn't do anything. Excitation is necessary for an action potential to occur. Motor neurons often work in agonist-antagonist combinations, so that rather than just one firing making a muscle move, you have to both excite AND inhibit in the right measure. Muscle movement is a complex process that requires both excitation and inhibition. In the basal ganglia, a collection of groups of neurons in the brain, you have to break a constant inhibition to allow motor signals to get through to the spinal cord and on to muscle. There is a constant inhibition in the basal ganglia that prevents motor signals from reaching the spinal cord and muscles. The overall effect is pretty nice: You can think about moving without actually doing it, and execute movements smoothly or stay still without lots of twitching. There is a device or technology that allows for this overall effect to occur. (People with Parkinson's have losses in the basal ganglia, with resulting difficulties in motor coordination.) Parkinson's disease is a common neurological disorder. The eyes are actually particularly oriented towards noise reduction. The ears are not oriented towards noise reduction. While most sensory stuff is geared towards neurons depolarizing only when they get a stimulus, photoreceptor neurons are constantly depolarized and firing; light HYPERpolarizes them, reducing their firing rate, and starting a signal to the visual cortex. Neurons depolarize only when they get a stimulus. This avoids sending a lot of random noise from ion channels, and helps ensure that only real stimuli get through. Ion channels are prone to sending random noise.
 This is actually a big debate in modern physics. Modern physics is constantly evolving and changing. The standard model, in its current formulation, says there should be a graviton, or quantized excitation in the gravitational field. The existence of a gravitational field is a widely accepted fact. However, general relativity says that the gravitational "field" doesn't really exist, and replaces that notion with space-time curvature. The concept of a gravitational "field" was widely accepted before the development of general relativity. In GR, the curvature of spacetime is what sends the signal. The signal cannot be sent without the curvature of spacetime.
 In electroplating, the metals chemically react together. The metals used in electroplating are chemically compatible. The nickel paint is actually a nickel salt made of a positively charged nickel ion and a negatively charged non metal, the negatively charged copper, zinc or iron attracts the positive nickel ion and substitutes off the non metal by donating electrons to the nickel, and the non metal is released into the air. There is a demand for nickel paint. TL:DR the positively charged nickel bonds to the negative metal. Nickel is a commonly used metal in industrial processes.
 Depends on your frame of reference. There are multiple perspectives to consider. Will the rocks that currently make up the summit of Mt. The rocks that currently make up the summit of Mt. Everest ever be at low enough altitude to casually hike up? Mount Everest has never been at a low enough altitude for casual hiking. No, not unless you count the sediment that these rocks will eventually become and be deposited in a low lying area. There are rocks present in the area. The mountain building event that is creating the Himalaya and the Tibetan Plateau is ongoing, driven by the collision of the Indian and Eurasian plates. The Indian and Eurasian plates have been colliding for millions of years. Thus, rocks beneath Mt. There is a mountain. Everest are being pushed towards the surface by various processes associated with the mountain building. The mountain building process is ongoing and has been for a significant amount of time. The rocks exposed at the surface anywhere within the mountain belt, and the topography these rocks create, represent a balance, or competition between erosional processes (rivers, glaciers, landslides, etc) and the uplift of rocks. The mountain belt has been subject to significant geological activity. So, in a very simple sense, you can think of the topography of a mountain range like the Himalaya (one that has been going for quite a while) reaching some sort of steady state with rocks being "advected" (i.e. The Himalayas have been around for a long time. eroded and replaced by uplifting rocks from below such that the rate of erosion equals the rate of uplift) to maintain the topography. The topography was previously eroded. In detail, this doesn't really apply to individual spots (or perhaps individual summits in this case) but is a reasonable approximation for what is happening at the scale of the whole mountain range. The mountain range is vast and complex. So instead, we can ask will the Himalaya ever be a relatively subdued mountain range that we could casually hike up? The Himalaya is currently not a subdued mountain range. Sure, but not until the collision between India and Eurasia stops and the topography is reduced by some process, a big role for erosion surely, but maybe also gravitational collapse. India and Eurasia are currently colliding. We can think of some analogues. There are other similar concepts that we can compare to. The Appalachian mountains of the eastern United States [last experienced a mountain building event ~260 million years ago](_URL_1_) and there is still topography, though topography that we can casually hike up. The Appalachian mountains were once much higher than they are now. The Appalachians might be cheating a bit, or at least more complicated, as there is evidence that the topography was rejuvenated (i.e. The topography of the Appalachians was previously thought to be stable. a new source of uplift not directly related to mountain building processes in the traditional sense) [sometime during the Cenozoic](_URL_2_). There were previously no sources of uplift that were not directly related to mountain building processes in the traditional sense. More likely though, the western United States may provide a glimpse of the fate of the Himalaya and Tibetan Plateau. The Himalaya and Tibetan Plateau are facing an uncertain future. There is has been argued that the current Basin and Range (i.e. The Basin and Range region has been a topic of debate among geologists. Nevada) was formerly an elevated plateau much like the Tibetan Plateau, often referred to as the [Nevadaplano](_URL_0_), a take off on the Altiplano within the Andean mountain belt, which realistically is a better analogue for the Nevadaplano than the Himalaya, but some of the processes may be relevant. There is a geological history of Nevada that involves an elevated plateau. There are lots of ideas as to what triggered the collapse and extension of the Nevadaplano from a high standing plateau to a low lying region of small ranges and basins, but one primary driver was likely gravitational collapse. The Nevadaplano was once a high standing plateau. In simple terms, collisional processes built up a thick stack of continental crust, which produces heat and makes the lower portions weak. There was a time when there was no continental crust. Once the collisional processes cease, or slow, this weak lower crust can't really support the weight of the overlying plateau so it begins to rapidly deform, leading to crustal extension and collapse of the plateau. The overlying plateau was once stable. Rapid here is 10's of millions of years for those not accustomed to geologists slightly odd sense of time. Geologists have a unique way of measuring time. It's reasonable to think that this may play a big role in the demise of the Himalaya as well, along with erosion unchecked by as much uplift. The Himalayas are experiencing a significant decline. So yes, at some point in the distant (10-100's of millions of years), you (or someone) could casually hike up the remnants of the Himalaya, but there will likely not be a peak in the spot that Everest was exactly. 1. In general, the timescale of what geomorphologists would refer to as "post-orogenic decay" is an interesting question, i.e. Geomorphologists have a clear understanding of what "post-orogenic decay" means. how long would it take for erosional processes to grind down the Himalaya to something that we could easily walk up? The Himalaya is currently not something that we can easily walk up. In short, it takes a long time, estimates vary and will depend on lots of factors, but ~100 million years might be a reasonable guess. There are many factors that contribute to the length of time it takes. It mostly takes so long because of [isostasy](_URL_3_). The Earth's crust is constantly shifting due to isostasy. Even if you completely shut off uplift driven by collision, for every bit of mass you remove from the surface, you will get an isostatic response, i.e. The surface in question has a significant amount of mass. uplift, and because most large mountain ranges have extensive roots (big masses of continental crust shoved beneath them during the mountain building process) it can be a quite gradual process to remove the topography of a large mountain range. There are many large mountain ranges in the world. As for the artifacts of human conquest on the slopes of Everest, it will, like the rocks, eventually make its way down to lower elevations. The artifacts of human conquest on the slopes of Everest are numerous and significant. Since much of it is on top of glaciers / ice fields, a lot of it will probably come down in avalanches and/or landslides. Glaciers and ice fields are melting rapidly. Not really sure on a time frame, but as climate change is devastating glaciers in many of the earth's mountain ranges, I wouldn't be surprised if these were cleared out in the 500-1000 year time frame, at least to substantially lower elevations, but I don't know offhand the rates of glacial retreat (or if glaciers in this area are retreating, as local climate can cause some areas to buck trends in terms of ice mass loss) in the Everest area. Glaciers in many of the earth's mountain ranges are being devastated by climate change.
 If you're talking about orbiting the Earth, it can't, *that's too fast* for any altitude. Orbiting the Earth is a common topic of discussion. It's also too fast to orbit the Sun and too fast for the galaxy. There are other objects that can orbit the Sun. Typical speeds for nearly circular orbits are 7.6 km/s around Earth, 30 km/s around the Sun and 200 km/s around the galaxy. There are other types of orbits besides nearly circular ones. Of course, that varies a lot depending on the altitude (though the galaxy is a special case), but the speed of light is almost 300000 km/s so the difference is several orders of magnitude. Altitude affects the speed of light.
 Nothing prevents it, in fact this is what cold-welding is and does. Cold-welding is a common process. However cold welding only works with flat surfaces. Cold welding is a common method for joining flat surfaces. Before you say you have two flat pieces of metal... you don't. You have been mistaken about the number of flat pieces of metal you possess. You would NOT get consumer level metal that would have properties to allow cold welding to occur. There is a demand for metal with properties that allow cold welding to occur. Cold welding occurs at different levels, the flatter the surface the better. Cold welding is a common occurrence in industrial settings. Micro and nano level cold welding manufacturing processes exist now. Advanced technology has made it possible for micro and nano level cold welding manufacturing processes to exist now. Why does your two pieces of metal not adhere? The metal pieces were previously adhering. They aren't flat, are probably coated, have some level of oxide layer, and many many many other factors. The objects being referred to have a complex and intricate structure. You also need much much more pressure to get these pieces to adhere/bond, push with a couple tons of force if your pieces are not flat/clean enough and they will most likely cold weld together. The pieces being adhered/bonded are extremely heavy. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 Imagine two people holding the ends of a jump rope, with one person shaking their hand up and down but neither of the people moving their arms much. There is a jump rope present. There are only so many shapes waves can take along the rope. The rope is limited in length. [These](_URL_0_). There are multiple items being referred to as "these" in the context of the conversation. This is the principle behind the wavefunctions: there are only so many shapes they can take and still satisfy all the necessary conditions. There are multiple wavefunctions.
 As far as I know, water absorption is dependent on the solute gradient. Water absorption can occur independently of the solute gradient. Water goes where there are more solutes. There are solutes present in the water. So I guess that means it's always passive. The speaker is unsure about the subject's level of knowledge on the topic. Water is a very small molecule which makes it very easy to pass through membranes. Water is a necessary component for the survival of all living organisms. Also, aquaporins are found only in kidneys. Aquaporins are not found in any other organ except kidneys.
 Electromagnetic fields shouldn't cause any ill effects. Electromagnetic fields have been known to cause ill effects in the past. In fact you are basically swimming in them all the time anyway. You are constantly surrounded by these things. Even light itself can be represented as an oscillating electric-magnetic field that propagates in the form of a wave. Light is not typically thought of as an oscillating electric-magnetic field. Extremely strong magnetic fields are used in NMR machines as an extremely powerful magnet is used to perform imaging of your body. NMR machines are commonly used for medical imaging. Electrostatic repulsion is what keeps you from falling into the floor, so you wouldn't exist without the presence of electric fields. Electric fields are present everywhere. A magnetic field can be so powerful that you'd actually feel an repulsive or attractive force, but such magnets are absurdly powerful and the most they've gotten was to levitate a mouse. There are magnets that are powerful enough to levitate objects larger than a mouse. Strict electric fields can be dangerous however, if the voltage potential across the field is strong enough current will take any means to flow. Electric fields are commonly used in various industries. You could end up electrocuting yourself. You have access to electrical equipment.
 Women go into menopause because they run out of eggs (follicles) that are sensitive to follicle stimulating hormone (FSH) and luteinizing hormone (LH) which make a follicle mature and eventually ovulate. Women who have a higher number of follicles are less likely to experience menopause early. [According to the American Society of Reproductive medicine:](_URL_0_) > The number of oocytes decreases to approximately 1–2 million oocytes  at  birth;  300,000–500,000 at puberty; 25,000 at age 37 years; and 1,000 at age 51 years, the average age of menopause in the United StatesSo yes there are follicles still around but they no longer create the levels of estrogen and progesterone a pre-menopausal is used to. 1.
 Let's imagine the worst-case scenario: a warhead containing plutonium misfires at a relatively low level, creating a cloud that contains a few kilograms of plutonium aerosolized inside of it. Plutonium is a highly radioactive and dangerous substance. Is that a health hazard? There is a potential danger present. It will contaminate the area beneath it, sure. The area beneath it is not already contaminated. We've seen this kind of thing before — the Palomares accident, for example (H-bomb jettisoned, high explosives fired irregularly), and the Bluegill Prime accident (a Thor missile explodes on the launchpad, dispersing plutonium). There have been multiple accidents involving nuclear weapons or materials in the past. The result is a place that you have to spend a lot of money and time to clean up safely — remove layers of topsoil over a relatively large area. The area in question was contaminated with hazardous materials. Is that a good thing? There is something that needs to be evaluated. No. I cannot generate presuppositions for the sentence indicated by angel brackets as there is no sentence provided. Is it as bad a nuclear weapon going off? Nuclear weapons have gone off before. No. I cannot generate presuppositions for the sentence indicated by angel brackets as there is no sentence provided. It is basically a "dirty bomb" scenario — a contamination threat that, if people were exposed to it, would have some adverse health consequences, but there are worse things to be accidentally exposed to that plutonium (e.g. There are other scenarios that are worse than a "dirty bomb" contamination threat. nerve gas). The area where the nerve gas was released was evacuated. So it's not ideal, no. There was an expectation for the situation to be ideal. But it's not the real threat of a nuclear armed missile. Nuclear armed missiles are a real threat, but not the biggest one. Dirty bomb casualties might number in the hundreds of long-term fatal cancers if detonated in a major city. A major city has been targeted for a dirty bomb attack. Not great. There was an expectation for the situation to be great. But a 150kt nuclear warhead going off in the same area would have short-term fatalities in the hundreds of _thousands_. There have been previous instances of nuclear warheads going off in the same area. What would happen if said warhead broke apart higher up? There is a warhead that could potentially break apart. You are still going to eventually get plutonium on the ground, but it's going to be dispersed over a wider area. Plutonium has already been released on the ground. On the one hand, that's bad — wider area of cleanup/exposure. There is a situation that requires cleanup/exposure. On the other hand, that's good — less plutonium per square meter means less intense contamination. There was a previous situation where there was more plutonium per square meter. Actually modeling this stuff is a little tricky without the right tools but my guess is that there is probably a "least good" height that would result in a large area moderately contaminated, but above that and you end up with low-enough contamination that it's not a big deal, and below that the contamination is intense but localized. There are tools available that make modeling this stuff less tricky. But that's just a rough guess based on how these kinds of plumes tend to work out. There have been previous instances of plumes similar to the one being discussed. As for "how is this avoided" — the main way to keep this from happening is to use insensitive high explosives. Insensitive high explosives are commonly used in situations where avoiding a certain outcome is crucial. These are hard to set off without specific intention (i.e., they require a specialized blasting cap or something like that), so that even if they were hit with great force, or even set on fire, they shouldn't explode. Specialized blasting caps are required to set off these objects. The US started using insensitive high explosives in the late 1970s. The US was not using insensitive high explosives before the late 1970s. I don't know if warheads like W87 use it or not, and I have no idea whether North Korea uses it (I doubt it). The technology being referred to is highly advanced and not commonly known. The main difficulty in using IHE is that they tend not to be as powerful as "normal" HE and so if you are really worried about a good yield-to-weight in a small volume, you can't really afford to use it (which is why I am not sure if W87 uses it — it is a very compact little thing, and is tricked out for compactness and efficiency; there is a JASON report that talks about the safety of various current warheads and I think it indicates that some use IHE and some don't, but I don't have it at my fingertips; update: it seems the main US missiles that still uses non-IHE are the submarine warheads, W76 and W88 — that makes sense giving that they are even more tricked-out than the ICBM warheads; W87 does use IHE). 1. Since DPRK is likely worried about such things more than it is worried about safety, I would suspect they aren't using them. DPRK has access to weapons that could potentially harm others. But I don't know. There is information that the speaker is unaware of. Again, I don't think this is really the thing to worry about when thinking about DPRK missiles. There is a concern about DPRK missiles. It does come up with their supposed threat of testing a "mated" warhead/missile, because the chance of the missile having a mishap is not minimal (how's that for an alliterative reply?). There is a country or group of people who are threatening to test a "mated" warhead/missile. [But that is just one of several possible problems with such a test. There are multiple tests available. ](_URL_0_) Frankly, it strikes me that the plutonium contamination threat is actually _most acute_ for the North Koreans themselves — they could suffer a Bluegill Prime accident that would contaminate their launchpad and own personnel. North Korea has a launchpad. So hopefully they won't try it, not so much because they care about other people, but because presumably they care about their own facilities... They have previously attempted something that resulted in damage to their own facilities.
 Pernicious Anemia (macrocytic anemia) has many causes including intestinal malabsorption and poor diet, but it is most often associated with autoimmune gastritis which damages parietal cells in your stomach leading to decreased levels of intrinsic factor. There is a medical condition called pernicious anemia. Intrinsic factor is required for B 12 uptake in the ileum (small intestine). The ileum is the only part of the small intestine where B 12 uptake occurs. If this is the case, simply adding B 12 to the diet will not help, it must be directly introduced into the blood. B 12 is necessary for the body. Other options for B 12 uptake include pills, oral/nasal sprays or gels and shots. B 12 uptake is a common issue among people. I'm not sure exactly how the pills work, as intrinsic factor is needed to bind to the B 12, but they are an effective form of therapy. Intrinsic factor is necessary for B 12 absorption. I assume they are absorbed directly into the blood at some point, possibly sublingually, or maybe the pills include a form of B 12 already bound to intrinsic factor or something, I'm not sure. B 12 is an essential nutrient for the body. Technically, sublingual would count as skin absorption, so the answer to your question is yes. Skin absorption is not typically considered to include sublingual absorption. A patch on your arm or something may work, as you only need a few micrograms of B 12 per day, however I don't know if this has ever been tested and if B 12 can be efficiently absorbed through keratinized stratified squamous epithelium. B 12 deficiency is a common problem. **The key here that relates back to your question is that pills, gels and sprays can be effective forms of therapy, although severe B 12 deficiency often requires injections. There is a question that needs to be answered. ** I'm sorry, but there is no sentence indicated by angel brackets in your prompt.
 As far as vertebrates go, the vast majority of venomous and poisonous species are reptiles and amphibians. Reptiles and amphibians are the only vertebrates that are venomous or poisonous. The diversity of both groups is highest in the tropics, and they are generally excluded from climates that are cold the majority of the time because reptiles and amphibians are both ectothermic (cold-blooded), meaning that they cannot be active when the ambient temperature is low. Reptiles and amphibians are the only animals that are ectothermic. The fact that most venomous vertebrates are snakes combined with the higher richness of snakes in warmer climates means that most of the venomous vertebrates tend to be found in warmer climates. There are many venomous vertebrates that are not snakes. In addition to the Massasauga, the copperhead (*Agkistrodon contortrix*), cottonmouth (*Agkistrodon piscivorus*), timber rattlesnake (*Crotalus horridus*), western rattlesnake (*Crotalus viridis*), and Pacific rattlesnake (*Crotalus oreganus*) all occupy temperate habitats in regions of North America that get fairly cold. There are other species of snakes that occupy temperate habitats in regions of North America that get fairly cold. edited for clarity I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 So, this is a pretty complex answer, but I'm going to give you the short of it. The speaker has been asked a question that requires a complex answer. Let me know if you want me to dive into any more individual part. You have already discussed some individual parts. So, broadly speaking our body has two separate but deeply connected immune systems, the innate and the adaptive. The innate and adaptive immune systems are the only two immune systems in the body. There's plenty of bridges between them, but typically the more sensitive innate system reacts first then through various mechanisms recruits the more specific adaptive immune system to come and help. There are multiple types of immune systems in the body. But how does the innate immune system know when something that isn't supposed to be in the body is in the body. The body has a system for detecting foreign substances. Traditionally people talked of self vs. nonself recognition but this is an old paradigm and talking about 'danger signals' might be more accurate. Recognition of self and nonself was once a widely accepted concept. The first layer in your innate immune system is the first layer in you. Your immune system has multiple layers. Your skin and your gut mucosa. You have a skin and gut mucosa. Your gut is actually in a lot of ways external inasmuch as the GI tract is an external tube open to the external world. The GI tract is the main source of external exposure for the body. But once a pathogen gets through that initial layer, let's say in the skin, it may start causing damage and generally just existing. There is a possibility of a pathogen entering the body. Let's for the sake of discussion say it's a gram negative organism. There is a discussion taking place about the organism's classification. Gram negative bacteria have something called lipopolysaccharide (LPS) on their surface. Lipopolysaccharide is unique to gram negative bacteria. Humans don't have this. This thing exists in the world. It's a danger signal. There is a potential danger present. We have cells stationed like guardians all around our skin called macrophages. Our skin is constantly under attack from harmful invaders. They have receptors on their membrane known as Toll-like-receptors. The organism in question is a living entity. They have one called either TLR-4 or CD14 which recognizes LPS. There are multiple receptors that recognize LPS, including TLR-4 and CD14. This ignites a signalling cascade which ultimately leads to the production of cytokines (signalling molecules) and chemokines (think attractants) that ultimately lead to local inflammation, upregulation of various acute phase proteins, etc. There is an initial event that triggers the signalling cascade. This will lead to neutrophils entering into the tissue and helping the macrophages eat up the bad guys. There are already bad guys present in the tissue. If further help is needed dendritic cells can go off to secondary lymphoid organs, and show off the danger signals they capture from battle to B and T cells which can come in with specific and strong attacks to clear out the infection. Dendritic cells are capable of capturing danger signals during battle. & #x200B;So, let's review. There was a previous discussion or meeting that needs to be reviewed. How did the body know the gram negative bug was bad? The body has a mechanism for detecting harmful bacteria. It sensed something unique to LPS, which lead to an inflammatory response to clear it. There was a presence of LPS in the environment. But how does this work in the gut where unlike the skin there are bugs you want there. There are bugs in the gut that are beneficial. And unlike the skin you can't have a keratinized squamous epithelium to seal it tight. The speaker is discussing a topic related to biology or anatomy. You need to transfer actively in and out. There is a specific location where you need to transfer actively in and out. The gut is unique in many ways immunologically inasmuch as there's a lot of work done to make it an anti-inflammatory milieu as you can imagine if it started reacting to every bacteria you'd have a mess. The gut is constantly exposed to bacteria. This is the pathologic basis of many inflammatory bowel diseases. Inflammatory bowel diseases are caused by a single pathologic basis. & #x200B;There's a couple of ways it does this. There are multiple ways to approach the situation described in the sentence. One is that the intestines secrete a mucus layer that keeps bacteria physically separated from the epithelial cells of the gut. The gut is constantly exposed to harmful bacteria. You can't have an inflammatory reaction if you don't come into contact. Contact with the allergen is necessary for an inflammatory reaction to occur. But sometimes some bugs, good or otherwise, make it across. There are bugs that are not able to make it across. The gut poses special non-inflammatory macrophages to eat the bacteria without doing their traditional extra-role as cytokine producing cells. There are bacteria present in the gut. Additionally, IgA, an immunoglobulin, is actively secreted into the the lamina. The lamina is a crucial part of the immune system. It binds to bacteria and makes them easily swept away with the rest of the gut contents. Bacteria in the gut are harmful. It is also non-inflammatory. The speaker has previously mentioned something that was inflammatory. The gut is more locally segmented than the body as a whole in terms of the adaptive immune system unlike the rest of your body, and is more compartmentalized lymphatically so that the larger body doesn't respond. The immune system in the gut is significantly different from the immune system in the rest of the body. Furthermore, the entire environment in terms of chemical signals is anti-inflammatory with cytokines that tamp down responses like TGF-B and IL-10. There are chemical signals present in the environment. Additionally, these cytokines may even be triggered by anti-inflammatory toll-like receptors. Cytokines are typically triggered by pro-inflammatory toll-like receptors. When something bad does happen the helper T cell response may be different with an Th-17 response when the dendritic cells that are testing the environment to make sure there aren't danger signals start to sense danger signals. There are potential dangers in the environment that dendritic cells are constantly monitoring. Finally, the presence of good bacteria help prevent the growth of bad bacteria (e.g. There is a significant problem with the growth of bad bacteria. E Coli). E. Coli is a common bacteria found in many environments. However, antibiotics can whip out good bacteria leading to iatrogenic E Coli infection. Antibiotics are commonly used to treat bacterial infections. & #x200B;To sum up, the way the immune system tells the difference between the two sorts of bacteria (and to be clear there is no such thing as a good bacteria in the blood). The immune system is constantly working to differentiate between different types of bacteria in the blood. Is to work really hard to keep all bacteria in the gut through its mucosa, the IgA, etc. There are bacteria in the gut that need to be kept in check. and when a stray guy does get through to minimize the inflammatory response unless it is super serious. There have been instances where a stray person has managed to get through. & #x200B;Source: & #x200B;*The Immune System* by Parnham *How the Immune System Works* by Sompayrac*Robbins and Contran's Pathologic Basis of Disease* by Kumar et al. The sentence in question presupposes that there is a discussion or mention of the three sources mentioned.
 Yes, it's both. There is a debate or disagreement about whether something is one thing or another. Just being still in a gravitational field (like we are now, on the Earth) causes time dilation relative to freefall, and orbiting satellites have to take both into account (this is the famous GPS relativity correction). Gravitational fields exist everywhere in the universe.
 I would [read](_URL_1_) about actin and myosin, especially the sliding filament theory. The person has no prior knowledge about actin and myosin. Essentially myosin heads grab onto actin and use energy from ATP hydrolysis to move along actin, generating a contraction force. Actin and myosin are present in the same location. The ATP, which is kind of a chemical energy currency, is generated by metabolic pathways and a process called [oxidative phosphorylation](_URL_0_) but, ultimately, that energy is coming from food. ATP is the only chemical energy currency generated by metabolic pathways and oxidative phosphorylation. This myosin-actin cycle can be initiated by electrical signals from the brain via a pathway that involves calcium release via a [troponin/tropomyosin](_URL_2_) control mechanism. There is a myosin-actin cycle that can be initiated by electrical signals from the brain.
 It's all pretty minor stuff. There have been other instances of major issues. You don't have any major hotspots like the Yellowstone caldera, and you also don't have a subduction zone south of San Francisco, so you don't really have active volcanic arc volcanoes like Ranier and Helens farther south. There are major hotspots like the Yellowstone caldera. Major volcanic activity really has no real chance of returning for a very long time either. Volcanic activity was once present. The Pacific and North American plates are going to remain a transform boundary for the foreseeable future, and you don't have any major restructuring of the North American plate that could cause moderate volcanism farther inland (such as you had with the formation of the Basin and Range province). The North American plate has undergone major restructuring in the past. The sorts of volcanism you DO find in the American Southwest are more along the lines of minor lava flows, cinder cones, and hydrothermal activity such as hotsprings. There are other regions where you can find different types of volcanism. All pose quite small hazards. There are hazards present, but they are not significant.
 Oceans and mountain ranges. There are vast and diverse ecosystems in both oceans and mountain ranges. They influence wind and ocean currents, and the influence how humid the air is (if it moves over the ocean, it gets more humid for example). The Earth's climate is heavily dependent on the influence of wind and ocean currents. You get the most rain if you have wind coming from the ocean and hitting a mountain range, e.g. There is a mountain range near an ocean. south of the Himalaya for the rain season: The humid air has to move up, it cools down, the air can hold less water and it rains. The Himalayas are a significant geographical feature in the region.
 Even if sperm were able to penetrate ovum, there are a host of issues past that. Fertilization is not the only factor in successful conception. First would be discrepancy in chromosome number. There is a known genetic condition that causes discrepancies in chromosome number. This would lead to cells with different numbers of chromosomes after mitosis. There are multiple ways to interpret and generate presuppositions for the given sentence, but here are three possible options:1. These cells would be unlikely to "work together" when it comes to signalling, chemotaxis, etc. There are multiple types of cells involved in signalling and chemotaxis. Secondly, different species express different genes at a genetic level. Different species have unique genetic codes. If you were to create some zygote between species different enough the gene expression would most likely result in cells unable to function, and it'd be a miracle if they progressed past a clump of cells. There is a possibility of creating a zygote between species.
 The article you quote is really complete rubbish. The author of the article has a history of publishing inaccurate information. There is basically not a single correct statement in it. There are multiple statements in it, but none of them are completely accurate. Teleportation works the following way:You have Alice who has some qubit in an unknown quantum state and you have Bob who wants to know that state. Alice and Bob are both experts in quantum mechanics. Alice cannot just measure the state and tell Bob what it was, as single measurement does not reveal the complete state of the qubit and alters it in the process so that any subsequent measurement does not contain any useful information about the original state. The qubit in question is of great importance. Alice can still send the quantum state to Bob if they have a classical communication channel between them and share an entangled pair. Alice and Bob have previously attempted to send the quantum state without success. What Alice does is performing a measurement that reveals the relation between the state she wants to send and her half of the entangled pair. Alice has an entangled pair. Here quantum weirdness strikes for the first time: Even though there are infinitely many states, there are only four possible outcomes for this measurement. There is a measurement that has been taken. If Alice knows the relation between one half of her entangled state and unknown qubit had, then she knows the relationship between Bob's half of the entangled pair and the unknown state is. Alice has an entangled state with another person. So she calls Bob and tells him what the result of her measurement was. Bob was expecting a call from her. Then Bob knows that the state of his qubit differs only by one out of four transformations from the unknown one. Bob has a qubit. He performs this transformation and holds this qubit. The person referred to has the ability to perform the transformation and hold the qubit. Note that only information was transferred. There was a transfer of information that occurred. This kind of "teleportation" cannot be used for transmitting matter/energy and further note that no information was transmitted instantaneous or faster than the speed of light. Teleportation has been successfully used for other purposes. The information transfer needs to include classical communication between Alice and Bob. Alice and Bob have previously communicated using non-classical methods. If Bob doesn't get the message and doesn't transform his qubit accordingly, then the qubit will just behave completely random when measured. Bob has received a message about how to transform his qubit.
 The word "ground" is used in two different ways in electrical engineering. Electrical engineering has two distinct fields of study. So first, to clarify: The "ground" you are referring to is called "Earth ground" or "safety ground" and it must be connected to the Earth (eventually). The speaker is discussing electrical safety. If something goes bad with electrical equipment, it will hopefully shunt the electricity to the Earth rather than through your heart. Electrical equipment can malfunction. (Earth grounding has some other benefits, such as helping to reduce unwanted electromagnetic emissions.) There are electromagnetic emissions that need to be reduced. But every circuit has a "ground", too. There is a common misconception that circuits only have a positive and negative terminal. That ground doesn't need to be connected to Earth ground, although it can be. The ground in question is not located on Earth. This ground is simply a reference voltage to compare all voltages in the circuit against. There are other types of grounds in the circuit. So we call one part of the circuit "ground"=0 volts. There are other parts of the circuit that are not considered "ground". (A voltage is a relative value, so you have to have something to compare to.) There exists a standard unit of measurement for voltage. It is very possible that you could have two electronic devices, and if you compared their ground voltages, you'd find that they weren't the same. There are at least two electronic devices in existence. This is actually quite common. People often underestimate how common this is. This is also true of Earth grounds. Earth grounds have similar properties to other types of grounds. The potential across the planet is mostly the same, but you can have small local variation. The planet has a uniform electrical potential. Some soils are not very conductive and so will take time to equalize their charge. Some soils are conductive and will not take time to equalize their charge. The biggest source of such potential differences are when a fault exists at something like a power substation. There are potential differences that can occur. This can lead to a localized ["Earth potential rise"](_URL_0_) that can be quite large. There is a significant risk of Earth potential rise occurring. This can be so big that the potential difference between a person's feet can become hazardous. There is a potential difference between a person's feet. I believe that there are also some long-standing small potential differences caused by things like the Earth's magnetic field, cosmic radiation, etc. There are various natural phenomena that can cause small potential differences. (I'm not 100% certain of this.) There is some doubt or uncertainty surrounding the situation. But if so, the magnitudes of such differences will be quite small. There is a possibility that there are differences. In general, Earth ground is Earth ground. The concept of Earth ground is universally understood.
 The answer is that we are not limited to a single electric field/wave. There are multiple electric fields/waves that exist. Unpolarised light is unpolarised not because it doesn't oscillate, but because it is formed from a whole bunch of waves that oscillate in all directions and hence has no preferred polarisation direction. Light waves have a preferred polarisation direction. Polarised light can then be formed by filtering out all waves except those that oscillate in a particular direction. There are multiple directions in which waves can oscillate. Your picture of circular polarisation is not quite right since it is not a single rotating wave but instead two perpendicular waves which are superimposed and delayed with respect to each other such that when one is at the maximum of its oscillation, the other field/wave is at zero, and visa versa. There are two perpendicular waves involved in circular polarization. When these two oscillations are added together the net effect is that the direction of the TOTAL electric field rotates. The electric field was not rotating before the two oscillations were added together. In the case that the magnitudes of these two fields are the same, then you get circular polarization, but in the case one of the fields is stronger than the other, the electric field magnitude will vary as it rotates, leading to an elliptical profile. The two fields being referred to are electromagnetic fields. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 Someone asked a very similar question a few months ago, [and this is a fairly frequently asked question,](_URL_0_) so I'll copy paste what I wrote there, since that user specifically asked about 'Newton's Laws' vs 'Einstein's theory' as well. This question has been asked multiple times before. -----------------------------------------------------A lot of people make the mistake of thinking, "Gee, I know what the words *law* and *theory* mean. Many people are confused about the meanings of the words "law" and "theory". You can't break *laws*, so those must be the things that are really solid, but a *theory* is just a like some kind of guess, I can come up with my own theory right now!" Breaking laws is a common occurrence. So let's try to tease out why these people are wrong. These people have been accused of being wrong. To scientists, words like *law* and *theory* have very specific definitions, so we need to do some semantics. Scientists have a tendency to use technical language. **A law is a declarative statement, based on observation, that seems to describe some behavior of some naturalistic phenomena. Naturalistic phenomena are observable. ** Newton's Laws are exactly that. Newton's Laws are widely accepted and recognized by the scientific community. "Objects in motion remain in motion, and objects at rest remain at rest unless acted upon by an outside force." There are forces acting on all objects in motion. This statement seems consistent with every observation we've ever made, and it has a great deal of predictive power. There have been many observations made in the past. Basically, a law is a statement of a fact that can be experimentally falsified. There are scientific experiments that can falsify statements of fact. One experiment that shows a body accelerating under its own volition, for no reason and with no discernible outside force, and this is refuted. There was an experiment conducted to test the acceleration of a body under its own volition. Now for *theory*. There was a previous discussion about a different topic. I have a definition of theory that I like, and others are free to disagree. There are multiple definitions of theory that exist. **A theory is a testable explanation of some set of natural phenomena that explains all the best currently available evidence. Natural phenomena exist and can be explained. ** Basically, a theory explains the laws or some bundle of them and it offers some *reason* for them. The laws being explained by the theory are currently not well understood. Einstein's *theory* is that we live in a four dimensional universe, and that space and time are related in some nontrivial way, and things get curvey which is the source of attraction between masses. The universe is four dimensional. The 'theory' provides a mechanism by which the 'laws' act. The 'laws' are currently not acting without the help of the 'theory'. Einstein's theory explains the results of tons of experiments or makes predictions (mathematically) that are consistent with them, such as the Michelson-Morley experiment and Gravity Probe-B. There have been numerous experiments conducted that require explanation. The theory *explains* the facts. The facts are currently unexplained. A bunch of laws, together, form the pillars that a theory stands on. The existence of a theory is dependent on the presence of a set of laws. If one of those facts turns out to be bunk, (like in Einstein's theory, that nothing goes faster than light), it will have to be modified or entirely replaced in order to account for this new evidence. Einstein's theory has been widely accepted as true. Furthermore, now that we have our definition of a 'theory' we can see that a theory is a fundamentally different thing from a law, so it wouldn't make sense to take Newton's law of inertia and try to promote it into a theory, because it's just a single statement about *one specific type of observation. The speaker has a clear understanding of the difference between a theory and a law. *  Another good example is evolution. Evolution is a widely accepted scientific theory. Darwin's theory of evolution by natural selection is a *theory*. Evolution is a fact, not just a theory. It explains the *fact* that organisms aren't the same as their parents, that new traits can emerge, and these traits can proliferate through the population over successive generations if they prove to be beneficial. Organisms have parents. Natural selection is the mechanism so maybe (as much as I hate the phrase) we should call 'survival of the fittest.' The concept of 'survival of the fittest' is widely misunderstood. Species changing over time is the *evidence* from experiments and the fossil record, and Darwin's *theory* ties it all together. The existence of experiments and fossil records is undeniable. It's amazing that Darwin came up with his theory before DNA was even known about, but was found to be very consistent with the microbiological understanding of genes and mutations. Darwin's theory was not widely accepted at the time. Bottom line: Theories don't somehow graduate into laws after they get proven, because they're different beasts entirely. The scientific community often confuses theories and laws. Laws are statements about specific phenomena, and the laws, together with the evidence and facts, are explained in aggregate as theories. Phenomena are only considered laws if they can be explained as part of a theory.
 The matrix is a linear transformation of the vector; it takes one vector as an input and gives a new vector as the output. The vector being transformed is a mathematical object. [Here](_URL_0_) is a list of examples of what the matrix elements look like for some different kinds of linear transformations, and what the transformation does to the vector geometrically. There are multiple types of linear transformations.
 Heat generally causes materials to expand. Materials contract when cooled. It is possible that it caused the crack to close. There was a crack that needed to be closed. Alternatively the tea dust particulate could have formed a seal within the crack. There was a crack that needed to be sealed.
 Simplest explanation is the foundations are built very deep, which makes the center of gravity of the structure beneath the ground so it is impossible to topple it over without decoupling it from the foundation. The structure in question is very large and heavy. [Here is a link explaining with pictures](_URL_0_) There are pictures that need explaining.
 All the light you see in pictures of galaxies, whether it be in the form if visible light or other frequencies, is produced by stars in that galaxy. There are other sources of light in galaxies besides stars. We see a bright spot simply because there is a dense accumulation of stars close to ~~the supermassive black hole at~~ the centre of the galaxy (whatever they're rotating around - [there's quite a debate about it](_URL_0_)). There are other possible explanations for the bright spot besides the dense accumulation of stars. There are more light sources and they are closer together at that position. There are multiple light sources in the area.
 A transmission line is constructed with two conductors separated by a dielectric insulator. There are at least two conductors in the transmission line. The properties of both the conductors and the dielectric are important, as well as the overall geometry. The conductors and dielectric have been previously tested and analyzed. In principle there would be no difference between an ionic conductor and a metallic conductor of the same conductivity and geometry -- conductivity is the only material property involved. All conductors have the same conductivity regardless of their material properties. However my understanding, and a quick search turns up [this paper](_URL_1_) and [this table](_URL_0_), that ionic solutions typically have a much (10^6 times) lower DC conductivity and a much quicker decrease with frequency than most metallic conductors. Ionic solutions are commonly used in various industries. So your ionic transmission line would likely be very lossy. There is a need for an ionic transmission line. The cutoff frequency on the other hand is decided first of all by the geometry of the transmission line, not the materials; for example a rectangular waveguide will have a very different cutoff to a circular/coax waveguide. The transmission line's geometry is the most important factor in determining the cutoff frequency, regardless of the materials used. My experience is that changing material is only a small correction on top of the overall shape of the electromagnetic modes; however I've never before thought about 10^6 change in conductivity so perhaps it would be more significant in this case. There is a significant difference between changing materials and changing conductivity. I'll have to think on this. There is something that requires thinking. In summary, I think an ionic transmission line works, but would be much more lossy, and unless it's so lossy the EM modes are significantly changed, would have a similar cutoff frequency (for each mode) to a metallic transmission line of the same geometry. There is a need for a transmission line. EDIT: the cutoff frequency which is geometry dependent is a *lower* limit for the frequency of propagating modes, not an upper limit. There are multiple frequency limits for propagating modes. the rolloff at high frequencies due to the increasing resistance can also be described as a cutoff frequency. There is a device or system that experiences rolloff at high frequencies due to increasing resistance.
 [This gif](_URL_0_) is basically your proposed experiment on a much larger scale. The experiment proposed in the past was on a smaller scale. The star at the center of the image released a large pulse of light, and what you are seeing isn't the gas expanding, but rather the pulse of light itself moving through a large cloud of gas around the star. The gas around the star is not visible to the naked eye. [Here](_URL_1_) is another video you might find interesting as well. There are other videos that you have found interesting before.
 No. I'm sorry, but the sentence indicated by angel brackets is not provided. They are completely unrelated. There is a common assumption that the two entities in question are related. Polar migration is a result of convection in the outer core,  about 3000 km below us. The Earth's outer core is made up of molten material. In contrast,  earthquakes are a result of deformation in the brittle crust - mostly within the top 15km. The Earth's crust is brittle. This is driven ultimately by convection in the mantle (between the crust and the committee) but they are decoupled enough that mantle effects only exert themselves on geological timescales. The mantle is constantly in motion due to convection. And the mantle is itself decoupled from the outer core. The outer core is still intact.
 I've never heard this about water, but there is an example of this made famous by Richard Feynman involving the charge of an electron. Richard Feynman is a well-known physicist. Millikan used an experiment involving measuring charged drops of oil as they fell. The oil drops were previously known to be charged. However he had the wrong value of the viscosity of air, so his number wasn't quite right. The person in question was attempting to calculate a scientific measurement. Later experiments, which shouldn't have had this error tended to report numbers between Millikan's number and the 'real' value, converging towards the real value over time (i.e. There was an error in the initial experiments that affected the reported numbers. later values were closer). There were previous values that were farther apart.
 The way to get the resolution needed to image a planet at that distance would be to have multiple space-based observatories. There are currently no space-based observatories capable of imaging a planet at that distance. Two coordinated observations separated by a distance D give you resolving paper comparable to that of a single device of radius D.  Using Rayleigh's criterion, the smallest details we could imagine would be on the order of R lambda/D, where R is the distance to the object we're studying; lambda is the wavelength of the light we're using; and D is the size of the detection device. There is a need for high-resolution imaging in various fields of study. Having a D of around 50,000 km would yield a resolution of about 1 km at a distance of 10 light years. There is a need for high resolution imaging at a distance of 10 light years.
 When networks (be it fiber or polymer, etc.) There are various types of networks, including fiber and polymer networks. become solvated, they will expand to accommodate the addition of solvent molecules and a mechanical equilibrium is reached in the tension between network linkages and the osmotic pressure of the solution. The solution is under high osmotic pressure. When linkages are stretched out completely, they become pretty brittle and will break easily (chains/fibers are fully extended and can't extend farther without breaking). Linkages are often stretched out completely. Breaks at the molecular level cause defects and you get a positive feedback process that leads to crack formation and propagation. Cracks at the molecular level are a common occurrence. Additionally, adding a solvent lubricates the motion of fibers that are adjacent to each other weakening the overall structure. Fibers that are adjacent to each other have a tendency to weaken the overall structure. With paper towels, the later probably plays a bigger role since cellulosic fibers are pretty tough and not easily solvated in water. Paper towels are commonly used for cleaning. That was all a bit jargony, but the important thing is that you stretch out network forming components and dilute their volumetric concentration and lubricate their motion as well as making the chains/fibers more brittle. There are network forming components present. With paper towels, I would assume that there is some adhesive present as well that is somewhat water soluble which may be a larger factor than any of the other things I mentioned, but I'd guess it's a factor of all these things added together. There is a need for a substance to stick to a surface.
 ####**Q:** Could I still get measles if I am fully vaccinated? Measles is still a prevalent disease. **A:** Very few people—about three out of 100—who get two doses of measles vaccine will still get measles if exposed to the virus. Measles is a highly contagious disease. Experts aren’t sure why. There is a lack of information available to experts. It could be that their immune systems didn’t respond as well as they should have to the vaccine. The vaccine was administered to the individuals. But the good news is, fully vaccinated people who get measles are much more likely to have a milder illness. People who are not fully vaccinated are at a higher risk of getting severely ill from measles. And fully vaccinated people are also less likely to spread the disease to other people, including people who can’t get vaccinated because they are too young or have weakened immune systems. People who are not fully vaccinated are more likely to spread the disease to others. _URL_0_If anyone likes infectious disease news, check out r/ID_News There are people who are interested in infectious disease news.
 In a practical sense, I'm not aware of any liquids light enough or gases heavy enough to allow this to happen. There are no known substances that can make this happen. If you take one of the densest gases, radon, its density is something on the order of 10 g/L, and if you take a very light liquid, say an alcohol, they have densities on the order of *800* g/L. Radon and alcohol are commonly used in scientific experiments. This is all at STP, obviously. The pressure is not above or below STP. Gases are compressible, so you could probably fiddle with pressure to get the densities higher, but we're talking about heavy gases being orders of magnitude less dense than light liquids, so I doubt it's possible. 1.
 The answer to "where does that energy go"? Energy is being used. is almost always *heat*, and batteries are no different. Heat is a necessary component for batteries to function properly. The potential energy in a battery is "locked up" in chemical bonds. Chemical bonds are the only way to store potential energy in a battery. An unused battery undergoes self-discharge, which is an internal chemical reaction that breaks these bonds, releasing the energy in the form of heat. Batteries are made up of chemical bonds that store energy. Of course, batteries are specifically designed to have a low self-discharge rate, so the resulting rise in temperature is extremely small. Batteries are commonly used in devices that require low self-discharge rates.
 I think this is hard to judge because most of the images where you see a map of "lights" of the US or world  or other country are usually done in upwards of 200 passes of the satellite. Satellite imagery is the primary source for maps of "lights" of the US or world or other country. this means that it'll more than likely take longer than the christmas season to complete. The project in question has a deadline. if it could be done in a night I believe there would be a difference in the light maps. The presuppositions of the sentence <if it could be done in a night I believe there would be a difference in the light maps> are: 1. P.S. There was a previous conversation or context that led to the need for the presupposition in <P.S.>. sorry everyone hijacked your question with power consumption facts. There was a question that was hijacked by someone with power consumption facts. WTF mate. The speaker is surprised or shocked.
 > the choice of words implies consciousness has an influence. Consciousness is a powerful force that can influence decision-making. Would it be accurate to say "observe" simply means the photon interacting with anything at all, even some random molecule in the air? Photons can interact with random molecules in the air. Correct! The presuppositions of the sentence "<Correct!>" could be: 1. The important thing that has an influence is *interaction*. Interaction is the only thing that has an influence. Interaction with anything; man, animal, machine, dirt, doesn't matter. There exists a being capable of interaction. > What exactly did observe mean in this context? There was a previous conversation where the meaning of "observe" was discussed. You can treat it as a synonym for interaction. Interaction is a necessary component of communication. > How did they measure a single photon without absorbing it? There was a need to measure a single photon without absorbing it. They did absorb it; it was incident on a detector screen. The detector screen was functioning properly. That's how they know what the distribution is. There is a distribution that needs to be known. > And since by now similar experiments have been performed without collapsing it, what is the main difference there? Similar experiments have been performed before. What do you mean, "without collapsing it?" The object in question is prone to collapsing. Just because the photon is not measured or interacted with at the *slit* does not mean the photon does not pass through one or both slits, diffract or not diffract accordingly, and then ultimately be absorbed by the detector screen behind the slits. There are multiple slits present in the experiment. When it is interacted with at the slit, no diffraction pattern is measured; when it is not interacted with at the slit, one is. There is a physical object that can be interacted with at a slit. Either way it still hits the detector afterwards. The detector is always present. Hope that helps! The person receiving the message needed help.
 Are you talking specifically about birds? Birds are the only topic of discussion. Because they're not the only flying vertebrates, but they are the only (living) vertebrates with feathers. Other flying vertebrates exist. One thing to keep in mind that a lot of people confuse: birds are dinosaurs. Dinosaurs are not extinct. Also, pterosaurs are not dinosaurs. Dinosaurs are commonly mistaken for pterosaurs. They're archosaurs, like modern crocs and dinosaurs - including birds - but they're not dinosaurs. Archosaurs are a distinct group of animals that share similarities with both modern crocodiles and dinosaurs, but are not classified as either. The evolution of flight (in dinosaurs), the evolution of feathers, and the evolution of birds are very much decoupled from each other; flight seems to have occurred in non-avian dinosaurs as well. Feathers evolved before flight. Basically, all the parts were there. The project was completed successfully. If you look into the origin of flight in dinosaurs, you may hear that the dichotomy for the origination of flight is either ["tree-down" or "ground-up"](_URL_8_). Dinosaurs had the ability to fly. This widely regarded by paleontologists to be a pretty gross oversimplification of things, in large part because there was a lot of diversity in the group. Paleontologists have varying opinions on the accuracy of the oversimplification. There were both [cursorial feathered dinos](_URL_3_) and [arboreal feathered dinos](_URL_0_). Feathered dinosaurs were not limited to just one type of locomotion. [Here](_URL_12_) is a source on the origination of flight, although keep in mind that at this point more fossils have been found. There are other sources on the origination of flight. More recently paleontologists [have reconstructed the brains of birds](_URL_1_) and non-avian dinosaurs and found that the enlarged forebrain that we associate with the neurological ability to fly shows up earlier than we thought (the original paper is [here](_URL_6_). Birds and non-avian dinosaurs have brains that are significantly different from each other. This enlargement shows up multiple times to create an overarching trend. There have been previous enlargements that did not create an overarching trend. There are a few characters we strongly associate with flight: feathers, hollow bones, and a [unidirectional airflow system in the lungs](_URL_11_) that makes respiration highly efficient. Birds are the only animals with feathers. All of these show up prior to the emergence of birds; these unique lungs even [show up in crocodylians](_URL_2_) and are likely the ancestral condition for [archosaurs](_URL_4_). Unique lungs are present in crocodylians. While they do create the perfect scenario for flight, they also clearly conferred their own advantages individually, and they're also deeply entrenched in these dinosaur lineages. There are creatures that are capable of flight. Because many of the traits we associate with birds show up much earlier, there's actually very little to distinguish birds from their non-bird relatives. Birds have non-bird relatives. Here are some dinosaur characters that birds possess:- [Furcula](_URL_7_) (wishbone) and hollow bones (Theropoda). Birds are the only animals that possess furcula and hollow bones. - Feathers (for sure at least Coelurosauria, and either feathers or a similar integumentary structure show up even earlier in some dinosaur lineages and even into pterosaurs, which are related to but *not* dinosaurs). Dinosaurs and pterosaurs had a variety of integumentary structures, including feathers. Feathers could be used for display and for thermal protection (Norell and Xu 2005; [also linked above](_URL_13_)). Feathers have been used for display and thermal protection for a long time. - [Semilunate carpals](_URL_14_), a backwards-facing pubis, and a bony sternum; pinnate feathers on the forelimb (Maniraptora). There are animals with semilunate carpals, backwards-facing pubis, and a bony sternum. [This paper](_URL_9_) looks at the evolution of the semilunate carpal and says: >  The original selective advantage of this enhanced mobility is not clear, but cannot have related to pennibrachial folding unless relatively basal tetanurans had elongated feathers on the forelimb. The semilunate carpal has evolved over time. [Note: the pennebrachium was basically the wing, but termed differently because the authors weren't sure it was used for flight.] The authors were unsure about the function of the pennebrachium. Such a possibility should not be dismissed entirely. There is a possibility that has been considered. Specimens representing this grade of evolution have not been recovered from sediments that preserve extensive soft tissue, and filamentous integumentary structures [e.g. There are sediments that preserve extensive soft tissue and filamentous integumentary structures. feathers] have recently been reported in a basal ornithischian (Zheng et al. Feathers have been found in a basal ornithischian, indicating that feathers may have been present in more dinosaur species than previously thought. 2009). The year 2009 was significant in some way. However, it is likely that mobility of the wrist was initially associated with other functions, such as predation (Padian 2001). The wrist has mobility. - Asymmetrical flight feathers (Aviale). Birds with symmetrical flight feathers do not belong to the Aviale group. One thing that sets crown-group birds (the common ancestor of all living birds and all of that ancestor's descendents) apart from their immediate relatives is the [complete loss of teeth](_URL_5_) in the beak. Crown-group birds are the only birds that have completely lost their teeth in the beak. However, teeth are lost multiple times in theropods, so even that isn't a great distinction! Theropods have distinct teeth. I talking more about the evolution of feathers [here](_URL_10_). Feathers have evolved significantly over time.
 I think you want to take a look at something like a [Ragone Plot](_URL_0_). There is a need for a tool to analyze energy storage systems. There are other similar plots for comparing energy storage technologies. Other plots for comparing energy storage technologies have been previously used. Here are two examples with data for flywheels vs batteries:_URL_1__URL_2_The challenge is that you need to meet the overall energy density requirement (e.g. There is a need for alternative energy sources. range in a car) while still providing good power density (e.g. There is a need for a car with a range that can still provide good power density. accelerate a 2000 lb vehicle from 0-60 in 10-15 seconds). The vehicle is capable of accelerating from 0-60 mph. These plots give you some sense of that. There are multiple plots being discussed.
 It doesn't feel good for everyone. Some possible presuppositions for the sentence "<It doesn't feel good for everyone.>" are:1. The current leading theory for what happens when you crack your joints is that the sudden increase in space between the two joints causes a decrease in pressure and the dissolved gasses in the synovial fluid come out of solution to form a bubble (much like what happens when you open a slightly shaken soda can). There is a common belief that cracking your joints is harmful to your health. This bubble then cavitates (pops), resulting in the distinctive crack you hear. There is a bubble present. Now, one can make many different cases for why this can feel good, but it's likely a combination of stretching the connective tissues around the joint and the sudden increase and release of pressure within the joint caused by the cavitation process. The joint in question has connective tissues that can be stretched.
 Although I do not personally know of any that do *not* use ATP for metabolic purposes, we can come to several conclusions:1. There are organisms that use something other than ATP for metabolic purposes. All eukaryotes, because they rely on Mitochondria for energy production, must use ATP for their primary power-source, interconverting to the other NTPs. All living organisms require energy to survive. Thus, multicellular organisms must rely on ATP. Multicellular organisms cannot survive without ATP. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. All known prokaryotes (as defined) also rely on ATP, as the ATP synthase is very old, evolutionary - they functionally operate like mitochondria, but free of any surrounding cell, in that their ATP is produced at their cell membrane. All living organisms require ATP for survival. 3. There was a previous event that led to the situation described in <3.>. This leaves archaea. There were other options available besides leaving archaea. Probably the only chance for non-ATP based metabolisms, but apparently [the ATP-generation machinery is so old evolutionarily that it is inescapable. There are other chances for non-ATP based metabolisms. ](_URL_0_)So, until a new form of life is discovered, essentially everything operates through ATP, metabolically. There is currently no known form of life that operates without ATP.
 String theory is a misnomer. The concept of string theory has been widely accepted. It should not be called string theory. There is a theory that is currently being called "string theory". But sting framework does not sound cool. The speaker has knowledge about the Sting framework.
 There are various factors in play (such as heart rate) that explain the mortality rates of varying sized fauna. There is a significant difference in mortality rates among varying sized fauna. Firstly, smaller animals must satisfy the order of the food chain to maintain balance; more small animals means more food for larger ones and so the quicker they die, the quicker they are encouraged to reproduce, and the quicker they reproduce, the quicker there is more food. There is a delicate balance in the food chain that must be maintained. While heart rate seems to be a direct answer, it is only so for closed circulatory animals (not arthropods). Closed circulatory animals have a higher heart rate than arthropods. So essentially, smaller animals are evolutionarily programmed to reproduces efficiently and die quickly (which actually also makes more room for advantageous mutational changes). Smaller animals have a shorter lifespan than larger animals.
 The lions eat all the parts, including the organs, which are high in nutrients. Lions are the only animals that eat all parts of their prey. We don't. There was an expectation or request for us to do something. Aside from that, We don't need to eat from all the food groups to survive. There are some food groups that are not necessary for survival. Only to thrive. There are other goals besides thriving. Balanced diets are the result of scientific research and we only know about the concepts of nutrition now. People used to believe that diets didn't need to be balanced. What nutrition is for humans is the best possible combination of foods to completely supply all of our needs with no deficiencies, allowing us to be developmentally healthy. Humans have specific nutritional needs that must be met in order to be developmentally healthy.
 In VSEPR theory, bond angles are determined by the orbitals' desire to maximize distance between bonds (specifically between orbitals). Orbitals have a desire to maximize distance between bonds. Since electrons repel each other, bonds and lone pairs would try to get 'as far apart as possible'. Electrons always repel each other. As for water, keep in mind that it is sp^3 hybridized. Water has a unique molecular structure. So even though its geometry is 'bent', it still has 2 bonds and 2 lone pairs. The molecule in question has a geometry that is typically not associated with having 2 bonds and 2 lone pairs. Since not all four of these hybrid orbitals are unique, so to most effectively spread themselves apart, they do not uniformly move to 109.5 degrees (as it would seem that the lone pairs repel each other more than the two sigma bonds do in this case). There are four hybrid orbitals involved in this situation. As for the series, I would guess that is is coincidence. The speaker has reason to doubt the authenticity of the series. If you consider an sp^3 d hybridized atom, you note that not all bond angles are unique. There are hybridized atoms with unique bond angles. The bond angle between axial and equatorial orbitals is 90 degrees while the bond angle between two equatorial orbitals is 120 degrees. The atoms involved in the bond are in a stable state. So it doesn't fit nicely into the progression. There was a progression that the sentence was expected to fit into. The other thing to note (as I mentioned earlier) is that water is 'tetrahedral' when you consider it's hybridization. Water has a unique hybridization structure.
 Electromagnetic radiation encompasses a range of different wavelengths (of which visible light is one section), and at a specific wavelength will correspond to a specific quantised energy as given by E = hv. There are various types of radiation with different wavelengths. The second idea is that molecules are not static, rigid entities that highschool chemistry can sometimes portray. Molecules have been portrayed as static and rigid in high school chemistry. Instead, molecules have translational motion, rotational motion, vibrational motion along or perpendicular to the inter-nuclear axes and finally electronic states which all have energy associated with them. Molecules cannot have any other type of motion besides translational, rotational, vibrational, and electronic. In terms of greenhouse gasses, the region of electromagnetic radiation of most significance is infra-red radiation, which is almost always of suitable energy to cause absorption of this energy by molecules to become more vibrationally excited. Greenhouse gases are a significant concern for the environment. Part of the reason the Earth's climate is so specific is because the Earth emits radiation itself as a black body, which means it emits an continuous spectrum of electromagnetic radiation itself which it has absorbed from the Sun. The Earth's climate is not specific for any other reason. This outgoing radiation is IR radiation, and it turns out the the greenhouse gasses, especially CO2, absorb IR radiation at the maximum intensity "window" of the Earth's emitted radiation due to their molecular and chemical structure. Greenhouse gases are present in the Earth's atmosphere. In fact, the most important greenhouse gas is water as it absorbs far more strongly in the maximum emitted window. Water is the only greenhouse gas that absorbs strongly in the maximum emitted window. Sorry if this is a bit ramble-y but in my mind your question has quite a few bits in it. The speaker is apologizing for being unclear.
 Arachnids like some spiders and scorpions especially pseudo-scorpions secrete corrosive and dissolving enzymes over their prey and wait until the prey is reduced to a fine pulp which is then sucked up. Arachnids have a complex digestive system that requires them to secrete corrosive and dissolving enzymes over their prey. This is an example of external digestion. External digestion is a common occurrence in nature.
 [Here](_URL_0_) is an easy to read paper by a very well respected research engineer that tackles not only the voltage involved but the disbelief by people that it is so large. The research engineer has a reputation for producing difficult to read papers.
 You can alter (i.e. There are other options available for alteration. de-enrich) weapon's grade uranium for use in civil reactors, in fact this has been done: the Megatons to Megawatts agreement between Russia and the USA. 1. Reactors use about  <  5% enriched uranium (5% U-235, 95% U-238) whereas nuclear weapons are  >  90% enriched uranium. 1. Since natural uranium is about 99% U-238 you can combine weapon's grade uranium with natural uranium to get a greatly reduced enrichment. Natural uranium is commonly used in the process of uranium enrichment. Note that only the U-235 actually fissions (significantly) in a reactor. Other isotopes may undergo some level of fission in a reactor. Using weapon's grade uranium directly in nuclear reactors would be unnecessarily risky: it would pose a risk of people stealing the fuel for use in a bomb, and it would (depending on your reactor design) allow for the possibility of a dangerous meltdown occurring. Weapon's grade uranium is highly sought after by individuals or groups looking to create a nuclear weapon.
 You can't talk about infinity like that. Infinity is a topic that can be talked about in certain contexts. You can say that as the number of coin flips approaches infinity, the probability for any *finite* sequence approaches one. There is a finite sequence of coin flips. But you cannot extend that argument to infinity. The argument being discussed is related to a specific topic or issue.
 Yep. There was doubt or uncertainty before the confirmation of the statement "Yep." See [space filling curves](_URL_0_) for examples of mappings between an interval and multidimensional spaces. There are multiple examples of mappings between an interval and multidimensional spaces.
 Here is an approximation-heavy perspective. There is a lack of precision in the perspective being presented. Suppose quanta of heat jump around the lattice [randomly](_URL_1_). There is a lattice present. Thus the distance traveled after a time t is **d**\*sqrt(**R**\***t**), where **d** is the average jump distance and **R** is the average jump rate. The existence of a jump rate and average jump distance is assumed. By analogy (explained on the wikipedia page) **D**, the diffusivity, or **A**, the thermal conductivity, goes as **d**^(2)\***R**. The concept of diffusivity and thermal conductivity are crucial in the field of thermodynamics. In popular usage, the jump distance **d** is assumed to be the mean free path while the jump rate **R** is assumed to be approximately constant (actually, it is often assumed to rely on an energy barrier and the temperature but I am skipping this for now). The concept of jump distance and jump rate is widely used in various fields. This tends to give a good agreement with experiments, but it implies that the time spent jumping is negligible (so the jump rate does not depend on jump distance). Experiments have been conducted to test the accuracy of this statement. What if we instead assume the jump rate depends on jump distance? Jumping is a common activity. Specifically, what if **R** goes as **V**/**d** for some average velocity **V**? There is a situation where **R** is being measured. For [**electrical** conductivity](_URL_0_) that is a perfectly reasonable assumption that also gives good results. There is a need to measure electrical conductivity. However, this is because there is an external driving force and we find the average velocity by integrating over the distance **d** assuming we started at a stand still. There is a force acting on the object in question. There is a "force" for thermal conductivity (called the thermal driving force, and it is referenced [sometimes](_URL_2_)) but it is a side effect of the thermal gradient so the "force" only exists as a statistical effect, not a true force acting on a single particle. There is a significant difference between the thermal driving force and other forces that act on particles. Because of this the explanation I gave about electrical conductivity doesn't seem like it should apply here (though the result is correct). There is a specific context or situation that is causing the explanation of electrical conductivity to not apply in this case. Regardless, the fact that the conductivity scales (very roughly) with the mean free path has plenty of experimental evidence. There have been numerous experiments conducted on the relationship between conductivity and mean free path. All the models I have discussed are pretty simply approximations and phonon/electron simulations would give much more accurate results. There are more accurate methods of simulation than the ones discussed.
 Yes in principle, but brain death implies the person isn't breathing spontaneously anymore. The person in question was previously breathing spontaneously. However there are a lot of brain damage situations that involve permanent unconsciousness or quasi-unconsciousness and where the rest of the body may be fine as long as the person is given food and waterAlso it's normal for people with major trauma to be put in an artificial coma for a few days or weeks while their injuries heal a bit Brain damage can result in permanent unconsciousness or quasi-unconsciousness.
 When you're thinking of the ["cartoon oasis"](_URL_1_) pool of water with some trees in an endless sand-scape you're likely thinking of something in the Sahara. There are other places in the world that have similar features to the "cartoon oasis" described. The area that is north Africa has been slowly getting drier for something like 10,000 years. The Sahara desert was once a lush and fertile region. But all the water that was trapped underground is still there. There was a time when people thought the water trapped underground would eventually disappear. Aquifers, springs, underground rivers, etc. There are vast networks of underground water sources that include aquifers, springs, and rivers. are all still there, just under a lot of sand. There was a natural disaster that caused the sand to cover everything. [Link. There is a hyperlink that needs to be clicked. ](_URL_2_) IN some places the hard rock layers come closer to the surface of the sand, and the thousand year old water can leak out; this is your oasis. There are areas where hard rock layers are not close to the surface of the sand. [Link. There is a hyperlink that needs to be clicked. ](_URL_0_) The sands do shift, and sometimes oases get buried, but once trees and plants have taken root I imagine it's kinda hard to truly lose one to the desert. There are many trees and plants in the desert. Some big ones have been trading posts and military bases for centuries. There have been civilizations that have existed for centuries. Of course there's lots of ways a place can become a desert and lots of ways water can be forced to the surface; every oasis is going to be a little different. There are many different types of deserts, each with their own unique characteristics. The geology and history of the Sahara lends itself to this kind of thing. The Sahara has a history of being a place where unique geological formations occur.
 During a panic attack some regions of the brain become hyperactive. The brain regions that become hyperactive during a panic attack are different from those that become hyperactive during other types of anxiety. These can be identified using a functional MRI (a special type of MRI that shows what parts of the brain are active in real time). Functional MRI is the only way to identify brain activity in real time. Multiple regions have been found to be affected, these include: The amygdala which is involved in our perception of fear  &  parts of the midbrain that are involved in how we experience pain. There is a significant amount of research being conducted on the effects of the amygdala and midbrain on human perception and experience. If these parts of the brain malfunction (for example by giving a larger or more sustained response to a perceived threat) then you can experience a panic attack. The brain has parts that can malfunction. These areas and possibly even some we have yet to identify cause the downstream effects that people call associate with a panic attack. There are areas that cause downstream effects associated with panic attacks.
 Sure. The speaker was asked a question or requested to do something before saying "Sure." Apparently [silphium](_URL_0_) (a plant related to carrot and parsley) was driven to extinction by ancient Romans and Greeks, partly because they used it as a contraceptive. Silphium was a highly valued plant in ancient times. It induced menstruation, and therefore abortion. The substance was intended to induce menstruation. And there are many other plants that have abortifacient effects: bitter melon, wild carrot, blue cohosh, pennyroyal, nutmeg, mugwort, slippery elm, papaya, vervain, common rue, ergot, saffron and tansy. There is a significant demand for natural abortifacients. Animal studies have shown that pomegranate may be an effective abortifacient. Pomegranate has been extensively studied in animal experiments. These were known even before modern times. People in ancient times had knowledge of these.
 There is a whole field of research dedicated to this, it's called Operations Research. There are many other fields of research that are not dedicated to this topic. In many (simple) cases, theoretcal optima can be derived. Optimal solutions are not always achievable in complex cases. If the system becomes more complex, simulation might be easier to optimize your system. The system is not currently complex. However, this does require accurate parameters for your simulation model. Accurate parameters are difficult to obtain for simulation models. Basically it all boils down to linear programming and (heuristic) solutions. Linear programming and heuristic solutions are the only viable options. You can look up Inventory Control, Routing Problem, Spare Part Management or Shortest Path Problem for more reading. There are multiple problems related to inventory control, routing, spare part management, and shortest path that require further reading.
 The water content of hair is really low. Hair without low water content is unhealthy. The water that is there is associated and adsorbed to the keratin that makes up your hair, so it won't be able to crystallize at 0 C. In otherwords, hair doesn't freeze at the same temperature that water would. Keratin in hair has a unique property that prevents water from freezing at 0 C. Hair is not affected by the temperature at which water would normally freeze. If your hair is wet, then the water on the outside of your hair can freeze. Water is present on the outside of your hair. What your hair does in this situation when you bend it depends on how strong your hair is and how thick the ice is. Your hair is capable of bending in this situation.
 Yes. There was a question asked prior to the response of "Yes." Identical twins have the same genomic sequence. There are no environmental factors that can cause differences in the genomic sequence of identical twins.
 Conventional hard drives store information by changing the magnetic orientation of a thin film of material on top of the spinning platters. There is a need for conventional hard drives to store information. Solid state drives (SSD) trap charges (electrons) inside special transistors. Electrons can be trapped in other ways besides solid state drives. Dynamic RAM (DRAM) stores electrons in tiny capacitors. Electrons can only be stored in tiny capacitors. Static RAM (SRAM; used for CPU registers, caches etc) uses a couple of transistors arranged in such a way that they hold a set state (0 or 1) as long as power is applied. Transistors are the only components used in SRAM.
 Small oscillations about **any** stable equilibrium will behave like simple harmonic oscillations. There exists at least one stable equilibrium. And a simple harmonic oscillator, by the very definition of it, has a natural frequency determined by the mass of the oscillator and the shape of the potential energy function near that equilibrium point. The oscillator is in equilibrium.
 The sound in that situation would be more like just a pressure wave, since there is almost nothing keeping it contained in the gas. There is a situation where sound is being produced. If you increase the pressure in the center of a balloon, that will cause a push to move through the air molecules that bounces off the latex surface. Increasing the pressure in the center of a balloon is a common occurrence. If the latex wasn't there, the air molecules would just shoot off into space. The air molecules are currently being held in place by the latex. As the wave reaches the edge of the cloud, a burst of molecules/atoms will be pushed away by the pressure at a higher speed than the wave. There is a cloud present. Some of the energy will bounce back but most will go into the increased velocity of the escaping particles. There is a source of energy that is being released.
 This is indeed possible, though quite rare. There have been instances where this has occurred before. This phenomenon is called [uniparental disomy](_URL_0_), and you can read a bit about it at that link. Uniparental disomy is a rare genetic condition. I would imagine that in some cases there would be no noticeable effects, especially if you received two different versions of the chromosome from one parent (heterodisomy; i.e., you got both your maternal grandfather's and maternal grandmother's chromosome) so that you are not fully homozygous across that chromosome. There are cases where receiving two different versions of a chromosome from one parent can result in noticeable effects. However, there are some defects associated with uniparental disomy as the above link indicates; both Prader-Willi syndrome and Angelman syndrome can be (but are not always) caused by inheriting two chromosome 15's from the mother or father respectively. There is a link that discusses defects associated with uniparental disomy.
 Are you asking how we know what the composition of materials is? There is a need to know the composition of materials. I.e. The speaker is familiar with the concept of "i.e." how we know it's CaCO3 and not CaCO2? The substance in question has been identified as either CaCO3 or CaCO2. Or how do we know it has Ca in it? There is a substance being discussed. Or do you mean how do we know what minerals are present in a rock? There is a rock that we are trying to identify the minerals present in. These all have different answers, and I can do my best to answer what you want to know! There are multiple questions being asked.
 It's the fact that different types of waves travel at different speeds. There are multiple types of waves. The P waves (compression waves, like what we normally think of as sound) travel the fastest. There are other types of waves that travel slower than P waves. Then the S waves (transverse waves) travel a little bit slower. There are other types of waves that travel faster than S waves. Slower still are the surface waves, Rayleigh and Love waves. The ocean is calm. Every earthquake generates all of these types of waves, so the duration of the quake is a function both of the actual duration of the quake and the time between the first and last wave arrival, which naturally increases with distance. Earthquakes are a common occurrence. Essentially, the fast waves have more space to get a lead on the slow ones. There are waves that move at different speeds. There are other effects, too, like the number of reflected paths that exist at long distances, but the main thing is probably the different wave speeds. There are multiple factors that contribute to the speed of waves. Hope that answers your question! The person asking the question had a specific question in mind. *Edit: Also, there's dispersion, where waves of the same type (but different frequencies) travel at slightly different speeds as well. Waves of the same type have different frequencies. * I'm sorry, but there is no sentence indicated by angel brackets in your prompt.
 There is indeed a n2 gas laser emitting at uv wavelength(it is quite popular too _URL_0_). There is a demand for n2 gas lasers emitting at uv wavelength. What the article you refer to is taking about construction of ir lasers. The article being referred to exists. IR range light is produced in those by transitions between different vibrational levels in co2. CO2 is present in the environment. In co2 certain vibrations of a molecule change its total dipole momentum (caused by having different partial charges on carbon and oxygens) while in n2 both atoms are completely equivalent and as a result there is no electric dipole momentum. There are molecules that have different partial charges on carbon and oxygens. Without electric dipole momentum it is much harder to excite electric field. Electric dipole momentum is necessary to excite electric field.
 If you're just looking at straight population counts, it could be said that domestic livestock, like cattle, pigs, sheep, chickens, etc. Domestic livestock is the only population that matters when it comes to counting. have benefited from human dominance. Humans have dominated the world for a long time. If you are considering quality as well as quantity of life in the term "benefited," then it's harder to make that case. Certainly, as others have said the animals we domesticated to keep as pets, such as cats and dogs, have benefited, as have urban pest species and the invasive species we have introduced to certain areas. Humans have been domesticating animals for a long time.
 A strong acid is based on the bond between the H+ part of the molecule, and the negative ion. There are other types of acids that are not based on the bond between the H+ part of the molecule and the negative ion. So HCl is totally fine separating into H+ and Cl- which makes it a strong acid. HCl is commonly used in industrial processes. When we measure pH, we are talking about the amount of H+/H3O+ (which is H+ + H2O - >  H3O+). H+ and H3O+ are the only ions that affect pH measurement. The greater a concentration of H3O+, the more acidic. There is a measurable concentration of H3O+ present. Molecules like H2CO3, are much less likely to dissociate in water (of course there will be a little, but that is what makes it weak). Water is a strong solvent.
 Weeeell... > If we break that down to its individual elements or nontoxic compounds, it will no longer be a pollutant, correct? The speaker is concerned about the environmental impact of the pollutant. Not necessarily. There may be other possibilities. You can't really take all pollutants and pollutant systems together, but for things like photochemical smogs, smaller molecules are not necessarily more stable. There are different types of pollutants and pollutant systems. Chlorine gas degrades under UV light in the atmosphere to produce chlorine radicals, which go on to catalyse a whole family of nasty radical chemistry and leads to formation of atmospheric nitric acid, PANs and hydrogen peroxide. There is a significant amount of chlorine gas present in the atmosphere. All of these are pretty bad to get in your lungs. There is a substance that can get in your lungs. Carbon particulates are pretty much pure carbon - doesn't stop them being carcinogenic. Carbon particulates are commonly found in the air we breathe. That's all really just background though. There is a significant amount of information that is not just background. There are a few problems with this suggestion - first, I'm not really sure what kind of 'electron attractive' thing you're talking about. There is a suggestion being discussed. If you mean electronegative molecules, unfortunately these only act on tiny scales and would not effectively pull out atmospheric pollutants, which are extremely diffuse. Electronegative molecules exist and have the potential to remove atmospheric pollutants. I think this question might stem from a misunderstanding about the problems of pollution - most of the harmful chemistry stuff happens in the atmosphere itself. There is a widespread misunderstanding about the causes of pollution. It would be far easier to reduce emission of chemicals (like nitrous oxides, volatile organic chemicals and the like) than to try to deal with the products once they're up in the atmosphere. Chemical emissions are a significant problem in the atmosphere.
 The celestial sphere can be thought of as two dimensional, and so stars are located on it using either right ascension, a description of their distance from the prime celestial meridian, and declination, their distance from the celestial equator, or using azimuth and altitude, which obviously changes as the stars seem to rise and set. The celestial sphere is a widely accepted concept in astronomy. Stars are so distant their relative motion is undetectable for the most part, but not entirely, so their relative locations are updated periodically, and about every 20 years new star catalogs come out. There are advanced technologies that can detect the relative motion of stars. Observational astronomers don't generally worry about how far away a star is since you don't need that information to find it. Stars can be found without knowing their distance.
 The thing you're calling the energy (E) of the canonical ensemble is actually the ensemble **average** internal energy. The canonical ensemble is a widely accepted concept in the field of thermodynamics. When you derive the equilibrium distribution for the canonical ensemble (Boltzmann distribution), you do so using a Lagrange multiplier to constrain the average internal energy to a constant value. The Boltzmann distribution is widely used in statistical mechanics. But you're still allowing the actual energy to fluctuate around that average. There is an average energy level.
 So first of all, the things that spin that we are interested in are not the whole atoms themselves, but the nuclei of these atoms. Atoms have nuclei that spin. When a nucleus has non-zero nuclear spin, it will align itself to an external magnetic field (provided by the MRI). The MRI machine is available and functioning properly. There's a list of common isotopes which have non-zero nuclear spin, but the main one for most MRI imaging is hydrogen, since there is so much of it in the body. There are other isotopes besides hydrogen that can be used for MRI imaging. When you want to take an image, you send a radio pulse which kicks some of these spinning nuclei so that their axis isn't aligned with the magnetic field anymore. There are spinning nuclei that can be manipulated by radio pulses. After the pulse, these nuclei gradually realign with the field (gradually is milliseconds). The magnetic field was present before the pulse. As they do, they will emit a radio signal, whose frequency is related to which isotope it is, and the strength of the field. There are isotopes present in the environment. Basically, we grab a bunch of radio antennas and catch this signal, which tell us the relative density of hydrogen atoms in a particular area of tissue. There is a need to measure the relative density of hydrogen atoms in a particular area of tissue. This is where the contrast comes from. There is a clear contrast present in the situation. On a very simple level, you could say that basic MRIs respond to tissue water density, so tissue with differing water density gives you contrast. There is a need for basic MRIs to respond to tissue water density. I've glossed over a lot of details, but this is basically it. There were many details that were not discussed. You can inject various contrast agents (that have non-zero nuclear spin), or read other naturally occurring isotopes as well. There are contrast agents with zero nuclear spin that cannot be injected. Also, figuring out which radio signals came from which section of tissue is a combination of engineering and math involving the magnetic field, the radio pulse, and the antennas. There are multiple sections of tissue that emit radio signals.
 It's entirely possible that supernovae have formed "manmade" elements in the past, but because they decay so quickly (Uup-289 has a half-life of less than a second), they are essentially impossible to detect in the wild. "Manmade" elements have been detected in the wild, despite their quick decay.
 It's the rate of heat transfer that makes something "feel" cold, so in the first instance thermal conductivity that's more important. Heat transfer is the only factor that affects how something feels cold. The specific heat capacity (and also other properties of the substance) influence how the rate of heat transfer changes over time, and therefore how it feels on longer time scales. The substance in question has a specific heat capacity. So if you put your hand on a steel block, it will initially feel cold but quickly stop feeling cold and even begin to feel warm (as you warm up that patch of steel, and heat is only relatively slowly transferred to the rest of the block). The steel block is made of a material that conducts heat slowly. Conversely, if you put your hand in a bowl of cold water it will feel cold for much longer, not just because of the higher specific heat capacity but also because the heat will transfer quickly around the bowl of water and so you will, in effect, need to heat it all up rather than just a patch around your hand. The bowl of water is large enough to require heating up all of it.
 The Earth's magnetic field does not shield us from gamma rays. Gamma rays are harmful to humans. It can only divert charged particles towards the poles (those form auroras). Charged particles cannot be diverted towards any other direction except the poles. Cosmic rays refers to high energy massive (having mass) particles, not gamma rays. Gamma rays are not considered to be high energy massive particles.
 It is somewhat lke Jurrasic Park you need a good sample of DNA and a suitable host womb to use our currently available cloning technology. Cloning technology is currently available. We do have preserved Mamoth DNA and Elephants. Mammoths and elephants are closely related species. We don't have either for reptiles. There are no reptiles in the area. But the same process could conceivably be used. The process mentioned has been used before.
 Some bitcoiners (is that a word?) Bitcoiners are a well-known group in the cryptocurrency community. have calculated that you'd need 15 of them to achieve 51% of the current bitcoin network power. Bitcoin network power is a valuable resource. According to Bitcoin, the average is targeted to be 7200 bitcoins total mined per day. Bitcoin is a widely accepted currency. So 15 Titans could mine 3672 per day, and 1 could mine 245 per day (rounded up). There are at least 16 Titans capable of mining. At current exchange rates, that would be almost 34 grand per day. The speaker is familiar with the current exchange rates. Titan uses 9 million bucks in electricity per year, which works out to $24,657 per day. Titan is a company that requires a large amount of electricity to operate. So, you'd make 10 grand a day. You have a job that pays 10 grand a day. Of course, that doesn't count the startup costs - Titan costs $100 million, which means you'd need to run it for more than 27 years just to break even. The speaker is considering investing in Titan. That's going to be risky, because the jury's still out as to whether or not bitcoin is going to go anywhere from a financial point of view, and of course it also assumes Titan will run for 27 years without ever requiring repair, which would cost you both in loss of bitcoin output and the cost of the repair. Bitcoin is a popular investment option. (sources:  _URL_0_ (15 Titans per day statistic) , _URL_1_ ($9million / year in electricity bills statistic and the purchase price of Titan) , and math for the rest). Titans are a significant source of energy.
 Yes, they can. There was doubt about whether or not they could do something. [Relevant information from the Harvard medical school](_URL_0_). The Harvard medical school is a reputable source of information. It refers to microwave-safe plastics, but if something is not microwave-safe, it *definitely* is not safe for pouring and reusing a presumably very hot hydrophobic liquid. Microwave-safe plastics are commonly used for pouring and reusing hot hydrophobic liquids.
 No, one molecule does not have a state. Molecules are the only things that do not have a state. You need "many" molecules to define a state. Molecules are the only way to define a state. There probably is no specific minimum number. There may be a maximum number. Consider for example a droplet of fluid : the smaller it becomes, the larger the fraction of molecules that are at the surface of the droplet, and the more its behaviour becomes determined by surface effects (surface tension) as opposed to bulk effects (fluid behaviour). The droplet of fluid is becoming smaller.
 An orbital represents a standing wave, so you are right that it does not change with time. There is a physical phenomenon called an orbital. However, the electron still has angular momentum and kinetic energy in an orbital. The electron is in an orbital. This might seem contradictory, but we only need the values for these quantities to be constant with time, they don't need to be zero. There are quantities that need to be measured. The average velocity must be zero of course, since the electron remains in place, but that isn't the same as saying the average speed of the electron must be zero. The electron is in motion. You can ~~roughly~~ think of an electron in an orbital as obeying the virial theorem, where if the total energy is -E, the potential energy is -2E and the kinetic energy is +E. Electrons in orbitals have a total energy of -E. Electrons in orbitals have a potential energy of -2E. Therefore, the lower the total energy of the electron gets the more kinetic energy it has. The electron has a total energy. This is also true of the orbit of planets - close orbits have more kinetic energy even though they have less total energy than a similar mass planet in a larger orbit. There are planets with close orbits. Rather than asking if the speed is close to c, we can focus on the kinetic energy and the rest mass. The concept of speed is not as important as the concept of kinetic energy and rest mass. If the kinetic energy becomes large compared to the rest mass of the particle, then relativistic effects become important in your calculations. Particles have rest mass. For a hydrogen atom, the ground state is -13.6 eV, giving a kinetic energy of +13.6 eV, which is very small compared to the mass of the electron (0.51 MeV/c^(2)). The electron's mass is significant in comparison to the kinetic energy of a hydrogen atom in its ground state. But this energy scales with Z^(2), so for a massive element with Z=100 (Fermium) that has a single electron, you get a kinetic energy of 13.6\*10,000 = 0.136 MeV. There exists a massive element with Z=100 (Fermium) that has a single electron. That is now a pretty large fraction of the rest mass of the electron. The electron's rest mass has changed significantly. Therefore our back of the envelope calculation suggests that relativistic corrections are going to be important for the lowest orbitals of heavy elements. Relativistic corrections have not been considered before.
 Some would argue that gender is different from sex, as sex is defined/determined by the presence of large or small gametes and gender goes beyond that. There is a debate about the difference between gender and sex. From my understanding, there are no examples of a species having more than two sexes. There is a possibility that there are species with only two sexes. There are asexual species, species that change sex over time (parrotfish), species that determine sex by temperature of eggs (alligators), but none that actually have 3 sexes. There is a significant amount of research on the topic of sex determination in various species. The reason for this, as it has been explained to me, is that the probability of an organism meeting a fertile member of the opposite sex is difficult enough already in a two-sex system, that adding a third sex to the mix would then make it much harder and more complicated to find a compatible sexual partner. There is a two-sex system in place. Thus, there has been no evolutionary pressure for a third sex. There are only two sexes in existence.
 Matter isn't really solid. Matter is constantly changing. All interactions involve the fundamental forces: electromagnetism, strong force, gravity, and the weak force. The universe is made up of interactions that involve fundamental forces. Neutrinos are electrically neutral, so they don't interact with electric charges. Electric charges are present in most matter. They are color-neutral so they don't interact through the strong force. Particles that interact through the strong force are not color-neutral. The mass of neutrinos is currently unknown, but very small to zero, meaning they interact only slightly through gravity. Neutrinos are the only particles that interact through gravity. That leaves the weak force which is short range and, well, weak. There are other forces besides the weak force. In order to react through the weak force, collisions need to be dead on. Collisions that are not dead on cannot react through the weak force. Given that an atom is essentially empty space with an insubstantial amount of volume at its center taken up by the nucleus, (the electron is almost certainly not going to be hit) this leaves almost no chance for a neutrino to interact with anything, thus it passes straight through. There is a high probability that neutrinos pass through most matter without interacting.
 Transformation, as you describe it, occurs between prokayriotic bacteria, not eukaryotic body cells. Prokaryotic bacteria and eukaryotic body cells are fundamentally different in their ability to undergo transformation. Bacteria have evolved to swap around DNA, sharing beneficial genes, but human body cells have no such mechanism. Bacteria have been swapping DNA for millions of years. There are actually attempts to use bacteria as vectors to help deliver tumour antigens to create cancer vaccines, but that is a completely separate area. Bacteria have been successfully used as vectors to deliver other types of antigens.
 Chimps and gorillas have a gestational period just under humans which implies that ~9 months was a commonality likely shared with early hominids. Early hominids had a similar reproductive cycle to modern humans. As has been mentioned in order to stand upright our pelvis has rotated and shortened to accommodate the range of motion needed in our legs as well as narrowing which better supports our weight. Humans have evolved to stand upright. This is the reason childbirth is such a problem for us, female pelvises being unfused so that they can flex in labour and baby's skull plates unfused so that they can move and squish a bit. The human body is not perfectly designed for childbirth. When compared even to our closest great ape cousins we are born spectacularly immature and under developed, some say that's an advantage because we have more time to learn which is uncertain. Humans have a longer period of development than other animals. But for sure we would be unable to walk upright without it or major changes in reproduction. Humans have evolved to walk upright. So it's probably fair to assume that with the trend from quadraped to biped follows difficulty in labour and premature young. Animals have evolved from quadraped to biped. More recently we know that several other subspecies of homosapiens interbred, including Neanderthal and Denisovan man as we can still find remnants of Thier DNA in the current Human population. There were no other subspecies of homosapiens that interbred besides Neanderthal and Denisovan man. So it's reasonable to assume that they had nearly identical reproductive habits to us although we don't KNOW. They are a species closely related to humans. One of the big issues with studying this field is a real lack of data, we can study our own genetics and discover our familial links with sub species of homo but this was still relatively recently. There is a field that is being studied. Fossilisation being a rare process anyway we do not have complete fossil records of all hominids and homo though all stages of development. Fossilization is a natural process that occurs rarely in nature. Enough to comfortably decuce common ancestry but lacking the detail to easily study subtle changes in how young develop and are born. There is a scientific study being conducted on the evolution of species. Even after the consolidation of homosapiens sapiens from earlier sub species our earliest written languages are only a few thousand years old and aren't detailed records of pregnancy and childbirth. Humans have been around for a very long time. This how much ideas about it have changed since then and vary even now around the globe. People used to have a clear and consistent understanding of the topic. We can be fairly sure that pregnancy had a higher mortality rate and infant deaths were higher but how high they were we don't know. Infant mortality rates have been a concern for a long time.
 There was a ride very similar to that at Six Flags Over Georgia called the [Freefall](_URL_0_). There is a Six Flags Over Georgia amusement park. It has since been torn down though. The building existed at some point in the past.
 Yes, this is commonly done in research using few-turns coils and large capacitor banks. Research using few-turns coils and large capacitor banks is a well-established practice. See the pulsed-field equipment at [LANL](_URL_1_) and at [FSU](_URL_0_) for a bit of info. There is pulsed-field equipment at both LANL and FSU.
 Some foreign body (an antigen) is activating cells on your skin (IgE antibodies probably) to cause your mast cells to degranulate releasing histamine, causing inflammation and release of bradykinins which cause pain and itching There is a foreign body present on your skin.
 There are two main ways that tissues are absorbed. Tissues can only be absorbed in two ways. One is where they die by apoptosis, programmed cell death. Cells that do not undergo apoptosis do not die. In that case the cells themselves take care of their own dismemberment into basic chemicals and cellular fragments. The cells are capable of dismembering themselves without any external intervention. The other is by necrosis and this is a much dirtier process, attracting macrophages and generating reactive oxygen species and potentially an inflammatory response. There is a process other than necrosis that is cleaner and does not attract macrophages or generate reactive oxygen species. Eventually all of the cellular fragments are engulfed by macrophages and disposed of. There are cellular fragments present.
 You basically have it correct since smokers are already at higher risk the *relative* risk of death caused by obesity is less than in non-smokers. Smokers have a higher risk of death than non-smokers. Keep in mind that Figure 1 is showing risk within each smoking category and not comparing risks across smoking categories. Figure 1 is a visual representation of the risks associated with smoking. If you look at table 2 you will see that death rates in obese smokers is indeed higher than death rates in obese non-smokers. Table 2 exists and contains data on death rates of obese individuals. There is nothing surprising about this observation. This observation has been made before. Let us assume that being a smoker increases your risk of death by 25%. Smoking is a common habit among people. Let us also assume that BMI of 30+ also increases your risk of death by 25% and is independent of smoking so that the risks are additive (i.e. There is a significant correlation between BMI and risk of death. being obese and a smoker results in a 50% increased risk of death compared to a normal weight, non-smoker). There is a significant difference in the risk of death between obese smokers and normal weight non-smokers. So compared to normal weight non smokers the relative risk (RR) of death in each category would be:* Normal Weight, Non-Smoker: 1.00* Normal Weight, Smoker: 1.25* Obese, Non-smoker: 1.25* Obese, Smoker: 1.5The RR of death for normal weight, non-smokers versus obese, non-smokers would be 1.25/1 = 1.25. 1. The RR of death for normal weight, smokers versus obese, smokers would be 1.5/1.25 = 1.20. There is a significant difference in the risk of death between normal weight smokers and obese smokers. Obesity can cause the same number of deaths in smokers and non-smokers. Smoking and obesity are equally dangerous. Since smokers are already dying at higher rates the increased deaths caused by obesity have a smaller effect, percentage wise, on the overall death rate. Smoking and obesity are the only factors affecting death rates.
 When measuring these things, scientists are not looking at just the overall color of the star. Scientists are measuring something other than the overall color of the star. Rather, they are looking at the spectral lines emitted by the elements in the star. The star in question has elements that emit spectral lines. These [spectral lines](_URL_0_) are discreet with some width, and are spaced a certain distance apart depending on the elements. The elements that produce these spectral lines have unique properties. We know all the major elements that any star is made out of (it's mostly hydrogen and helium, and for more exotic bigger, older stars, they will have elements up through carbon or iron). Stars are the only celestial bodies that contain hydrogen and helium as their major elements. When there is a red/blue shift from the motion of the star relative to us, all of the spectral lines will be shifted up or down the same amount, regardless of wavelength. The star in question is visible to the naked eye. So as long as the laws of physics do not change across the vast distances of the universe (which is a central tenet of physics), we will see the same pattern we see when examining the elements here on earth, but shifted. The laws of physics have always been consistent across the vast distances of the universe. A star that is "redder" by color, will have different elements in it than our Sun, so the spectral lines will be differently spaced, rather than all shifted in the same direction. There are other factors besides color that can affect the elements present in a star.
 To answer this question, we first have to understand what birds are actually excreting vs mammals. Birds and mammals have different excretory systems. Generally, urination is used to remove nitrogenous waste from a biological system. Nitrogenous waste is harmful to biological systems. Nitrogenous waste is generated from the metabolism of amino acids that make up proteins, usually resulting in a free amino group(R-NH^2). Proteins are the only source of nitrogenous waste in the body. In the body, these free amino groups are quickly oxidized into ammonia, which is both highly toxic and very soluble in water. Ammonia is present in the body. The toxicity of ammonia is what drives the variance in forms of nitrogen excretion. Nitrogen excretion is a necessary process for living organisms. There are three common forms of nitrogenous compound that various vertebrates excrete: urea, uric acid and just ammonia. Vertebrates cannot excrete any other forms of nitrogenous compounds besides urea, uric acid, and ammonia. Which compound a creature excretes is usually impacted by its access to water. Creatures excrete compounds. The great majority of fish excrete pure ammonia. Fish are the primary source of pure ammonia in aquatic ecosystems. As mentioned before, ammonia is very soluble in water, so flushing ammonia out with just water is a very energy efficient model for excreting nitrogenous waste. Ammonia is a common nitrogenous waste product in living organisms. Since, generally, fish are not concerned with access to water, it is no trouble for them to excrete ammonia. Fish excrete ammonia. So, urea excretion is not as energy efficient as ammonia, but it is much more efficient at water conservation. Ammonia excretion is not efficient at water conservation. Mammals and amphibians excrete a different form of nitrogen, urea. All animals excrete nitrogen in some form. Since mammals are land-going and not always near water, they have to be more conscious of how much water they waste. Mammals have a limited supply of water. They will not want to waste the amount of water it takes to excrete nitrogen one atom at a time, so they concentrate it. Water scarcity is a major concern in the area where this sentence is taking place. Since ammonia is toxic, what it is concentrated into must also be less toxic so that it can stay in the body for longer. Ammonia is commonly found in the body. Ammonia has one nitrogen atom per molecule, while urea has two, so it is twice as efficient and requires less water to excrete. There are two types of molecules, ammonia and urea, that are involved in excretion. Many sharks also use urea since it can be concentrated in the animal to make it hyperosmotic to sea water, which is full of dissolved minerals. Sharks are constantly adapting to their environment. This allows water retention in the shark to be much easier. Sharks have difficulty retaining water without this mechanism. Lastly, we get to uric acid, which is also where we can try to answer your original question. Uric acid is a significant component in answering the original question. Uric acid is the nitrogenous waste of choice for birds, saurian reptiles and a very few desert-dwelling mammals like the kangaroo rat. Birds, saurian reptiles, and a very few desert-dwelling mammals like the kangaroo rat are the only animals that produce uric acid as their nitrogenous waste. Uric acid has four nitrogen molecules and is synthesized by a much more complex metabolic pathway that costs more energy, but can be eliminated using almost no water. Uric acid is a crucial component in the metabolic process of living organisms. Many desert reptiles excrete uric acid with feces as a dry mass, losing no water along the way. Desert reptiles are a common species in arid regions. So, since a uric acid is observed not only in birds, but also saurian reptiles, which also derived from dinosaurs, it is likely that the use of uric acid as nitrogenous waste came about before birds split off completely from reptiles. Uric acid is a common nitrogenous waste product in both birds and saurian reptiles. Of course, we will never know for sure, but two groups who have a common ancestor using the same form of nitrogenous waste that is by far the most difficult to make is a strong piece of evidence. There are two groups with a common ancestor.
 Black holes have no insides, so there's nothing in them. Black holes are not empty spaces, but rather contain a unique form of matter. It's basically impossible to give a short, succinct description of black holes that is also in any way even vaguely correct. Black holes are incredibly complex and difficult to understand. They are so completely different from anything we encounter in daily life that even metaphors fail. There exists a category of things that we encounter in daily life. So the best way to think of it, for the layperson just going about life wanting to be essentially educated as to how the universe works, is to imagine a very large, very old star. The universe is complex and difficult to understand. This star has used up all its fusion "fuel," if you will, and will soon collapse, exploding spectacularly in an apocalyptic cataclysm of radiation that will, briefly, outshine its whole galaxy. This star was once a source of light and energy for its galaxy. Inside the very core of that star, there's, well, more star. There are multiple layers within the star, with each layer containing more stars. The end hasn't come yet; the star is still being a star for the moment, so the interior is still star. The star has been a star for a long time. But it's *fantastically* dense. The speaker has previously mentioned something that is dense. In a minute, when the star explodes, it's going to become denser still. The star is currently not dense enough. Because you see, the thing that explodes when a star goes supernova is the *outside* of the star. Stars can explode in different ways. Imagine a bowling ball coated in cake icing … made of plastique explosive … and wired to a timer … okay this metaphor isn't very good. There is a situation that requires the use of a bowling ball. But the point is, it's the outer layer of the star that's actually going to do the exploding here in a minute. The star is going to explode soon. So let's wait. There is a situation that requires waiting. And wha-boom. There was a loud noise. Okay, that was a supernova. There were previous observations of the same celestial object. Nice one, right? The speaker is seeking validation for their actions. It happened kind of fast, so you might've missed it if you weren't watching carefully: The interior of the star reached the point where it no longer had sufficient pressure to hold the outer layers of the star up, so it essentially collapsed. The star had been stable for a long time before collapsing. The outer layer, meanwhile, began to drop like a rock, because all the pressure that had been supporting it suddenly vanished. There was a significant amount of pressure supporting the outer layer before it began to drop. This caused the star's outer layer to heat up *unbelievably* quickly, which caused lots of violently interesting things to happen. The star was previously not heating up quickly. There was a stupendous outrushing of radiation, first, and matter shortly behind it — helium and lithium ions mostly, and some other stuff. There was a catastrophic event that caused the outrushing of radiation and matter. But what you *couldn't* see was that that same explosion also went *inward. There was an explosion that occurred. *A spherically symmetric shockwave propagated inward, down toward the core of the star, compressing the already hellishly dense matter that was there until … well, the world came to an end. The star was already in a state of extreme density before the shockwave hit. There is a limit to how much *stuff* can occupy a given volume of space. There exists a measurable amount of *stuff* that can occupy a given volume of space. This is called the Bekenstein limit, after the boffin who figured it out, and I won't elaborate on it here because maths. The Bekenstein limit is a well-known concept in the scientific community. But suffice to say, there's a limit. There is a need to establish a limit. When that limit is reached — and in this case, due to the simply incomprehensible pressure exerted by that inward-focused shockwave, it was — the volume in question simply goes away. The volume in question existed before the limit was reached. Poof. Something disappeared suddenly. It ceases to exist. There was something that existed before. If you like, you can imagine God Almighty being offended by the ambitious matter and willing it out of existence in an instant. God Almighty exists. Just pop. There was a sudden loud noise. Gone. The person who was present before is no longer present. Forever. The concept of time exists. What's left, in its place, is a wee tiny … not. There was something that used to be in its place. An isn't. There was an expectation that An would be present. Part was, part isn't, part won't-ever-be, in the shape of a perfect sphere that doesn't exist. There is a concept of a perfect sphere that exists in people's minds. The boundary between where that sphere isn't and where the rest of the universe still continues to be is called the *event horizon. There is a sphere that exists in the universe. * The event horizon is not a surface. The concept of a surface is applicable to the event horizon in some way. It's not an anything. There is a context in which something is expected to be present. It's an isn't. There is a contradiction in the statement. But it *behaves* like a surface in most respects. There is an object that is being discussed. A perfect, impervious, impenetrable surface. The surface is made of an extremely durable material. If you threw something at it, that something would shatter into its component bits — and I don't mean chunks, or even dust, or even *atoms,* or even *protons and electrons. The object being referred to is solid and brittle. * I mean *individual discrete field quanta. There are other types of quanta that are not individual and discrete. * And those field quanta would spray off into space in all directions like bits of strawberry out of a liquidizer that has been unwisely started with the lid off. There is a field of quanta. That's what happens to all the *stuff* that was in the centre of that star, as well. There was a star in the center of the universe. Eventually, it'll be sprayed out into the universe in the most fundamental form possible, as little individual quanta of energy and momentum and spin and charge. The universe is made up of individual quanta of energy and momentum and spin and charge. Except due to a combination of relativity and thermodynamics, you will not actually witness that happening. There is a phenomenon that can occur, but it is not observable due to the combination of relativity and thermodynamics. Because the process takes a while. The process is necessary. For a typical stellar black hole right now? Stellar black holes are common in the universe. The process will take on the order of a trillion years. The process has already started and will continue for at least a trillion years. So don't wait up, is what I'm saying here. There is an expectation for someone to wait up. So black holes? Black holes are a known phenomenon. They have no insides. There is a group of beings that are commonly believed to have insides. They aren't. There was an expectation that "they" would be or do something. That's their defining characteristic, qualitatively speaking: They *aren't. They have other defining characteristics besides the one mentioned. * There's nothing in them, because there's no in, because they aren't. There are objects that should have something in them. There's *stuff* which is, even right this very moment as we sit here talking about it, in the process of *scattering* off black holes. There are black holes in the universe. You can't see, observe, detect or interact with any of that stuff, but we know it's there, because it has to be. There is something present that cannot be directly perceived by human senses. And we know eventually it'll spray out into the universe, first and for hundreds of billions of years as photons — a few a day — with such long wavelengths that they can barely be said to exist at all. The universe is constantly expanding. Later, *hundreds of millions of millennia* after we, our species and our solar system have long since ceased to exist, black holes will start emitting radiation we'd recognize as radio waves. 1. Then, in an accelerating process, all the way up through the electromagnetic spectrum until finally, in the last tiny fraction of a second before the black hole evaporates entirely, the potential energy available will be in the hundreds-of-electronvolts range, and we'll get the first electrons and antielectrons, then a few protons, and then a cataclysmic burst of short-lived exotic particles that lasts hardly longer than a single instant, then the black hole will have ceased to not exist. There is a black hole that is in the process of evaporating.
 I'm not a botanist/biologist so hopefully somebody can give you a better response than mine. Someone asked a question related to botany or biology. But, from my understanding in a haplobiontic life cycle the organism never switches between multicellular haploid and diploid phases and there is no alternation from one generation to the next. There is a haplobiontic life cycle. While in a diplobiontic life cycle both phases are represented by multicelluar phases and alternate by generation. Multicellular phases are the only phases present in a diplobiontic life cycle. The haploid phase would be a gametophyte with one set of genetic information, while the diploid would be a sporophyte with two sets. There is a clear distinction between haploid and diploid phases. What your notes are probably referring to is that in an organism with a haplobiontic life cycle the diploid phase is not a full fledged life form, if that makes sense. Organisms with a haplobiontic life cycle exist. An example would be something like a zygospore that is waiting to be triggered by environmental conditions to start producing the haploid phase of the organism, which in this case represents the "mature" phase of the organism that collects energy that it uses to produce more diploid structures by mating (two haploid structures fusing) to continue the cycle; it will probably be the phase of the organism that we are most familiar with. There are environmental conditions that trigger the production of the haploid phase in the organism. In a diplobiontic life cycle the organism will have a haploid form and a diploid form that may or may not be similar in appearance, structure, etc. The organism's haploid and diploid forms have distinct appearances. but will differ in the genetic information they contain. There are multiple organisms being compared. The haploid reproductive structure would be a gametophyte that produces male and/or female gametes that later on fuse to form a diploid structure that developes into a multicellular sporophyte which will develop and produce the haploid form to continue the cycle. There is a cycle of reproduction happening. What your notes are probably referring to when they say that in a diplobiontic life cycle the haploid gametophyte is suppressed is that the haploid form is often purely for reproduction like the diploid form of a haplobiontic organism I described above, while the dibloid sporophyte phase is the phase that collects the energy for the process. There is a diplobiontic life cycle. I'm not sure this is true in the same way that it is in the case of a haplobiontic life cycle, so hopefully somebody more knowledgeable can clarify that. There is a concept or phenomenon being discussed that is related to a haplobiontic life cycle. In either case "completely suppressed" might not be the best term because it might imply that they are absent. The speaker is discussing a situation where the term "completely suppressed" has been used. They are not necessarily absent, but it is more a matter of the role they play in the life cycle of the organism. The organism has a complex life cycle. I'm also not sure that it in every case the stated phase is the one suppressed, I think those are just the more common cases. There are cases where the stated phase is not the one suppressed. haplontic would mean that the organisms cells are haploid, while diplontic would mean they are diploid and haplodiplontic would mean they can be both. Organisms can only have either haploid or diploid cells. An organism that qualifies as the two former would be haplobiontic, as it each generation exists in the same phase. An organism that does not qualify as the two former would not be haplobiontic. Humans, diploids, produce humans that are also diploids (and they use the fusion of haploid (single)cells to do this). Diploid cells are necessary for the production of humans. An organism that qualifies as the latter would be diplobiontic in that it produces copies in one form that then produce the next form, and so it possess both haploid and diploid cells (not necessarily at once). The organism in question is capable of reproducing asexually. To summarize, a haplobiontic organism does not alternate generations between haplontic and diplontic forms and a diplobiontic does alternate. Organisms can be classified as either haplobiontic or diplobiontic. So for the former, the organism lives as one or the other and produces the alternate form in order to produce its next generation. The organism in question has two distinct forms of living. Growth/cellular mitosis only occurs in one phase. There are multiple phases in which cellular processes occur, but growth/cellular mitosis only occurs in one of them. In the latter, the organism lives for a while as one and then produces the other which lives as that form and produces the other and so on, alternating between the two. The organism is capable of producing multiple forms. Each phase contains a process of cellular mitosis in order to continue the cycle. Cellular mitosis is a necessary process for the continuation of life. Hopefully that makes sense and I didn't mix anything up... Hopefully if I got something wrong somebody will take the time to correct it. The speaker is unsure if their message was clear.
 in general, camouflage morphologies arise like any other aspect of development. Organisms with camouflage morphologies are common. The DNA sequences that mediate them primarily arise in the regulatory elements of genes controlling development rather than at the level of the protein sequence. Regulatory elements of genes controlling development are more important than protein sequences in mediating DNA sequences. This then results in alteration of when and where certain genes are expressed and allowed to interact with one another to effect local developmental processes. Genes have the ability to interact with each other. Assuming that some morphologies allow their carriers greater reproductive success (by not getting eaten), the DNA sequences permitting those morphologies get passed on and become more frequent in the population. Some organisms are more likely to be eaten than others. Over time, other mutations may improve on the morphology from the standpoint of camouflage and also spread through the population. There are already mutations that have improved on the morphology from the standpoint of camouflage. Give this process a few million generations, and you can get something like the picture. The process being referred to has already undergone millions of generations. Also note that other factors such as epigenetic patterns and the environment will affect the development process, leading to variation on the camouflage theme in any given individual. Epigenetic patterns and the environment have a significant impact on the development process. Unfortunately I'm not an expert on the genetics of camouflage, but I'd recommend reading work from Sean Carroll's lab if you're interested in the genetics and evolution of morphology (especially in insects). 1.
 Yes. There was a question asked prior to the response of "Yes." There are at least three ways to boost brain executive function broadly. There are various methods to enhance cognitive abilities beyond executive function. The first is aerobic exercise. Aerobic exercise is a common and widely accepted form of physical activity. 30 minutes at a challengingly high, but sustainably high, heart rate for three times per week. The person in question is physically capable of sustaining a high heart rate for 30 minutes at a time. The second is brain training. The first is physical exercise. Not all training is equal, and this is a developing field, but the Dual N Back task has good evidence of effects on IQ. There are various types of training available. Again, this is something you have to commit regular time to. Committing regular time to this is necessary for success. The third is cholinergic boosts. Cholinergic boosts have been extensively studied in the medical field. Nicotine, Donepezil, Rivistigmine. Nicotine, Donepezil, and Rivistigmine are all drugs used to treat Alzheimer's disease. The cholinergic boosts have side effects and tend to have weaker effects overall than the first two. The first two cholinergic boosts have stronger effects overall.
 Each atom can behave like a little tiny magnet (a little rotating charge, if you will), but if you have a bunch of atoms all pointing in random directions, the total magnetic field is zero. Atoms are the building blocks of matter. In magnetic materials, the magnetic moments of each atom align to point in the same direction. Magnetic materials are abundant in nature. The material property that embodies this is called magnetic susceptibility. Magnetic susceptibility is a well-known and widely studied material property.
 There is a way to analytically find a function that transforms between a uniform random variable and a random variable distributed according to some other PDF. There exists a need for a function that transforms between a uniform random variable and a random variable distributed according to some other PDF. If you have some random variable x, distributed according to the PDF f(x), and you want to find some function a(x) such that a follows some given distribution g(a), you simply require that the probability of finding x between x' and x'+dx' is equal to the probability of finding a between a' and a'+da', where a' = a(x'). The given sentence presupposes that there is a need to find a function a(x) that follows a given distribution g(a). This amounts to setting the CDFs equal to each other and solving for the unknown variable. The unknown variable is important for solving the problem. So now let's consider the special case where we're starting with a uniformly-distributed variable. Uniformly-distributed variables are commonly used in statistical analysis. These are easy to generate (approximately) using a standard PRNG algorithm like a multiplicative linear congruential generator, or something similar. A common use for PRNG algorithms is in the creation of randomized computer simulations. So let's say we have some random variable r, uniformly distributed on [0,1]. The variable r is a crucial component in the situation being discussed. The CDF for this distribution is F(r) = r.Now we want to find some x(r) such that x is distributed according to some PDF g(x). 1. The CDF for g is denoted by G(x), and we just apply the transformation rule above by setting G(x) = F(r) = r.For this method to be convenient, you have to have some functional form of the CDF G(x). 1. An example would be x distributed according to an exponential distribution. The exponential distribution is commonly used in finance. In this case, g(x) = e^(-x/k)/k. The function g(x) is commonly used in mathematical models. If you evaluate the CDF of this distribution, set it equal to r, and solve for x(r), you'll find that x(r) = -k ln(1 - r). The distribution being evaluated has a well-defined CDF. Since r is uniform in [0,1], (1 - r) is as well. The range of values for r is limited to [0,1]. So you can just as well use x(r) = -k ln(r). There is a need for a mathematical formula to solve a problem. Now, generate r uniformly in [0,1], and if you calculate x(r) for each value and histogram the results, you'll find that x(r) is distributed exponentially with mean k.This is just one particular example. 1. Another example is the [Box-Muller transform](_URL_0_), which takes two uniform random variables and generates a Gaussian random variable. The Box-Muller transform is a widely used method in statistics. If doing this transformation analytically is too difficult, or if no simple functional form of the CDF is available, you can always use a Monte Carlo acceptance-rejection method. There is a need for a transformation. This can be kind of computationally wasteful, but it's guaranteed to work. There are other methods that are less computationally wasteful but not guaranteed to work. If some analytic transformation exists, you should use it, but even if one doesn't, this is a way to generate random variables according to an arbitrary PDF. Analytic transformations are commonly used in generating random variables.
 This begs a few questions....what makes you say that a worm will sometimes come out of an apple with no entry holes? There is a belief that worms can come out of apples with no entry holes. Have you seen such a thing? There exists a thing that is unique or unusual. What makes you say that an entry hole must be visible? There is a situation where the visibility of an entry hole is being questioned.
 Technically the speed of the planet *would* have an effect on the time dilation but it would be relatively tiny; planets and stars move too slowly to notice the effects of Special Relativity (i.e. The planet in question is moving at a significant speed. time dilation due to speed) or such effects are vastly outshined by those of General Relativity (i.e. The effects of General Relativity are more significant than those of time dilation due to speed. time dilation due to gravity). Gravity affects time differently in different parts of the universe. To notice time dilation due to speed you have to get much closer to the speed of light than any planetary body we know of does. The speed of light is the fastest speed possible.
 It depends on the kind of study, sometimes they do. _URL_0_ >  No significant difference was shown in energy excretion in stools between lean and obese subjects who consumed the 2400-kcal/d diet [134.3 ± 48.9 kcal/d (lean) compared with 133.2 ± 44.8 kcal/d (obese) (P = 0.96); 4.9 ± 1.8% compared with 4.8 ± 1.4% (P = 0.87), respectively] or 3400-kcal/d diet [145.1 ± 42.7 kcal/d (lean) compared with 173.7 ± 65.0 kcal/d (obese) (P = 0.21); 3.8 ± 1.1% compared with 4.6 ± 1.8% (P = 0.240), respectively]. 1. However, there was a large interindividual range for the percentage of calories lost in stools (2400-kcal/d diet: 2.1–9.2%; 3400-kcal/d diet: 1.6–7.6%). There were significant differences in the percentage of calories lost in stools between the two diets mentioned. So between 1.6% and 9.2% of calories consumed are lost in the stool... >  The change in the percentage of urine calories between the 2400- and 3400-kcal/d diets was not different in either lean or obese subjects [−0.5 ± 0.5% (P = 0.34) and −0.6 ± 0.5% (P = 0.15)]. 1. In addition, calories in urine were not different between lean and obese subjects when expressed as total calories or as the percentage of ingested calories with either the 2400-kcal/d diet [88.4 ± 30.8 kcal/d (lean) compared with 99.3 ± 31.2 kcal/d (obese) (P = 0.48) and 3.2 ± 1.1% (lean) compared with 3.5 ± 1.1% (obese) (P = 0.56)] or the 3400-kcal/d diet [106.0 ± 34.1 kcal/d compared with 112.6 ± 28.4 kcal/d (P = 0.64) and 2.8 ± 0.9% compared with 2.9 ± 0.7% (P = 0.72)]. There were no significant differences in calorie excretion between lean and obese subjects. ...and between 0.7% and 1.1% of calories consumed are lost in the urine. Calories lost in urine can have a significant impact on overall calorie intake. Assuming I'm reading that correctly. There is a possibility that the speaker may not be reading correctly.
 I am not a NASA flight surgeon, but I can talk about how quickly they could get home. NASA has a team of flight surgeons. The ISS makes 16 orbits around the earth a day. The earth is the only planet that the ISS orbits around. Essentially the world turns beneath the orbit, which means each orbit is over a different part of the world. The Earth's rotation is responsible for the movement of the orbit. Twice a day or so, on two sequential orbits, the Soyuz could return to its primary landing site in Kazakhstan. The Soyuz has a primary landing site in Kazakhstan. If there is a crew emergency that cannot wait up to a day, there are contingency sites in North America, wide open prairies or farmland that would be considered, depending on the weather that day. There have been crew emergencies in the past that have required immediate action. These sites are usually within a helicopter ride of a hyperbaric chamber... useful if an astronaut had too low air pressure in his or her spacesuit while on a spacewalk. There are frequent spacewalks that astronauts go on.
 I think you're reasoning that a large bird could obviously beat a small bird, so why bother defending the nest if the large bird knows that? There is a nest that needs defending. Well if the two bird were to enter into conflict, it would come at a cost to both of them (energy, risk of injury, risk of predation, etc.). There are at at least two birds present in the situation. Now a bird defending its nest is going to be more likely to risk these costs, because its fitness is tightly linked to offspring survival. Birds have a strong instinct to defend their nests. A large bird might just be sacrificing dinner. There is a large bird present in the area. It's an extension of the life-dinner principle. The life-dinner principle is a well-known concept. I'll add that, although size is very important in determining the outcomes of conflicts within species, it's not always a great predictor between species. Size is a crucial factor in determining the outcomes of conflicts within a species. Sometimes smaller species are better/quicker/meaner than larger species. Larger species are not always better/quicker/meaner than smaller species.
 It means exactly that: out of the four forces, gravity is the weakest one. Gravity is one of the four fundamental forces. Gravity only seems strong because we live right next to a giant mass of rock and experience gravity all the time. There are other forces at play that make gravity seem strong. When an entire planet worth of gravity is opposed to a small fridge magnet worth of magnetic force, the fridge magnet usually wins. There is a planet with a significant amount of gravity. That's how weak gravity is. Gravity is generally considered to be a strong force.
 The short answer to this is no. There was a question asked. All living things (I am excluding viruses from this discussion) are composed of cells surrounded by a membrane. All organisms have a membrane that surrounds their cells. They also all use DNA to store the instructions necessary to create proteins. DNA is the only way to store instructions for creating proteins. Given these similarities, scientists have concluded that all life on Earth shares a common ancestor. All life on Earth has similarities. It is important to note that this does not preclude the possibility that life *originated* elsewhere however. Life exists elsewhere in the universe. Since all life must perform many of the same functions (DNA replication, protein synthesis, metabolism), there is a subset of genes that all currently known living organisms possess. All living organisms have DNA. One of the most well-described of these genes is is the ribosomal RNA (or rRNA) gene. The ribosomal RNA gene is crucial for the survival of the organism. Similarities in this gene are used to determine the "relatedness" of two species since parts of it are not under selective pressure and can mutate at a (somewhat) predictable rate. Two species being related is important information.
 Depends on who you ask. There are varying opinions on the matter. Most of the time a lake is a natural freshwater body with an inlet and an outlet, a pond is usually a man-made water body that doesn't necessarily have inlets/outlets, and a lagoon is usually a body of ocean/sea water that lies behind a barrier such as a reef. There are bodies of water that do not fit the definitions of lake, pond, or lagoon. Those are the general definitions, but there are exceptions depending on who you talk to, what the history of the water body in question is, and personal preference. There are multiple definitions for the term in question.
 In terms of structure, soaps are long, nonpolar (oleophilic/oil-loving) alkane chains with a polar (hydrophilic/water-loving) end. Soaps are commonly used in everyday life. The nonpolar section of the molecule solvates (grabs onto) oils and greases and surrounds and isolates them as a [micelle](_URL_3_) with the polar ends pointing outward. Micelles are commonly found in nature. upon flushing these micelles with water, the polar interaction between them sweeps the soap and oils/greases away and down the drain. The micelles were previously coated in soap and oils/greases. [Here](_URL_1_) is a typical soap, Sodium Stearate. Sodium Stearate is a common ingredient in many soaps. You can see the long nonpolar region and the polar end where the sodium (Na) ion is. There is a microscope or other device that allows for viewing the nonpolar region and polar end. The function of detergents is fairly similar, ~~but some detergents use surfactants rather than soaps~~. Detergents are commonly used for cleaning. [The wiki article](_URL_0_) for detergents gives pretty good details on some different varieties. There are multiple varieties of detergents. I'm not sure if this is quite what you meant by "effect of soap and detergents on the environment", but in terms of biodegradability, it seems the trick is to make the soap without using additives (only fats/oils, lye and water). Soap and detergents have a negative impact on the environment. Surfactants and detergents are, in general, less biodegradable than soap molecules. Soap molecules are biodegradable. It seems to me that most of the recent improvements have been a matter of doing [the same things, but better and faster than before](_URL_2_). The previous methods were inefficient. I wish I had some more information on a big and new industry improvement, but it seems like more or less, soap is being made as it has been for a while. There has been a recent development in the industry. The reason to skip on the additives for biodegradability is that many of the artificial additives and fragrances are environmentally persistent, generally getting where they ought not be, or they degrade into pieces that are harmful to the environment. Artificial additives and fragrances are commonly used in products. If the degradation products are very harmful, they're generally left out altogether for obvious reasons; most companies that value their PR would screen these out in the R & D process. Companies that do not value their PR may not screen out harmful degradation products in the R&D process. Perhaps someone else has a bit more info on this topic who is closer to the industry...Let me know if that answers your question, and if anything is unclear! 1. ~M-----------------------------------------------------**Tl;dr**: ~~There doesn't appear to be any earth-shattering new advances in the soap making process; it's a pretty mature industry.~~ The industry has not changed *tremendously* in recent years, but see below for details pertaining to enzymes, additives, Phosphorus addition (or recent lack thereof). 1. See also /u/meandyouandx 's post with some insights on the industry. There is an industry being discussed. edit: Thanks /u/ucstruct and /u/yoenit, I've been straightened out: soaps and detergents are both surfactants, and soaps are a specific type of detergent. Soaps and detergents are commonly used in households. edit 2: Many additional comments below just go to show my passing knowledge on the subject; keep reading, there's good stuff below! There are multiple comments below the sentence.
 No. I'm sorry, but the sentence indicated by angel brackets is not provided. Even though the image on your retina is upside down relative to the object you're observing, the brain doesn't actually do any 'flipping'. The brain is capable of processing visual information in a way that compensates for the upside-down image on the retina. It just knows (through early development) which neurons connected to cells on your retina are associated with which direction, and so in that sense it is hard-wired into your brain. The brain's hard-wiring is not influenced by external factors.
 > where as in America it seems to be a linchpin of society. There is a significant cultural difference between the location mentioned and America. While my expertise is not in cultural studies, as an American psychiatrist I would argue that this is not really the case. There is a debate or disagreement about cultural studies. There is actually quite a stigma towards psychotherapy. Psychotherapy is not widely accepted by society. Anyway, I wouldn't use your phrasing (i.e., "works"), but yes, psychotherapy can be very helpful in reducing the symptoms of some psychological disorders. Psychotherapy is a common treatment for psychological disorders. One of the most researched therapies is an approach known as [Cognitive Behavioral Therapy](_URL_0_). Cognitive Behavioral Therapy is widely accepted as an effective treatment. Obviously studying a treatment method like this is fraught with methodological limitations, however there is evidence that it can be beneficial for symptom reduction in some psychological disorders. There are psychological disorders that require treatment.
 For vertical loads with the same diameter steel bars, the four pillar towers would be stronger. Steel bars are commonly used in construction. The stress in the pillars depends on the cross sectional area of the steel. The pillars are made of steel. Same with the deflection due to bending from the wind forces, which depends on the moment of inertia (and therefore the cross sectional area and distance from the centroidal axis). The cross sectional area of the object in question is significant. The triangle trusses are lighter and sufficient in many cases, but the box trusses are definitely stronger. There are situations where weight is a crucial factor in construction.
 It explodes in all directions uniformly. There is an explosive device. Because it's so far away and there's no shadows, it's hard to see depth. There is an object that is far away. So rays that are coming a bit more towards you just look like shorter/slower rays moving to the side. There is a person observing rays. It's kinda like a photo of an atmosphere, which look like a colored circle around the planet while it's in fact an orb. The planet in question has a unique and distinct atmosphere.
 Any acceleration would effectively be an “error” term on both your velocity and friction factor. There is a need for velocity and friction factor calculations. How large and meaningful that error is depends on the magnitude of the acceleration compared to the magnitude of the fluid velocity. There is a fluid velocity and an acceleration present. What matters more is what the span of velocities are. There is a situation where the span of velocities is important. A good exercise would be to find the pressure loss at the expected minimum and maximum fluid velocity. There is a fluid system in place. How different those two number numbers are should give you a decent idea of how good of an approximation you have. There are two numbers being compared.
 There are some relations that might be interesting to you from investigations of hopper flow. There have been investigations of hopper flow. The discharge rate through a hopper may be described by:W = C*ρ*g*(D−k*d)^2.5 ,where ρ is the particle density, g is the acceleration due to gravity, D is the aperture diameter, and d is the particle diameter (for a monodisperse particle system), while C and k are unitless constants. Particles passing through a hopper are subject to a discharge rate. See _URL_0_ and references therein. There are references available at the URL provided. All grains in the hourglass are subject to gravitational acceleration. Grains outside of the hourglass are not subject to gravitational acceleration. If you look at grains in the top of the top half in the center, their downward velocity is related to the discharge rate. Grains are present in the top half of the center. However, this rate increases as the level in the top half get low. The top half refers to a specific group or category. There is friction between the particle in hourglasses because the grains converge toward the center (slowing down the flow which would otherwise free fall) Particles in hourglasses are made of different materials.
 To try and put this in perspective:There is an experiement which demonstrates something called the casimir effect. The casimir effect is a well-known phenomenon in the scientific community. This is basically where two very very thin (Low mass) metal plates are placed very close together. There is a need for two very thin metal plates to be placed close together. The gravitational attraction is designed to be almost 0, and so is the electromagnetic, and van der waals forces etc. There is a need for forces to be almost 0 in certain situations. Ultimately there is no interaction between the plates. The plates were initially expected to interact. However what we find is that the plates are pushed together slightly. The plates were expected to be pulled apart. This is caused by the "Energy Density of the Vacuum" which spontaneously produces particles at all points in space, existing for miniscule amounts of time and then disappearing, not violating Heisenberg's uncertainty principle (Not Breaking Bad :P). Particles are constantly being produced and disappearing in all points of space due to the Energy Density of the Vacuum. We observe this effect because inside the plates, only certain size wavelengths of particles can exist (half wavelengths to be exact). Particles of other sizes cannot exist inside the plates. However outside the plates there is somewhat "more vacuum" than inside the plates, and so the spontaneous creation of particles causes a pressure on the plates pushing them together. There is a significant difference in pressure between the inside and outside of the plates. This effect is well documented, and has an associated "Energy density of the vacuum". There is a scientific community that has documented this effect. When we discovered that the universe was accelerating in it's expansion, and we reignited the cosmological constant as this force, we hoped this casimir effect might be the answer. The universe was not accelerating in its expansion before the discovery mentioned in the sentence. However, our observations show that the energy densit of the vacuum in the casimir effect is approx.~ 120 orders of magnitude larger than the apparent cosmological constant required to explain Dark Energy! The existence of Dark Energy is widely accepted. This is an incredibly large error (Stupidly large). There have been previous errors that were not as large. So, I hope this gives you some real world idea of the most likely candidate for the cosmological constant, despite the error hopefully we can fix that. There is a cosmological constant that needs to be identified. Source: Dissertation on Dark Energy and the Cosmological Constant. The universe is expanding. (I can send you my paper if you want). You have already received the paper.
 Let's consider the Fourier transform (the Laplace is slightly more complicated, but only slightly). The Laplace transform is not as commonly used as the Fourier transform. The basis functions of the Fourier transform are sinusoids. Sinusoids are the only basis functions of the Fourier transform. However, a sinusoid is more than just a frequency; it is a frequency *and* a phase. A sinusoid is commonly thought of as only a frequency. This is often not the most convenient expression to work with, so you can apply a trig identity and instead represent the sinusoid as a sinewave plus a cosine, each having the same frequency but a different amplitude. Trig identities are commonly used in mathematics. This is also not the most convenient expression to work with, so you can apply Euler's identity and write the sinusoid as a complex exponential. Euler's identity is a well-known mathematical formula. There is your (e\^something). There is something that belongs to you. The transform gives the "amount" of the function present at a given frequency. The function being transformed has a specific frequency. This is obtained by *correlating* the function with a sinusoid of the frequency of interest. The function being correlated has a clear and distinct pattern. There is your "multiplied by (e\^something)". There exists a mathematical equation involving multiplication and the constant e.The value of the exponent in the equation is significant. Easy peasy. The task at hand is simple. [Here's the full story with pictures](_URL_0_) if you're interested. There are pictures available for the story. However, if you're into compact abelian groups, read what the other guy wrote. There is another person who wrote about compact abelian groups.
 Bars, and indeed spiral galaxies in general, are formed by density waves - that is, the structures are stable, but the placement of a given star within the structure varies. Spiral galaxies are the only type of galaxies formed by density waves. Mutual interactions between the stars keep the structure stable. The stars in question are part of a larger structure. This is hard to get your head around, so here are a couple of animations - _URL_1_ _URL_0_ These don't show bars, unfortunately, but the same general theory applies (as described in the paper linked in one of the other comments). There are complex theories that require visual aids to understand.
 There are programs that do this, you can search for automatic image vectorization. There is a high demand for automatic image vectorization. Plenty of web services. There is a high demand for web services. The basic algorithmic approach is to trace the outline of the image (or of each solid colored block). The image or solid colored block has a clear outline. Then you fit parametric (bezier) curves to your trace, and you have a vector outline that can be scaled as desired. There is a trace that needs to be scaled. There are heuristics involved in the tracing process, but generally works very well as long as you have good inputs. The tracing process is a common practice. On the other hand, if your input is super low resolution, the trace becomes more ambiguous and your output is less likely to be what you want. Low resolution images are common in digital media. Similarly, it works well for large blocks of solid color, but if you try to feed in something with lots of noise, gradients or textures, most approaches will do poorly. There are many approaches to image processing. Here's a paper from 2003 that covers some of the techniques used for the tracing portion: _URL_0_ There were multiple papers published in 2003 that covered the techniques used for the tracing portion.
 Water always freezes at the same temperature. Water is always in a liquid state before it freezes. The stream and the pond just have different ways of distributing the heat and ice that allows the pond to freeze over first. The stream and the pond are located in different climates. In a pond, as you get close to freezing, the warmer water sinks to the bottom. The pond is large enough to have different temperature layers. The water at the surface is exchanging heat with the air, so once the air gets below 0 C and the surface water is at 0 C, ice will form. The air temperature is currently above 0 C. The water at the surface is not frozen. Without strong currents, the ice forms a smooth sheet on the top with liquid water below. There is a body of water with ice on top. In a stream, the flow ensures the water is mixed and the temperature is more uniform from top to bottom. The water in the stream is not mixed without the flow. So you need to cool the entire volume to 0 C, not just the surface layer. The substance being cooled is capable of reaching temperatures above 0 C. The cooling process will take a significant amount of time. And you need to cool it before it flows out of the stream. The stream is hot. Once the water gets down to 0 C, ice can begin to form. Water is present. But any ice will be pulled along with the current, so the stream deposits the ice at its edges first. The stream has edges.
 Pre-telescope astronomers didn't know the order and size of the planets. Astronomers after the invention of the telescope knew the order and size of the planets. Around the same time as the telescope was introduced,  Copernicus, Brahe, Kepler, and Newton came up with ideas about gravity, planetary motion, and planetary orbits that enabled people to figure out the orbits (position and speed)  of planets. People were unable to figure out the orbits of planets before the introduction of the telescope. The planets that are travelling around the Sun faster are closer to the Sun,  and the planets that are travelling around the Sun slower are farther from the Sun. There is a clear distinction between the speed of planets orbiting the Sun. After the introduction of the telescope astronomers were able to begin seeing planets much better - through telescopes they didn't just look like moving stars in the sky,  but rather astronomers could actually see them as discs or round objects. Astronomers were unable to see planets before the introduction of the telescope. Pre-telescope astronomers didn't know about any moons other than Earth's Moon. There were other moons in the solar system that pre-telescope astronomers were unaware of. After the introduction of the telescope astronomers were able to begin seeing moons. Astronomers were not able to see moons before the introduction of the telescope. By looking at the actual appearance of planets via telescopes,  and  by  calculating the orbits of moons around planets,  astronomers  were able to begin  calculating the mass and size of planets. Astronomers were unable to calculate the mass and size of planets before the invention of telescopes and the study of moon orbits.
 Every SSD I've come across supports actually erasing the entire drive by issuing an ATA Secure Erase command: _URL_0_The problem with other erasure methods is that the wear leveling and compression algorithms in the controller will transparently remap your writes, so you won't be writing to the memory cells you think you are, and will leave some memory untouched, either because the data was compressed or just because the SSD has a physically higher memory capacity than it exposes externally. SSDs are widely used for data storage. If you use a piece of software that just tries to write zeroes to every logical sector of the drive and then read the whole disk back afterwards, it will appear that the entire drive is empty, but there's a translation layer between the logical data storage that your operating system depends on and what's physically happening inside the device. There is a need to erase data from a drive. ATA Secure Erase is an instruction to the drive firmware that asks it to internally erase all blocks, bypassing all the tricks the controller performs for performance and reliability reasons during normal operation. The drive firmware has blocks that can be erased.
 I assume you're talking about saccadic masking, rather than the broader saccades, which is the whole process of looking at different parts of whatever you're looking at. The speaker has knowledge about saccadic masking and saccades. Masking is the part of the process where the brain masks out the motion blur in the transition between two focal areas. The brain is capable of masking out motion blur. It's important in any question about why something evolved to note that there is no such thing as an "evolutionary reason," because that suggests that evolution is a deliberate process - i.e. Evolution is not a deliberate process. that a lemur at some point decided to start a process to evolve into humans and so that's why humans are here. Lemurs have the ability to make conscious decisions. Evolution is simply passing on or weeding out of genetic instructions based on how effective those instructions are at making a life form that can survive. Life forms have genetic instructions. So, for instance, if you were a mutant cheetah who's mutation helped you run faster than other cheetahs, you'd be more likely to catch prey, therefore more likely to eat, therefore more likely to survive long enough to impregnate another cheetah and pass your mutant fast-cheetah genes on to the next generation. 1. If, on the other hand, you were a mutant cheetah who only grew 2 legs, you'd be very unlikely to survive anywhere near long enough to mate, and so your non-beneficial mutation would not be passed on. Mutant cheetahs with only 2 legs exist in the world. What this has to do with saccadic masking is that it's not hard to imagine that a creature with the brain structure that processes vision as we do (not all animals do), but who is incapable of saccadic masking, would be in a living hell. A creature with the brain structure that processes vision differently from humans may not be affected by saccadic masking. Every time its eyes moved, the world would blur like an extremely fast swish pan in a movie. The entity with the moving eyes is a living being. This would be incredibly disorienting, not to mention nauseating. The situation is so overwhelming that it would cause disorientation and nausea. Now put that non-masking creature next to a masking creature and consider the differences - while the masking creature sees an ordered world and walks gracefully through it on its way to food, shelter, and sex, the non-masking creature sees brief flashes of distinguishable images interspersed with insanely disorienting motion blurs. There are two different types of creatures being compared in the sentence. It would stumble about, possibly throw up, have a hard time finding food - in short, its survival would be very much in question. The environment is hostile and challenging for the subject. Hence, saccadic masking would logically be naturally selected to be passed on. It should be noted that, as with most "how did this widget in the body evolve" questions, this is highly speculative. There is a widget in the body that is being questioned.
 In an ideal circuit, the current flowing through two parallel paths will be dependent on their respective resistances. There are at least two parallel paths in the circuit. The path with lower resistance will have higher current flowing through it. There is a path with lower resistance. This is true because each path (as they are in parallel) will have equal voltage differences. There are multiple paths in the situation being described. Since V=IR, a lower resistance necessitates a higher current. Electricity is being used in the situation. The only way that current flows through one path and "ignores" the other is if one path has 0 ohms of resistance. There are two paths for current to flow. In other words, it is a perfect conductor (in real life, even the best conductors have some resistance). There are no perfect conductors in real life. Current is higher in the path with less resistance because electrons are able flow through it more easily. There is a path with less resistance. Current is essentially the number of electrons that flow through an area in a given amount of time, and resistance effectively slows that flow down. Electrons are the only particles that contribute to current flow. Therefore, less resistance results in greater flow (e.g. Greater flow is desirable. higher current). There was a previous current that was lower than the current being referred to in the sentence. You can think of current like water flow. Electricity is similar to water in that it flows in a specific direction. You have two pipes connected in parallel, one with a lot of blockage and one with little blockage. There is a plumbing system in place. The water flow will be greater in the pipe with less blockage. There are multiple pipes with varying degrees of blockage. The water doesn't "know" which pipe has less blockage. The water is sentient and capable of making decisions. It just flows more easily through the one that does. There is a substance that flows through something.
 More stable than what? There was a previous situation where stability was lacking. Phosphines, with their three bonds and a lone pair, are perfectly stable until oxygen comes along and spoils everyone's fun. Same with organic sulfides; they can be oxidized to sulfoxides and sulfones. Organic sulfides are commonly found in nature. The real question here is whether these two elements are actually breaking the octet rule when forming structures whose Lewis dot structures give more than 8 electrons to the S/P atom. There is a debate about whether the octet rule is a reliable guideline for predicting the behavior of elements. The general (and growing) consensus is that they don't! There is a topic or issue being discussed. The notion that sulfur and phosphorus have d-orbitals available to form extra bonds is a fiction, and not even a particularly useful one (like, say, VSEPR). Sulfur and phosphorus do not have d-orbitals available to form extra bonds. What distinguishes S from O or P from N are their large atomic size sand their low electronegativities. Elements with small atomic sizes and high electronegativities are not distinguishable from each other. They have a tendency to make more bonds because more atoms fit around them, and they can form bonds with larger ionic character with highly electronegative atoms. There are more atoms around them than other elements. Ever notice how you never see hypervalent compounds with a bunch of bonds to hydrogen, like PH6^- or SH6? That's because hydrogen isn't electronegative enough to form those bonds with high ionic character. Ionic bonds are formed by elements with high electronegativity.
 Extra testosterone won't add new follicles, however it will cause hair to turn from [vellus hair](_URL_0_) to [androgenic terminal hair](_URL_1_) in the classically male pattern. Testosterone is the only factor that causes hair to turn from vellus to androgenic terminal hair in the classically male pattern. Once a hair turns to a terminal hair it will not turn back to vellus. Terminal hairs are more desirable than vellus hairs. This can be seen in some women who have polycystic ovarian syndrome which can cause an increase in androgeneic hormones. Some women do not have polycystic ovarian syndrome and therefore do not experience an increase in androgeneic hormones. Another side effect that is really important is the increase in the amount of red blood cells you have. You already have side effects. It doesn't sound like a problem, but it really is. There is an issue that is being discussed. It can cause hyperviscosity syndrome which taxes the circulatory system and your body's ability to oxygenate itself. Hyperviscosity syndrome is a common condition. This extra viscosity makes it harder for your heart to pump the same volume of blood throughout your body, so your red blood cells aren't getting oxygenated in the lungs fast enough. The blood in question has a higher than normal viscosity. Another issue with too many extra RBCs is related to blood clotting. Blood clotting is a common problem associated with extra RBCs. It can cause pulmonary embolisms, deep vein thrombosis, heart attacks, and strokes. There are known cases where the mentioned conditions were caused by something else. All of these side effects can occur at **any age**. People of all ages can experience these side effects. All in all unless there is a medical reason, such as gender reassignment, low testosterone, etc. There are certain medical reasons that can exempt someone from a particular requirement. there are too many risks in using testosterone for illicit means. Testosterone is commonly used for illicit purposes.
 The vitamins may not absorb correctly. The body is in need of vitamins. Though they may also not be absorbed from food either. There is a substance that may or may not be absorbed from food. 1. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Your body may not absorb them correctly without other food to digest. Other foods can help your body absorb them correctly. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. The vitamins may not be necessary in the large doses vitamins provide. Vitamins in small doses may be more effective than large doses. Excess water soluble vitamins will be excreted. The body has excess water soluble vitamins. Fat soluble vitamins will likely be stored in your fat. Your body contains fat soluble vitamins. If you take too many fat soluble vitamins, you can get too much, or even overdose. Taking fat soluble vitamins is common. If you're eating a fairly well rounded diet, vitamins are not necessary. You are currently not eating a fairly well rounded diet. Some supplements like Vitamin D can be helpful even with a well rounded diet. Supplements are often necessary to maintain a healthy lifestyle.
 Black holes are generally detected through the xrays emitted from the matter in their accretion disks as it gets compressed and mightily heated as it spirals down toward their event horizons. There is a significant amount of matter in the accretion disks of black holes. "Rogue" kind of implies it's moving through space, not bound gravitationality with other objects. There are other objects in space that are bound by gravity. We can detect them, but only if they run into something that lights up. Something that lights up exists. Really big ones can be also be detected by their gravitational effects - orbits of stars being deflected. There are other ways to detect really big objects in space besides their gravitational effects. Objects can also be detected through microlensing effects - background stars and galaxies light flaring as it is magnified or dimmed as it is deflected by the gravity of the black hole. There are black holes in the universe. At one point their was a theory that dark matter halos of galaxies might be composed of a lot of pretty small black holes. There is a significant amount of evidence that supports the theory of dark matter halos being composed of small black holes. However, to make up the mass, there would need to be a LOT of microlensing events. There is a significant amount of mass that needs to be made up. There were some studies looking for them. Some people were actively searching for them. Not enough were detected for dark matter to be from the small black hole theory. There is a theory that suggests dark matter comes from something other than small black holes. One could in theory use microlensing to  track a rogue black hole once you'd initially located it and gotten a 2nd fix on its location; but its an awfully big sky and they're pretty small. Microlensing has been successfully used to track other celestial objects. You might have to look a pretty long time to find your first one. There are many items to search through. ---EDIT--- Relevant article _URL_0_ The article indicated by the URL is relevant to the topic at hand.
 Disclaimer, I've never worked in this field. There is a field that the speaker is referring to. I'd say it really boils down to them being a custom built. The speaker has previously discussed the topic of the custom built item. Transformers are in principle very simple. Transformers are often considered complex by many people. You have them all over your house. You have a lot of clutter in your house. The smallest ones can cost just a couple dollars. _URL_0_A very simplistic transformer diagram featured above. The diagram is a recent invention. And indeed it's almost that simple for very small voltages (100s volts is very small compared to national grids). There are national grids that operate on much higher voltages than 100s volts. But on a city scale we are talking about 100,000s of volts. There is a city with a population large enough to require 100,000s of volts. And often they'll be transforming from different input voltages to different output voltages, hence why they tend to be custom orders and not a "shelf" product. There are multiple types of electronic devices that require voltage transformation. Think about the difference between having to build a software that fits your needs (as hospitals often do) compared to just getting one that's already been created. There is a need for software in hospitals. It would still take time to integrate it to your systems but you'd be cutting the whole production time. Your systems are not currently integrated. A city or state will open a bidding war between companies. There are multiple companies interested in bidding. This will take plenty of time by itself. There are other tasks that will not take as much time. That company will then need the raw materials to build it, and you can bet that company will have their own bid war on such materials. The company in question has already secured the necessary funding for the project. So we could already be talking 3 countries involved at this stage, if not more. There are multiple ongoing conflicts involving at least three countries. Which means international imports of big, heavy materials and parts. There is a high demand for big, heavy materials and parts in the international market. Meanwhile there will be other building phases such as planning, design and testing. There are other building phases that are equally important. Shipping from another country, China to the US for example. The products being shipped are high-value and require special handling. And then of course there will be the installation side. There is a project or plan that requires installation. This isn't something that happens everyday so you'll need to build the team of engineers to install it. There is a complex and unique project that requires a team of engineers to install it. Arrange for the transportation to the location. There is a specific location that needs transportation arranged for. If you compare the whole process to say, offshore wind turbines, where they're also massive however we do them much faster. Offshore wind turbines are a common point of comparison for this process. How? There is a specific action or task that needs to be accomplished. Because we already have most of the above processes out of the way. The processes mentioned were difficult to complete. That is, if you had to install 100+ of identical transformers it wouldn't take 1 year each. There is a need to install 100+ identical transformers. Even if you already had one lying around, you'd still need to assemble a team and equipment to transport and install it. There is a valuable object that requires a team and equipment to transport and install. So complex logistics is the issue. There are multiple parties involved in the logistics issue.
 > In other words, are there colors that can't be produced using light or the color wheel but still exist in the visible spectrum? There is a possibility that there are colors that exist in the visible spectrum but cannot be produced using light or the color wheel. The other posters are wrong. The other posters have made incorrect assumptions. It *is* possible, but not under normal circumstances for normal humans. There are extraordinary circumstances that allow for the possibility mentioned. Most humans are trichromats, meaning that we have three different types of light sensors (called cones) in our eyes. Humans without trichromatic vision are at a disadvantage in certain situations. When light comes in, these sensors are excited to different extents, as shown here: _URL_0_Your brain interprets the combination of three types of signals as color. Light is always present to excite the sensors. And colors like "brown" don't have a specific wavelength of light (ever seen a brown rainbow?). There are no colors that do not have a specific wavelength of light. Note the green and red receptors and how much they overlap. There are both green and red receptors present. In order to perceive non-standard colors, you have to selectively disable either the green or red receptor, usually by overexposing one color so the receptors get "tired". There are non-standard colors that cannot be perceived without disabling either the green or red receptor. This will enable signals to be sent that do not correspond to any wavelength of light, allowing you to experience a brand new color as your brain tries to make sense of it. There are currently no known colors that do not correspond to any wavelength of light. Super greens and reds are possible by this method. This method has been tested and proven to work.
 > Can electro magnets be not only switched ON or OFF, but can their percentage of magnetic capabilities also be controlled? Electro magnets have magnetic capabilities that can be controlled. Yes, you can tune the field strength by controlling the amount of current flowing through them. The field strength needs to be tuned. > What type of negative effects do magnets have on cell phones, laptops, TVs, etc? Electronic devices are affected by magnets. Strong, changing magnetic fields can interfere with electronic circuits. Electronic circuits are commonly used in everyday life. They can also mess with hard drives, magnetic strips on credit cards, etc. There is a group of people who have the ability to manipulate hard drives and magnetic strips on credit cards.
 What you're asking about are very distantly related birds. There are many types of birds in the world. In that case, the answer is no. The speaker previously asked a question. Birds are incredibly diverse, with over 10,000 living species. There are more bird species than any other type of animal on Earth. Distantly related birds not able to hybridize any more than a tiger and a giraffe can hybridize. Birds and mammals cannot hybridize. However, within families you can definitely get some weird hybridization. Families are typically homogeneous. A number of duck species hybridize with the mallard. Ducks are capable of hybridizing with multiple species. For example, here's a report on [American black duck-mallard hybrids](_URL_1_). American black duck-mallard hybrids are a common species. Several members of the [pheasant family can hybridize](_URL_2_). The pheasant family is a diverse group of birds. They're the most extreme example I can think of, because they'll readily hybridize between different genera. There are multiple genera that can hybridize readily. This isn't something unique to birds, though. Other animals also exhibit this behavior. There are multiple instances of this happening with crocs, like [this hybrid](_URL_0_) between a Cuban crocodile (*Crocodylus rhombifer*) and an American crocodile (*C. acutus*). Crocodiles are frequently bred in captivity for hybridization. And plenty of mammals hybridize. Mammals are capable of hybridization.
 In most cases, the moment of death would be defined by the irreversible cessation of a heartbeat. Death is not always defined by the cessation of a heartbeat. In the scenarios you mentioned:* a lethal blow to the head would cause massive intracranial hemorrhage leading to herniation of the brain, loss of spontaneous breathing, and then cardiac arrest. There are scenarios that involve a lethal blow to the head. Herniation may also lead directly to cardiac arrest. Cardiac arrest is a common outcome of herniation. * immersion in water leads to lack of oxygen and resulting cardiac arrest. Water is a necessary element for human survival. ----Patients may die by brain criteria, also called *brain death*, if there is irreversible cessation of function of the entire brain. The existence of brain criteria for death is widely accepted in the medical community. These patients will continue to have a heartbeat for a short while, often no more than a few days, if continued on a mechanical ventilator. Patients who are not on a mechanical ventilator will not have a heartbeat for a short while. Brain death results in lack of automatic breathing, so patients not on a ventilator will rapidly become hypoxic and have a cardiac arrest. Patients who are brain dead cannot breathe on their own. Either way, they can be legally and ethically dead by reason of irreversible whole-brain dysfunction before the heart stops. There is a legal and ethical framework in place for determining when someone is dead. To give a somewhat grisly example, a person killed by rifle fire to the head would likely be dead by brain criteria immediately, since high-energy rifle rounds cause massive disruption of the skull contents, while the heart (being undamaged) may continue to beat for a short while on the order of a few minutes, gradually deteriorating from decreasing oxygen and blood volume until, starved of both, it stops. The person in question was shot in the head with a high-energy rifle round.
 Glaciers deposit rocks and gravel in a "terminal moraine" at their edges: we can map this and estimate the area that was covered by ice sheet. There was an ice sheet in the area. But the thickness is a little trickier. The material being discussed has a thickness. There are three ways to calculate the ice sheet thickness:First, we can use mathematical and computer modeling of the ancient ice sheets. The ice sheet thickness is a significant factor in climate change research. All the modern ice sheets (Greenland, Antarctica) have a particular height profile that depends on the properties of ice, so we assume the same physics applied during the last ice age. The ice sheets of Greenland and Antarctica have a unique height profile that is not found in any other region of the world. We also know the amount that sea level dropped during the last glacial maximum. Sea level rose significantly after the last glacial maximum. We can compare the volume of water in our simulated ice sheets against the volume of water missing from the ocean. There is a significant amount of water missing from the ocean. Finally, we can identify a few mountains where the ice flowed around the mountain but didn't get over the top: that tells us how high the ice was at that location. There was a study conducted on the ice flow around mountains. _URL_1__URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 It depends on how sharp the blade is. The blade is sharp enough to cause harm. If the edge of the blade is larger than cells (such as with any steel knife, then yes you're just separating the tissue rather than cutting cells. The blade being larger than cells is a common occurrence with steel knives. Blades made of glass or diamond, such as those used in [ultramicrotomy](_URL_1_) and preparation of samples of transmission electron microscopy are capable of cutting cells. Blades made of glass or diamond are commonly used in ultramicrotomy and preparation of samples of transmission electron microscopy. A diamond blade of a microtome can slice a red blood cell into 100 slices! A red blood cell is a common object to be sliced by a diamond blade of a microtome. [Diamond blades](_URL_0_) are even capable of slicing viruses which are much much smaller than cells. Viruses are a significant threat to human health. Blades made of [obsidian](_URL_2_) are also amazingly sharp, producing an smooth edge 3 nanometers thick. Obsidian is a rare and valuable material for making blades.
 Geometric Mean Distance (GMD) is used when calculating the impedance of three-phase power transmission lines. The use of GMD is a common practice in the calculation of impedance for three-phase power transmission lines. Some line structures are imbalanced thus causing different inductance values on each phase. There are line structures that are balanced and do not cause different inductance values on each phase. This can be mitigated by transposing the phase conductors in the middle of a line to give each the same average inductance. The current phase conductors are not giving the same average inductance. GMD is used to calculate the average (effective) inductance over the entire length. The entire length is a significant factor in calculating the average (effective) inductance using GMD. GMD is simply the geometric mean of the distance between each phase conductor. There are multiple phase conductors involved. Edit: I removed the word "intrinsic" from "intrinsic impedance." There is a concept called impedance. Intrinsic impedance is a wave impedance of an electromagnetic medium. Electromagnetic waves cannot propagate without a medium.
 Receptors begin to develop within the first several weeks. The human body is capable of developing receptors. However, neural pathways for many of these (pain, for example) will not exist until the third trimester, with development of the thalamus. Pain is not the only sensation that requires neural pathways to develop in the third trimester. Check out results in: **DISCOVER** (*When does a fetus feel pain? There is a study or research on when a fetus feels pain. *)**JAMA** (*Fetal pain:A systematic multidisciplinary review of the evidence*). 1. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 Once the load (device to be powered/charged) is removed from the charger, very little power will be used. The charger is designed to conserve power. Most power bricks have little LEDs that remain on, and there is a small amount of power dissipated in the cord/other components that stay electrified (commonly referred to as phantom power), but only a VERY small amount of power is still consumed. Power bricks are commonly used in electronic devices.
 Relative humidity is just the ratio of the observed specific humidity to the maximum possible specific humidity, which itself is a function of temperature. The atmosphere is capable of holding a maximum amount of water vapor. If it's cold outside, then the maximum specific humidity is very low, and it doesn't take much water vapor at all to get near 100% RH. Cold weather is common in the area where the sentence is being spoken. Relative humidity isn't a particularly useful product; the actual water-vapor content can remain unchanged, yet the relative humidity starts swinging wildly only because the temperature is changing. Temperature changes frequently in the environment. It provides very little useful information. There is a need for useful information.
 The closest there is to an animal that spends their entire life in the air is probably the Alpine Swift. There are other animals that spend a significant amount of their life in the air. They have recently been found to spend upwards of 200 days in a row airborne and only land at their breeding ground. The birds in question have a breeding ground. They eat, sleep, and drink all while airborne. They are able to fly without any mechanical assistance. Nature Paper:_URL_1_But probably easier to read the Wikipedia article:_URL_0_I suppose that, theoretically, creatures like bacteria could spend longer airborne but I'm not aware of any studies done (they'd be very hard to track individually unless we find some type of bacteria that spends its whole life cycle airborne) There is a possibility that bacteria can spend time airborne.
 There are many variations of dentition (posh word for a set of teeth). Dentition is a complex and diverse subject. Each is relevant to the evolutionary background of the animal. Animals have evolutionary backgrounds. Similarly, there are good reasons for creatures having no teeth at all. Creatures with teeth are not as successful in their environment. It is all to do with what they typically use their teeth for, the structure of the tooth, and how these relate to the lifespan of the animal. Animals with longer lifespans have teeth that are structured differently than those with shorter lifespans. Sharks have many rows of teeth - the sheer power of their jaws and the work they have to do to bite and hang on to and kill their pray means often their teeth are left behind in their food (the sheer size of the multi-directional forces mean they often extract their own teeth when hunting and eating). Sharks have a high rate of tooth loss due to the force required to bite and kill their prey. Humans never use this kind of force - we do not use our teeth to hunt! Animals use their teeth to hunt. Rodents have teeth that are continuously erupting and being produced - this is because they are constantly wearing their teeth so much that they always need a new supply of tooth material. Rodents have a high rate of tooth decay and damage, leading to a constant need for new teeth. They retain pockets of tooth structure-producing cells that we are rid of once our teeth have developed. Tooth structure-producing cells are necessary for dental health. Humans do not typically use our teeth for wear-intensive processes except in pathological habitual grinding scenarios and other anomalies. Humans have teeth that are not designed for wear-intensive processes. Horses have very long teeth, that develop whilst they are juveniles and stop growing throughout adulthood, but they erupt constantly as their teeth wear. Horses are the only animals with teeth that develop during their juvenile years. If a horses' teeth do not wear quickly enough, they grow too long for them. Horses have teeth that grow continuously. This is why they occasionally have their teeth filed down! Teeth filing is a common practice in their culture. Again, humans have no such need for this amount of tooth structure as our diet is more nutrient rich and less volumous than a horses (i.e. Humans have a diet that is significantly different from horses. we need to do less chewing daily to get our nutrients). Chewing food is currently the most effective way to get nutrients. These are just a few examples. There are many more examples that are not included. Then you have our teeth, which have developed into one juvenile set of 20 teeth, followed by an adult set of 32 teeth. Humans have two sets of teeth, one juvenile and one adult. We can only speculate what the primordial genetic advantage of this is in the primitive sense - however, how our modern lives differ from the primitive has shaped the way we get dental disease, and hence the way we practice dentistry today. There is a primordial genetic advantage that exists in the primitive sense. Here's some points on dental history:In history, before the mass production of food was necessary to feed large aggregations of people in cities, we had a diet devoid of refined sugars and mostly consisted of fibrous foods like meat and fresh fruit/vegetables etc. People in history had a longer lifespan due to their healthier diet. This meant that tooth decay was actually a relatively rare disease. Tooth decay was once thought to be a common disease. Mostly the problems people had was tooth wear (attrition). People had dental problems other than tooth wear. When bread started to be produced en masse, it was very gritty due the flour being ground in between 2 stones. Bread was not gritty before it started to be produced en masse. In ancient Egypt tooth wear from this grit became a huge problem and people managed to wear their teeth down to the nerves (pulp chambers) before they could fill themselves in with dentine. People in ancient Egypt had access to dentine. This would have been very painful and the teeth would have got nasty infections pretty quickly. The person in question did not experience the pain and infections mentioned in the sentence. The discovery and introduction of refined sugars into the diet many centuries later led to us consuming a lot of bacteria-friendly foods that increased the general levels of plaque in people's mouths. Bacteria-friendly foods were not consumed before the introduction of refined sugars into the diet. These foods are also less fibrous and softer, so the plaque is not naturally sloughed off the teeth due to friction whilst you chew. The person speaking has dental issues. This is the reason why we need to control the levels of plaque in our mouth today with brushing/flossing/rinsing. Plaque buildup in our mouth is a serious problem that needs immediate attention.
 A couple of things jumped out at me here. There were multiple things to be observed in the situation. >  This spontaneous appearance of virtual particles doesn't violate the law, providing that the energy is paid back very quickly, and when I say quickly I mean in an unimaginably short time span. Virtual particles exist in the first place. This idea of "paying back" energy is not generally a useful one. Energy cannot be paid back. I'm sure you're familiar with the fact that the uncertainty principle is not a limitation of our measurements, it's a fundamental property of the universe (you can say that that the universe "doesn't know" what's going on to arbitrary precision). The universe is not deterministic. So, the fact that energy conservation appears to be violated is better understood as that the universe "doesn't know" how to impose energy conservation to arbitrary accuracy, so you get these little "wobbles" in very localized regions in spacetime, which is what is usually stated as these things happening in a small amount of time. The universe is not a perfect system and has limitations in imposing energy conservation. >  This is called Planck Time:The time that a virtual particle exists depends on the energy of the process - it's certainly not true that all virtual particles last for exactly 1 Planck time. Virtual particles are a common occurrence in the universe. The only thing that's special about Planck units (Planck length, Planck time etc) is that our knowledge of physics may not apply below that kind of scale. There exists a scale below which our knowledge of physics is not applicable.
 It's way past my bedtime, and I'd never heard of correcting spheres until a few minutes ago, so consider this all very speculative. The speaker is tired and likely needs to sleep soon. What I gather is that the spheres are made of magnetically soft iron, which also describes the steel the ship is made out of. The ship is made of steel. The notable feature of soft iron is that it greatly enhances any magnetic field that passes through it, which can affect the compass reading if it's distributed asymmetrically (if you like thinking about it this way, the Earth's magnetic field is an H field but what compasses measure is B field). Soft iron is commonly used in magnetic devices. The idea behind the correcting spheres is to put a big chunk of soft iron right next to the compass in such a way that when combined with the steel in the ship it looks symmetric to the compass. The ship has a compass. That means that all components of the Earth's magnetic field are strengthened the same amount, so the result points in the same direction. The Earth's magnetic field has multiple components. Sources: I started with the Wikipedia article on magnetic deviation and worked through part of [this NGA handbook](_URL_0_). The NGA handbook is a reliable source of information on magnetic deviation. Edit: I just want to add that I thought this was a really cool question. There was a question that was considered cool by the speaker. I think I'd seen correcting spheres before and never known that they even had a name, much less such a specific technical purpose. Correcting spheres are a common tool in technical fields. That opened up the whole field of compass adjustment, which it had never occurred to me might exist but which is actually fascinating. Compass adjustment is a complex and little-known field. So, thanks for such a solid contribution to the sub. The person being addressed has made multiple contributions to the sub.
 Bacteriophages can be used to treat bacterial infections, but phage therapy hasn't really caught on. Bacteriophages have been extensively researched for their potential use in treating bacterial infections. Viruses can also be used to deliver genes in gene therapy. Gene therapy is a common practice.
 All sorts of neat stuff! There are many different categories of items that can be considered "neat stuff." Besides the basic corticospinal tracts (which control voluntary muscle activity) and the spinothalamic tracts and dorsal columns (which transmit sensation), there are multiple white matter tracts leading from various effectors in the body and the eyes and the ears to the brain that keep us upright. There are many different types of white matter tracts in the body that contribute to our ability to maintain balance. Inputs from joint-position sensors go to the cerebellum, along with inputs from the vestibular nuclei (which process balance) and some inputs from the visual system (outside the usual optic tract-LGN system). The cerebellum is heavily reliant on inputs from joint-position sensors. There they synapse with cerebellar nuclei and also with cerebellar cortical neurons, mostly in the vermal centerline. The cerebellar nuclei and cortical neurons are crucial for proper brain function. Outputs from that area (vestibulospinal, rubrospinal, and other tracts) go down the spinal cord and affect primarily axial musculature to make small adjustments to keep us upright. The human body is constantly making small adjustments to maintain balance. So, yes: the COM would be moving around: but there's a massive and redundant feedback loop which keeps axial musculature moving to counteract these perturbations and maintain the COM over the feet. The body's axial musculature is constantly in motion.
 Two points:   Asking why with regards to evolution can often lead to rather ad hoc and pointless speculation. Evolution is a complex and unpredictable process. Especially without counter examples or convergent evolution with similar selective pressures to refer to. There are no known counter examples or convergent evolution with similar selective pressures. The mechanism of peristalsis is old. Peristalsis is a natural process. Worms use the same principle to move around. Worms are capable of movement. Basically though, peristalsis is a good way to move food around through the intestines. The human body relies on peristalsis to digest food. I wouldn't be surprised if peristalsis co-evolved with the development of intestinal tracts (but my knowledge of zoology and phylogeny can not back up that supposition) * edit, there are alternative systems to peristalsis used in organisms such as mussels. Peristalsis is a crucial factor in the development of intestinal tracts.
 Targeting is one of the biggest problems in stem cell research today. Stem cell research is a widely accepted field. If you come up with a solution for it, you'll be a very rich man (or you'll make somebody very rich). There is a problem that needs to be solved. We're fairly accomplished at keeping stem cells alive, and we've got a good amount of data on how to differentiate cells into nearly every kind of cell in the body. Stem cell research is a highly funded and important field. However, this hasn't really translated into many practical uses, since there aren't a lot of techniques more advanced than "inject them somewhere nearby and hope like crazy it works." There is a lack of practical applications for the techniques mentioned. I know of a two methods people are working on for this. There are at least two methods being developed for this. The first is to immobilize the cells in some kind of gel. Cells can be immobilized in other ways besides using gel. The idea is to give cells some time to secrete matrix around themselves, and to expose them to cytokines from neighboring cells for longer to help with differentiation. Cells are capable of secreting matrix around themselves. The second method is to find a peptide or other drug that binds to the area you want cells to go to. There is a need to direct cells to a specific area. You attach this tag to your stem cells, and hope it glues them in place long enough to settle down. Stem cells are difficult to keep in place. As for the blood-brain barrier, I'd be surprised if active transport could drag an entire cell through it. The blood-brain barrier is a well-known and extensively studied phenomenon. Active transport is used more for drugs. Drugs are the primary focus of active transport. Eukaryotic cells are bigger, and harder to get across. There are smaller cells that are easier to get across.
 It would depend largely on what portion of the insect was damaged, assuming it didn't lose enough hemolymph to die outright. The insect in question was damaged. For instance, if it suffered a substantial brain injury - one that inhibits the prothoracic glands, the corpus cardiacum, etc. The organism in question has prothoracic glands and a corpus cardiacum. - then even if it makes it to the pupal stage, the insect will not be able to produce the necessary hormones (prothoracicotropic hormone, ecdysteroids, juvenile hormone) to complete development and become a fully functional adult. The insect has already reached the pupal stage. If the larva suffers an injury to the muscles that would eventually become the mouth region, it's possible that the the mouthparts and associated glands would not develop properly, preventing the adult from actually exiting the pupal case. The larva has muscles that will eventually become the mouth region. That being said, some muscles are destroyed during metamorphosis and not replaced. Muscles play a crucial role in metamorphosis. However, they would provide both energy and cellular materials for other developmental processes. Other developmental processes require energy and cellular materials.
 >  Is there even a surface? There is a possibility that there is no surface at all. There is no real surface >  Could a probe land on it and travel on it? There is a planet or celestial body being discussed. It could not land on it but it could fly through it. There is an object that exists which cannot be landed on. The "visual" surface of saturn for instance is less dense and lower force of gravity than the surface of the earth. Saturn's "visual" surface is habitable for humans. There wouldn't be any oxygen to burn though so your flight would be short. There is a possibility of a flight taking place. >  Is it the same gas all the way through the planet? The planet has gas throughout its entirety. No. I cannot generate presuppositions for the sentence indicated by angel brackets as there is no sentence provided. As you go down you will run into higher concentrations of denser gases. There are denser gases present in the area. They probably have a solid core made of the same kind of rocky stuff earth is made out of. The planet in question is similar in size to Earth. However there is still no surface. There was an expectation for a surface to exist. There would be a gradual transition from gas to liquid to solidy stuff. There is a substance that can exist in gas, liquid, and solid states. >  Why are they gas and not rocky like the inner planets in our solar system? There are other planets outside of our solar system. The sun blew all the gas away from the inner solar system. There was a significant amount of gas in the inner solar system before the event mentioned in the sentence. I use gas in the astronomical sense meaning Hydrogen and helium. Gas is commonly used in non-astronomical contexts. Since most of the solar system is made of hydrogen and most of the rest is helium that adds up to a lot of stuff. The universe is mostly made up of hydrogen and helium. Earth for instance being the largest rocky planet still does not have enough mass to hold onto hydrogen and helium. There are other planets that have enough mass to hold onto hydrogen and helium. They float to the top of the atmosphere where they are carried off by the solar winds. There is an atmosphere on the planet. When you get to Jupiter however the sun is not strong enough to blow the gas away and it condensed into Jupiter. Jupiter's atmosphere is primarily composed of gas. >  Add anything else that's interesting! There is something that needs to be added. I'm not really an expert so this is pretty much it. There are others who are more knowledgeable on the topic. If you're interested in this topic however I would really suggest checking out [yale's open course "Frontiers and Controversies in Astrophysics"](_URL_0_). There are many topics related to astrophysics that are worth exploring. It's a course designed for non science students split into three parts: Extrasolar planets, Black holes, Dark matter/energy. The course is not designed for science students. The first 8 lectures are on Extrasolar planets of which a few of them are all about planetary system formation and why our solar system is the way it is. There are other lectures besides the first 8. Basically he will answer your questions better than anyone here could. The person in question has a vast knowledge on the topic of the questions being asked.
 The second law of thermodynamics states that entropy always increases (things become more disordered) over time for an **isolated system**. There exists a system that is completely isolated. One might conclude from this statement that any process where entropy increases is moving forward in time and any process where entropy decreases is moving backwards in time. There is a universal law of entropy that governs all processes. & #x200B;However, what should be of no surprise is that we are able to make systems more ordered with some external input back into the system without violating the laws of physics. There is a system that needs to be ordered. Suppose I'm at the pub and I'm playing pool with my mate. I have been to a pub before. A few shots into the game, he tells me he's found a way to kick the table such that sometimes all the balls end up back in their original triangle shape. He has played this game many times before. He then goes and demonstrates this and aside from being totally stunned, I'd agree that was rather impressive - certainly deserving of a publication. He had previously attempted to demonstrate something similar but failed. But I probably wouldn't conclude he had invented a kick that made us travel back in time to before we started the game. There is a game being played. In all fairness neither do the authors in their original paper. The authors were expected to have a different opinion. & #x200B;Fingers should really be pointed at Moscow Institute of Physics and Technology for making a press release entitled "Physicists reverse time using quantum computer". The press release caused controversy among the scientific community. Still the original research is excellent and has generated a large PR buzz, so perhaps they did the right thing. The research was controversial. & #x200B;For the scientifically minded I encourage everyone to read the original paper [_URL_0_](_URL_0_) The original paper mentioned in the sentence is highly regarded in the scientific community.
 If your old wives' tale involves ultracentrifugation of a semen sample to separate sperm by the mass difference between the X and Y chromosomes, then there might be something to it. There is a common belief that ultracentrifugation can be used to separate sperm by the mass difference between the X and Y chromosomes. EDIT: That's the way it's often done for the livestock industry and perhaps some humans - that or sorting the cells with a fluorescent dye attached to an antibody that specifically binds one sex chromosome or the other. The livestock industry and some humans have a need to determine the sex of their offspring. If there were a simpler way, you'd better believe they'd be all over that. There is a complex way that is currently being used.
 Read the video description. The video has a description available. Its not actually stopping it, just vibrations synced with the camera to make it *appear* to stay still. The camera is not capable of staying still on its own.
 The *right* way to think about compression is in terms of set theory. Compression can be thought about in other ways besides set theory. Imagine a set of "Things" as 'people in the world'If we assign each 'person' a positive integer between 0 and 7 billion. There are at least 7 billion "things" in the world. Now, the number of bits required to represent a particular person is log(7e10)=33, so 33 bits. There are at least 7 billion people in the world. So the number of bits necessary is 33. There is a specific task or project that requires a certain number of bits. Suppose we have some 'method' to 'compress' that data. There is a need to compress the data. Suppose I claim that I can represent a particular person from all others in only 10 bits. There are other methods of representing a particular person. Since 10 bits can only distinguish between 1000 different possible numbers, by mathematical fact I must be in some way making it impossible to distinguish between more than 1000 people, therefore making my 'compression' impossible. There are more than 1000 people involved in the situation. However, I can get around this. There is an obstacle that needs to be overcome. What if I say "Well, yes, a person is 33 bits of data (because of how many unique persons there are). There is a system that assigns a unique 33-bit code to each person. However, my application need only consider people who are citizens of my small town. There are other applications that consider people who are not citizens of the small town. My small town only has 16 thousand people, which means that we can represent each person in my town with a DIFFERENT number such that it only goes from 0 to 16000. There are no duplicate numbers assigned to any person in the town. This only takes 14 bits". There are other things that take more than 14 bits. Then my 'compression' algorithm to convert from a 33-bit person to a 14-bit person can work by simply identifying the person, making sure that they belong to my small town (if not error 'incompressible'), then figuring out their small town id instead....'compressing' the data. The algorithm is designed to work only for people who belong to a small town. As long as you ALREADY know in advance that your 'target' data possible set is a much much smaller subset of items than your 'source' data set, then it's theoretically possible to create a mapping function that 'compresses' by representing an item from your source data set by its ID in the target data set. The source data set is significantly larger than the target data set. For example, the reason your mersenne prime example works is that if you represent a mersenne prime by its index in the set of all integers, then the index will be much larger because the number of integers is much much larger than the number of mersenne primes. There exists a set of all integers and a set of all mersenne primes. However, if you represent the prime by it index in the set of mersenne primes, then you can simply represent it as N where P=2^n -1 ALL compression basically works this way. The set of mersenne primes is a well-known mathematical concept. Run length encoding compresses from the set of all binary strings to the set of binary strings where there are repeating patterns (smaller). There exists a set of binary strings where there are no repeating patterns. JPEG encoding compresses from the set of all possible pixel maps to the set of pixel maps with low-frequency changes and smooth colors (much smaller and maps to the real world data better). There are many possible pixel maps that are not included in the set that JPEG encoding compresses from. Huffman coding compresses from the set of all binary strings to the set of binary strings with uneven frequency distributions in the characters. Binary strings with even frequency distributions cannot be compressed using Huffman coding. Compression mathematically CANNOT work if the number of things you need to represent is the same size as the represntation bits for that set. There is a need for compression in the situation being discussed. It only works by mapping a source set to the target subset. There is a source set and a target subset that need to be mapped.
 I've read articles both for and against this thesis. There are people who have written articles for this thesis. Some articles compare energy efficiency between humans and chimps and claim that humans use only a quarter of the calories that chimps do for locomotion. Chimps are known to be more physically active than humans. But the same studies show that chimp locomotion is highly variable, and the same individual chimp can vary tremendously in energy efficiency depending on gait. Chimps have a wide range of gaits. And different chimpanzees can vary significantly too, calling into question the "one quarter energy used" figure. Chimpanzees have been studied extensively. Other studies which use measures such as oxygen consumed show that humans are about 25% more efficient than chimpanzees at locomotion, but **only** when walking. Humans and chimpanzees have similar levels of efficiency in locomotion when not walking. They are not more efficient when running. They are less efficient when walking. Some people point to studies like this and go "aha, that's why we're persistence hunters, we don't chase them down because we aren't great runners, but we can outwalk any other species under the sun". Some people believe that humans are the only species that can outwalk other species. But other scientists say this is jumping to conclusions because of the inherent variability in locomotion. There is a debate among scientists about the validity of a certain conclusion. 25% more efficient may sound like a lot, but it still falls [within the 95% prediction interval](_URL_0_) for mammals as a whole. Mammals have a wide range of efficiency levels. So perhaps it's something else, or maybe a combination of things. There are multiple possibilities for what the situation could be. Our lack of body fur and upright postures make us particularly good at evaporative cooling, so maybe we were persistence hunters because we could go for a long time without overheating in the hot grasslands of Africa. Humans evolved in the hot grasslands of Africa. Or maybe it's because we're not very powerful, we don't have huge sharp teeth and powerful jaws, we don't have claws. There are other creatures in the world that are more powerful than us. Maybe catching up quickly with your large prey isn't the best option for us, maybe it's safer to exhaust your prey before you catch up and smash its skull with a large rock.
 I believe the phenomenon your friend is referring to is [genetic dominance](_URL_0_). Genetic dominance is a widely accepted phenomenon in the scientific community. The genetics of skin color, however, are fairly complex (i.e. Skin color is determined by genetics. involve many genes), and to my knowledge, are not yet fully understood, so I'm not sure where the specific figure of 8 generations comes from. There is ongoing research on the involvement of multiple genes in the process.
 When trying to understand relativity, remember that *where you are* isn't as important as *how you're moving*, or, more accurately, how everything you're observing is moving. Observation of movement is crucial in understanding relativity. [Here's a popular illustration of relative simultaneity](_URL_2_) involving blinking lights (or, in this case, lightning strikes) on a train. There is a phenomenon called relative simultaneity. To get a deeper understanding of this and other elements of relativity, you should familiarize yourself with [space-time diagrams](_URL_0_). You have a basic understanding of relativity. In such a diagram, space (ie. There is a diagram that requires space. position) is on the horizontal axis and time is on the vertical axis. There is a graph being discussed. So something sitting still follows a vertical path, and something moving follows a diagonal path. There is a clear distinction between objects that are stationary and those that are in motion. The bigger the angle from vertical, the faster the thing is moving, up to an angle of 45^o which corresponds to the speed of light. There is a limit to the speed of light. Points on these diagrams are called *events*. There are diagrams that have points on them. They describe one particular place and time. There was only one place and time that they could be describing. Higher events happen later than lower ones. There is a hierarchy of events. You can think of horizontal lines as "slices of simultaneity." Horizontal lines are the only way to represent simultaneity. Every event that falls on the same horizontal line happens at the same time. Events that occur on different horizontal lines do not happen at the same time. Now notice the blue axes on the [diagram](_URL_1_) on the Wikipedia page. The diagram on the Wikipedia page has blue axes. These represent a moving reference frame (relative to the black axes). There is a black axes system in place. Notice that not only is the time axis angled (representing a nonzero velocity), but the space axis is also angled. There is movement happening in the observed system. This shows that this moving observer will have different "slices of simultaneity," so they will see different events as simultaneous. There are multiple moving observers. Edit:  So to answer your question, no, there is no universal "now." There was a question asked that required an answer about the concept of "now". Each observer has his or her own "now," although two observers moving at the same velocity (same speed *and* direction) will have the same "now" since they will be in the same *reference frame. There exists a universal "now" that all observers can agree upon. * I'm sorry, but there is no sentence indicated by angel brackets in your prompt.
 When a star is rotating, light from the side of the star approaching the observer is blue-shifted, and light from the other side is red-shifted, due to the Doppler effect. The star is rotating at a high speed. If the planet is orbiting the same direction as the star's rotation, it will block some of the blue-shifted light first; otherwise, it blocks the red shifted light first. The star's rotation is significant in determining the color of the light blocked by the planet. With sensitive spectroscopes astronomers can (in some cases at least) work out which way the planet is orbiting. Astronomers have access to sensitive spectroscopes.
 Yes and no. There was a question asked that required a yes or no answer. One of the essential processes of life is assimilation, which is where the body takes in organic compounds, such as protein, and then breaks these organic materials down into more useable materials. Organic compounds are necessary for life. For example, from proteins come amino acids. Amino acids are only produced from proteins. These amino acids, the building blocks of proteins, are then synthesised by the body's cells into more useful proteins that are currently needed. The body is in need of more proteins. For example, a steak you eat may contain lots of actin and myosin (structural and motor proteins), but you body may need more collagen. There is a need for collagen in the body. The body breaks down the proteins in your steak, and uses the amino acids obtained from this process to build new collagen. The body cannot build new collagen without the amino acids obtained from breaking down proteins in your steak. The key to this is that the body doesn't assimilate non-organic matter very much (with exceptions, such as the inclusion of calcium carbonate in the bone structure) but can use organic molecules (made of atoms...) to manufacture more complex, useful structures. The body can assimilate some non-organic matter. Hope this answers it for you. The person asking the question had a previous inquiry. EDIT: changed 'hopw' into 'hope'. There is a desire or need for something. Silly me. I have made a mistake. ANOTHER EDIT: See humaniteer's comment for more specific information about protein synthesis. Protein synthesis is a natural process in living organisms.
 > is there something about viruses that deadly that makes them hard to pass on? Viruses are deadly because they mutate rapidly. There's no evolutionary advantage in spreading rapidly and obliterating all of your potential hosts. There are potential hosts that can be obliterated.
 It is all normal evaporation. There was a previous incident that was not normal evaporation. In warmer weather, the air is able to absorb all of the evaporating moisture. The air is not able to absorb all of the evaporating moisture in colder weather. Cold air holds much less moisture so the evaporated pool water condenses into a cloud of tiny droplets until it spreads out enough to no longer be visible. The air temperature was significantly colder than the temperature of the pool water. Look up "Dewpoint" and "Relative Humidity" for further information. "Dewpoint" and "Relative Humidity" are important concepts to understand.
 Dark matter is a somewhat ambiguous name given to a set of astronomical observations that physical theories not including dark matter don't explain. There are physical theories that include dark matter. These observations tend to suggest the presence of mass that we can't see - hence the choice of "dark matter". There are other observations that suggest the presence of visible mass. For example, if you measure the velocity of a bunch of stars moving around the center of a galaxy, and then plot those velocities as a function of distance from the center, you get what's called a [galaxy rotation curve](_URL_1_). There are multiple galaxies with different rotation curves. The velocities of the stars are a function of how much mass is contained in the galaxy. The galaxy contains a significant amount of mass. We can measure how much mass is in the galaxy based on the its luminosity and by combining that with what we know about galactic astrophysics. There is a significant amount of mass in the galaxy. However, the velocities of the stars we actually measure are greater than what is predicted by the mass of the galaxy, which implies some extra mass around the outside that we don't see. There is a galaxy that has been measured. This is the "dark matter". Dark matter is a known entity in the scientific community. They tend to look something like [this](_URL_0_). There are various designs that look similar to the one shown in the URL.
 You seem to be asking about manufacturing tolerances within the pharmaceutical industry. The pharmaceutical industry has strict regulations regarding manufacturing tolerances. There are very strict and equally complicated regulations on this sort of thing. There is a high demand for compliance in this area. It's not as simple as +/- 2% or something like that. There is a complex calculation involved that cannot be simplified to a +/- 2% range. In general, in the U.S. (there are similar rules in Europe but I'm not familiar enough with them to comment), the FDA requires that pharma companies follow "Good Manufacturing Practices" and have chemistry and manufacturing controls in place to ensure compliance. Pharma companies in the U.S. are not always compliant with the FDA's "Good Manufacturing Practices" and may not have proper chemistry and manufacturing controls in place. If you want a survey of the relevant regulations, they are on the [FDA's website](_URL_0_). The FDA's website is the only place where relevant regulations can be found.
 A photon can only interact with an electron when they're at the same position (physicists say that electromagnetism is "local"). Electrons and photons are the only particles that can interact with each other. So you have a combined probability distribution for the photon, and *this* electron, and *that* electron, etc. There are multiple particles involved in the experiment. etc. I'm sorry, I cannot generate presuppositions without knowing the sentence indicated by angel brackets. In the combined paths of the photon and *this* electron where they meet somewhere, there's some probability that the electron absorbs the photon - is excited. There is a photon and an electron that have intersecting paths. So altogether that means there's some probability that it excites *this* electron and some probability that it excites *that* electron, etc. There are multiple electrons that can be excited. etc. I'm sorry, I cannot generate presuppositions without knowing the sentence indicated by angel brackets. (Make a thick enough wall of atoms and it'll almost certainly excite *some* electron). There are enough atoms to make a thick wall. So there's some probability that all of these electrons have been excited. There is a source of energy that could have excited the electrons. And if the photon travels along all possible paths, then all of the electrons have been excited. All possible paths have been traveled by the photon. With some probability. There is a chance that the event will occur. If you measure the atoms, then you will find that, with only one photon emitted, only one atom can be excited. Atoms can be measured. So you will find which electron has been excited, with some probability. There is a process to determine which electron has been excited. But which one this was, was not "decided" before you measured. There were multiple options to choose from before the measurement was taken. (Depending on how you interpret the rules of quantum mechanics, this is either "wavefunction collapse", where the universe "decides" which electron has been emitted because you have measured it, or "decoherence", where your measuring device exists as a probability wave in states that have measured several different atoms, but due to thermal effects the different parts of this wave can't interfere anymore.) There are different interpretations of the rules of quantum mechanics.
 Because there's a piece that holds the transparent screen element (which is what you actually see on the screen) that has a rectangular cutout, which both holds the screen element and blocks out the extraneous light, forming a rectangular beam. There is a transparent screen element that needs to be held in place. If you look at old slides like those used on slide projectors, you'll see the slide has a rectangular piece of cardboard or plastic around it that performs the same function. Old slides are no longer commonly used.
 Hopefully an actual scientist will chime in here, but broadly the drop in oestrogen signals to the ovaries that the woman is not pregnant to get them to release a new egg. There is a significant drop in oestrogen levels in women's bodies. The combined pill (containing oestrogen) tricks a woman's ovaries into behaving as if she's already pregnant so that no egg is released.
 Radiolab is an amazing one. Radiolab is not just amazing, it is life-changing. All the podcasts are online at _URL_0_. There are multiple podcasts available online at different URLs. They talk about many different interesting science topics, but what's great about the show is that they (1) talk about things that actually have something to do with life, (2) cover the subject in-depth and thoroughly, and (3) explain it very non-technically even though they directly interview experts in the field and so on. The show is popular among people who are interested in science. If you are looking for a starting point, my favorite one is probably Words (which is about what language really is and how it affects the brain). There is a need for a starting point.
 Although I was not yet alive in those times, I do enjoy reading old physics papers from time to time. There were times in the past when old physics papers were written. It is quite well-known that the scientific community was largely divided in the early when it came to quantum mechanics. The scientific community eventually reached a consensus on quantum mechanics. Famously, Einstein and Bohr became the faces of the two sides of this divide, but both had some prominent people on their side. There was a significant divide between two groups, with Einstein and Bohr as the most well-known representatives. For Einstein de Broglie and Schrödinger were among his more notable "allies", whereas Bohr's entourage contained people such as Heisenberg, Pauli, Born, et cetera. There was a significant divide between the scientific communities of Einstein and Bohr. The latter group was actually far from happy with the EPR paper. The EPR paper was highly anticipated. There is a reasonably well-know letter which Pauli sent to Heisenberg to complain about this work. Pauli and Heisenberg had a professional relationship. He literally states that whenever Einstein voices views on quantum mechanics, it ends up being a catastrophe. Einstein has voiced views on quantum mechanics before. In his letter, he urged Heisenberg to respond to the EPR paper in order to avoid confusion for the American readership. Heisenberg had not yet responded to the EPR paper. However, Bohr was the one who published a [response](_URL_0_) to the EPR paper. Bohr was not expected to publish a response to the EPR paper. It is a very interesting paper, in the sense that it really discusses the concept of realism. The author has a deep understanding of the concept of realism. It is worth remembering that these people where very dominant figures in science up until the 60's when Bell's work came along. These people were not dominant figures in science after the 60's. I guess that it is hard to estimate the extent of this divide. There is a divide that exists. It is, however, worth noting that entanglement was certainly not a big research topic in this period. Entanglement was a big research topic in other periods. As to the breakthrough step, I am tempted to say that it was Bell's work. Bell's work was a significant contribution to the breakthrough step. There is a serious amount of work on the probabilistic structure of quantum theory which was done in the 70's. Quantum theory is a widely studied field. Quantum correlations, as captured by violations Bell's inequality are a crucial element of this work. Quantum correlations have been extensively studied in the past. Of course the experiments were a necessary, but I doubt that many people who were active in the field were surprised by the outcomes. The field in question had a history of failed experiments.
 More of a risk. There have been previous risks. What's in yours are strains of bacteria that your body has already had in it, probably for quite some time, and your immune system is used to keeping them under control. Your body has a natural defense system against bacteria. Somebody else's will probably contain at least a few different bacterial strains to yours. There are multiple bacterial strains that exist in the world. Touching their poo might increase the chance you get infected with this different strain (I say might, because if you wash your hands thoroughly afterwards, and haven't wiped those bacteria anywhere else for safe-keeping in the meantime, you should be OK). There is a different strain of bacteria that can be found in poo. Your body may not already have the recipe for antibodies (i.e. Antibodies are necessary for fighting off infections. immunity) against that strain, and respond only slowly to it, allowing the bacteria to multiply enough and make you sick before your immune system finally gets ahead of it. There is a strain of bacteria that can cause illness. How this relates to a disabled arm and prophylactics, though, you'll have to explain. There is a person with a disabled arm involved in the situation. If it's gross, please leave me ignorant. There is a possibility that something gross may be encountered.
 You are correct that in general, the surface North Atlantic is saltier than the South Pacific. The South Pacific is generally less salty than other oceans. However the Gulf of Maine is considerably fresher due to all the rivers which flow into it and the fact that it is isolated from the open ocean by Georges Bank. There are many rivers that flow into the Gulf of Maine. The salinity level in the Gulf of Maine is about 33 parts per thousand while most of the North Atlantic is ~ 35.5 parts per thousand. The Gulf of Maine is a unique ecosystem with distinct salinity levels.
 "The seeds of Capsicum plants are dispersed predominantly by birds: in birds, the TRPV1 channel does not respond to capsaicin or related chemicals in birds (avian vs mammalian TRPV1 show functional diversity and selective sensitivity). Birds are the only animals that disperse the seeds of Capsicum plants. This is advantageous to the plant, as chili pepper seeds consumed by birds pass through the digestive tract and can germinate later, whereas mammals have molar teeth which destroy such seeds and prevent them from germinating. Birds are the primary consumers of chili pepper seeds. Thus, natural selection may have led to increasing capsaicin production because it makes the plant less likely to be eaten by animals that do not help it reproduce." Capsaicin production is a desirable trait for plants. Source: Tewksbury, J. J.; Nabhan, G. P. (2001). The source material is a research paper. "Seed dispersal. Seeds are being dispersed naturally. Directed deterrence by capsaicin in chilies". Capsaicin is a natural deterrent for certain animals. Nature 412 (6845): 403–404. The article in question was published in the journal Nature.
 Not a scientist, but i found [this](_URL_0_) - seems like you could make do with a laser, but the following electric arc would probably be very straight, and not all pretty and lightning-like. There is a need for a tool to create a straight electric arc.
 The collision is about the pressure that the gas clouds exert on each other. There are at least two gas clouds involved in the collision. If you try to push two fluids ('fluid' in physics is a broad term encompassing any material that can flow, including gases and plasmas) into each other, the pressure between them will increase. There are at least two fluids present. Certainly, the collision between gas clouds is radically different from the way billiard balls collide. Gas clouds and billiard balls are both objects that can collide. There won't be any particular moment when we announce "Look! People have been anticipating an announcement of some sort. They've collided! There were two objects in motion. ", it's a process that occurs over millions of years. The process is natural and not man-made. As the gas cloud runs into the gas of the Milky Way disk, that pressure will compress the gas, which will cause dense clumps to form. There is a gas cloud moving towards the Milky Way disk. These clumps will eventually grow into stars. Stars are formed from clumps. Worth noting that gravitational forces also do play a role in triggering star formation during merger and close encounter processes. Gravitational forces are not the only factor in triggering star formation during merger and close encounter processes. Because the nearer part of an object gets pulled more strongly than the farther part, we get what are known as [tidal forces](_URL_0_), which cause a cloud to deform its shape. Tidal forces are a common occurrence in the universe. Essentially, this acts to stir up the gas and disrupt its relatively quiescent state, facilitating the formation of those dense clumps that turn into stars. Gas clumps are necessary for star formation.
 It's the change in temperature, not the temperature itself, that causes this to happen. There is an event or phenomenon that occurs due to temperature. So water the same temperature as the glass won't cause it to break, but water of a different temperature will. The glass is made of a fragile material that is sensitive to temperature changes. The water raises or lowers the temperature of the glass it encounters, causing it to expand or contract relative to the rest of the object. The glass is made of a material that is highly sensitive to temperature changes. Because glass is brittle and not very elastic, this can cause it to break. Glass is a commonly used material in construction and household items.
 If you're talking about simulations of large-scale structure, most of them don't even simulate anything significantly smaller than a galaxy, and sometimes not even galaxies. Simulations of small-scale structures are not important in the field of large-scale structure simulations. For the most part they're not interested in the relatively small-scale processes that occur within galaxies, as the main aim of these simulations is to better understand how large-scale structure (meaning galaxy clusters, superclusters, and cosmic walls  &  filaments) forms and evolves. The simulations are primarily focused on understanding the formation and evolution of large-scale structures in the universe, rather than the intricacies of individual galaxies. The evolution of a single star, or even the evolution of an entire galaxy, has very very little effect on the mass distribution of the universe. The universe's mass distribution is affected by various other factors.
 No. I'm sorry, but the sentence indicated by angel brackets is not provided. The easiest way to think about this is with the concept of "cardiac reserve". The concept of "cardiac reserve" is widely accepted in the medical community. This is basically how much more you can stress out your cardiovascular system. Your cardiovascular system can be stressed out. Think of it like manna in a video game. Manna is a common concept in video games. Take a healthy adult (or a level 8 wizard). The person making the request is in need of someone who is healthy or a skilled wizard. When going through daily activities, their heart is working at 30%^1 capacity to keep them functional. The person in question is human. That person can sprint up the stairs, go play a game of basketball, or whatever and get that number up to 60^1 or 70%^1. The person in question is physically fit and capable of sprinting up stairs and playing basketball. This is that person using up some of their reserve, but they are OK. The person has reserves. The blue bar is not that far down, and it will fill back up quickly. The blue bar has been low before. Take a nonhealthy adult (or a cursed level 2 wizard). The person in question is not a healthy adult or a level 2 wizard who is not cursed. Say you've got a sedentary person that eats too much; has a touch of atheroscleorisis and about 50 extra pounds. The person in question has a history of unhealthy eating habits. This person's heart has to work harder to pump blood through those messed up arteries and all that extra mass. This person has a medical condition that affects their arteries and heart. His heart is operating at 70%^1 capacity when walking around. He is physically active. A sprint up the stairs will wind him, and a brief game of basketball will seriously challenge his cardiac reserve, pushing him to the limit. He has a pre-existing heart condition. Their blue bar is near zero, and if any more orcs show up he is screwed. There are orcs present in the situation. Going up Everest is a cardiovascular challenge (for a variety of reasons, only one of which is the altitude), and it will eat into your cardiac reserve. There are many reasons why people attempt to climb Everest, despite the known cardiovascular risks. If your baseline cardiovascular workload is challenged due to high blood pressure (or whatever), this puts you dangerously close to (or past) your limit. You have a baseline cardiovascular workload. It's a boss fight. The fighters are evenly matched. You don't take a cursed level 2 wizard into a boss fight and expect good things to happen. There is a cursed level 2 wizard. Going to a lower elevation (or getting extra oxygen) will reduce the demand placed on your cardiovascular system. There is a high demand placed on the cardiovascular system at higher elevations. It will decrease the workload a bit; this is why they put people on oxygen in the hospital. The workload is currently too high. The analogy here would be getting a buff on your manna; it doesn't make the spells any cheaper, but it does make it so you can cast more of them. There is a magical world where spells and manna exist. ^1 This number is 100% made up because I didn't want to Google the real value. There is a real value for the number mentioned.
 This is a great question, unfortunately "coupled oscillators" typically takes up an entire chapter in advanced classical mechanics textbooks. The topic of "coupled oscillators" is a complex and important one in advanced classical mechanics. To give a complete description in a Reddit comment is a daunting feat. Reddit comments are typically short. The key point is that sufficiently close to **any** stable equilibrium, a mechanical system will undergo [simple harmonic motion](_URL_1_). In simple harmonic motion, the restoring forces are linear in the displacements from equilibrium (**F** = -k**x**, Hooke's law). The system in question is in a state of simple harmonic motion. So you essentially turn your system of differential equations governing your system into a *linear* system, which can be solved exactly (whereas the more general motion will have a more complicated, nonlinear, set of differential equations which may not be solvable analytically). The original system of differential equations was not solvable analytically. So you write your system of linear differential equations as a matrix equation, then following the standard procedure in linear algebra, you find the eigenvalues and eigenvectors of the appropriate matrix. Linear algebra is a widely used mathematical tool. These are your [normal modes](_URL_2_). There are other modes besides normal modes. The eigenvalues are the frequencies of the normal modes and the eigenvectors are the normal modes themselves. The normal modes have distinct frequencies. The normal modes form a complete basis, so any general motion of your system (in the small oscillation approximation) can be expanded in normal modes. The system in question has small oscillations. You can even define [normal coordinates](_URL_0_) which uncouple your system of differential equations. Normal coordinates are commonly used in differential equations. Then instead of working with a system of coupled oscillators, you can treat it as a system of uncoupled oscillators (just remember that you made a coordinate change when you interpret your results). There was a previous attempt to work with a system of coupled oscillators.
 According to what I read, you're largely right. You have read something that supports the person's statement. From what I read in *The Emperor of All Maladies* by Siddhartha Muhkerjee, most people before the modern era, from ancient Egyptians, Greeks, up to the nineteenth century, were puzzled by it. People in the modern era are no longer puzzled by it. There was an Egyptian medical treatise that listed several cases and their treatments; the case that seemed to describe cancer had no treatment listed. An ancient Egyptian civilization existed that had advanced medical knowledge. Furthermore, people just didn't see enough cases of cancers because people during the time didn't live long enough for the mechanisms that cause cancer (e.g., mutations in genes, viruses, etc.) Cancer was not a well-known disease during the time period in question. to get to the point that they became symptomatic. The person in question was exposed to a harmful substance.
 The idea is not and never was viable. There was an idea proposed. It was always a pet theory of the marine biologist who came up with the idea in the 1930s and the [writer](_URL_2_) (without a scientific background) who popularized the idea in the 1980s onward. The marine biologist and the writer had a close relationship. The hypothesis has several large gaping holes in its logic as well as several factual errors about human and aquatic mammal biology and behavior. There was an attempt to create a hypothesis. [This site](_URL_1_) has long been a clearinghouse of information. This site has been a reliable source of information for a long time. It has a [page devoted](_URL_0_) to quickly debunking specific claims of the AAH, such as supposed similarities in skin, sweat glands, and subcutaneous fat shared by humans and aquatic mammals. There are claims made by the AAH that suggest similarities in skin, sweat glands, and subcutaneous fat shared by humans and aquatic mammals.
 EPA states that tap water has no more than 500 ppm of impurities. Water with more than 500 ppm of impurities is harmful to human health. Say, for sake of conservatism, you start with not lemonade but pure, dehydrated, lemonade concentrate. Lemonade concentrate is a common ingredient in many recipes. So that's 1,000,000 ppm "impure". The substance being referred to is typically considered pure. That gives us the equation: 1,000,000 * (1/2)^x = 500. The equation is solvable. Solve for x and we get 11. There is an equation that involves x. So yes! The speaker was previously asked a question. After doing this 11 times you will be unequivocally left with just water. The substance being used in the process is not water.
 A while back I was trying to approximate the weight of a skyhook. There exists a device called a skyhook. I assumed the acceleration varied uniformly along the tether from its anchor point to a maximum where it touched the payload. The tether was anchored at a fixed point. The material had constant strength so the cross section at any point was simply determined by the force needed to support the weight of the tether and the payload below that point. The tether and payload were heavy enough to require constant force to support them. The curve turns out to be the error function. The error function is a well-known mathematical concept. The thickness of the line starts out very close to zero, grows quickly in the middle then has a big thick end near the anchor. The line was drawn by hand. Error functions show up in lots of things. Errors are a common occurrence in various systems and processes. In case anyone's wondering, a .13 earth radii long Spectra tether catching a Mach 3 payload and moving it to near mach 15 weighs about 7000 tons. There is a need for a Spectra tether to catch a Mach 3 payload and move it to near Mach 15.
 No. I cannot generate presuppositions for the sentence indicated by angel brackets as there is no sentence provided. Mars' magnetic field is around ~~1500~~ 15,800-19,900 nanotesla (thanks /u/robolith, I gave the orbital value, useful for some of the later solar wind discussion but not for the magnet discussion!). Mars has a magnetic field. That's within the range that the earth's magnetic field fluxuates in a solar storm, which isn't exactly something that we need to adjust our compasses for. The earth's magnetic field is constantly fluctuating. Even if you were to have an extremely sensitive magnet that field would almost certainly be overwhelmed by magnetic minerals in the Martian crust such as magnetite, hematite, and pyrrhotite. There are magnetic minerals in the Martian crust such as magnetite, hematite, and pyrrhotite. Even those are mainly responsible for localized anomalies in the northern portion of the southern hemisphere, so you couldn't reliably count on them to point in a specific direction if you were close enough to swing a magnetic needle. There are magnetic anomalies in the northern portion of the southern hemisphere. Essentially the reason Mars is a dead planet now is because it doesn't have a magnetic field shielding it from solar winds. Mars once had a magnetic field that shielded it from solar winds. Without an active dynamo (spinning core, roughly) creating enough energy to shield the planet, solar winds blasted away volatiles on the surface and, for this specific question, mean that we can't use a compass to navigate on Mars. There was a time when Mars had an active dynamo that created enough energy to shield the planet from solar winds. ----Dunlop, D. J. Dunlop, D. J. is a real person. (2005). The year 2005 was significant in some way. Magnetic minerals in the Martian crust. There is evidence of magnetic activity on Mars. Journal of Geophysical Research, 110(E12). The journal article was published recently. doi:10.1029/2005je002404 Some good more basic information can be found [here](_URL_0_). There is a need for more information on the topic discussed in the article.
 The thing is, blood isn't entirely water - it's 55% blood plasma, which of itself is 92% water by volume. Blood is often mistaken for being entirely water. The rest of it is a myriad of other compounds and biological materials - electrolytes, dissipated proteins, glucose, hormones, enzymes, red blood cells, white blood cells, etc. There are many different types of compounds and biological materials present. Proteins themselves consist of both hydrophobic and hydrophilic-oriented amino acids, and if exposed to the air or other adverse conditions, can denature and come apart, exposing these groups. Proteins are essential components of living organisms. Proteins will partially or completely unfold as necessary to minimize surface-free energy, and can bind quite well to surfaces, requiring some extra effort to get them off. Proteins are constantly in motion and adjusting to their environment. As red blood cells burst, and as the other proteins get exposed to the knife's surface, it's not likely that the hydrophobic coating will prevent *all* of the genetic material from binding. The knife was used in a medical procedure. As an example, serum albumin, the most common protein present in blood, actually has 11 binding domains for hydrophobic compounds, so it could theoretically bind *better* to your knife's surface than if it weren't treated, depending on which methodology you used to make it hydrophobic. Serum albumin is commonly used in the production of hydrophobic compounds.
 The outcomes for any one area, as I understand, are notoriously difficult to predict due to the vastly interconnected nature of planet wide climate. There are multiple areas affected by the planet wide climate. In general, I doubt you'd find all of the Earth becoming like a single climate. The Earth's climate has never been uniform in the past. There is too much variation. There has been a recent increase in the amount of variation. Additionally, I don't think there would be areas that are completely uninhabitable, though some deserts may expand. There are currently areas that are completely uninhabitable. What you will see are large upticks in extreme weather, sea level rise, and overall unpredictable changes. The world is currently experiencing extreme weather, sea level rise, and unpredictable changes. This would lead to more hurricanes, more damage from storms, local variations in climate due to shifts in rainfall, as some areas gain it and some lose it, longer and deeper droughts, which could lead to fires, etc. Climate change is a real phenomenon. It's hard to predict these things locally (except maybe sea level rise effects), but it's fairly straightforward to answer what happens to a system when you add energy. There are many unpredictable factors in local systems. I'd like to hear from someone who specializes in this field, as it's just an area of interest of mine and not something that I'm really qualified to talk about. There are experts in the field that the speaker is interested in.
 I suspect that your idea of what "all of what mathematics" is is rather narrower than what a professional mathematician thinks of when she thinks of all of mathematics. 1. Most of the math that one encounters in high school and even at the early undergraduate level is computational. Math that is not computational is not encountered in high school or early undergraduate level. You long divide, factor polynomials, simplify radicals, solve triangles, compute derivatives, and so on. Mathematics involves complex problem-solving. These are all things that Wolfram Alpha can do, and Wolfram Alpha can do it a lot faster than you can. Wolfram Alpha is a highly advanced technology. That might lead you to the belief that Wolfram Alpha could put mathematicians out of a job—if it can do all of these things faster and more reliably than mathematicians can, then what are mathematicians left to do? Wolfram Alpha is capable of doing tasks that mathematicians can do. The truth is that the things that I listed above and other things that Wolfram Alpha can do are things that most mathematicians would hardly even consider "doing mathematics", in the same way that, say, high intensity interval training isn't what most professional basketball players would consider "playing basketball". 1. Hear me out. You have something to say that may be controversial or difficult to hear. A professional basketball player needs to be able to run fast and jump high. A professional basketball player must have strong leg muscles. This is achieved through high intensity interval training. The individual has previously attempted low intensity interval training. It's something that most basketball players ought to do, and basketball players in high school ought to do a lot of it if they want to become athletic enough to play in college or professionally. Basketball players who do not do this will not be able to play in college or professionally. High intensity interval training is something that a basketball player must do, but it is not playing basketball. Basketball players who do not engage in high intensity interval training are at a disadvantage. Completing various computational tasks is something that a mathematician must do, but it is not doing mathematics. A mathematician's job involves more than just doing mathematics. And it is indeed done better by computers in the same way that moving fast is done better by cars. Computers and cars are comparable in terms of their ability to perform tasks. But that doesn't mean that a car could replace a professional basketball player. Professional basketball players are highly skilled and valuable. Whether or not all of mathematics is ultimately reducible to logic isn't answered by this question. Mathematics and logic are distinct fields of study. The computations that Wolfram Alpha can do aren't things that professional mathematicians care about. Professional mathematicians care about computations that are not possible for Wolfram Alpha. Wolfram Alpha works on problems that are already solved: it can solve certain kinds of partial differential equations for you, but that is only because mathematicians figured out how to tell a computer how to solve certain kinds of partial differential equations. Mathematicians have not figured out how to tell a computer how to solve all kinds of partial differential equations.
 Relativistic effects aside, let's live a little and consider we are in a Newtonian universe (linear approximation of reality)100rpm is the angular velocityrpm = 2*pi radians /min = 2*pi radians /(60s) = pi radians /(30s)100rpm = 100 * pi radians /(30s)speed of light is 299,792,458 m/srelevant angular velocity formula w * r = v100 * pi radians /(30s) * r = 299,792,458 m/ssolve for rr = 28,628kmI hope I did that right. 1. But in the future a better place to ask this would probably be r/theydidthemath There is a current place where the question was asked.
 This page has a lot on the general concepts;- _URL_1_And here is something specific to the evolution of the penis but mainly as it pertains to the shape;- _URL_2_This is interesting though and shows the penis has been around for a very long time. 1. - _URL_3_"Sexual reproduction came before sexual organs. Organisms without sexual organs existed. It came in the form of single celled organisms that have both a diploid state (where all chromosomes are paired) and a haploid state (where the chromosome pairs are separated, so each cell has half the full number of chromosomes). There are other forms of single celled organisms that do not have both a diploid and haploid state. For example, amoebas are normally diploid, but can form small haploid cells ... called spores ... that can travel and combine with other spores to produce new diploid individuals (fertilization). Amoebas are capable of producing haploid cells through a process called sporulation. That's basic sexual reproduction. Sexual reproduction is a fundamental process for all living organisms. The next step is in the slow specialization of two kinds of haploid cells. There are already two kinds of haploid cells present. Some get smaller and are specialized for mass-production, and for lightness (so they can be carried farther by air or water) ... while others get larger as they contain all the nutrients needed to start a new individual after fertilization. Some organisms have evolved to become smaller and more specialized for mass-production and transportation through air or water. The smaller cells we call "male gametes", and the larger ones we call "female gametes." There are two distinct types of cells, one smaller and one larger. The next step are organs that specialize in either mass-producing and distributing male gametes, or specialize in producing female gametes and providing an environment for growth after fertilization (e.g eggs in the case of animals or seeds in the case of plants). There are organisms that have organs specialized in mass-producing and distributing male gametes or producing female gametes and providing an environment for growth after fertilization. And finally comes the specialization of individuals to have only one kind of sexual organ or the other, rather than all individuals having both (the way most flowering plants are). Individuals used to have both male and female sexual organs. Male and female organs will continue to get more and more differentiated from each other, but will always work together. There is a natural process of differentiation between male and female organs. That's because those individuals of any generation that do *not* work well with the sexual organs of the opposite sex, don't reproduce, and therefore those genes don't last long. 1. But other than that ... any slight alteration in the sex organs of either sex that makes it a little better at doing what it does best (e.g. There is a significant emphasis on sexual performance in society. the way that placental mammals slowly kept the egg internally for longer and longer until the egg is never laid outside the body, but becomes a placenta ... and the young "hatch" directly from the mother)"- _URL_0_ Placental mammals have evolved a unique reproductive system.
 You cant. There is a task or action that needs to be done. But the odds are pretty good for a planet to last a billion years or sk. There are other planets in the universe that have lasted a billion years or more. We can tell what stage the star is at in its lifecycle. Stars have a lifecycle. But yeah...especially if it's taking you thousands of years to get there the planet may have been destroyed or chucked out of its orbit (especially in a binary star system) There is a planet that is thousands of years away.
 Sound is generally measured in terms of power per unit area (intensity) or pressure (force/area) rather than energy released by an event. Sound can be measured in terms of energy released by an event. Your question is a bit vague and difficult to answer directly but I'll go through a related calculation which should give you some idea. There is a question that needs to be answered. [This website](_URL_1_) says that a lawnmower measured 3 feet away is around 107 dB. There is a website that provides information about the decibel level of lawnmowers. Decibels are a logarithmic unit comparing two things... in this case it's comparing the pressure of the sound to the 20 uPa reference. There exists a standard unit of measurement for sound pressure. [You can read this page](_URL_0_) for more information on the unit, or just trust me that 107 = 20\*log10(pressure/20 uPa) gives a sound pressure of 4.5 Pa and a sound intensity of 0.05 watts/m^(2). There is a need for more information on the unit. 3 feet is about one meter, and the surface area that this power is spread over is 4\*pi\*(1^2) = ~12.5 m^2. The surface area in question is a flat, circular surface. Multiply intensity by area and you get 0.63 watts. There is a source of energy that can be measured in watts. Lawnmowers typically have engines producing a few horsepower, which I'll call 3000 watts... so 0.02% of the power goes toward producing sound. Lawnmowers are commonly used in residential areas. This will obviously vary by what's producing the sound, but unless something is specifically designed to be noisy, the answer to your question is "not much". There is a sound being produced.
 The closest thing you could get to a plasma gun would be a plasma torch or plasma cutter, which creates a jet that's usually a couple inches long. Plasma guns are commonly used in warfare. You couldn't make something like the sci-fi weapon where you shoot a "bullet" of plasma a very long distance. Plasma weapons are a common feature in science fiction. Creating a plasma requires either enough heat or the right electric fields to ionize a gas. A gas can only be ionized if there is enough heat or the right electric fields. If you were to try to shoot a ball of plasma, the gas could quickly cool and dissipate. Plasma balls exist and can be shot.
 One common approach is to "knock out" or "silence" the gene and then observe the effect on the phenotypes. The gene in question has already been identified. Another method, which is less reliable, is to infer the function of a gene from other genes that have similar sequences/structures (homologs) and that you know the function of already. There are genes with similar sequences/structures that have known functions. you can also infer a gene's fucntion based on genes nearby in the genome (if that region is associated with a particular pathway for instance). There are other ways to infer a gene's function besides analyzing genes nearby in the genome. These last two methods can be done by BLAST searches of a gene sequence. BLAST searches are commonly used in gene sequencing.
 If the infection is viral, it has the potential to do a wide range of damage to various parts of the body. Viral infections are common and can affect many different parts of the body. Viral respiratory infections for example can start attacking the throat, and then move down into the lungs and cause a cough. There are various types of respiratory infections that can attack different parts of the body. The same virus being able to cause multiple symptoms is the reason different people have different experiences while sick from the same thing. Different people have different immune systems.
 LED displays are commonly multiplexed. LED displays are often used in outdoor advertising. This means that it is not on continuously, but is actually flickering in a pattern (usually line by line or something similar). There is a device that is supposed to be on continuously. If humming causes your eyes to vibrate at a frequency that is close to a multiple of the display flicker rate, then aliasing occurs. Humming can cause your eyes to vibrate at a frequency that is close to a multiple of the display flicker rate. Aliasing is the same phenomenon that causes car wheels or propellers to sometimes look weird in video. Aliasing is a common issue in video production. Basically, you are seeing a beat pattern between the display refresh/flicker and the vibration of your eyes. Your eyes are vibrating.
 Your brain definitely processes information while you are asleep. You are not aware that your brain processes information while you are asleep. Primarily to keep you from danger. There is a dangerous situation that needs to be avoided. Examples, loud noises (including alarm clocks), hot or cold temp changes, dampness, pain, etc will all trigger responses from your body and in many cases make you do something to adjust, be it roll over or wake you up. Your body is constantly responding to external stimuli. Some of these items can impact what you are dreaming about as well, making me want to believe it is actually registering as more than a simple reflexive action against stimuli. Some items do not impact what you are dreaming about. But if you're question is more along the lines of could you listen to audiobooks while asleep and retain the information without ever hearing it while awake, I'm more doubtful of that 1.
 We are used to seeing smoke rise up, because it is carried by convection currents. Smoke rising up is a common occurrence. In microgravity, there would still be air currents but no set direction for the smoke to go. There is a presence of smoke in the environment. If the air is very still it might make a spherical cloud around the source, just like [flames on the  ISS](_URL_0_). The air is usually not still around the source.
 If you are an astronaut, in a space suit, firing a gun, then yes - you will hear something as sound will be transmitted through your glove into the suit. There is a possibility that an astronaut may need to fire a gun while in space. It wont sound anything like a normal gun firing, as most of that noise is generated by the shockwave of the bullet going through the air. The gun being fired is not a normal gun. The astronaut floating a few feet away will hear nothing, unless the bullet hits them of course The astronaut is in a vacuum environment.
 The emission in both comes from ultrarelativistic jets (jets with Lorentz factor >  > 1) which are moving towards us so that their radiation is boosted to very high frequencies/energies, but they are in different systems and last for different times. There are two distinct systems emitting ultrarelativistic jets. Blazars are jets coming from a supermassive black holes at the center of galaxies that are continuously accreting matter, and they are quasi-stable objects that can radiate for long periods of time. There are supermassive black holes at the center of galaxies that are continuously accreting matter. GRBs are short, catastrophic events lasting from 0.2-2000 seconds that result from the collapse of a massive star or the collision of a neutron star with another neutron star or a black hole. There are massive stars that can collapse.
 theoretically yes. There is a theoretical possibility of a positive outcome. just like you can see the blast wave in an explosion you would be able to see the "blast waves" of the sound compression. There are sound compressions that produce "blast waves." The issue is that in order to see the wave the force of the wave would be similar to an explosion. There is a wave that is so powerful that its force can be compared to an explosion. obviously no such speaker exists; however you could create a series of explosive packets that would explode in a certain rhythm to create a beat. Explosive packets have been created before to create a beat. after all what is music but a collection of sounds arranged to be pleasing to the ears. Music is only considered pleasing if it is arranged in a certain way. tl:dr yes but the force of each beat would be the same as an explosion There is a device that can measure the force of each beat.
 the best time to do it would be when the moon was black, no sunlight on it. The moon has phases. But the dispersion of light from the moon (or any object) is dictated by the r^2 rule. Light dispersion is a common phenomenon. As you double the distance from an object, you receive 1/4 the light. The object in question emits a constant amount of light. I grabbed some numbers to get an estimate of the power required to generate a barely visible dot on the moon:3.839*10^26 W * 37 / ((100^0.2)^6.5) * (385000km)^2 / (25 light years)^23.839*10^26 W : 1 solar luminosity37: the solar luminosity of vega (which has apparent brightness of 0)(100^0.2)^6.5): the ratio of vega's apparant luminosity to that of a barely visible star in perfect conditions 385000km : distance to the moon25 LY: distance to vegaResult: 95 MegaWattsSo presumably a 95 MW perfectly focused laser  on a black moon in perfect conditions would show a barely visible dot. 1. Things I didnt take into account:-stars emit light in a sphere (all directions, the moon reflects in a non-uniform semi-sphere) (this would lower the result)-The moon is not a prefect reflector (this would raise the result) The universe is full of stars that emit light in all directions, which affects the measurement of the result.
 The plumes recently reported on Europa by NASA offer a golden opportunity for investigations based on this notion. There is a notion that the plumes recently reported on Europa by NASA are significant. Plume around Enceladus were identified and examined by Cassini about 3 years ago, and the presence of salt was confirmed. There was a previous belief that there were no plumes around Enceladus. Even more interesting: hydrothermal silica was identified, a litteral "smoking" gun for the existance of the most plausible place for life to exist within an ice moon (hydrothermal vents)! Hydrothermal vents are a known source of hydrothermal silica. ([source](_URL_0_)). The source mentioned in the sentence is a reliable and credible source. This opens the door on planning a mission *specifically* designed to look at material ejected by Europan plumes. There are Europan plumes that eject material. Hydrothermal precipitates and their composition would be highly significant, but one could not rule out the detection of organic molecules (en lieu of frozen fish). There is a possibility of finding hydrothermal precipitates.
 > I was told it would rain (with 100% chance of rain) from 10pm Tuesday-4pm Wednesday. There was a weather forecast given. From my interpretation this means that there is a x% chance to be 1mm of rain at some location within the forecast location range over that time period. There is a forecast location range.
 Temperature will have two main effects, both related to the density or air decreasing with increasing temperature. The atmosphere is affected by temperature changes. First, air density affects the aerodynamics of how the plane flies. The weight of the plane is not a factor in aerodynamics. Less dense air means that the plane will have to fly faster to produce the same lift but also that there will be less drag at a given speed. The altitude of the plane is high. Those effects cancel to some extent but there will still be a net increase or decrease depending on the exact design of the airplane. The airplane design has a significant impact on the net effects. Second, air density affects engine performance because you get more or less oxygen in the same volume of air. Air density is a significant factor in engine performance. Colder/more dense air increases the engine's maximum power output but how it affects efficiency at a given power level again depends on the exact design of the engine. The engine in question is designed to operate in a wide range of temperatures and altitudes. So the answer to your question is that it depends on many details of the design of the airplane and engine. There are many factors that affect the design of an airplane and engine. Your best bet would probably be to research flight performance characteristics for specific aircraft. There are specific aircraft that have unique flight performance characteristics worth researching. If there is data for different altitudes that might give some insight because air density also changes with altitude. There is data available for different altitudes.
 > Assuming some kind of destructive ecological genie were to appear and grant me a wish of one species to wipe off the planet, what reasons should I take into account for not choosing mosquitoes? There is a destructive ecological genie that can grant wishes. How severely would such an extinction negatively impact eco-systems? Eco-systems are currently facing a threat of extinction. Would there be any other repercussions? There have already been some repercussions. Mosquitos are a vital species in the ecosystems they inhabit, at least from a biocentric perspective. Other species in the ecosystems they inhabit are not as vital as mosquitos from a biocentric perspective. The malaria parasite has a number of dead end hosts. The malaria parasite has evolved to specifically target certain species as dead end hosts. If an ecosystem has enough non-human vertebrates, malaria can not become endemic in a region, because the malaria parasite is too likely to end up in a species in which it can not replicate itself. Non-human vertebrates play a crucial role in preventing malaria from becoming endemic in a region. [If an ecosystem has a human population density below 5 people per km and enough non-human vertebrates, the malaria parasite can not establish itself there. There are non-human vertebrates present in the ecosystem. ](_URL_0_) This may not be particularly great news for any humans who wish for the human population to grow at the cost of their local ecosystem, but for the non-human species who inhabit these regions where malaria is endemic, it is great news. There are humans who wish for the human population to grow at the cost of their local ecosystem. Now, more importantly, if we know that human population density is restrained by the malaria parasite, we could expect a similar phenomenon to occur in other species. Malaria parasite affects human population density. There are four different Plasmodium species that are known to infect rodents. Rodents are the only animals that can be infected by Plasmodium species. One of these is Plasmodium Berghei. Plasmodium Berghei is a well-known and extensively studied species. The mosquito [Anopheles Dureni](_URL_3_) feeds exclusively on rodents, especially Thamnomys surdaster. Anopheles Dureni is the only mosquito species that feeds on rodents, particularly Thamnomys surdaster. It transmits Plasmodium Berghei between these rodents. There are multiple species of rodents in the area. [It's also known that strong interspecific competition occurs between different species of mosquito in the Aedes genus. There are multiple species of mosquitoes in the Aedes genus. ](_URL_2_) Thus, if we were to get rid of the species of mosquito that pose a nuisance to humans, we could expect their place to be filled by species that pose a nuisance to non-human vertebrates, affecting their population number. There are currently species of mosquito that pose a nuisance to humans. Indirectly this would end up affecting humans, because rodent species diversity through the dillution effect prevents diseases from gaining a foothold in these animals. There are diseases that can be prevented by the diversity of rodent species. [When humans disturb a habitat, rodents that harbor hemorrhagic viruses tend to spread rapidly. Habitats are frequently disturbed by humans. ](_URL_1_)In conclusion, the mosquito has the effect of controling the population numbers of a variety of vertebrate species, increasing vertebrate biodiversity as a result. There is a significant problem with overpopulation of vertebrate species. Because mosquitos, especially their larvae, are in competition with one another, other species may end up filling the niche currently occupied by species that prey on humans. There are multiple species that prey on humans. This could affect the biodiversity of the species preyed on by these other mosquitos, which would end up affecting humans too. There are other mosquitos that prey on species affected by this situation.
 It depends on the material, and to a lesser extent the environment. The material is the primary factor in determining the outcome. If you have a certain amount of coal and you're using the reaction C + O*_2_* - >  CO*_2_*, that will take a specific amount of oxygen. Coal is a commonly used fuel source. But of you're burning methane with CH*_4_* + 3 O*_2_* - >  CO*_2_* + 2 H*_2_*O, that will take a different amount. Methane is being burned. You also could burn carbon, but not get a good burn, and end up with a little 2 C + O*_2_* - >  2 CO, which uses half as much oxygen for a given amount of carbon (and results in poisonous carbon monoxide). Carbon burning is a common practice. You could even use a completely different oxidizer, and burn C + 2 Cl*_2_* - >  CCl*_4_*. There is a need for an oxidizer. For that matter, redox is only one type of reaction. There are many types of reactions besides redox. You can have fires without an oxidizer if you use a different type. There are alternative types of fires that do not require an oxidizer.
 It wasn't derived by Newton, it was a supposition he made that was consistent with observation data, and it possible to use it to derive Kepler's empirical laws. Newton was not the first person to make this supposition. You can derive it from arguably more fundamental things, including [Einstein's equation](_URL_1_) and [Gauss' law for gravity](_URL_2_) (although the latter is much the same thing, you can see its generality by extending it to arbitrary dimensionality). There are other fundamental things that can be used to derive it besides Einstein's equation and Gauss' law for gravity. Recently [it was derived from thermodynamics](_URL_0_) as well. Thermodynamics has been a well-established field for a long time.
 Even though a small fraction of the neutrons are delayed, there delayed by such a long time compared to the timescale for prompt neutron emission that they greatly extend the *neutron lifetime*, which is a timescale that’s sort of an average of the prompt and delayed neutron timescales. The prompt neutron emission timescale is significantly shorter than the delayed neutron timescale. This is the timescale over which the neutron population evolves, and it’s slow enough that it can be controlled in a reactor. Neutron population is a significant factor in reactor control. Whereas the prompt neutron lifetime is too short. The neutron lifetime has been measured before. You can find derivations of this in reactor physics texts, like Lamarsh. Reactor physics is a well-established field of study.
 It looks like bollocks to me. There is a disagreement or conflict between the speaker and someone else about the validity or truthfulness of something. His starting premise is wrong: that the expansion of the universe is not uniform. The universe is expanding. He uses the example that we can see distant galaxies receding, but we don't see a ruler growing. There is a concept of distant galaxies receding. There are two problems with that: first, if a ruler was growing at the rate dictated by Hubble's Law, it would grow about the diameter of an atom per decade. 1. Not exactly enough for us to watch it grow. The plant in question was expected to grow rapidly. Second, the energy in the chemical bonds so completely swamps the expansion of the universe (at least locally), that we'd not expect the ruler to grow along with the expansion of space. The universe is expanding. Similarly, we know that gravity is so strong locally that our solar system won't grow with the expansion of space at any perceptible level, at least for a very long time. The expansion of space is a significant force. As for the centre of the universe being at the big bang and using Euclidean geometry to derive relativity from there... Also bollocks. The big bang theory is widely accepted as the origin of the universe.
 Yes, the same proton could exist since the quarks condensed into baryons. The existence of protons is dependent on the condensation of quarks into baryons. In fact quite a lot of them probably have-- the diffuse intergalactic hydrogen gas that makes up so much of the baryonic matter has pretty much been sitting there quiescently for ~14 billion years. 1.
 I disagree with your premise. You have a premise. Physical attraction is not so black and white like how you are describing. Physical attraction is a complex and nuanced concept that cannot be simplified into binary terms. Yes, there are genetic factors that contribute to people's perception of "beauty" but we don't live in cavemen times anymore and different people are attracted to different things in people now-a-days. People's perception of beauty has evolved over time.
 Pixels turn completely white (transparent) when you switch them off. Pixels have a default state of being transparent. When your screen cracks a conductor that is wired in series is severed, thus pixels are powered off while background light keeps running. The device with the cracked screen was previously functioning properly. The black blotch is the result of messed up polarizing filter and/or pixels cracking and leaking (thus the name liquid crystal display). There was a manufacturing error in the production of the polarizing filter.
 Viscosity in liquids is caused by several factors and there is no single model to explain it perfectly. There are multiple types of liquids that exhibit viscosity. If you imagine two thin layers of liquid moving past each other with different speeds, as molecules diffuse back and forth they will exchange momentum between the layers and cause some viscosity. There are two layers of liquid present. This is the primary source of viscosity in gases. Gases have viscosity. But the molecules in each stream will also stick to each other through a variety of non-covalent forces, like hydrogen bonding or polar interactions. There are multiple streams involved. This also makes it harder for the liquids to flow past each other, the same way sliding friction slows down one solid sliding over another. Liquids are flowing past each other. More complicated molecules with branches and rings can also present more points of interaction. There are many simple molecules that do not have branches or rings. [This paper](_URL_0_) uses a regression approach to estimate the viscosity of several substances. This paper is based on a new and innovative approach to estimate the viscosity of substances. They find the most important factors to consider are the "density" of the molecule, the shape (as measured by the number of rings), and the fraction of the surface that can form hydrogen bonds. The researchers have already identified several factors that affect the molecule's properties. Their fit is still imperfect (R\^2 is 0.85) but it gives you some idea of the factors that play a role. There are multiple factors that play a role in determining the fit. Edit: I should add that "density" isn't the best description of the actual variable they use, which is something called the gravitational index and has dimensions of MASS^(2)/LENGTH^(2). The variable they use is related to gravity. Like density, the gravitational index is a measure of how concentrated the distribution of mass is but they are very different quantities. There is a need to measure the concentration of mass in various situations.
 facial features are innate, and we know this because blind people emote in the same way as sighted people. Facial expressions are universal across all cultures. source: _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 Many breeds were selected for their retrieving instinct, so that they could be brought along on bird and rodent hunts and retrieve a shot or injured mark. There were specific breeds of dogs that were not selected for their retrieving instinct. This helps explain why some dogs seem to "naturally" fetch a ball, while others have to be taught to bring the thing back after they catch it. Dogs have an innate ability to fetch objects. Canines hunting as a pack will often offer "the other end" of a prey animal to one or more of their peers. Canines hunting as a pack implies that they have a social hierarchy and a system of sharing food. The animals will then shake their prey until it's good and dead. The animals are predators. This might be what some of our dogs are looking for when they don't give the ball back, and incidentally it's also the instinctive behavior behind playing tug. Some dogs do not give the ball back. (If you don't play tug with your dog because you don't want to teach him to "compete" with you, that's stupid. Playing tug with your dog is a common way to teach them to compete with you. It's you and the dog versus the toy, not you versus the dog.) There is a toy that both you and the dog are interested in. Credentials: just a very well-educated pet supply pro. The person in question has extensive knowledge about pet supplies. Too lazy to source my answers, just saw this wasn't getting much attention so I thought I'd throw my two cents in. The person who wrote the sentence is not known for being diligent in their research.
 Some have no eyes. There are creatures that exist without the need for eyes. Some have eyes, and generate their own light. There exists a species that has evolved to generate their own light through their eyes. You will not find much more than speculation about animals that live on the abysmal floor (or below). There is a significant interest in animals that live on the abysmal floor. We really do not know, we cannot go there enough to study those animals. There are animals in a location that we are unable to study.
 Right. The speaker was previously unsure or incorrect. The nucleus has a much larger mass, however, which *usually* corresponds to a smaller uncertainty in position. The nucleus is a fundamental particle in an atom. In addition, if people talk about the uncertain position in an electron, they usually mean the relative position of electron and nucleus. Electrons have uncertain positions. Due to the big mass differences, this is roughly the same as an uncertain position of the electron. There are significant differences in mass between the objects being compared.
 Pills usually weigh a few grams, but only contain a few milligrams of active ingredient. Pills are commonly used for medical purposes. So they can just make the exact same pill, and leave out the active ingredient. The active ingredient is not necessary for the pill to be effective. For injections, usually Saline (just salt water that matches your blood's salt levels. Saline injections are commonly used in medical procedures. Also used for emergency blood transfusions if they just need to get blood pressure up), mixed with whatever they need to make it look and feel exactly like the medicine. Emergency blood transfusions are often necessary to raise blood pressure quickly. Or again, the exact same carrier liquid, without the active ingredient. The active ingredient was previously present in the carrier liquid.
 You're both (sort of) right. There was a disagreement between two parties. It's very easy to make a time machine to the future by doing what you're proposing. Time travel is possible. Essentially if you don't break causality, there isn't much of a problem. Causality is a fundamental principle in the situation being discussed. However, once you break the light barrier (which is impossible locally and likely globally), lots of funny things start happening, essentially breaking causality. Breaking the light barrier is a possibility that has been explored extensively. The problem is once something goes faster than light, the concept of time is no longer so simple, and that object can look to some observers as going back in time. The concept of time is simple when something is not moving faster than light.
 You may be thinking of [this Science article](_URL_0_), which reports: > This is preliminary evidence that when people expect information to remain continuously available (such as we expect with Internet access), they are more likely to remember where to find it than to remember the details of the item. The Science article mentioned in the presupposed sentence is widely known and has been referenced by multiple sources. One could argue that this is an adaptive use of memory—to include the computer and online search engines as an external memory system that can be accessed at will. The use of external memory systems is becoming increasingly necessary in modern society.
 What you see is water vapour condensing in the air. Water is present in the air. Most of urine contains organic compounds such as urea and creatinine, which have very low vapour pressure at cold or room temperatures, and salts, which doesn't come off the solution phase at all. Organic compounds in urine are not easily detectable at cold or room temperatures. For all intents and purposes, the vapour that condenses is pure water. Water is the only substance that can condense from vapor.
 I was talking to a ocean physics guy ("tides specialist") the other day and I asked the same question. The ocean physics guy is a well-known expert in the field of tides. In modern times they're done with [satellite altimetry](_URL_0_), and apparently have some insane depth resolution (10^1-2 millimeters?) Satellite altimetry is a widely used technology in modern times. The satellites acquire a single-point depth measurement at a location every ~10 days, but it's continuously acquiring at different locations. The satellites are constantly moving. The large amount of data collected can then be used to reconstruct and answer different questions. There are many questions that need to be answered. Edit: Googling lead to [this page](_URL_1_) which has better answers. There was a need for better answers.
 A black hole's spin is determined by the matter which has fallen into it (and by its initial spin, for example when a stellar core collapses to form a BH, it has some spin). The matter that falls into a black hole has a significant impact on its spin. Since most of the matter which has fallen in came from the plane of the galaxy, we tend to assume that the SMBH's axis of spin is roughly aligned with the axis of spin of the Milky Way. The Milky Way has a well-defined axis of spin. The SMBH's spin does **not**, however, determine the spin of the rest of the galaxy. There are other factors that determine the spin of the rest of the galaxy.
 A great problem, and probably something you can write a master thesis on. There is a significant problem that requires attention. Some assumptions:* Edge and corner pieces are recognizable as such* If two pieces fit together, we always know this. The puzzle being worked on involves physical pieces. * We cannot use any sort of pattern on the pieces. There are no patterns that can be used on the pieces. Apart from the previous two bullet points we have no idea where a piece belongs to. There are at least two other bullet points that we do have an idea about. Some initial thoughts:You can make estimates based on the relative number of center (M) and edge (E) pieces, but different length to height ratios will lead to different E to M ratios. There are different methods for solving Rubik's Cube. All you get that way is a lower limit on the size (corresponding to square puzzles, asymmetric puzzles will have the same ratio at a larger overall size). There are other ways to obtain a higher limit on the size of puzzles. Corner pieces (C) help: There are just 4 of them, if you draw the first one it doesn't tell you much, but with the second one you can be reasonably confident that the puzzle is not too much larger than what you have already. The puzzle in question has at least 4 corner pieces. The third and fourth will refine these estimates even more. There were previous estimates made. You know the length or height once you have a continuous connection between the corresponding edges (you don't need to have them in a straight line). There are multiple corresponding edges that can be connected to determine the length or height. This is a problem in [percolation theory](_URL_0_). Percolation theory is a widely studied field. In the limit of infinite puzzle size, you need on average half the puzzle pieces for this if I remember correctly. There exists a puzzle that is infinitely large. There is another heuristic estimate, and one that will lead to a reliable (but not exact) estimate the fastest: Count the number of connections you found. There are multiple heuristic estimates available for finding reliable estimates. I don't have an exact formula, but in a puzzle of N pieces (N >  > 1), the probability that two random pieces are next to each other is approximately 4/N. There exists a puzzle with N pieces where the probability of two random pieces being next to each other is a crucial factor. With sqrt(N) pieces drawn your expected number of connections is 2, while your expected number of corner pieces is 4. The puzzle in question involves a square with N pieces. With 2sqrt(N) pieces drawn you expect 8 connections and 8 corner pieces. There is a puzzle or game involving drawing pieces. With 4sqrt(N) pieces drawn you expect 32 connections and 16 corner pieces. There is a puzzle or game involving drawing pieces. The number of connections grows much faster, with its inevitable sqrt(observed) scaling it gives a more reliable estimate than the corner pieces. There are multiple methods for estimating the number of connections. In addition, its dependence on the overall puzzle shape is much smaller. The puzzle in question has a specific shape.
 Epigenetically, sperm and eggs are different, carrying different patterns called "genetic imprinting." There is a scientific understanding of epigenetics. In sperm and eggs, there are some genes (less than 1% of the genome) that are always epigenetically "turned off" by way of methylation (adding CH4 groups to the DNA) or histone modification (changing the protein core that the DNA is wrapped around in order to make the DNA more or less accessible to be translated into protein) so that they can't be expressed. Some genes in sperm and eggs are not epigenetically "turned off" and can be expressed. The genes which are turned off are consistent and different in sperm or egg cells, such that all sperm have some specific things inactive and all eggs have other things inactive. There is a clear distinction between the genes that are turned off in sperm and egg cells. That means that a few genes in your body are only expressed in the paternal allele and others only from the maternal allele. There are genetic differences between the paternal and maternal alleles. If gene A was turned off in your mother's egg, all the active gene A in your body is derived from your father. Gene A is present in the body. This is one of the main problems when making "male eggs" that another poster listed below. "Male eggs" are a commonly known term in the field of agriculture. The ovum is capable of dividing and has in it the necessary proteins for fertilization, but if you take out the egg genetic material and add sperm genetic material and try to fertilize this "male egg" with sperm, the resulting fetus is going to be deficient in the maternally-expressed genes. The process of fertilization requires both egg and sperm genetic material.
 It is an autoimmune reaction triggered by gluten. Gluten is a common trigger for autoimmune reactions. Gluten is a protein found in wheat, barley and rye. Wheat, barley, and rye are the only grains that contain gluten. If you have celiacs and you eat gluten ,  your immune system attacks your own tissue in the small intestines. Eating gluten is a common occurrence for people with celiacs. Causes lots of pain,  lots of gastrointestinal symptoms,  and can cause many other widespread non GI symptoms due to malabsorption of nutrients caused by the intestinal damage. There is a medical condition that causes malabsorption of nutrients. It sucks,  and having one autoimmune condition makes developing others much more likely. There is a high prevalence of autoimmune conditions. Also chronic inflammation issues. There are other health issues present besides chronic inflammation. All can be solved by strictly avoiding gluten,  including things incidentally contaminated with gluten. Gluten is a major problem for many people. People with celiac also tend to not tolerate dairy well as the intestinal damage in the small intestines makes them deficient in the enzyme that breaks lactose. People without celiac disease can tolerate dairy well. If they follow their gluten free diet long enough for the intestines to heal,  the tolerance to dairy can return. The person in question has a history of gluten intolerance. The protein in oats is similar enough to gluten that cell biopsy’s from people with celiacs disease will all react to oats. Celiac disease is a common condition. Not as severely,  but enough that I also won’t eat any oats. There is a food allergy or intolerance present. Some People claim to have a non celiac gluten intolerance,  but it looks from what I have read to not be typically based in science. There is a widespread belief that gluten intolerance is a real condition. Causes of celiacs? Celiac disease is caused by a genetic predisposition. Idk,  but there is a genetic component as it runs in families,  but people will not always manifest symptoms at birth. There is a known genetic condition that runs in families. I didn’t start having problems with gluten until my late twenties. I have always been able to eat gluten before my late twenties. There is a clinical trial going on right now for a series of injections that is possibly curative? There are individuals who are currently participating in the clinical trial. Idk for sure,  but even if you could just modulate the amount of reaction so that incidental contamination wouldn’t cause symptoms,  that would be a game changing development for people with celiacs. There is a current problem with incidental contamination causing symptoms for people with celiacs. You could eat at restaurants that have shared kitchens,  and you could buy products that are produced on machinery that also is used to process wheat. Restaurants with shared kitchens are common. I also have heard of an oral medication in development that has a protective effect that allows incidental gluten exposure without causing intestinal inflammation. There is a significant problem with gluten exposure causing intestinal inflammation. But right now,  you just have to be super careful about what you eat,  as there is no other treatments available
 Particles, virtual or otherwise live on the spacetime background. Particles on the spacetime background have a physical presence. Think billiard balls on a pool table, the table is still there even without the balls. The pool table is a permanent fixture in the room. With that said, a real spacetime cannot actually be divorced from the fluctuations which exist on it and constantly occur, therefore it feels disingenuous to say that a spacetime always can exist without the frothing quantum fields which sit on it, future physics might marry the two concepts. The fluctuations on a spacetime are constantly occurring. Here's a pretty accessible article from Nature which explores that idea,  * _URL_0_ There is an idea being explored in the article from Nature.
 No a long slender body is the ideal shape. The presuppositions of the sentence "<No a long slender body is the ideal shape.>" could be:1. Picture kinda like an arrow but points on both end There are two distinct endpoints that the arrow is pointing towards.
 I’m unsure of many animals, but owls eat mice, shrews, and other birds whole. Owls are carnivorous animals. They will digest the animal’s soft tissues and regurgitate the hair, feathers, and bones as a “pellet”. The animal in question is a bird of prey. They’re fairly interesting-in seventh grade we dissected them, and a pellet the size of a 100 grand candy bar could have two whole skeletons in it. Animal dissection is a common practice in seventh grade science classes.
 Objects float due to their displacement of water. Water is present. The water would need somewhere to be displaced to, so whatever non-container holds it up would need to have room for the water to move. There is a non-container holding up the water. The depth of the water would need to be sufficient for the draft of the vessel. The vessel is currently in need of a certain depth of water. This is, of course, if the water were behaving as if in a normal gravity environment regardless of what hokum is used to separate it from the ground. The water is not behaving as if in a normal gravity environment.
 I'll start by admitting that I don't know the supposed science behind this, but the fact that the trial is unpublished (especially given its dramatic claims) should raise red flags. There is a trial with dramatic claims. I've checked out the information on the website, and it's really not complete enough to make a judgment. There is a website with information that the speaker has checked out. I've also emailed Dr Hirsch asking for a complete copy of the study. Dr Hirsch is the only person who has a complete copy of the study.
 Yes. There was a question asked prior to the response of "Yes." Peripheral nerves, such as in the arm, will grow back in the proper setting. Nerve damage has occurred in the arm. Central nerves in the spinal cord or in the brain will not. The nervous system is essential for bodily function. A nerve that is cut in the arm will die out past the cut, but the part nearer the spinal cord is still alive. The arm is still functional despite the cut nerve. You can stitch the two ends together and the alive part will cross the repair site and it will grow through the dead area at about a rate of 1 mm per day and it will [regain function](_URL_0_) There was a previous injury or damage to the area that needs repair.
 Strangely enough, there sort-of *is* a maximum temperature, and this maximum temperature is *also* 0 Kelvin. There is a concept of maximum temperature that is widely accepted. First, you have to understand how temperature is defined. Temperature is a measurable quantity. It is defined in terms of the energy E of a system and the entropy S of a system. The system being referred to is a closed system. For many systems, as you add energy to them, they gain entropy. Energy is added to many systems. The rate of change of the entropy of the system with respect to the energy of the system is defined to be the inverse of the temperature. The system in question is a closed system. That is, `[; \frac{1}{T} = \frac{dS}{dE} ;]`For some systems, however, the rate of change can be *negative*. The system in question has a measurable rate of change. That is, they gain entropy as they lose energy. Entropy and energy are inversely related. These systems have negative temperature. There are systems that have positive temperature. If you put a system with negative temperature in contact with a system of positive temperature, then energy will transfer from the negative temperature system to the positive temperature system. There exists a system with negative temperature. Which is to say, *the system with negative temperature is hotter than the system with positive temperature*. There exists a system with negative temperature. This agrees with the second law of thermodynamics: as the negative-temperature system loses energy, it gains entropy. Negative-temperature systems exist. As the positive-temperature system gains energy, it gains entropy. The system is positive-temperature. Overall, entropy is gained. There was a system in place that was previously organized. Now that we know that negative temperatures are hotter than positive temperatures, let's compare two negative-temperature systems. Negative temperatures exist in the real world. Take a system "C" with temperature -1 and a system "H" with temperature -1/2 and put them into contact. The systems "C" and "H" exist in the same physical space. What happens? There is an event taking place. Both systems gain entropy from losing energy. Energy is always lost in any system. System "C" gains one unit of entropy for losing one unit of energy; but system "H" gains *two* units of entropy for losing one unit of energy. There are at least two systems involved in the situation described. So when you put these two systems together, energy transfers from "H" to "C". Energy cannot be created or destroyed, only transferred. That is, system "H" is hotter than system "C". System "C" is not hot at all. So *systems with "small negative" temperatures are hotter than systems with "large negative" temperatures. There are systems with "small negative" temperatures. *Which is to say, in terms of how "hot" a system is, the temperature scale goes something like this:           positive T                negative T    0|-------------------+inf -inf-------------------|0    coldest     warm         hot     v. hot      hottest 1.
 Without three dimensional bonds, there's not enough information here to say they are different. There is a need for three dimensional bonds to differentiate between objects.
 Surface tension is simply the energetic cost of producing additional surface area, since atomic bonds are generally unsatisfied to some degree at a surface. There is a physical phenomenon called surface tension. As long as the system is more than a few molecules deep, the surface tension is independent of the depth or the total thermal energy. The system in question has a significant number of molecules. However, it is strongly dependent on the temperature.
 Sudden increase in humidity. The air was previously dry. The coil gets wet from condensation but when the compressor is running the air is cold so it's ability to absorb water is very low. The air conditioning system is in use. When the compressor turns off the air heats back up, absorbs the water from the coil and blows the humid air out of the vents. The compressor is currently on and running.
 Please speak to a doctor for recommendations on drug treatments for anxiety. There is a high prevalence of anxiety disorders in the population.
 Well, in a way yes. There was a previous disagreement or argument. Albinism is caused by a malfunctioning gene that produces melanin, and since most species have melanin in their system, they do have the gene that codes for the synthesis of it. Melanin is essential for survival in most species. Since apart from pigmentation, this gene doesn't exactly affect anything else, it's one of the few "bad" mutations, that actually allows the animal to survive and procreate with. This gene has been extensively studied and its effects on pigmentation are well-known. Sure it inhibits camouflage ability, it makes protection from the sun basically nonexistant, but apart from that everything else functions fine. The product being discussed is intended for outdoor use. Therefore, especially animals that live furter from the equator, where extreme sunlight isn't as big of a problem, these animals have a chance to survive and have offspring, which also enhances the probability of seeing an animal with albinism. Animals living closer to the equator have a lower chance of survival due to extreme sunlight. It's in a way similar in polydactily, in that animals that have it can survive, just that it's way easier to spot a completelly white animal, than an individual that has 6 fingers on each limb. Animals with polydactyly are rare.
 Certainly it is possible. There is doubt about the possibility of the situation. It has already happened in fact (although it was not a guided or intentional effort). The event was unexpected. Merely look around at all the different races of humans. There are multiple races of humans present in the environment. Japanese look distinctly different from Germans. Germans look distinctly different from Japanese. Mexicans look distinctly different from Sudanese (and so on). There are distinct physical differences between Mexicans and Sudanese people. This is exactly what you are talking about. You have already discussed this topic before. Each race has distinct traits which sets them apart from other races. Different races have different physical characteristics that distinguish them from each other. These differences arose from selective breeding. Selective breeding was intentional. The selection was not due to some master plan but cultural pressures and other pressures saw certain societies favor certain traits and over time became a distinct population. There were multiple societies involved in the selection process. The problem with setting out a planned course for selectively breeding humans is:1)  Humans take a long time to mature and reproduce. Selective breeding of animals has been successful in the past. You probably would not want to have a couple reproduce till about 20 years of age so all traits were apparent and you could select appropriately. There is a desire to selectively breed individuals based on desirable traits. Then wait another 20 years for the next set and so on. Even if you pushed it down to 13 years old you still have to wait a long time and thus getting an effect from the selective breeding would take centuries. Selective breeding has been attempted before. 2)  You will have a tough time keeping a large enough breeding population (and all their offspring and their offspring) in line, in track and breeding the way you direct. Breeding populations require strict management to maintain genetic diversity. People tend to have sex with whom they choose and not who someone else tells them to do it with. People often feel pressured to have sex with someone they don't want to. 3)  It is insanely creepy. There is a person or entity that finds the situation creepy. But sure, in theory you could do it. There is doubt about whether the task can be accomplished.
 [Doctors](_URL_0_) who play games may make fewer errors. Doctors who do not play games may make more errors.
 Maybe, if you are talking about quantum mechanics. There is a possibility that the topic being discussed is not related to quantum mechanics. From a classical (non-quantum) perspective, it would not change the weight for sure. Weight is a significant factor in the classical perspective. How batteries work: Imagine a nine-volt battery. A nine-volt battery is a common type of battery. It has a positive terminal and a negative terminal. There is a device or object being referred to. Imagine that underneath those terminals are two little tanks (compartments) filled with atoms. There are two terminals present. (Protons, neutrons, and electrons)The difference between an empty battery and a charged battery is that in an empty battery, both tanks are filled with equal amounts electrons and protons. There exists a battery with two tanks, one for electrons and one for protons. In a live battery, one of the tanks has all the electrons for both of the tanks, and the other tank has only protons and neutrons. There are two tanks in a live battery. The negative terminal is attached to the tank with lots of electrons, and when the negative terminal is connected to the positive terminal, the extra electrons flow from the negative terminal to the positive terminal, thus restoring the balance. The tank has an excess of electrons. When you charge a battery, you suck electrons from the positive tank and put them into the negative tank, making the electrons want to flow back to the positive tank as well. Electrons are present in the positive and negative tanks before charging.
 Yes. There was a question asked prior to the response of "Yes." Pretty much all of the sound comes from the air the lightning goes through, not from the target itself. There is a target that the lightning is passing through. By far most lightning goes only through the storm cloud itself and we can hear these aswell. Lightning can occur outside of storm clouds. Only reason they do not seem as loud is because they are further away than if lightning strikes near you. There is a situation where lightning strikes near you and it is loud.
 As others have stated, some epiphytes will get nitrogen from bacteria or fungi that fix N2 from the atomosphere. Epiphytes are the only plants that can get nitrogen from bacteria or fungi that fix N2 from the atmosphere. But for the most part, epiphytes rely on atmospheric deposition for mineral nutrients. Epiphytes are unable to obtain mineral nutrients from the soil. Dry deposition (including ions as vapor in the air) will provide sulfur and nitrogen, mostly as nitrate but also as ammonium and nitrite. There is a significant amount of dry deposition occurring in the environment. Wet deposition knocks fine dust/soil particles out of the air and onto / near the plant. Fine dust/soil particles are present in the air. This is the source of most minerals -- K, P, Fe, Mg, Ca, etc. Minerals are essential for human life. I've heard it suggested that the ability to collect dust/minerals is the stronger selective force for many tropical epiphytes to have water-collecting leaf morphology since it's humid enough that they're not experiencing high transpirational losses. Tropical epiphytes have water-collecting leaf morphology.
 The leading theory on how gold in the Earths crust exists nowadays is by asteroid impacts in the late heavy bombardment era. Gold is not naturally occurring in the Earth's crust. If those are correct there should be gold on the moon. There is a possibility that there are correct data or information about the moon. _URL_0_LCROSS detected gold in October 2009 during an impact test: _URL_1_ There was a mission to detect minerals on the moon.
 This is already under development, although tungsten is denser (higher terminal velocity), and less prone to melt compared to steel. Tungsten is a material that is commonly used in high-speed applications. The real problem is that the radar signature of the incoming attack is the same as a nuclear ballistic missile strike, land based nuclear weapons systems are designed to be launched before such a strike hits the ground, so a pinpoint attack could result in global retaliation. There is an incoming attack with a radar signature similar to a nuclear ballistic missile strike. [Popsci isn't a great source for scholarly information, but it is a perfect intro. There is a need for an introduction to the topic. ](_URL_0_) The person in question has a history of being involved in controversial situations.
 As you said, an anti-inflammatory drug will exert its effect systematically and it does harm the body if used long-term. An anti-inflammatory drug is commonly used for long-term treatment. A classic example is corticosteroid, a powerful anti-inflammatory class of drugs. Corticosteroids are widely used in medical treatments. It has a slew of side effects from long-term use and one of them is increased risk of infection because of suppressed immune response (inflammation is a necessary component of immune response.) Long-term use of medication is common. For short-term use, however, it's mostly safe especially when used as prescribed. The medication in question has potential risks associated with long-term use. Also, there are many instances where anti-inflammatories are injected locally, like in epidural space or inside a joint capsule to treat pain. Anti-inflammatories are commonly used to treat pain. In those cases, the drug will stay in the closed compartment and will not have systemic effects. The drug has been tested in cases where systemic effects are a concern.
 Preamble: Geographic isolation today does not necessarily correlate to isolation throughout history. Geographic isolation in the past was more prevalent than it is today. However, the large mouth bass is a sport fish that is stocked throughout most of the USA. The USA has a significant number of sport fish species. According to the USGS, the natural range of the species is: > Native Range: St. Lawrence and Great Lakes, Hudson Bay (Red River), and Mississippi River basins from southern Quebec to Minnesota and south to the Gulf; Atlantic Slope drainages from North Carolina to Florida; Gulf Slope drainages from southern Florida into northern Mexico (Page and Burr 2011). The species mentioned in the sentence is native to North America. So to answer your original question of the hypothetical catches in MA and CO, both would actually be classified as introduced (not native). There is a question that was asked about hypothetical catches in MA and CO. [Here's the link to the USGS species page](_URL_0_) Hope that helps! There is a USGS species page.
 I assume you mean "for what reason does a proton attract *an electron* fundamentally". Electrons are attracted to protons. It's kind of 'cause that's how it works'. There is a system in place that governs how things work. Electromagnetism is one of the fundamental forces and it has no underlying mechanic (what we know of). There are other fundamental forces besides electromagnetism. How they attract can be explained on a QM level with exchange of virtual particles: [_URL_0_](_URL_0_)Bonus: Feynman on basically the same question: [_URL_1_](_URL_1_) Virtual particles exist and play a role in attraction on a QM level.
 In 3d you can have situations requiring arbitrarily many colors. Color perception is subjective and can vary greatly between individuals. Take a cylinder, cut it into N slices like a pizza for any number N, and then on the top of the cylinder attach N concentric rings. The cylinder is a common object that most people are familiar with. Every ring touches every wedge and vice versa, so for each wedge pick one ring to fuse it with, and now you have N different 3D regions that all touch each other. There are N different 3D regions that all touch each other. You then need N colors to color them all differently. There are at least N objects that need to be colored. Since N was arbitrary, we can make it as big as we like. There is a variable N that can be manipulated.
 Energy conservation is a direct result of time independent laws of physics. The laws of physics are always time independent. Expansion is time dependant, so conservation of energy does not need to hold. Energy conservation is not always necessary. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 I've answered this question before. The person asking the question has asked it before. So I am just gonna copy my old post. The author has previously made a post. > We are very sure the impact caused the KT extinction. The extinction event was caused by a single impact. At least we are quite sure that the [Chicxulub impact](_URL_4_) triggered the extinction. The extinction event was caused by a single event. > [(first paper)](_URL_0_) > [(crater theory)](_URL_2_) > [(newer article)](_URL_5_) > there is also some evidence that the [deccan traps](_URL_1_) played a role too. The author of the first paper has a different opinion than the crater theory. Quite likely it was the combination of asteroid impact which triggered the eruption of the Deccan traps and the combined climate change from both events that caused the extinction. There were multiple events that led to the extinction. [(article)](_URL_3_)   > also sorry that these papers are all behind paywalls. There is a website with articles.
 If the modification using CRISPR occurred in the sperm or egg, yes, that could be passed on to offspring. CRISPR technology has been successfully used to modify genetic material in sperm and eggs.
 As you read, gravitons is just a name for (quantized) gravity waves. Gravity waves have been quantized. Just like photons are just a name for (quantized) electromagnetic waves. Electromagnetic waves exist independently of human language. The way you manipulate light is by creating currents and moving charges around, and the way to create gravitons is by moving masses around. There is a need to manipulate light. But gravitons are by definition just small perturbations, and what you want is to create big heavy configurations, so the understanding of gravity at this "linear level" doesn't give you anything. There is a need to create big heavy configurations.
 Short answer: It's a clade, though some people also call it a superorder. There is a group of organisms that can be classified as a clade or a superorder. There's not a total consensus. Some possible presuppositions for the sentence "<There's not a total consensus.>" are:1. Longer answer: The traditional view that ancestral groups can be stuffed into exactly 7 levels (Kingdom, Phylum, etc. There are more than 7 levels to categorize ancestral groups. etc.) I'm sorry, but there is no sentence indicated by angel brackets in your prompt. turns out not to reflect reality well. There was an expectation that the sentence would reflect reality accurately. What the old named levels (Class, Order, etc.) There were old named levels in the past that are no longer used. really represent, in reality, is the *last common ancestor* of a given cluster of descendants, typically just after a novel evolutionary innovation occurred. There are multiple clusters of descendants that have a last common ancestor. Classifications are really a sequential list of evolutionary innovations, in the order that they occurred in the history of a given lineage. Evolutionary innovations are the only basis for classifications. But here's the problem, *a lot of lineages had more than 7 such innovations* and need *way* more than 7 tiers. There are many lineages with more than 7 innovations. Take the Cetacea, from your example. The speaker has previously mentioned an example involving Cetacea. Here's the traditional way we used to classify the bottlenose dolphin:1. The bottlenose dolphin has been recently reclassified. Kingdom Animalia2. There are other kingdoms besides Kingdom Animalia. Phylum Chordata3. There are over 50,000 species within Phylum Chordata. Class Mammalia4. Mammals are a diverse group of animals. Order Cetacea5. Cetacea is a group of marine mammals. Family Delphinidae6. Delphinidae is a family of marine mammals. Genus *Tursiops*7. Tursiops is a species of marine mammals. Species *truncatus*But the above list doesn't come close to capturing all the important evolutionary innovations that occurred in the history of the bottlenose dolphin. Bottlenose dolphins have a rich evolutionary history. It doesn't show where vertebrates arose, or the moment when lobe-finned fishes first crawled up onto land, or the fact that bottlenose dolphins are toothed whales and not baleen whales. Vertebrates arose from a single ancestor. To solve this problem, at first new tiers were simply stuffed into the existing system, resulting in a classification something like this: (many variants exist and the Cetartiodactyla that you asked about may end up in several different places)1. The problem was complex and required a solution. Domain Eukarya2. Eukarya is a well-known domain in the scientific community. Kingdom Animalia3. There are other kingdoms besides Kingdom Animalia. Subkingdom Metazoa (multicellular animals)4. There are other subkingdoms besides Metazoa that contain multicellular organisms. Phylum Chordata5. There are other phyla besides Chordata. Subphylum Vertebrata (vertebrates)6. Vertebrates are the most evolved species in the animal kingdom. Superclass Gnathostomata (vertebrates with jaws)7. There are other superclasses of vertebrates without jaws. Class Mammalia8. Mammals are the only class of animals that have hair or fur. Subclass Theria (animals with placentas)9. There are other subclasses of animals that do not have placentas. Infraclass Eutheria (animals with *well developed* placentas - excludes the marsupials)10. Animals without well developed placentas do not belong to Infraclass Eutheria. **Superorder Cetartiodactyla** - here's the one you asked about. There are many different species within the Superorder Cetartiodactyla. 11. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Order Cetacea12. Cetacea is a group of marine mammals. Suborder Odontoceti (toothed whales  &  dolphins)13. Toothed whales and dolphins are aquatic mammals. Family Delphinidae14. Delphinidae is a family of marine mammals. Genus *Tursiops*15. Tursiops is a species of marine mammals. Species *truncatus*... but that STILL doesn't capture all the critical evolutionary events. There were multiple critical evolutionary events that occurred in the history of *truncatus*. There was a whole series of innovations that occurred between the invention of jaws (Gnathostomata) and Class Mammalia (for example, in order: the origin of bone, lobe-fins, the transition to land, the amniotic egg, and the unique skull design that led to the mammals.) Innovations between Gnathostomata and Class Mammalia were crucial for the evolution of vertebrates. Trying to stuff five more levels in between "Superclass" and "Class" illustrates how artificial the whole idea of 7 tiers is. There is a hierarchical system in place with seven tiers. What we going to call the five new levels - hyperclass? There are already existing names for the five new levels. megaclass? There are multiple classes available. Basically, every evolutionary lineage has a *different number* of important evolutionary events and there is really no reason that one should be called a "Class" and another one an "Order". There are multiple evolutionary lineages. So now we come to what a lot of biologists do now - simply abandoning the words "Kingdom", "Phylum", etc. Biologists used to use the words "Kingdom", "Phylum", etc. So now we end up with this: 1. There was a problem or issue that needed to be resolved. Eukarya2. There are at least two Eukarya organisms being discussed. Animalia3. There are other kingdoms besides Animalia. Metazoa4. There are at least four different types of Metazoa. Bilateria5. Bilateria is a well-known and widely studied organism. Deuterostomia 6. Deuterostomia is a group of animals. Chordata 7. There are at least 7 different types of Chordata. Craniata 8. There are at least 8 different types of Craniata. Vertebrata9. There are at least 9 different types of Vertebrata. Gnathostomata (vertebrates with jaws)10. There are other types of vertebrates without jaws. Sarcopterygii (lobe-fins and their descendants)11. There are other types of fish that are not lobe-fins or their descendants. Tetrapoda (four-footed animals)12. There are other types of animals that do not have four feet. Reptiliomorpha (this excludes the amphibians)13. There are other groups of animals that are closely related to Reptiliomorpha. Amniota (animals with amniotic eggs)14. Amniotic eggs are a defining characteristic of reptiles, birds, and mammals. Synapsida (the mammal-like reptiles)15. There were other reptiles that were not mammal-like. Therapsida16. Therapsida 16 is a fossilized specimen. Mammalia17. Mammalia 17 is a scientific classification. Theria18. There are 18 different species of Theria. Eutheria (placental mammals)19. There are other types of mammals besides Eutheria. Cetartiodactyla20. There are at least 20 different species of Cetartiodactyla. Cetacea21. There is a species of marine mammals called Cetacea 21. Odontoceti (toothed whales  &  dolphins)22. Toothed whales and dolphins are aquatic mammals. Delphinoidea (dolphins + beluga + narwhal)23. There are at least three species of marine mammals that belong to the Delphinoidea group. Delphinidae (just the dolphins)24. Dolphins are the only members of the Delphinidae family. *Tursiops*25. There is a species called Tursiops. *truncatus*Now this is starting to look too long and it's becoming apparent that every damn little evolutionary branching event is going to get its own name, isn't it? There have been multiple evolutionary branching events. But that's the reality of what really happened. There was a discrepancy between what was believed to have happened and what actually happened. In actual practice we are sort of in an uneasy compromise now. There was a disagreement or conflict that led to the uneasy compromise. Biologists have tacitly agreed that some of those branching points, like Craniata and Vertebrata and Amniota, are definitely important and should be named. Biologists have previously disagreed on the importance of branching points. Others (like Reptiliomorpha and possibly Therapsida) are of little interest except to paleontologists. There are many other groups of organisms that are of great interest to non-paleontologists. Overall, the words "Kingdom", "Phylum", "Class" and "Order" are increasingly not used at all. The scientific community is shifting towards a more simplified classification system. Yet people doing fieldwork - those out in the wild working with actual animals - tend to still use the lowest of the old traditional levels, "Family" and "Genus", because they are handy mnemonic devices for remembering the most closely related clusters of species. People who do not do fieldwork do not use the lowest traditional levels for classification. Back to your main question: When I hear people use Cetartiodactyla they usually don't try anymore to specify whether it's a "class" or "order", because that's completely arbitrary. People commonly use the term Cetartiodactyla without understanding its classification system. They usually just say "Cetartiodactyla". The speaker is familiar with the term "Cetartiodactyla". And there are some biologists, probably including your professor, who grew up with the older system and are accustomed to calling Cetartiodactyla an order or a superorder. Some biologists, including the professor, have been using the older system for a long time. tl;dr - No consensus yet. There have been multiple attempts to reach a consensus. Sorry for length The speaker is apologizing for the length of a previous statement.
 _URL_0_ >  Loose connective tissue is a category of connective tissue which includes areolar tissue, reticular tissue, and adipose tissue. There are other categories of connective tissue besides loose connective tissue. Loose connective tissue is the most common type of connective tissue in vertebrates. There are other types of connective tissue in vertebrates besides loose connective tissue. It holds organs in place and attaches epithelial tissue to other underlying tissues. There are multiple types of tissues in the body. It also surrounds the blood vessels and nerves. There are blood vessels and nerves present. If you've ever slaughtered an animal, you've seen that stuff. You have experience slaughtering animals. It's usually a thin, I would call it diaphanous membrane that's easily cut or pulled away, but strong enough to stabilize positions of organs in situ. There are organs in the body that need to be stabilized.
 Per _URL_0_ it would appear that the brain switches into a different form of functionality when sleep deprived. The brain has multiple forms of functionality. Certain parts of the brain stop reacting normally(as compared to being wide awake), and other parts start over-reacting. The prefrontal cortex tends to become over-active and that could explain why our behaviors become more irratic and irrational as we become more and more exhausted. The brain's prefrontal cortex is responsible for regulating behavior. What I personally find most interesting though is the act of microsleep. Microsleep is a common occurrence. Where the brain basically says 'fuck it' and just forces you into sleep for small moments of time, no matter what. The brain has the ability to control when and how we sleep.
 As far as I know, Autism is not suitable for cognitive based therapies. Autism is suitable for non-cognitive based therapies. Applied behavioral analysis is used as means to modify autistic behaviors and develop self care abilities, but little has suggested any cognitive techniques to be applicable to autism. Cognitive techniques have been used to modify behaviors in other conditions. As for timelines, there's not a clear answer its not like psychoanalysis was just singly supplanted by one other thing. Psychoanalysis was once the dominant form of therapy. Multiple different paradigms coexisted and still coexist to this day. Different cultures have different paradigms. The American Academy of Child and Adolescent Psychiatry adopted as official stance that psychotherapy in general was of "limited use" for autism in 1999. Psychotherapy for autism was widely used before 1999. When those notions were really accepted and where, I don't know. There was a time when those notions were widely accepted. But its not like there was a move from Freudian to CBT, instead the move was in general away from both and trying to manage it behaviorally. There was a shift in the field of psychology. People still surely use both, but neither has any substantial weight to their application to autism, and in general more complete understanding of the condition and more experimental data are needed. People have been using both methods for a long time.
 >  have we ever seen a planet form? There is a scientific community that studies planet formation. Astronomical objects like stars and planets form over what humans would consider very long timescales (from as low as a million years to around a billion), so we haven't been observing anywhere near long enough to see any new objects grow from practically non-existent to full-fledged planets/stars. 1. We have, however, observed an enormous amount of protostars, although you wouldn't expect them to undergo significant evolutionary changes over the course of a single human lifetime. There is a significant amount of protostars in the universe. They tend to experience temporary shifts in temperature and brightness due to thermal instabilities though, and those *do* occur over readily observable timescales (for example, the protostar [V1647 Orionis](_URL_2_) rapidly expanded into a supergiant back in 2004). There are thermal instabilities that cause temporary shifts in temperature and brightness. Also, [a candidate protoplanet](_URL_1_) (still in the process of formation) was found orbiting the pre-main sequence star HD 100546 a few years ago. There are other candidate protoplanets orbiting the pre-main sequence star HD 100546. Its mass is predicted to be 15-20 times that of Jupiter though, which is high enough that it might actually be able to fuse deuterium in its core - and that would make it a [brown dwarf](_URL_0_) instead of a planet. There is a celestial body with a mass predicted to be 15-20 times that of Jupiter. In addition, we've observed protoplanetary discs around other stars, although the evidence for planets forming within them tends to be indirect (usually being based on gaps and distortions within the discs themselves). Other stars have protoplanetary discs.
 I was just reviewing this last night for my wife who is not a physicist! The speaker is knowledgeable about physics. She asked your same question just as I was getting into the derivation of the Lagrangian. The person being referred to had previously asked a question. I wish I had the answer off the top of my head but I eventually found [this beautiful explanation](_URL_0_) on the internet. 1. Turns out,  the classical action is what it is because of the radially symmetric gravitational potential and the non-relativistic speed of the particle(s) in motion. The gravitational potential is the only factor that determines the classical action.
 It is possible to develop deep vein thrombosis if sitting for long periods of time, which can the cause a pulmonary embolism, or blood clot in the lungs, which can certainly be fatal. Sitting for long periods of time is a common occurrence. This is why it suggested that you do some simple exercises while on long haul flights or sitting at a computer for hours every day. You spend a lot of time sitting. The pulmonary embolism itself could cause pulmonary oedema, which could be interpreted as frothing from the mouth by the media. There was a media frenzy surrounding a medical condition.
 Evolution of spinal motion roughly went like this: * Bottom-dwelling marine organisms (such as worms) developed rudimentary cartilaginous spine and, because they were bottom-dwelling, lateral spine motion * They eventually gained the ability to move away from the bottom; their spine evolved from being cartilaginous to being bony, while retaining lateral spine motion. Organisms with spines are exclusively marine. You still see this today in fish — [elasmobranchii](_URL_0_) have cartilaginous skeletons. Fish with bony skeletons are extinct. Bony skeletons are advantageous because they can support stronger muscles, which make for faster and more efficient swimming. Animals with non-bony skeletons are not capable of fast and efficient swimming. * These marine animals eventually moved to land and became the first amphibians. There were no other animals that moved to land before these marine animals. They retained bony spine and lateral spine motion, and developed lungs. There were other organisms that did not retain bony spine and lateral spine motion, and did not develop lungs. The problem with lungs and lateral spine motion in amphibians is that you compress one lung and expand the other every time you make a step, so you have to synchronize your breathing to your steps (or you have to stop to breathe). Amphibians have a unique respiratory system that requires them to synchronize their breathing with their steps. * This gradually leads to development of transverse spinal motion, which also leads to changes in gait — rather than the lizard-like gait of lateral spinal flexion you get mammal-like gait of transverse spinal flexion * At this point, two interesting things happen. 1. One, transverse spinal motion ultimately enables bipedal gait, which eventually leads to humans. Humans are the only species that have bipedal gait. * Second, which is what you were actually asking about, some vertebrates with transverse spinal flexion return to marine habitats. Some vertebrates with transverse spinal flexion have previously returned to marine habitats. All marine mammals are descended from that lineage, which is why all marine mammals have transverse spinal flexion. There exists a lineage from which all marine mammals are descended.
 When light is presented as an electromagnetic wave, one often sees a picture of two sine-waves oscillating in phase, but at an angle of 90 degrees with respect to one another. Light can be presented in other forms besides an electromagnetic wave. It is important to notice that the depth in such a picture does not refer to length, but to field strengths. There are pictures that refer to depth in terms of length. It's not that light roughly moves a long a line while wiggling around it, it's that the field strengths of the electric and magnetic fields oscillate while light moves along the line. There is a scientific phenomenon involving the movement of light along a line. They oscillate and thus repeat, and the length after which 1 repetition occurs is 10 meters, in your example. The object in question is a physical entity that is capable of oscillating. It's not very accurate to assign the frame of classical EM waves to a single photon, as it is a quantum object, so we can't really talk any more about perfectly oscillating EM fields. EM waves are often assigned to single photons. Plane waves, however, can fit this description and are often used in classical optics. Classical optics is a widely studied field.
 Pressure does not directly affect buoyancy because it does not cause a net force; an air bubble in water feels a force in every direction due to the water pressure so pressure will never result in a net downward force. There is a phenomenon called buoyancy. This is assuming there isn't somehow a huge gradient in water pressure on a length scale commensurate with the size of the air bubble, but that isn't the question. There is a possibility of a huge gradient in water pressure on a length scale commensurate with the size of the air bubble. Instead, the buoyant force is equal to the weight of displaced fluid. The fluid in question is being displaced by an object. Air will always displace a weight of water larger than its own weight because water is more dense than air. Water and air are the only two substances involved in this scenario. Water pressure can indirectly change the buoyancy of air in it by changing the water's density but water is almost completely incompressible and its density is nearly unchanged by very large changes in pressure. Air is present in water. An air bubble should always float up in water. Water is present. After writing up this answer I googled it and found [this](_URL_0_) post that goes into some more numbers and reaches the conclusion that nitrogen (air is mostly nitrogen) is unlikely (read: realistically impossible) to ever be denser than water for physically meaningful conditions. 1.
 It may be hard to calculate if a observable difference exists as the overall data reporting process has become better and the rates of events may be the same but our ability to record sinkholes has vastly improved. There have been improvements in the overall data reporting process. This can cause an uptick in sinkhole events. Sinkhole events have been occurring frequently in the area. A secondary source of more sinkholes is our water transportation infrastructure is growing as urbanization has increased over the years. Sinkholes are a significant problem in urban areas. Broken water mains are often a source of sinkholes, therefore an increase in the total miles of pipes will lead to an increase in the probability of failure somewhere. When a failure occurs a sinkhole is possible as the water may erode the soil that is supporting the layers that rest on top. The soil is not strong enough to support the layers on top. It is likely that more sinkholes are occurring due to anthropogenic causes. Sinkholes have been occurring in the past due to natural causes. Hope this helps, this is my first time responding in the sub. The person who wrote the sentence is new to the subreddit.
 Paleontology is more of a coal thing. Coal is a significant part of paleontology research. If you look at coal under a microscope you can often still see the details of long-dead land plants and grains of pollen. Coal is often examined under a microscope. Sometimes there are larger fossils, and sometimes animals. There are times when only smaller fossils are found. Many coal towns have fossils on display as trophies. Fossil hunting is a popular activity in coal towns. As a result of coal mining and coal research there's a lot of bizarrely specific and rich knowledge about the eras and places when significant amounts of coal was being laid down. There was a significant amount of coal being laid down in various eras and places. Paleontologists have named this era the carboniferous, a time dominated by bizarre horsetail relative trees called lycopods that looked like they were designed by Dr. Seuss, alongside dragonflies the size of hawks and primitive tetrapods from before mammals and reptiles diverged. There were no other eras dominated by bizarre horsetail relative trees called lycopods that looked like they were designed by Dr. Seuss. There are biomarkers in oil, but it was mostly dead oceanic algae. Oil spills are common in the ocean. Not much of the original microbes remain. There were originally a large number of microbes present. Oil companies still give a few biologists jobs, but the microbes they're most financially interested in are oil-eating scavengers who came much later. Oil companies have a history of hiring biologists.
 In terms of getting a tan:  glass absorbs UV light, the kind of light that causes sunburn and tanning. UV light is harmful to the skin. So, if you are exposed to sunlight through the glass of a window, your rate of tanning will be greatly reduced. In addition, as explained by others, some light will be reflected and some will be refracted, but that won't affect your tan much. Light is present in the environment. The effects of the speed of light changing is negligible. The speed of light can change.
 Water (the hydrosphere) is the key factor in our mineral cycle. Minerals are not important for our survival. Without it, no clays, and all the instable minerals (mafics, feldspars, etc.) The presence of "it" is necessary for the formation of clays and instable minerals. which end as clays will remain as an inheritance from the source rock. The source rock has already undergone a process of erosion. Mars has had a hydrosphere, now gone, which produced ancient clays, sulphates and hydroxydes. Mars was once a planet with a thriving ecosystem. But more recent sediments are dominated by the host-rock mineralogy and are often close to regolith. The host-rock mineralogy has undergone significant changes in recent times. Titan has some kind of liquid seas/lakes of hydrocarbons. There are other celestial bodies with liquid seas/lakes of hydrocarbons. preliminary indications are that longer chained hydrocarbon sediments surround these bodies. There are bodies present in the area. It is unclear how the inheretance from the source rock would evolve in that context, probably not much as there is very little chemical interaction between most silicates and hydrocarbons (but there could always be local surprises). There is a source rock present in the context.
 In short, no. There was a previous conversation or question that required a response. We know of no physically possible solution to the equations that create a wormhole. There are multiple equations that create a wormhole.
 (PhD Bacteriology)"Smoking preserves fish by drying, by deposition of creosote ingredients, and, when the fish are near the source of heat, by heat penetration" ref: _URL_0_In fact, smoking is not a very good way of preservation. The person with a PhD in Bacteriology is knowledgeable about food preservation techniques. There are lots of bacteria and fungi that don't care about the smoke at all, and will grow in spite of it. There is a significant amount of smoke present in the environment.
 In quantum mechanics conservation of information is phrased as "unitary evolution" or you might say the conservation of probability. The concept of "unitary evolution" is widely accepted in the field of quantum mechanics. I think typically you'd consider this a postulate of the theory rather than a consequence of some symmetry, but it can be related to (for example) the "phase symmetry" of the wave function: only the magnitude of the state vector matters, not its phase in the complex plane. The theory being discussed is well-established and widely accepted.
 If it's a "very rare disease", then the number of surgeons with experience/training in that procedure is going to be limited. There is a high demand for surgeons with experience/training in the procedure for the "very rare disease". Surgery isn't like working on a car, where one guy can pretty much do anything. Surgery requires a team of specialists with different skills. It's pretty specialized. There is a specific field or area of expertise that the sentence is referring to. (Yes, there are genral surgeons, but they do general surgeries like tonselectomies, appendectomies, wound closures, etc...)So, even though medical costs in general are outrageous, there is a matter of supply and demand involved when it comes to "rare" procedures. 1.
 The cranes you describe use electromagnets. The cranes you describe are used exclusively in the construction industry. Electric currents create magnetic fields around them. Magnetic fields can only be created by electric currents. _URL_0_By repeatedly looping wire around a metal rod and then running a large electric current through it, you can create a magnetic field similar to a permanent magnet (the kind you have on your fridge). A metal rod is readily available. The magnetic field from the wire loops adds up in one direction. The wire loops are made of a magnetic material. It also magnetizes the metal rod. The metal rod is magnetic. This happens because the atoms inside the metal all have what is called a magnetic moment (they all have a small magnetic field of their own). The metal is made up of atoms. Normally the magnetic moments of the atoms in the metal are random, and so they all pretty much cancel out. The metal is not exposed to any external magnetic fields. But when the magnetic field from the wires goes through the metal, it causes all the atoms' magnetic moments to line up, which means the magnetic fields from all the atoms is now adding up, not canceling out. The metal is made of magnetic material. This amplifies the wire's magnetic field and results in a powerful over all field. The wire's magnetic field was weak before the amplification. [Here is an image showing the wires, the metal atoms' moments and the field](_URL_1_). The image in question is of high quality and resolution. Now that the current is flowing through the wire, the whole thing acts like one big powerful magnet. The wire was not previously magnetic. But when you turn off the electric current, the wire stops creating a magnetic field and most of the magnetic field goes away. Electric current is flowing through the wire. The metal atoms which were lined up by the field quickly become randomized again when the field is turned off, and so the system stops acting like a magnet very fast. The metal atoms were previously lined up by the field.
 Chemical processes do not affect the rate of radioactive decay. Radioactive decay is a natural process that cannot be altered by external factors. Of course, if you burn radioactive wood the smoke will be radioactive, so if you inhaled it you would have greater radiation exposure. Radioactive wood exists and can be burned. No change in the fundamental decay processes though. There have been changes in other decay processes.
 A good example here is Jupiter, because each atmospheric band rotates at a slightly different speed to another - this is called differential rotation. Jupiter is a planet with multiple atmospheric bands. Jupiter's polar regions rotate about 5 minutes slower than it's equator, at 9h 55m, while it's equator takes 9h 50m. Jupiter's polar regions have a significantly different climate than its equator. The official speed of rotation of Jupiter is measured by its magnetosphere, which is also 9h 55m. Jupiter's magnetosphere is the only way to measure its rotation speed. This was determined by radio astronomers. Radio astronomers were the only ones who could determine this. Venus has no appreciable magnetosphere, so Magellan in the early 1990's used it's radar to accurate determine its rotation of the surface. Venus is a planet. ESA's Venus Express spacecraft used Infrared to look at its surface last year and found Venus' rotation has actually slowed considerably (6.5min!) Venus' rotation was previously thought to be stable. since Magellan visited. Magellan is no longer alive.
 Short answer: almost definitely. There was a question asked that required a short answer, and the answer given was almost definitely. Long answer: In 1687, Isaac Newton published something called "Philosophiæ Naturalis Principia Mathematica," which could be considered the Bible for physics. Isaac Newton was the first person to publish a book on physics. Included in it was the Law of Universal Gravitation, which describes the force of gravity between two objects at a given distance. There are at least two objects in the universe. Around a hundred years later, Henry Cavendish performed experiments that determined the mass of the earth, along with an accurate value for a constant ("G", the gravitational constant) that made Newton's gravity equation work. Henry Cavendish was the first person to perform experiments that determined the mass of the earth. Since the scientists involved in putting objects in space knew, with reasonable accuracy, how far away from the earth's center of mass those objects would be, they also would have known that those objects would be experiencing weightlessness, or to be more specific, microgravity. The scientists involved in putting objects in space had a thorough understanding of the earth's gravitational pull. But, as Sycosys worded it, freefall is probably the most accurate way to describe this--it's why you can simulate being in space with a gut-wrenching airplane ride. There is a way to simulate being in space.
 >  Will we notice how one had obviously larger momentum by the way the debris flies after the collision? There was a collision that resulted in debris flying. Remember that relativistic momentum is conserved in all frames, so it must be conserved in the center of mass frame. The concept of relativistic momentum is widely accepted in the scientific community. If there is net center-of-mass momentum (i.e., one of the asteroids is much larger or much higher gamma than the other) then the collision products will all be produced in a fast-moving CoM frame. There are two asteroids involved in a collision. So yes, the debris would be a pretty clear indicator of which one had higher momentum. There were two objects in question. >  Or assuming an they could crash and get stuck together, would they maintain a large velocity in the direction of the faster asteroid? There are two asteroids moving towards each other. It would depend on how large the difference in gamma was between them, but certainly if they are the same mass and one is moving with v much closer to c, the combined product after collision (if they somehow stuck together, which would be difficult considering how much energy would have to be dissipated) would move also at nearly c, and in the direction of the originally-faster asteroid. There are two asteroids involved in a collision. So again, yes. The speaker has previously mentioned the topic.
 Technically, Central America is part of North America. North America is a continent. They have quite a few monkey species. There are many other animal species in the area. Additionally, Trinidad, an island of the Caribbean has two types of native monkeys. Trinidad is a popular destination for tourists interested in observing native monkeys. I have no answer for your question regarding Mexico, U.S.A and Canada. There is a question about Mexico, U.S.A and Canada.
 So I can't speak to the your secondary question about mutation rates, but as for your initial question, >  Would solar systems with young stars have more radioactive isotopes? 1. ...the answer is definitely yes. There was a question asked. The main sources of radioactivity on Earth today are primarily Thorium-232, Uranium-238, and Potassium-40. Radioactivity is a significant concern for the safety of the planet. These all have long half-lives of 14 billion years, 4.5 billion years, and 1.3 billion years, respectively. There are objects in the universe with half-lives of 14 billion years, 4.5 billion years, and 1.3 billion years, respectively. This makes sense, considering that the age of the Earth is somewhere around 4.6 billion years - all the shorter half-life isotopes would have mostly decayed by now. The Earth is at least 4.6 billion years old. That said, there are definitely shorter half-life isotopes that were really important for the formation of the Solar System as we currently observe it. There are longer half-life isotopes that were not important for the formation of the Solar System as we currently observe it. When we look around at the asteroids, we notice that there's a surprising amount of differentiation among them, which strongly suggests their parent bodies had at least partially molten interiors that allowed the different elements to separate out. The asteroids are made up of different elements. This is why we see that certain asteroids like [16 Psyche](_URL_0_) are particularly metal-rich - it's very likely the remnant of an iron core from a forming protoplanet that eventually broke up. There was a protoplanet that broke up. The problem is that when you carry forward the amount of energy available to initially melt and differentiate these small bodies, the heat from release of gravitational potential as well as the heat from Uranium, Thorium, and Potassium decay simply don't provide enough energy for their cores to melt. Small bodies exist in the universe. However, if you include the heat added by the decay of short-lived isotopes - most notably, [Aluminum-26](_URL_1_), with a half-life of 700,000 years - suddenly all the energy equations balance, and we can reproduce the early differentiation of the Solar System on paper. There are short-lived isotopes that decay and add heat to the Solar System.
 Those side effects were witnessed in clinical trials. The clinical trials were conducted on humans. In those trials,  a statistically relevant numbers of patients were seen with the "issue". The "issue" was not present in any patients outside of the trials. Further, statistical outliers, assuming quality controls were in place, are not permitted to be excluded, because they impact public health. Quality controls were in place.
 The tricky part of extrasolar capture is that you have conservation of energy to deal with. There are other parts of extrasolar capture that are not tricky. If a planet that wasn't orbiting the sun was on a trajectory that brought it close by, it would have enough kinetic energy to escape the sun as well. There are planets that do not orbit the sun. You need to add a third body to make capture work. There are currently only two bodies involved in the capture process. For example, a planet could graze by Jupiter and transfer some kinetic energy, leaving the planet trapped in an orbit and adding boosting Jupiter to a higher average distance from the Sun. There are other planets in the solar system besides Jupiter. It is possible though, and [this paper](_URL_0_) explores the topic in more depth. There is a topic that needs to be explored. They talk about clusters of stars that might have some extrasolar planets floating around. There are many clusters of stars in the universe. Capturing an extrasolar planet would probably leave you with a higher eccentricity and an orbit in a different plane from the other planets, so those features would be clues that capture happened. There are other planets in the same solar system. But a planet that formed around our sun could be sent into a funny orbit by interacting with another planet as well, so it would be tough to prove how a given planet was formed. There are multiple planets in our solar system. The 8 planets in our solar system have pretty low eccentricities and they line up in a nice plane, so they were most likely all formed from the same protoplanetary disk. There is only one solar system in the universe. An extrasolar capture would have to graze an existing planet just right to settle into one of those orbits, and even then it would have an orbit that was too close for comfort with at least one other planet. There are existing planets in the orbit mentioned.
 Don't know if you care but, an aircraft also has this to consider:Magnetic dipThe compass dial will tend to align itself with the geomagnetic field and dip toward the northern magnetic pole when in the northern hemisphere, or toward the southern magnetic pole when in the southern hemisphere. The earth's magnetic field affects aircraft navigation. At the equator this error is negligible. The Earth has an equator. As an aircraft flies closer to either pole the dipping error becomes more prevalent to the point that the compass can become unreliable because its pivot point has surpassed its 18 degrees of tilt. The Earth's magnetic field is not uniform. Magnetic dip is caused by the downward pull of the magnetic poles and is greatest near the poles themselves. The Earth's magnetic poles are located at the North and South poles. To help negate the effect of this downwards force, the center of gravity of the compass bowl hangs below the pivot.The 2008 FAA Instrument Flying Handbook mentioned a dip compensation weight. There is a downwards force affecting the compass bowl. The 2012 edition talks instead about the pendulous mounting arrangement. The previous editions did not mention the pendulous mounting arrangement. Compass navigation near the polar regions, however, is nearly impossible due to the errors caused by this effect. There is a navigational system that is used near the polar regions.
 No, they can't. There was a previous conversation where someone suggested that "they" could do something. They may look similar, but they're quite distantly related, and they diverged a long time ago. There are two distinct species being referred to. Alligatoroidea and Crocodyloidea, the larger groups that contain modern alligators and crocodiles, respectively, extend back into the Cretaceous. There were no other groups that contained modern alligators and crocodiles during the Cretaceous period. However, lots of different croc species can successfully hybridize. There are multiple species of crocodiles that exist. And I'll head folks off at the pass on species definitions: crocs care not one whit for how we define a species. Crocodiles have a unique way of defining species. For more info on how biologists grapple with species definitions, check out [this FAQ](_URL_2_). Biologists struggle with defining species. Edit: I mention the divergence between crocodiles and alligators not because there's some hard rule about divergence dates or even taxonomic rank being the deciding factor in hybridization, but to illustrate that these animals are quite different despite the fact that they may look superficially visually similar. There is a common misconception that crocodiles and alligators are the same animal. I mentioned weird bird hybrids in another comment, but I think it's worth pointing out that there have been hybrids between sand dollars and sea urchins *in different orders* ([source](_URL_1_)). There have been previous discussions about hybrid animals. While kind of thing this is rare, it's worth noting that it can happen. Rare things often have value. Ultimately, rules about different genera/families/hybrids are infertile/etc. There is a belief that rules about different genera/families/hybrids have been attempted before. are not going to hold up. The original sentence presupposes that there was a previous expectation that something would hold up. Okay, back to crocodiles. Crocodiles were previously discussed. The American crocodile (*Crocodylus acutus*) and Cuban crocodile (*Crocodylus rhombifer*) can successfully hybridize. Crocodiles are not typically known for hybridizing. While their ranges overlap and hybridization can occur naturally, they're doing so more and more often. There are multiple species whose ranges overlap. See [this article](_URL_0_) and [this article](_URL_3_) on the subject. There are multiple articles available on the subject. The American crocodile is also known to hybridize with the Morelet's crocodile ([source](_URL_4_) and [source](_URL_6_)). The American crocodile and Morelet's crocodile are closely related species. These are all New World croc species that are fairly closely related. There are no Old World croc species that are closely related to these New World croc species. Also, the saltwater crocodile (*C. porosus*) can hybridize with some of the Indopacific species. The Indopacific species are closely related to the saltwater crocodile. The Philippine crocodile (*C. mindorensis*) is one of them ([source](_URL_7_)). The Philippine crocodile is a rare species. The Siamese crocodile, *Crocodylus siamensis* can hybridize with the saltwater crocodile as well. The saltwater crocodile is a common species in the same habitat as the Siamese crocodile. The weirdest croc hybrid I can think of off the top of my head is that *C. siamensis* can hybridize with the Cuban crocodile ([source](_URL_5_)). There are multiple crocodile hybrids that exist. So no, there are no gator/croc hybrids out there, but modern crocodylians *can* do some wonky things. There is a misconception that gator/croc hybrids exist. Some level of background hybridization is natural and expected where species overlap. Hybridization occurs frequently in areas where species overlap. However, as some populations are reduced, habitat is lost, and climate change impacts coastal habitat, these hybridizations seem to be on the rise. There are multiple populations that are being reduced. Many crocodylians are endangered, and some are critically endangered. There is a significant decline in the population of crocodylians. Increased hybridization could put additional pressure on struggling species. There are already struggling species in the environment. Hybridization also occur in captivity, which can be problematic for captive breeding programs trying to preserve species. Hybridization is a common occurrence in captivity.
 There are quite a few satiety (fullness) signals that reach the brain, all of which are integrated together to form a perception of being full. The brain is capable of integrating multiple signals to form a perception of fullness. The first signals from the stomach come much earlier than 20 minutes, but it can take up to 20 minutes for all the signals the stomach sends to reach as it sends signals through various nerves and peptide horomones. The stomach sends signals through nerves and peptide hormones. The slowest of them take up to 20 minutes to reach the brain. There are faster ways for information to reach the brain. Not all of the signals are from your stomach though. There are signals coming from sources other than the stomach. You get some signals from taste, smell, sight etc… when eating and then further on in your intestines and liver, additional horomones are sent to the brain to indicate further digestion. The human body is capable of receiving signals from multiple senses during the process of eating. In the long term, the brain also gets signals from the blood and fat tissue, the levels of glucose and leptin in your blood help control how full or hungry you feel when not currently eating. The body's signals to the brain are not solely based on food intake.
 10 km/h means that it's practically still relative to Earth and would crash into us due to mutual gravity. The object in question is currently in motion. But assuming it was travelling fast enough to just fly past without ever coming closer than the orbit of Moon, it would cause some pretty strong tidal effects. The object in question is capable of travelling at high speeds. The strength of the tidal forces would be about eighty times as strong as those of Moon. The Moon has tidal forces. What exactly would happen I can't say. There is uncertainty about the future event. Also it would probably cause a significant change to Earth's orbit around the Sun, details of that would depend on the exact trajectory of the planet. The planet in question is not currently in Earth's orbit.
 Yes. There was a question asked prior to the response of "Yes." The two electron states are separated by a fixed energy, which corresponds to a specific wavelength. There is a measurable energy difference between the two electron states. The transition will either absorb or emit that specific energy via a photon of that wavelength. There is a specific energy that can be absorbed or emitted through a photon of that wavelength. So if the transition absorbs a 500nm photon, the excited electron will emit a 500nm photon when it falls back to the previous state. The electron is in a state where it can absorb a 500nm photon. There might be other paths possible though: If the electron can hop down to an intermediate state and then to the ground state it can emit two photons with different wavelengths than 500nm. There are other possible paths for the electron to take. The precise path is governed by chance and certain selection rules. There are certain selection rules in place.
 Your muscles don't know the difference between a "real" workout, and an incidental one... all they care about is how much work they're required to do, and whether it's demanding enough to elicit an adaptation response. Muscles are capable of adapting to different types of workouts. So, pushups done in your office are the same as pushups done in the gym. Pushups are a common exercise. However, if you're well trained in pushups, you may need a stronger stimulus to create an adaptation response. You have already been doing pushups. In this case, you'd be better off in the gym, because I presume you don't have a squat rack in your office or bedroom. You have a desire to work out.
 You make a drosophila line that expresses the yeast gene gal4 under control of a promoter of interest (say actin for example). 1. You make a separate cell line that expresses a gene of interest (say green fluorescent protein) under control of UAS. A gene of interest has already been identified. When you cross the two lines, any drosophila cell that acrivates your promoter of interest (actin) will express gal4, which will in turn bind to UAS and express your gene of interest (GFP). 1. Now all actin expressing cells glow green! Actin expressing cells did not previously glow green. It's a split system because it requires the crossing of two genetic elements to see a phenotype. Genetic elements are the only factors that determine phenotype. Either individual line is usually phenotype free. Individual lines can have phenotypes.
 At the moment, the tallest structure in the world is the [Burj Khalifa](_URL_1_) building in Dubai, UAE. The Burj Khalifa building is the only structure in Dubai that is taller than any other building in the world. It stands as about 830 meters, though nearly two hundred meters of it isn't for human occupation. The structure in question is man-made. The answer to this questions is currently about a kilometer is as high as you can get with today's technology. There is a question that requires an answer about the highest point achievable with today's technology. Currently being built is the [Kingdom Tower](_URL_3_) in Saudi Arabia which aims to reach an even 1,000 meters. The Kingdom Tower is being built by a team of highly skilled engineers. There are some others planned around this height as well. There are multiple construction projects happening in the area. The problem with super-tall towers is you have to deal with the torque such a building will generate on itself--so you need to make sure the center of gravity isn't too high up the tower. Super-tall towers are being built frequently. This is why such super tall towers are wider at the base and thin out as you get higher, it's a more stable configuration. Tall towers are often built in areas with high wind speeds. The [Warsaw radio mast](_URL_2_) is a good example of this, it was almost 650 meters tall and bent in half and collapsed back in 1991. The Warsaw radio mast was a significant landmark in the area. There are proposed towers even taller than this--outside today's technology. There is a significant advancement in technology that will allow for the construction of towers taller than what is currently possible. One of the most massive is the [X Seed 4000](_URL_0_) at a whopping 4,000 meters. The X Seed 4000 is a well-known and widely recognized structure. As you notice from the picture, the base is enormous. The picture is clear and high quality. You can actually find completed design plans for it. There is a specific "it" being referred to. More fantastic projects are also being discussed with the most famous being the [Space Elevator](_URL_4_) which would be go somewhere far past 36,000 km (geostationary orbit). The technology for a Space Elevator is currently being developed. The "idea" is a bit different here as it's be more like "hanging down" a tower than one traditionally supporting its own weight. The tower in question is not a traditional tower.
 It is convention only, to allow scientists to talk to each other without having to describe which coordinate system they are using every time. Scientists frequently communicate with each other. Let me explain. The listener is unaware of the topic being discussed. The direction of the angular momentum of an object doesn't mean anything by itself. Angular momentum is a property of objects. What matters is that when object A with angular momentum interacts with object B with angular momentum, that the angular momentum is conserved. Angular momentum is a crucial factor in the interaction between objects A and B. Then, you can know how the objects will be acting afterwards. There are objects present that will be acting in some way. The reason we use these conventions, is that you don't always want to start back at the very beginning. Say you know how a certain experiment will end up, and then you want to move on. The experiment has already been conducted. You can start with "this experiment will lead to an angular momentum in the +z direction" and move on, without having to describe what that means. There is a scientific experiment taking place. If instead we used a left hand rule, but used it consistently throughout all calculations, everything would work out just the same. Consistent use of a right hand rule is currently being used in calculations.
 Yes, it does. The speaker was asked a question prior to saying "Yes, it does." With vagal deinnervation of the heart, it will continue to beat. The heart has undergone vagal deinnervation. However, the brainstem keeps you breathing. You are not consciously aware of the brainstem's role in breathing. Without oxygen, the heart will eventually cease to beat. The heart requires oxygen to beat normally.
 Both gonorrhea and chlamydia are asymptomatic in at least half of infected people. At least half of infected people are unaware they have either gonorrhea or chlamydia. That's actually why there's been the attempt to shift from "sexually transmitted disease" to "sexually transmitted infection," as "disease" tends to suggest symptoms. There is a widespread concern about the negative connotations associated with the term "sexually transmitted disease." It's also hard to figure out how many people have a disease without symptoms. There is a disease that can be present without symptoms. Between men and women, symptoms are a bit different, as men will get urethritis (burning on peeing+discharge) while women get cervicitis (pain+discharge, but not related to peeing.) Men and women have different anatomies that result in different symptoms for the same infection.
 We know that two particles were entangled because of the their measurement statistics. Particles can be entangled through means other than measurement statistics. Specifically, an ensemble of similarly prepared two particle systems will violate a Bell type inequality if the two particles were entangled. Entangled particles have a significant impact on the violation of Bell type inequalities.
 Wouldn't the brains that conceived of modern medicine also be part of the evolutionary process? The development of modern medicine is a result of the evolutionary process. Also, what does "rate of evolution" really mean? The concept of "rate of evolution" is widely debated among scientists. It's not like it proceeds along at a steady pace. There is an expectation that it should proceed at a steady pace. I feel like what you are trying to ask is, does the fact that we are allowing genes into the gene pool that might not have made it before affect the course of evolution? Genes that were previously excluded from the gene pool are now being allowed in. Since we are potentially eliminating a genetic bottleneck, I would think so. There was a genetic bottleneck that needed to be eliminated. I would guess that it would be a hard thing to determine scientifically until we had a good bit of data. There is a scientific question that needs to be answered. Since evolution proceeds at such a slow pace and modern medicine is fairly new, I'm guessing we don't have the data yet. Evolution has been occurring for a long time.
 Because they either contain theobromine, or caffeine (which is partially metabolized to theobromine). The presence of theobromine or caffeine is a common occurrence in many substances. Dogs are the most popular example of this, but most animals that can get toxicity from it are due to the same reason:  they lack the ability to metabolize and excrete it rapidly, so it builds up and starts causing problems. Animals that can metabolize and excrete toxins rapidly do not experience toxicity from this substance. Should be noted that the type of chocolate and size of the dog plays a huge role in this too. There are different types of chocolate. Milk chocolate is relatively safe (compared to the other chocolate types), dark chocolates are medium of the way (depends on purity), baker's chocolate can get you toxicity pretty quickly. There are other types of chocolate that are more dangerous than milk chocolate. And a large dog will be able to handle more theobromine than a smaller dog. Dogs are commonly exposed to theobromine.
 The big bang is incredibly well supported, but I'd say there are specifically two big guns we can point towards:  1. 1. The universe is expanding. The universe has a definite size. Objects are receding away from us proportionally to their distance to us. There is a universal law of physics that governs the movement of objects. We know this by measuring the redshift of galaxies. Galaxies emit redshifted light. (Though the full picture is a bit more complicated as the rate of expansion is dynamic.) There is a picture that involves expansion. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. If the universe is expanding, then at one point in the past everything must have been very close, dense and hot. The universe exists. The cosmic microwave blackground is the evidence of this hot and dense past. The universe has a hot and dense past.
 Most people speculate that RNA came first, since it is replicable and can catalyze certain chemical reactions. RNA is the first molecule that can replicate and catalyze certain chemical reactions. The only way we know of proteins to be made is by using RNA, so it is unknown how proteins could come before RNA. Proteins are essential for life.
 Dairy isn't UNHEALTHY for the human body. Consuming dairy products is a common practice among humans. But there are other ways to get calcium in your diet. Calcium is an essential nutrient for the human body. Mother's breast milk is dairy. Cows produce breast milk. It isn't necessarily a cow's milk as many people assume. Some possible presuppositions for the sentence "<It isn't necessarily a cow's milk as many people assume.>" are:1. Calcium, Vitamin D, and other nutrients found in dairy are essential for life. Your body needs calcium to operate the muscles, to provide strength for bones, etc. Calcium is essential for the proper functioning of muscles and bones. As for lactose, it is a sugar that most people are able to process and use in their body. Most people consume lactose regularly. However some people are intolerant to lactose, and it can lead to gas, diarrhea, upset stomach, etc. Lactose intolerance is a common condition. Just like how some people can't eat gluten, peanuts, etc...some people are just unable to process certain chemicals in food. Some people are able to process certain chemicals in food. Lactose in itself isn't necessary for life though, but the sugar/energy found in it is. Lactose is not the only source of sugar/energy necessary for life. Do you have any other specific questions regarding it? You have already asked some questions about it.
 Well, some form of low-attenuation light-speed communication is probably best. There is a need for communication. Broadcasting an simple yet artificial-looking electro-magnetic waveform is best at this point. There is a need for broadcasting an electro-magnetic waveform.
 No it does not, for several reasons. There are reasons why the speaker believes that something does not happen. In fact, events like these support the conclusion that our climate is changing. The scientific community agrees that our climate is changing. For starters, no single weather event proves or disproves climate change. Climate change is a widely debated topic. Climate by definition is looking at long term trends. Climate change is a real phenomenon that is happening over a long period of time. Climate change today is occurring on a global scale over years and decades. The Earth's climate has been stable in the past. While this can seem like a long time, and it's long enough to look at climate, keep in mind that in terms of the Earth's ~4.5 billion year history, this is extremely rapid. The Earth's climate has changed significantly over the course of its 4.5 billion year history. We have climate change events recorded in the geologic record, and while it has happened before, this event is occurring very quickly. Climate change events have been occurring for a long time and are a natural part of the Earth's history. Regardless, what we're looking at is a trend, which requires taking data over that time frame and fitting a line to those points. There is a need to analyze data over a specific time frame. This has a couple implications. There are multiple possible interpretations of the sentence "<This has a couple implications.>", so here are three different presuppositions that could be generated:1. One is that aberrant events do happen. Aberrant events are rare occurrences. Statistically, subsequent events are likely to fall closer to that trend line. The trend line has been established through extensive research and analysis. This is known as [regression towards the mean](_URL_3_). Regression towards the mean is a widely accepted phenomenon in statistics. It means that a year of relatively cooler weather following an extremely warm year (or a year of fewer extreme storms following a very active year) does not negate the trend even though from an individual perspective it seems to. There is a trend of warming or increased storm activity over time. Another example would be a year of relatively more sea ice, which is used as an indicator of warming polar temperatures, following years of record lows. There have been years of record lows in polar temperatures. The expansion of sea ice seems significant in the very short term, but the longer trend still shows a significant decrease in the ice. The sea ice has been expanding in the short term. This is illustrated in [this GIF](_URL_4_) (from [this article](_URL_10_)). The article referenced in the sentence is widely known and has been extensively discussed. The other implication is that the line describing the overall trend will have points both above and below it, just by the nature of fitting a line to data. There is a trend that needs to be described. That means that some years will be cooler or warmer than that trend predicts. There is a trend in predicting the weather. There can even be several years of stable temperatures followed by a burst of warming. The climate has been stable for a long time before the burst of warming. The globe overall is still getting warmer, and [that trend is still there](_URL_2_) (image is from the same article as above). The world's temperature has been increasing steadily. That's generally why you have to look at the big picture here. There are multiple perspectives to consider in this situation. In terms of increased snowfall, there are a number of ongoing, interrelated meteorological phenomena that can [cause colder, wetter winters](_URL_7_). There has been an increase in snowfall in recent years. Warmer Arctic summers and melting sea ice seem to be leading to more atmospheric moisture in the northern hemisphere, which is in turn [causing more snowfall in the winter](_URL_8_) ([additional source 1](_URL_6_) and [additional source 2](_URL_9_), both PDFs). The northern hemisphere is experiencing more snowfall in the winter. Events like this can be caused by the [polar vortex weakening](_URL_5_). The occurrence of events like this is not uncommon. The polar vortex is a large body of air that rotates over a center of low pressure at the poles. The Earth's climate is heavily influenced by the polar vortex. It is cyclonic, so it spins with Earth's rotation. The Earth's rotation is significant for the cyclonic movement. When the polar vortex is strong, it tends to stay more compact around the poles. The Earth's climate is affected by the strength of the polar vortex. When the atmosphere, and particularly the stratosphere, warms, the polar vortex weakens and sends cold air down to lower latitudes. The polar vortex is a natural phenomenon that is affected by changes in the atmosphere. The degree to which this cold air spreads away from the poles depends on high pressure systems that surround it, which is tracked using something known as the Arctic Oscillation index. There are high pressure systems that surround the cold air. A positive AO index shows strong high pressure systems, while a negative AO index shows weak high pressure systems and allows that [expansion of cold polar air](_URL_1_). There are high pressure systems in the atmosphere. [Here is a recent article](_URL_0_) looking at these trends over the past few years. There have been significant trends over the past few years. How much this factored into the most recent snows (like what the AO was around that time) I don't know. There was recent snowfall.
 Basically, tides happen because the Earth has a non-zero size (it's not a "point mass"). The Earth's size is a significant factor in the occurrence of tides. The gravitational force of the Moon on the Earth is slightly bigger on the moonward side and slightly smaller on the opposite side because gravity falls off like 1/r^2 and r is slightly different. The Earth's gravitational force on the Moon is also affected by the same phenomenon. In a simplistic case (say, if the Earth was all deep ocean) this force mismatch results in a tidal bulge (the Earth bulged both towards and away from the Moon) and as the Earth rotates this bulge tries to stay aligned with the Moon. The Earth's ocean levels are not uniform. In actuality tides on Earth are a bit more complicated. The Earth has tides. Both land and oceans respond to tidal forces (i.e. Tidal forces have a significant impact on both land and oceans. develop a tidal bulge), but the oceans respond with a much greater amplitude. There is a tidal bulge that occurs. Also, on Earth bathymetry (shape of the shorelines and the ocean floor) plays a large role in the exact timing of high and low tides in a given location because, basically, land is getting in the way of where the water would otherwise go. Water levels are affected by the shape of the ocean floor. See also [the Wikipedia article on tides](_URL_0_). There is a Wikipedia article on tides. The only requirement for a terrestrial object to be affected by the Moon's force is for it to have some mass. There are other requirements for a celestial object to be affected by the Moon's force. For it to be noticeably affected by tidal forces it's size would have to be very large (large enough to be noticeable when compared to the distance between the Earth and the Moon). There are other celestial bodies that are noticeably affected by tidal forces.
 Sort of. There was some uncertainty or ambiguity in the situation. Several neutrinos from the 1987 Supernova were detected about three hours before the light arrived. Neutrinos are particles that can travel faster than light. However, at the time I don't think anyone made the connection that it was a supernova until after the fact. There was a supernova that occurred. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by angel brackets.
 There was an /r/askscience discussion of this a few years ago:_URL_0_ There was a topic discussed on /r/askscience a few years ago.
 It's because we all came from a single common ancestor whose DNA was a right-handed helix (spins counterclockwise as you move in a single direction). All living organisms share a common ancestor. Thus this structure was passed down ever since then. This structure has a long history. This common ancestor was assumedly one of the first living things. Living things existed before this common ancestor. However, the DNA helix may become left-handed under certain conditions. The DNA helix has previously been assumed to always be right-handed. This DNA conformation is referred to as [Z-DNA](_URL_0_), and may be useful for reducing strain in DNA when it's in the process of being copied, though I don't think its presence has been proven in vivo (in a living thing), only in a lab setting. Z-DNA is a widely accepted term in the scientific community. Feel free to ask for more clarification if need be There is a lack of clarity or understanding in the current situation.
 In species with tool use, a common strategy is to poke it with a stick. Tool use is common among certain species. But seriously, it's not something you can generalize. There are exceptions to the rule. It's like along how animals eat. Animals have a specific way of eating. In ant colonies, a dead ant will give off a particular chemical signal that causes other ants to respond to it as if it's dead and take it to the rubbish heap, and they'll do this even if it's alive and resisting and the signal was just squirted onto it by a mischievous scientist. Ants have a highly developed sense of smell that allows them to detect even the slightest chemical signals. Meanwhile mammals with a lot of parental care behavior, or animals with strong pair bonding, will respond to the death of their imprinted attachments with behaviors that look like self-destructive grieving. Animals without strong pair bonding will not exhibit self-destructive grieving when their imprinted attachments die. In general, instincts toward a conspecific or toward a predator, prey species, etc. Animals have instincts towards their own species. are generally going to differ from instincts relating to a corpse, and there's no high level abstraction needed to "understand" that something is dead. People have instincts relating to corpses. But that's still not really general - the general ways that human animals inuit that their conspecific is dead are going to be common at least to the great apes and likely a lot of others. Animals have a way of detecting when their conspecific is dead. Maybe you can rephrase your question a little more specifically? The person being addressed has already asked a question.
 It's all about immune system. The immune system is the most important factor in the situation at hand. All mammals have a similar immune system meaning problems that affect one mammal can likely affect others. Mammals are prone to diseases. Invertebrates immune systems are wildly different and not very well understood currently (horseshoe crabs being a prime weird example). Invertebrates have immune systems. I've never personally seen any literature that suggests that they do have hypersensitivity reactions but it is possible we will find something similar but not the same in the future as we learn more about their immune strategies. There is a group of organisms that are being studied for their immune strategies.
 Well physiologist are actually the ones who do this and it can be done in a few ways. Physiologists have a specific set of skills required to perform this task. You can measure how much oxygen an organism is consuming and how much CO2 they are expelling to approximate how much glucose is being metabolized. Organisms consume oxygen. This could then be used to determine how much ATP is produced. ATP production is a crucial factor in the process being discussed. From there you could estimate how many ATP is used per reaction. There is a scientific experiment being conducted. I did the math and its around 10^25 reactions in a day or about 10^20 reactions per secondThis is a form of indirect [Calorimetry](_URL_0_)Exercising significantly increases theses numbers. 1.
 Actually the space shuttle is really bad in terms of efficiency of it's wings regarding lift and is more like a "flying brick". The space shuttle was designed to be efficient in terms of lift. Just so you can have an idea, the plane the use to train astronauts to land the shuttle needs to be heavily modified so it has a sink rate of 6 times the usual. The shuttle landing training program is a critical aspect of astronaut training. A wing is more efficient when is is very long and thin like the ones you find in gliders, or the U2. Wings that are not long and thin are not efficient. But in there are a lot of factors the need to be taken in consideration that define how a wing is shaped aside efficiency, like speed at which the aircraft must fly, expected load, limitations of the materials that are used, etc. The materials used in wing construction are limited. in the case of the shuttle, the wing is a something that is really more like a drag inducing appendage to make it slow down and give it a way to return to earth as a glider, but it would not be really useful in a conventional aircraft. The shuttle is designed specifically for space travel.
 The shape of the arc is roughly a magnetic field line. The magnetic field line is visible to the naked eye. Solar flares are thought to be caused by [magnetic reconnection. Magnetic reconnection is the only known cause of solar flares. ](_URL_0_) The person in question has a history of being involved in controversial situations.
 Materials Scientist - The ends of batteries and the terminals on the remote are made from either nickel or steel. The materials used in batteries and remotes are limited to nickel and steel. In the atmosphere, both of these metals exist with an oxide film. There is an atmosphere present. Even brand new, there is a thin layer of oxide on this metal. This metal is prone to oxidation. It just comes with exposure to oxygen. Oxygen is necessary for the process to occur. Metal oxide is an insulator that electrons will not travel through. Metal oxide is a common material used in electronic devices. The only reason metal contacts work is that the oxide layer is small enough that either the electron can avoid the oxide atom or it can quantum tunnel through the layer. There is a significant problem with metal contacts not working properly. The other thing going on here is a battery's charge changes as it is drained. A battery is being drained. A rechargeable NiMH will be 1.4V when it is just charged, 1.2V through most of its life, and 1.1V when it is close to death. The battery is rechargeable. Alkaline and heavy duty batteries are similar. There are other types of batteries that are significantly different from alkaline and heavy duty batteries. The thickness of oxide an electron can tunnel through is related to its voltage, so near death the oxide layer is thicker and the voltage is lower. There is a material with an oxide layer that can conduct electricity. When you rotate the battery, you remove some, but not all, of the oxide layer and allow new paths to go through and this gives you just a bit longer battery life. The battery has an oxide layer.
 It's not hot enough to boil your blood. The temperature is high enough to cause discomfort. You feel pain from the temperature, but not from your blood heating up (in the sense that your blood does not contain heat/pain receptors). You have a body that can sense temperature. When your skin encounters high enough temperature, some types of nociceptors like the wide dynamic range nociceptor respond (their afferent fibers are embdedded throughout your cutaneous tissue). Your skin has the ability to sense temperature changes. They have varying thresholds of temperature at which they fire pain signals. There are different types of pain signals that can be fired. Others, like myelinated fast conducting A fibers can be triggered by heat (mechanothermal receptors) as well. There are other types of fibers that can be triggered by heat besides myelinated fast conducting A fibers. As a side note, your skin sends pain signals at about 42 degrees Celsius (106 degrees Fahrenheit), although the exact temperature threshold varies from person to person, and areas of the skin to different areas. The human body has a specific temperature threshold for pain signals.
 Reactors for power generation keep the fission reaction at a neutrally-sustaining level - graphite rods moderate the reaction to control it. Nuclear power plants are widely used for power generation. In a bomb, the fission reaction is designed to happen as quickly as possible to release the maximum amount of energy before the generated heat blows the nuclear material apart. The bomb was designed to release a specific amount of energy.
 Yes, or at least mitigate it significantly. There is a problem that needs to be addressed. See [this](_URL_0_)I'm sure there are plenty of reasons this would be difficult with a car, one of which is the requirement to have license plates. There is a problem with owning a car.
 Motion does not require energy. Energy is required for most forms of motion. It would take energy to speed up the moon, or to put the moon into a higher orbit, but every 28 days its in the same place at the same speed. The moon's position and speed are crucial to some aspect of life on Earth.
 If you wake up by yourself you will feel more refreshed, as an alarm clock will almost certainly interrupt a natural sleep cycle. Waking up by yourself is a natural and desirable way to start the day.
 To a certain extent, yes. The speaker is uncertain about the answer. As you probably know, acoustic waves are mechanical: they exist as the motion of particles in a medium. Acoustic waves are the only type of waves that exist as the motion of particles in a medium. They have a speed based on the medium (primarily the density and elasticity of the material), and they have a wavelength that's related to the speed and frequency of the wave. The medium in question is a solid material. The medium, be that a solid, liquid or gas, has it's own properties. The properties of the medium are unique to that specific medium. One of these properties will be some fundamental length scale. There exists a set of properties, one of which is a fundamental length scale. For a solid, it's the size of the lattice structure. The lattice structure of a solid is crucial to its overall size. For a gas, it's the mean-free-path (the average distance a particle moves before interacting with another particle). Particles in a gas are constantly interacting with each other. Long story short, for an acoustic wave to be self-sustaining, the wavelength needs to be much bigger than the fundamental length scale of the medium. Acoustic waves can be self-sustaining. Normally you'd set the limit at 10 times that fundamental scale, but the larger the better. The fundamental scale is a well-known concept. If you go beyond that limit, the acoustic energy quickly transforms into heat, which gets absorbed by the medium. The limit mentioned in the sentence exists and is clearly defined. For reference, the Mean Free Path in air at STP is 68 nm, which gives us a maximum frequency of 504 MHz. Air at STP is a common medium for transmitting signals. That said, there are other length scales that can come into play before the distance between particles. Particles can interact at different length scales. For example, the thermal penetration depth tells about how far temperature diffuses during a cycle of the wave. Temperature diffusion is a common phenomenon during a wave cycle. Since sound waves are also temperature waves, if that scale is large compared to a wavelength, the sound will become severely damped. Sound waves and temperature waves are closely related phenomena. Similarly, the viscous penetration depth can damp particle motion to kill a wave. Particles in motion can create waves. *Edit: Just ran the numbers, and the frequencies of import for air are these: 50.4 MHz (100x the Mean-free-path), 194.5 MHz (10x the thermal penetration depth), 235.4 MHz (10x the viscous penetration depth), and 504 MHz (10x the Mean-free-path). Air frequencies have a significant impact on the environment. * I'm sorry, but there is no sentence indicated by angel brackets in your prompt.
 This is actually one of the things we studied in forensic toxicology - the case of [Ross Rebagliati](_URL_0_), a Canadian snowboarder whose Olympic gold medal was in jeopardy after testing positive for marijuana. Ross Rebagliati was not the only athlete who tested positive for marijuana during the Olympics. His defense was that he did not partake in smoking, but was in the vicinity as others smoked. There were others smoking in the vicinity. The conclusion in our class is that passive inhalation is usually not enough to give significant blood THC concentrations - one study reporting blood THC levels of 1 - 6 ng/mL right after exposure (to give context: with normal inhalation, blood THC rises to above 100 ng/mL in the minutes immediately after, and settles to about 30 ng/mL in about 20 minutes, in a typical user). There have been studies conducted on the effects of passive inhalation of THC. And even obtaining that level required _extreme exposure_ - high concentration of smoke and limited volume ("hot-boxing"). There was a group of people who were trying to obtain a certain level of achievement. Subjects complained of such severe eye irritation that they requested sealed goggles. The subjects were exposed to a harmful substance that caused severe eye irritation. So my toxicology professor is adamant passive inhalation does next to nothing, physiologically. Passive inhalation is often considered to have a significant physiological impact.
 Since we don't currently know if life forms exist on the other planetary bodies in our solar system, this is a Very Bad Idea. There is a possibility of life forms existing on other planetary bodies in our solar system. Recent science seems to indicate that Europa may be mostly water under an icy crust, and if that is the case, life may exist near undersea vents like on Earth, or at the border between the ice and the water. Europa is a planet. Blindly seeding bacterial life on a poorly understood and unexplored planet would essentially destroy our ability to verify if extraterrestrial life exists there, because from that point on anytime evidence of bacterial or bacterial activity was found, we'd have to spend a lot of effort to make sure that it wasn't actually our Panspermia Thing. There is a possibility of bacterial life on a poorly understood and unexplored planet. This may turn out to be impossible to resolve. There may be a complex issue at hand. So no, this is something we should never, ever do. There was a previous instance where this action was taken.
 The domestication of the cat (and the dog) are both instances of artificial selection. Humans have been practicing artificial selection for a long time. Essentially, humans picked the cats/dogs with the best traits for life among humans, ie, friendliness, companionship. Humans have been selectively breeding cats and dogs for generations to enhance their desirable traits. Those that were unfriendly or aggressive were eventually phased out (although, of course, not completely). There was a group of people who were unfriendly or aggressive. That could be one of the reasons why cats like to be around people. Cats have a strong desire to be around people. There are other reasons as well, that have to do with the social structure of cats and their psychology. Cats have a complex social structure that affects their behavior. Generally, among most mammals, it is favored to form alliances with those that can help you. Mammals have a strong instinct to form alliances. We see this among chimps, for example, who groom each other. Chimps are the only animals that groom each other. Keeping close proximity and affirming relationships through contact / lack of aggression helps strengthen relationships and increases your chances of access to food, help fighting predators, etc. There are other ways to strengthen relationships besides keeping close proximity and affirming relationships through contact/lack of aggression.
 Not even remotely. There was an expectation of something being remotely related. With your bison example, neither. There was a previous discussion about a bison example. They were waiting for it to succumb to its wounds so it'd be an easier kill. The animal in question was wounded. They are not sadistic masterminds, they are following the rule of nature in that they want to expend the least amount of energy for the maximum they can gain. There is a natural law that governs their actions. Attacking a dominant, defensive bison will almost certainly lead to injury. There is a dominant, defensive bison present. Wolves almost never attack humans, its very rare. Humans are not a natural prey for wolves. Also wolves are relatively small, the Alpha in The Grey was the size of a grizzly. Wolves are typically not as large as grizzly bears. Seriously it was a film. The audience was expecting something other than a film.
 In classifying phases and phase transitions, classically we (in condensed matter) rely on local order parameters, such as magnetisation or density. There are multiple ways to classify phases and phase transitions. Essentially one can classify phases and transitions by looking at the dimensionality of the order parameter, the dimensionality of space(time), the symmetries of the problem and the range of the interactions. There are multiple ways to classify phases and transitions. Wilsonian renormalisation formally implements this and allows calculations to predict universal properties of these phases and transitions. There are phases and transitions that can be predicted through Wilsonian renormalisation. Topological ordering is everything else. There are other important factors besides topological ordering. The term is woolly and its meaning can depend on who you talk to and the context. The speaker is unsure of the term's meaning. Take topological insulators for instance; the order parameter is non-local and the result of integrating over momentum space. Topological insulators are a well-known concept in the field of physics. Another (frequent but not necessary) phenomenon is the existence of discrete, degenerate ground states. There are multiple phenomena that exist in addition to discrete, degenerate ground states. My personal preference for understanding quantum systems is real-space (or entanglement) renormalisation of the density matrix, where one progressively coarse grains out high-frequency components, and eventually end up with just a matrix that describes the system. 1. The rank of the matrix then encodes for the "amount" of topological ordering in the ground state. The matrix has a rank. Unfortunately, this doesn't seem to generalise nicely to statistical (rather than quantum) problems. There are statistical problems that do generalize nicely.
 >  Do all wavelengths of light travel at the same speed? Light has different wavelengths. Yes. There was a question asked prior to the response of "Yes." In fact, anything massless will travel at this speed at all times. There exists something that is massless. It gets weirder when you look into relativity and find out that it's same no matter how you're moving, so if you move at 99.99999% the speed of light away from me and I shine a flashlight, you'll still see the light going by at the usual speed. The laws of physics are consistent no matter how fast you are moving. >  If so, what is the speed of light based off of? The speed of light is a well-established concept. It's just a fundamental property of the universe. The universe has many fundamental properties. The definition of the meter is based off the speed of light, but the speed of light is one of those things that just "is". The speed of light is a fundamental constant. >  What would be the biggest implications (scientifically) of breaking the light barrier? Breaking the light barrier is possible. 1. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Faster than light travel. Traveling faster than light is possible in some alternate universe. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. Relativity. The concept of absolute truth does not exist. 3. There was a previous event that led to the situation described in <3.>. Causality (the principle that if A causes B, then A comes before B). There is a clear understanding of cause and effect in the situation. Only 2 of these can be true. At least one of these is false. If relativity and causality are true, then FTL travel is impossible. FTL travel is a concept that has been explored or discussed in some capacity. If relativity and FTL travel are possible, then it's possible to break causality. FTL travel is not currently possible. If FTL travel is possible and causality holds, then relativity goes out the window. FTL travel is not currently possible.
 What does "verify" mean in this case? The speaker is unsure of the meaning of "verify" in a specific context. If you mean "cogently describe all solutions to", then yikes, this is *way* out of the league of high-school algebra. There is a high-school algebra course. The difficulty of proving Fermat's Last Theorem is just a tiny baby corner case of the eldritch horrors that lurk in the darkness of algebraic geometry, which is where you have to go to deal with this sort of thing. Algebraic geometry is a field of study that is full of complex and difficult problems. To be specific, as one small example, here's a perfectly reasonable question in the style you proposed: are there any positive integer triples in the solution set to x^(4) + y^(4) - z^(4) = 0? There exists a solution set to x^(4) + y^(4) - z^(4) = 0. You need at least some reasonably clever number-theoretic arguments to demonstrate that there are not. There are people who have already attempted to demonstrate that there are not any clever number-theoretic arguments. If you replace 4 by 400, things get totally out of hand. The original sentence presupposes that there is a situation where replacing 4 with 400 is possible.
 There are very strong meta-analyses on the subject which basically show LDL is particularly bad in conjunction with low HDL (cardioprotective). There is a significant amount of research on the subject of LDL and HDL levels. HDL tends to go down when you are physically inactive, smoke, obesity etc. There is a correlation between physical inactivity, smoking, obesity, and low HDL levels. LDL tends to go up when you eat a lot of crap like foods high in saturates. Eating foods low in saturates tends to keep LDL levels stable. Atherosclerosis is a disease as we age where our vessels harden with horrible fibrofatty plaques that can essentially predispose us to thromboembolic disease if one of these plaques were to rupture and promote thrombogenesis ie. Our vessels do not harden with fibrofatty plaques as we age. clots in our arteries that can result in a heart attack, ischaemic stroke etc..(sorry if you know this shit). There is a high prevalence of unhealthy lifestyle choices that contribute to the formation of clots in our arteries. In other words, high LDL is shown to drive this process, with several other factors such as smoking, inactivity, diabetes etc accelerating the process, but the main issue is the high LDL cholesterol and low HDL cholesterol, because that is the stuff that is driven into the structure of your blood vessels, producing these plaques. High LDL cholesterol is the primary cause of plaque buildup in blood vessels, with other factors only contributing to the acceleration of the process. As we age it happens anyway but to a lesser degree if we look after ourselves. Looking after ourselves is a crucial factor in slowing down the aging process. At your age, your cardiovascular risk isn't that high BUT the point is,atherosclerosis is a chronic disease that manifests itself after a long period of time so if your blood levels are constantly exposed to these deranged lipids, you will develop significant atherosclerosis and probably ischaemic heart disease after a few decades... As my professor at uni says ' there's no such thing as an acute-MI ( sudden heart attack) it's taken years and years of preparation through inactivity and eating crap you don't need.' 1. So basically, there is a strong correlation at the moment with LDL and heart disease. LDL is the only factor that correlates with heart disease. I only know this because I've had a consultant of cardiology and epidemiology ranting about this over the entire of last week. 1. (cardiovascular bsc student)Of course there will be doubters, just like 9-11 conspiracy theorists and as you said with climate change deniers and so on. 1. These generally have very poor evidence behind it, often misrepresented in poorly conducted trials and so on. There is a widespread belief that these are often based on unreliable evidence. Oh and to improve your cholesterol levels:exercise exercise exercisedon't eat crap, avoid saturates and so on. There is a concern about the person's cholesterol levels. It's pretty obvious when you're eating crap. You have a history of eating unhealthy food. don't smoke (just don't)lose weight? You have previously smoked. Alcohol, a modest intake has been shown to actually improve your HDL! Alcohol consumption is generally associated with negative health effects. Sorry ranted a bit there but I hope that pushes you in the right direction. The speaker had been ranting before.
 Likely no. There is a possibility that the answer is yes. I work with several marine-mammal stranding response teams that do necropsies (animal autopsies) on stranded carcasses, and it takes quite a while to cut *into* a sperm whale even when you have large knives, multiple people and can brace yourself on solid ground. 1. (There is an excellent 1-hr documentary on a sperm whale necropsy [here](_URL_0_), for the curious, with a great comparative anatomist). A sperm whale necropsy is a rare event that is not often documented. You'd only have a minute or two before you passed out from lack of air; not nearly enough time. There is a situation where lack of air is a concern.
 Wind chill doesn't *change* the temperature. The temperature can change due to other factors. It changes how *fast* you loose heat energy. Heat energy can be lost at different rates. A thermometer will reach the same reading whatever exposed to wind or not, but one exposed to wind will reach it *faster*. A thermometer is a device that measures temperature. This is essentially why we use fans to improve the function of heat sinks. Heat sinks are necessary for some kind of machinery. The fan moves air over the heat sink, allowing more air to touch the hot surface, and carry away heat. There is a heat source that needs to be cooled down.
 It undoubtedly depends on the snail, its envirionment, and a few other factors. The snail's environment is a crucial factor in determining its fate. However, snails are likely incapable of sustaining top speeds for long periods of time due to depletion of the mucous membrane. Snails have a mucous membrane. The freshwater snails that I study take on average 106 seconds to traverse 1 inch.
 Ze French 'ave used this for ages to [ouvrir bouteilles de vin](_URL_0_). French people have been drinking wine for ages.
 Head colds actually significantly impacted Apollo 7, the first manned Apollo launch. Apollo 7 was successfully launched despite the significant impact of head colds. All three astronauts developed head colds during the course of the 11-day mission. The astronauts were not sick before the mission. They became snappish and irritable, and refused a number of orders from the ground. There were multiple people involved in the situation. The blame for this "mutiny in space" is mostly placed on mission commander Wally Schirra. Wally Schirra was the mission commander during the "mutiny in space." One of the original Mercury 7, he was NASA's most senior astronaut and the only person to fly in all three manned rocket programs: Mercury, Gemini, and Apollo. The speaker is knowledgeable about the history of NASA's space programs. When he began refusing to cooperate, his two crewmates followed his lead. He was in a position of authority over his crewmates. Experiments outside the scope of testing the new capsule were scrapped, one of those "live from space" TV interviews was refused, and the entire mission took on an air of stubborn negativity. There were originally plans for experiments outside the scope of testing the new capsule. Everything came to a peak before re-entry: the astronauts were supposed to put their helmets on, in case of depressurization. The astronauts were aware of the possibility of depressurization before re-entry. But the astronauts, with head colds and fearing burst eardrums, wanted to be able to pinch their noses to equalize their sinus pressure as they landed. The astronauts were aware of the potential risks of landing with head colds and burst eardrums. They ended up disobeying a direct order to put their helmets on, and Schirra basically told the flight director to go to hell. The direct order to put on helmets was given in a dangerous situation. None of the three astronauts flew again: Schirra retired, while the two younger astronauts kept their jobs but were permanently grounded. At least one of the three astronauts had a medical condition that prevented them from flying again. Schirra actually used the experience to star in commercials for a cold remedy. Schirra had a bad cold. For later missions, I'm unaware if illness has ever significantly affected performance. Illness has never significantly affected performance in previous missions. However, there have been recorded infections: at least 29 according to [this article from 2012](_URL_0_). There is a concern about the spread of infections. These can potentially be serious, as zero gravity is a terrible place to get sick. Zero gravity is a common occurrence in the location where the sentence was spoken. For reasons we don't really understand, the immune system is significantly weakened in zero-g, while pathogens are strengthened. There is a significant amount of research being conducted on the effects of zero-gravity on the human body. And the aerosol cloud from a sneeze doesn't drift to the ground like it does on Earth - it just flies outward, to land on and stick to all the instrument panels and such. There are instrument panels and other surfaces in the environment where the sneeze occurred. Infection control in space is serious business. There are frequent outbreaks of infections in space.
 A qubit is the basic unit of information in a quantum system (it's exactly analagous to a 'bit' in conventional computing). Quantum systems are the only systems that use qubits as the basic unit of information. A qubit can be made of any two-level quantum system that exhibits entanglement and superposition. There exists a quantum system that exhibits entanglement and superposition. The hydrogen atom is a useful model for this, but more commonly scientists will create an 'artificial atom' because they can be constructed to have specific energy gaps that don't occur naturally in atoms. Scientists have successfully created artificial atoms with specific energy gaps. Common models include partially-superconducting circuits, quantum dot electron traps, microwave cavities, etc. There is a significant demand for advanced electronic devices. A qubit, unlike a regular bit, doesn't just exist in state |0 >  or state |1 > ; it can exist in any superposition of those two states, e.g. A qubit is a fundamental unit of quantum information processing. Y = A*|0 >  + B*|1 > . There are two variables involved in the equation. This is sometimes represented using the Bloch sphere (the state of the qubit represents a point on the sphere). The Bloch sphere is a commonly used tool in quantum mechanics. Qubits achieve the special quantum computing outcomes they do because when you perform an operation on them, you're effectively performing it on multiple states at the same time with relevant probability weights between each. Quantum computing outcomes are achieved through the use of qubits. This makes a quantum computer really good at certain types of operations (factorising large numbers is one, 'searching' or oracle algorithms are another). Quantum computers are not good at all types of operations.
 I asked Ron Ellingson from Mount Baldy Ski Lifts (who provides the balls) and he replied: The balls are black because of the uv protection in the balls. The balls are made of a material that requires UV protection. They last longer. The product in question has a shorter lifespan. Black blocks the sun which is what warms the water . The water is only warm when the sun is shining.
 Water absorbs least strongly at around 470nm. There are other substances that absorb more strongly than water at around 470nm. Interestingly, the highest spectral irradiance (a wavelength dependent measure of irradiance) of sunlight at sea level is also around 470nm (exercise to the reader to figure out why :D). Sunlight at sea level has a significant impact on the environment. This means that blue light at 470nm travels furthest through water (this is why water is blue). Water is always blue. I'm not sure where the "dark zone" starts, we can define the cutoff as 1% of original intensity. There is a "dark zone" that needs to be defined. If the absorption coefficient a of water at 470nm is .0002, we use d = 1/a to determine the distance at which the intensity of light is reduced by a factor of e (2.718). Water is commonly used in experiments involving light. Continuing this math, we find that only 1% of 470nm light is present after 230m, which corresponds very nicely with this diagram: _URL_0_TL;DR Apparently pure water is not that much clearer than ocean water. The diagram mentioned in the sentence is accurate and reliable.
 Even though changes in the gravitational field propagate at finite speed (c), and it takes about 8 minutes for signals from the sun to reach Earth, the Earth accelerates toward where the sun is **now** rather than where it was 8 minutes ago. The sun's position changes rapidly enough that the Earth must constantly adjust its acceleration. [Here](_URL_0_) is a paper explaining why. There is a specific paper being referred to.
 AT & T has a [doc](_URL_0_) comparing energy consumption between UMTS (3G) and LTE (4G). There is a significant difference in energy consumption between UMTS (3G) and LTE (4G). It depends. There is a specific situation or context that the speaker is referring to when they say "it depends." Overall it seems too me that despite of: >  The bottom line is that while LTE is much faster than 3G, it also uses more energy...when you also regard the much higher data rate it's more energy efficient per transmitted KB. LTE and 3G are both widely used technologies.
 Maybe this is too far off topic, but it's reminiscent of the way we think about cliches and colloquialisms. There is a topic being discussed. If you hear a phrase repeated to you throughout your lifetime, you may stop thinking consciously about the literal meaning of the words while still understanding the implication of the phrase. People often hear phrases repeated throughout their lifetime.
 All of the metals you listed do indeed function as enzyme cofactors, as do most trace, essential elements of the human body. Metals that do not function as enzyme cofactors are not essential elements of the human body. I'll go over each and some of their basic functions:**Copper** has the most different functions of the metals you listed. Other metals have similar functions to copper. It is extremely important for essentially all levels of life. Life cannot exist without this thing. It's primary functions in humans are the facilitation of metabolic processes, human development, and erythrocyte synthesis. Humans cannot survive without the functions facilitated by this sentence. Biochemically, it serves as a cofactor for various oxidase enzymes around the body. Oxidase enzymes are present in the body. Source: _URL_2_**Selenium** is a bit more niche. Selenium is not widely known. It is involved in the synthesis and function of glutathione peroxidases, which serve to protect the body from harmful oxidation reactions. Glutathione peroxidases are essential for protecting the body from harmful oxidation reactions. Specifically, selenium atoms are contained in selenocysteine, a rare amino acid, which are residues in selenoproteins. Selenocysteine is a crucial component in the formation of selenoproteins. Glutathione peroxidases are a category of selenoproteins. Selenium is an essential component of glutathione peroxidases. Finally, thioredoxin reductases, which are involved in sulfur bond formation, are also selenoproteins. Selenium deficiency affects the function of thioredoxin reductases. Source: _URL_0_**Chromium's** mechanisms are less understood, but it is believed to be involved in metabolism of carbohydrates, lipids, and proteins, as well as insulin release. Chromium's mechanisms have been studied extensively. Source: _URL_1_**Molybdenum** is also an enzyme cofactor. Molybdenum is a common element in enzyme cofactors. It has a known role in the function of sulfite oxidases, xanthine oxidases, aldehyde oxidases, and mitochondrial amidoxime reducing components (mARCs). There are multiple functions that sulfite oxidases, xanthine oxidases, aldehyde oxidases, and mitochondrial amidoxime reducing components (mARCs) are involved in. Source: _URL_3_A few others that you might be aware of are iron, well known for its role in oxygen transport, and magnesium, which is often used to stabilize phosphate groups in phosporylated compounds. Iron and magnesium are the only two elements that have a significant role in oxygen transport and phosphate group stabilization, respectively.
 This is somewhat complicated -- the answer will change depending on if you mean by volume or by mass. There is a distinction between measuring by volume and measuring by mass. I believe that by volume the answer is yes, because otherwise your lungs would be constantly expanding or shrinking. The speaker has knowledge about the volume of something. I think that by mass the answer should be that we breathe out more than we breathe in, because we convert oxygen to carbon dioxide and we add some water vapor. We inhale more oxygen than we exhale carbon dioxide. However, I don't have a source for this so this answer is just temporary until someone with a source or more authority can respond. There is a need for a source or authority to validate the answer.
 I think you would probably be better off just taking the aforementioned capsule before eating. There is a capsule that was previously mentioned. It's hard to say whether the vitamins in the powder would be able to withstand the boiling process. The vitamins in the powder have been previously tested for their ability to withstand heat. I'm by no means an expert on these things, but I would think that if you prepared your rice, or what-have-you, then took the supplement before eating that it would be just as beneficial as having it in a smoothie - after all, it's just tossed into smoothies, so it shouldn't be a problem. 1. Maybe call a local nutritionist to get some more precise info on it? There is some information that is not precise. Either way I hope whatever you choose to do works out for you. You have a decision to make. ^.^ There is a person or entity represented by the symbol <^.^>.
 Friction is a good culprit in mechanical systems, but equivalent types of loss occur in other systems (e.g. There are other types of loss in mechanical systems besides friction. viscosity leads to drag in fluids; randomization of electron paths leads to ohmic resistance in electrical systems). Fluids have viscosity. I think the concept you're reaching for is this:  it is never, in practice, possible to create a completely ordered system, and slight amounts of disorder in any energy-transducing system will yield loss of ordered energy (mechanical, electrical, chemical) to disordered energy (heat at uniform temperature). There is a fundamental law of thermodynamics that states that it is impossible to create a completely ordered system. Friction is due to lack of order in the physical shape of sliding solids on the molecular scale, or to viscosity in liquids or gases -- which in turn is due to momentum transfer by disordered molecular motion perpendicular to applied shear. There is a physical phenomenon called friction. Electrical resistance is due to disorder in the electron-nucleus interaction in a conductor. There is a conductor present. Etc. There was a previous mention of something else before <Etc.>. The problem is that such statements have to be so general (to encompass all the forms of disorder and of ordered energy) that they just boil down to restatements of the second law of thermodynamics. There are multiple statements that have to be made to encompass all forms of disorder and ordered energy.
 Inheriting two copies of the gene usually leads to death in infancy [1], and a lot of achrondroplasic dwarfs have chronic pain, which would cause a general decrease in "fitness" (in the Darwinian sense). There is a genetic condition that causes death in infancy when two copies of the gene are inherited. It seems fair to say it probably puts people at a pretty serious sexual disadvantage as well. People are already at a disadvantage in terms of sexual opportunities. 1. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 Erm, I'm not going to answer all of your question, but I'll just pick up on a few points. The speaker is avoiding answering certain questions. There are several models used to describe a nucleus. Scientists have discovered new models to describe a nucleus. Science describes models rather than reality. Models are more important than reality in science. One model of the nucleus is the liquid drop model that sees it as a sphere analgous to a drop of water. The nucleus is not a solid object. If this droplet is too large - eg in a U238 nucleus, it is unstable, and nucleons can spontaneously be emitted. The droplet in question is in a U238 nucleus. (This isn't a prefect model by any means, but was one of the first used to describe radiation due to nuclear decay). Radiation due to nuclear decay was a significant problem that required immediate attention. As to quarks - they are seen as point like particles and the quarks in the nucleons are held together by the strong force. The existence of quarks is widely accepted in the scientific community. They are also moving around very quickly - so fast that the majority of the rest mass of a nucleon is due to the relativistic increase in mass of its constituent quarks. The quarks in a nucleon have a significant impact on its mass.
 Designing a computer language is a pretty tricky business, really. Designing a computer language is a highly specialized field. There are a lot of tradeoffs to be made, which explains why there are [so dang many](_URL_10_) of them. There are many options available, but they all come with tradeoffs. When starting a new one from scratch, you ask yourself a lot of questions. Starting from scratch is a common occurrence. Ultimately, the question that matters most is, "What do I want to be _easy_ in this language?" There is a language that the speaker is trying to learn. You might even call it the First Question of Computing. Computing has a set of fundamental questions. That's only half the problem, however. There is a problem. To understand the second half, let's take a little detour into the mid 20th century, and look at computers themselves. The mid 20th century was a significant time for the development of computers. Now, ever since [the first computers](_URL_28_) came online, we brave and foolish folks who program them have had a vast number of varied answers to this question. Computers have been online for a long time. Some folks wanted to [make war simpler](_URL_11_), some wanted to [make intelligence simpler](_URL_23_). There is a current issue with the complexity of war and intelligence. But in general, the early computers were often single purpose machines. Early computers were not versatile machines. Enter [ENIAC](_URL_17_), which is often called the first "general purpose" computer. ENIAC was not the first computer ever created. All of a sudden, we had a machine which could do a lot of different things. There was a time when we did not have a machine that could do a lot of different things. This was exciting! The person who said "This was exciting!" And terrifying at the same time. There is something that is both scary and awe-inspiring. How do you tell a computer the size of a small house that you want to calculate the logarithm of any number you give it, just as a simple example? A computer can calculate the logarithm of any number given to it. The answer was to have a very small number of very simple instructions that the computer could perform, and then build up from this small [instruction set](_URL_6_), combining them in various orders, until you eventually make a "program" that does what you want. The computer was not able to perform complex instructions. Amazingly, this still holds true today! There was a time when people thought this statement was false. Your typical PC running what's called the [x86 instruction set](_URL_3_) is basically just performing a bunch of the same small(-[ish](_URL_19_)) number of instructions over and over, until you get [what you wanted](_URL_5_) to get. The x86 instruction set is widely used in the computer industry. [As a brief aside, mathematicians had already attempted this reduction of an algorithm to the most [basic set](_URL_31_) of operations and postulates - let's just say it [didn't go so well](_URL_21_), and both mathematicians and computer programmers are struggling with some [fundamental problems](_URL_9_) that fell out even today.] Mathematicians and computer programmers have been working on this reduction for a long time. One key feature of almost all instruction sets is their emphasis on arithmetic. Arithmetic is the most important aspect of instruction sets. There's a reason we call computers "computers", after all. Computers were not always called "computers". The designers of the earliest computers answered the First Question of Computing with "I want _math_ to be easy." Math was not easy before the designers of the earliest computers answered the First Question of Computing with "I want math to be easy." So computers got really good at math, [really quickly](_URL_18_). Computers were not good at math before. Unfortunately, as the things we asked computers to do became more and more complex, it became very tedious to construct programs using that very small set of possible instructions. Computers were initially able to handle complex tasks. One particularly [forward thinking programmer](_URL_7_) decided one day to add a [layer of indirection](_URL_22_) between the program writer, and the machine. The programmer had previously encountered issues with the direct communication between the program writer and the machine. Basically, she decided to answer the First Question of Computing with, "I want to make _writing complex mathematical algorithms_ easy." The person in question has experience with writing complex mathematical algorithms. The first of the truly great computer programming languages, [FORTRAN](_URL_27_), was finally born. FORTRAN was not the first programming language to be created. FORTRAN allows the programmer to type things like "do the following thing [10 times](_URL_2_)", written not in instruction-set codes, but in plain old [English](_URL_32_). FORTRAN is an outdated programming language. This was an enormous step forward, but involved some sleight of hand behind the scenes. There were people involved in the process who were not supposed to be there. Basically, the FORTRAN compiler would read in the program which was nice to human eyes, and for each line of code, it would create a bunch of those instructions from the instruction set that [preserved the intent](_URL_12_) of that line of code, but could now be executed by the machine. The original program was not written in a way that could be easily executed by the machine. This truly was wizardry of the highest order. Very much like a growing baby, FORTRAN changed and grew as the years went by, as different people asked it to answer the First Question of Computing in different ways. FORTRAN was created to answer the First Question of Computing. Computers started to get smaller and faster, and made their way into the home. People used to only have large and slow computers. All of a sudden, folks much like myself started to give [_very_ different answers](_URL_15_) to the First Question of Computing. People were previously giving similar answers to the First Question of Computing. We were playing with the computer, exploring what it would let us do, what it could be pushed to do. The computer was new to us. With this large set of new things that people wanted to be _easy_ to do on a computer, a whole slew of new languages popped up. People were struggling to do things on a computer before this large set of new things was introduced. Some of them let you [manipulate lists](_URL_20_) really easily, some of them let you [manipulate hardware](_URL_0_) really easily. There are multiple tools available for manipulating lists and hardware. In each language, it was easy to do some things, but remember those tradeoffs I mentioned right at the beginning? People speak multiple languages. They were right about to bite us programmers in the butt. There were programmers who were in danger of being bitten. In C, for instance, it is in fact very easy to manipulate hardware. Hardware manipulation is a common practice in the field of C programming. Many [operating systems](_URL_13_) are written in C for just this reason. C is the most popular programming language for operating systems. Unfortunately, making it easy to manipulate hardware makes it really hard to [manage your computer's memory](_URL_8_), among other things. There are other things besides managing computer memory that become difficult when hardware is easy to manipulate. C programmers spend a lot of time worrying about where _exactly_ they stored this variable or that string, how to get rid of it, how to let other parts of the program know where it is. C programmers often struggle with memory management. Needless to say, if you're not answering the First Question of Computing with "I want to make hardware manipulation easy", C is going to give you a rough ride. The First Question of Computing exists. The designers of [Java](_URL_25_), for instance, answered the First Question of Computing with, "I want to make [running on lots of different machines](_URL_30_) easy". Java is a widely used programming language. While the jury may still be out on whether or not they succeeded, they did have a clear vision because they succinctly answered the First Question of Computing. The First Question of Computing is a widely recognized concept. (A few other global principles went into the design as well, of course.) The design was not solely based on the mentioned global principles. Now for each of these new computer languages, you'd have a different [grammar](_URL_1_) that defined what a legal line of code looks like, much like English grammar is different than Finnish grammar. There are multiple new computer languages being developed. Both let you speak and [convey meaning](_URL_16_), but they sound pretty darn different. There is a need to convey meaning. What's the same, however, is that for each line of code in the "high-level" language, we use a compiler or interpreter to transform our friendly code into the kind of instructions the machine likes to read. There is a high-level language being used. This constant, this fundamental purpose of the compiler, is the second half of designing a computer language. A computer language cannot be designed without a compiler. First it [parses](_URL_26_) your friendly code, then [generates](_URL_24__generation_(compiler\)) machine code. The code being parsed is written in a friendly language. We can now hopefully answer what it means to create a new programming language. There is a need for a new programming language. First, you need to answer the First Question of Computing. You have already started learning about Computing. Once you have decided how _you_ want to answer that question, then you write the grammar that fulfills your answer, and the compiler that translates your grammar to the grammar of the underlying machine instruction set. You have a question that needs to be answered. This process, this mapping between two different levels of representation, but a map that _preserves meaning_, is far and away one of the most amazing ideas I've ever learned about. There are multiple levels of representation involved in the process being discussed. It has applications in a huge number of different [endeavors](_URL_14_), across all [walks of life](_URL_4_). There are countless endeavors in the world. It is the idea of a [_code_](_URL_24_). The [_code_] mentioned in the sentence is a widely used programming language. The fact that you asked this question means you've taken your first step into a truly amazing journey. You have been hesitant to take this journey before. Stay curious :) Curiosity is a valuable trait to possess.
 The second one is kind of BS but said a lot. People often make false claims. In reality light (i.e. Light is often perceived differently than it actually is. photons) doesn't travel through materials at all. Materials are impenetrable to photons. Light is an oscillating EM wave and when it is incident on a solid surface its electromagnetic field INDUCES a corresponding polarization within the material. Solid surfaces are the only materials that can be polarized by light. By polarization I mean a net local squishing of the positive (atomic nuclei) and negative (electrons) charges in the material. The material being discussed has both positive and negative charges. In general there are equal numbers of positive and negative charges but when they are spatially separated, or squished, you get a brief net dipole of polarization. There is a phenomenon called polarization that occurs when positive and negative charges are spatially separated or squished. When we talk about "light" moving in a material we really mean this polarization wave and it necessarily travels slower than light. There is a material in which light can move. When it reachs the other side it effectively induces a net varying electric field at the surface which then is basically a light wave coming out the other side. There is a surface that the object in question is reaching. From this perspective it it easy to see why it's not too mind bending that waves of instantaneous polarization propagating through a material are slower than light and how that presents no relativity or causality concerns. There is a material that allows for waves of instantaneous polarization.
 Here's the shot on youtube, it's only about 20 s long:_URL_0_Two major errors stand out as very wrong to me. The video was uploaded recently. I see from the wiki page for the movie that the planet is much larger than earth, and in orbit around the sun. The planet in question is habitable for humans. I'll assume it is twice the radius of the earth* The other planet is moving ***wayyyyyyyyyyy too fast***. 1. A collision between earth and another planet in an orbit near earth's would be on the scale of the planetary escape velocity, so probably a few 10's of km/s. There is another planet in an orbit near Earth. We can do a quick estimate of its speed from the movie. The movie contains a scene where the speed of something is shown. Assuming the field of view of the camera is about 30 degrees wide, I see that it went from spanning 20 degrees to 30 degrees between the 3:03 and 3:14 marks, which means it covered... (back of the envelope trig)... 24,000 km in those 11 seconds, which means it is closing at about 2,200 km/s. The camera is observing an object that is moving towards it. That's about 100 times too fast! The object in question was moving at a speed that is considered dangerous. * No tidal effects and earthquakes. There have been previous instances of tidal effects and earthquakes. The planets would have been tearing each other apart from tidal effects before they hit. There were multiple planets in the system. See the Roche limit, linked in this thread. The Roche limit is a well-known concept in astronomy. They would not have been sitting peacefully, they would have been tossed around, possibly into a (literal) vast chasm of darkness. There was a dangerous situation that caused them to be tossed around. Edit:  because the collision is happening so ridiculously quickly, there may not have been too much time for the tidal effects to do much. The collision is happening at an incredibly fast speed. The wiki page says that the planet made a close pass earlier in the film, and surely that would have caused major tectonic havoc. The planet in question is known for its unstable tectonic activity.
 > So, to control the power of the gun, you only need to adjust the amount of power being supplied? The gun has a power supply that can be adjusted. Yes. There was a question asked prior to the response of "Yes." Powerful railguns build up their power through letting the charge in capacitors or pulsators build up over time. Railguns are commonly used in military applications. > and the fire button is basically just a switch allowing the current to flow? There is an electrical device being discussed. On simple designs, yes. Simple designs are often preferred. In more complex systems(such as high power railguns like those I mentioned above), the fire button/trigger would connect to a circuit that tells the capacitors to begin building charge. There are high power railguns that exist. > Also what is the armature? There is an object or device called an armature. In this case it's the projectile. The projectile has been previously mentioned or is already known to the listener. You may want someone more qualified to answer this subquestion. There are other subquestions that require a higher level of expertise.
 Off the top of my head, not that I've heard of. There is a possibility that the speaker has heard of the topic before. If we did, the main identifying features would be the abundances of elements and isotope ratios in the object - however, we're not really too sure of the compositions of the Asteroid Belt or Kuiper Belt, let alone the Oort Cloud! There are objects in the universe with identifiable features based on their element abundances and isotope ratios. It could well be that some interesting surprises turn up as we study these in further detail. There is a need to study these in further detail.
 The black hole would do the pulling like any normal way. There are other ways for objects to be pulled besides the black hole. The quark outside the black hole will have its pair created, nothing special. There is a black hole nearby. As for the one that falls inside the black hole, another forms, but both are destroyed (or whatever actually happens) as it reaches the singularity. There is a black hole present in the situation. The black hole increases in mass/energy. There was a previous measurement of the black hole's mass/energy. But wait, did we see a breaking of conservation of energy in this? Conservation of energy is a well-established principle in physics. We started off with a black hole and a pair of quarks, but we ended up with an identical pair of quarks and a black hole of slightly larger mass. There was a scientific experiment conducted involving a black hole and quarks. Where did the extra mass/energy of the black hole come from? The black hole had extra mass/energy to begin with. Someone else know what's not right here? There is something wrong here that the speaker is not aware of. Edit: thanks to /u/dgm42 for realizing that the extra energy comes from holding one of the quarks from being sucked inside the black hole! There is a black hole present.
 Not quite, but basically yes to within a few degrees. The speaker is referring to a measurement or calculation. [Wikipedia has the exact values. Wikipedia is a reliable source of information. ](_URL_0_)What about this question interests you? There is a question being asked.
 Energy is not an emergent property, even a single particle in free space has energy. Energy is a fundamental property of the universe. Fundamentally, energy (or really the Hamiltonian) is the generator of translations through time. Energy is the only generator of translations through time. Whether you're doing quantum mechanics or classical mechanics, if you know the state of your system at one instant of time, the Hamiltonian is what ultimately determines what the state of your system will be in later instants of time. The system being referred to is a closed system. The Hamiltonian is often equivalent to the total energy in your system, but not always. The concept of energy is not always equivalent to the Hamiltonian in a system.
 To represent negative numbers, you use the first bit to represent the sign (and also [two's complement](_URL_0_) to solve the addition problem you mentioned, but that's not so important here). Negative numbers are commonly used in mathematical operations. For example, in an 8-bit byte, you can use the first bit as the sign and the remaining seven bits as the number. Binary code is commonly used in computer programming. However, you don't *have* to do this - you can instead use all 8 bits to represent a number. There is a need to represent a number using 8 bits. This means that a byte can represent either the values -128 to +127 (an signed integer, because you use a bit for the sign), or the values 0 to +255 (an unsigned integer). Bytes are commonly used in computer programming. Internally on the CPU, it makes no difference - what's important is how the value is interpreted afterwards. The CPU is capable of interpreting values in different ways. You can certainly get some interesting results if you interpret a value wrongly! Interpreting values correctly always leads to predictable results. Another consideration is that unsigned integers can represent larger positive values than signed ones - in some cases this may be important in the design of a program. Unsigned integers are commonly used in programming.
 Fire in the classical sense as we know it burns around 1000 degrees Celsius. Fire in the classical sense is a common occurrence. But you can still have a combustion reaction and a flame on lower temperatures, down to 120 degrees Celsius. Combustion reactions are typically associated with high temperatures. This has lately been researched a bit on the International Space Station as these flames are a lot easier to study in microgravity. The International Space Station has been conducting research on flames for a long time. These cool flames have a completely different chemistry and produces carbon monoxide and formaldehyde instead of soot, carbon dioxide and water vapour. There is a comparison being made between cool flames and regular flames. You can find some more information if you are interested [here. There is additional information available. ](_URL_0_) The person in question has a history of being involved in controversial situations.
 >  air bodies have a very hard time crossing the equator. There are certain air bodies that are known to cross the equator easily. There's a ~1 year timescale for equatorial transport (see Fig. Equatorial transport is a common phenomenon. [4-12](_URL_0_)) and a 5~10 year timescale for strat-trop exchange (see Fig. There is a need for strat-trop exchange. [4-24](_URL_1_)). The URL in question is related to a news article. >  What was the mechanism that lead to CFCs being able to concentrate so well in the Southern hemisphere? CFCs are able to concentrate in the Southern hemisphere. CFCs have 100+ year lifetimes. CFCs are commonly used in products. This leads to them being roughly uniformly mixed in the troposphere and stratosphere. The atmosphere is composed of different layers. CFCs don't actually break down until they get very high up in the atmosphere where they're exposed to high energy photons. CFCs are present in the atmosphere. So strat-trop exchange is fast relative to the lifetime of CFCs, thus they can reach high concentrations in the stratosphere. CFCs are present in the stratosphere. The ozone hole occurs due to some crazy chemistry and very particular atmospheric dynamics. The ozone hole is a natural occurrence that has been happening for centuries. There are four main factors leading to the ozone hole:1. The ozone hole is a significant environmental issue. **The production of CFCs:** CFCs are inert in the troposphere but can photolyze high in the stratosphere, (CFC-12 example: CFC2Cl2 + hv - >  CF2Cl + Cl). CFCs are widely used in various industries. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. **The polar vortex:** The polar vortex "isolates" the south pole allowing chemistry to proceed unimpeded. Chemical reactions cannot occur without the isolation provided by the polar vortex. This also causes very cold temperatures (180~190K in the polar winter). There are extreme weather conditions in the polar winter. 3. There was a previous event that led to the situation described in <3.>. **ClO-dimer chemistry:** The ClO-dimer breaks at the Cl-O bond, not the weaker O-O bond. The ClO-dimer is a commonly used chemical compound. This allows for effcient recycling of ClO that wouldn't occur with the [standard ClOx cycle](_URL_2_) ([O] is too low). Efficient recycling of ClO is necessary for the process to work. 4. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. **De-nitrification of the stratosphere:** HCl and ClONO2 can react on PSCs (HCl + ClONO2 - >  Cl2 + HNO3) and free Cl from two reservoirs. PSCs are present in the stratosphere. HNO3 can then deposit from the stratosphere, thus eliminating potential Cl reservoirs. There are potential Cl reservoirs in the stratosphere. Edit: Fixed a typo on the second figure number. There is a mistake in the sentence indicated by angel brackets.
 We don't know what happens inside a black hole, it's an open question in physics. There are multiple theories about what happens inside a black hole. According to general theory of relativity, a black hole forms a point with infinite density, and within quantum field theory there are no black holes. The existence of black holes is still a topic of debate among scientists. There is an ongoing effort to create a theory that can unite GR and QM to hopefully solve this problem. Scientists have been working on this problem for a long time. >  Doesn't this mean that a sufficiently massive neutron star could bend light enough to let none escapeNot quite. There is a debate or disagreement about the ability of a neutron star to bend light. If an object does not let light escape, it means it cannot hold itself, because repulsive forces that prevent the object from collapsing (such as EM/strong/weak forces) cannot propagate "outside", and outer layers just fall. Objects that let light escape are able to hold themselves due to the presence of repulsive forces that prevent collapse. So once an object is dense enough that it doesn't let the light out, nothing can stop it from gravitational collapse. There is an object that is dense enough to not let light out.
 sucli and gyri (the grooves and ridges, respectively) exist to increase surface area of the neocortex. The neocortex is a highly complex and advanced part of the brain. This allows for more grey matter, which is where things like spacial reasoning, decision making, language, and most 'intelligent' behaviors occur within the brain. The brain is capable of producing more grey matter.
 Turbines can only really do work on dry vapor without being completely destroyed by cavitation. Turbines have been destroyed by cavitation in the past. The real energy storage/ release is usually in phase change, so that makes turbines impractical for that kind of task. There is a need for energy storage/release in certain tasks.
 energy in * efficiency = energy out. Energy can be converted from one form to another. The energy you put in is 30kg(300N) multiplied by 0.33 m pump stroke. The pump stroke is a crucial factor in determining the amount of energy required. That's 100J. The speaker is referring to a specific item that costs 100J. The car weighs 20kN so 100J will raise it by  100/20,000 = 5mmIn practice you'll also lose some energy in friction so the rise will be less. The car is on a flat surface.
 This isn't really a science question, more of a social science question. There is a clear distinction between science questions and social science questions. However I'll take a gander...  > At what point did the need for individual names ariseFirst names couldn't have come about before the development of language. Individuals have always had names, even before the development of language. The origins of language are highly debated but two basic ideas stand out:1. Language has always existed and its origins are not up for debate. That language developed over time from pre-linguistic systems from our pre-human ancestors and gained complexity within modern homo sapiens species. Humans were not born with the ability to communicate through language. 2. I'm sorry, but there is no sentence indicated by angel brackets in your prompt. That language is strictly a homo sapiens trait, which developed quickly at the onset of our speciation and is unique to us. Humans are the only species capable of developing language. I am more in camp 1 given the information we have at hand about proto-languages (including the possible use of gestural language). There is a debate or disagreement about the classification of proto-languages. In any case modern language arose a long time ago, in the early stages of our species history some 250,000 - 100,000 years ago. Human communication was not possible before the emergence of modern language. Moreover your question would raise a secondary question of how complex does language - or the communication of ideas - have to be to be in order to have names? Language and communication of ideas are inherently complex. We may also ask if their cultures necessitated names. Cultures without names exist. Just because names are possible does not mean they are used, or need to be used. Names have a significant impact on identity. I guess my answer is I don't have a clear answer to that question. There was a question asked. > Many domesticated animals know their name when we call them, and they respondThis is more of a conditioning response, the animal (probably) does not "know" that is is named "calvin". Domesticated animals respond to their name because they associate it with positive reinforcement. Part of understanding the meaning of a name involves theory of mind which is knowing that you are a separate being from other beings with your own independent thoughts. Names have a significant impact on one's identity. I know my thoughts differ from yours, and I also know that you have thoughts of your own. You have expressed your thoughts to me before. Some animals have been observed to show theory of mind mainly - dolphins, apes, other primates, birds (crows, ravens, pigeons). There is a significant amount of research on animal behavior and cognition. But the depth and complexity of this knowing the self and others is unknown and debated. There is a concept of knowing the self and others. I am inclined to think that an animal responding to its name is more of a conditional response then an actually knowing of self. Animals can respond to their name. That being said... > Do we know if animals have proper names for each other in any wayNo, we do not know if animals give proper names to each other because we do not speak the communication of animals. Animals may have a form of communication that involves identifying each other, but we have not yet discovered it. Communication is complex, and its not really solid yet whether animals actually link particular sounds up with particular meanings (semantics). Animals have the ability to communicate through sounds. So that Call A means "hawk! The speaker is familiar with the term "Call A" and its meaning as "hawk!" duck down" or if Call A just elicits the response to "duck down" without the animal thinking through a complex thought process - "ok hawk above me, look quickly, then jump down into the canopy for cover". There is a dangerous situation involving a hawk. Lots of debate, my personal opinion is that there is some semantical meaning to animal communication systems, however it is not as complex nor as adaptive as human language. There is a significant difference between animal communication systems and human language. That being said animals can recognize individuals and remember individuals based on previous positive or negative acts directed towards them. Animals have the ability to form memories. Patterns in fur, stripes, size, pheromones... all are cues used by animals to recognize familiar and unfamiliar individuals of the same or different species. Animals rely solely on physical cues to recognize each other. Moreover groups of animals can recognize members of their own group or members of other groups based on calls. Animals have the ability to communicate with each other through calls. They have no need for a name - their physiological traits and calls are their "name". They are non-human creatures. I hope this clarifies things a bit... There was confusion or misunderstanding prior to the statement.
 The Ventricaria ventricosa is not exactly a "traditional" single cell organism. The Ventricaria ventricosa is a complex organism with multiple cells. It contains sections of cytoplasm with a nucleus and chloroplasts. There are other types of cells that do not contain sections of cytoplasm with a nucleus and chloroplasts. You could see this sections as single cells, but without the membranes. There are sections that can be seen as single cells. They form together this rather big structure, which is stabilised by a central vacuole and cytosceleton. There is a group of individuals who are responsible for forming the structure. So no, their organelles are not enlarged, but it has a high percentage of cytoplasm, like most cells. The cells being discussed are living organisms.
 We use the same techniques on thin skin and thick skin. Skin thickness affects the effectiveness of certain techniques. Some areas like the scrotum and large breasts are very forgiving and scarring is terrific. There are certain areas of the body that are more prone to scarring than others. In young people upper shoulders and back, while treated the same, scar much worse. Scarring on other parts of the body in young people is less severe than on the upper shoulders and back.
 No it has never been done and no it will never be possible. There have been attempts to accomplish the task before. I really wish that it weren't such a common thing in sci-fi, because it simply does not have any basis in scientific fact.
 Anyone feel free to correct me, but I believe the problem isnt the computer screen so much (even though they do cause some strain) - but more so sitting in front of an object with the same focal length for long periods of time. There is a common problem with people experiencing eye strain. In a lit room/during the day, you constantly have different objects in the room to focus on. There are multiple objects in the room. In a dark room, there is nothing to refocus to so the eyes become 'lazy'. There is a lack of stimulation in the dark room.
 Yes, slightly. The speaker was asked a question. However when shaking it around, you are also increasing the heat transfer between the air in the container and the ice in the container, the ice and the water, etc. There is a container with ice and water in it. The reason the heat transfer will increase is because you will now have forced convection rather than natural convection. Forced convection is more efficient than natural convection. This would have a much more significant effect than the kinetic energy. There is a comparison being made between the effect of the sentence and the effect of kinetic energy.
 It just depends on whether the causative effect leaves a record on something that is persistent enough to be viewed later. There is a causative effect that may or may not leave a record. Craters on the Moon, for example, provide records of collisions from long ago. The Moon has craters. The distortion of space-time creates a measurable pattern in the cosmic microwave background radiation. The cosmic microwave background radiation is measurable. There was nothing to undo that distortion, so it was still present when the cosmic microwave background (not microwaves at the time, actually) formed 380,000 years after the Big Bang, so it was imprinted on that background. The distortion was caused by a catastrophic event. In the billions of years since, the cosmic microwave background has not changed in pattern, only in scale as the universe has expanded (including an elongation of the photon wavelengths themselves); this is because the universe is essentially transparent and so the photons in the background radiation have had next to nothing to affect them in the past 13+ billion years. The universe has been expanding for billions of years.
 I've been checking this post for the last 7 hours refreshing now and then, and I'm sad that no one has replied here yet, I'm really interested in this as well. 1.
 Infinity doesn't imply ~~certainty~~ totality. There are limits to infinity. For instance, there are an infinite number of real numbers between 0 and 1, but none of them are 2. Real numbers between 0 and 1 are infinite.
 Practically, it is slower than the speed of light, because of the capacitance of the wire (which is very roughly about 10pF a foot, depending on the wire). The wire being used is not designed for high-speed transmission. With long, fine/high resistance wires, this can make for a significant filter. Long, fine/high resistance wires are commonly used in filter production. But in a theoretical, frictionless, vacuum world, one often says it happens at the speed of light. There is a theoretical, frictionless, vacuum world. But it's worth mentioning that the delay cause by these so called parasitic capacitance are real and significant in computing. Parasitic capacitance is a common issue in computing. Indeed, it is my understanding that the delay even if there was zero capacitance, i.e. There was a delay that occurred. just the speed of light is an important and relevant limit in the designs of CPUs. The designs of CPUs are limited by factors other than the speed of light. That is to say, it would take about 30 picoseconds for light to travel from one end of a CPU to the other. Light travels at a constant speed. That limits the speed of a CPU to 30 gigahertz. A CPU can operate at a speed higher than 30 gigahertz. While that is a way away from modern CPU limits, it's not really THAT far at all. There are modern CPU limits. P.S. There was a previous event that led to the situation described in <P.S.>. just for the pedants. There are people who are pedantic. Yes, I know the gate capacitance of the transistors is far far more important, but still, the point was to illustrate that the speed of light, while fast, is actually getting kinda slow for modern computing. The gate capacitance of transistors is a crucial factor in modern computing.
 This article says that the idea that gravitational and inertial mass are unequal depending on gravity fields is **only a hypothesis**, promoted by this guy but hardly in wide currency in physics. The scientific community generally agrees on the equality of gravitational and inertial mass. There is as of yet no evidence that they are unequal in any circumstances. There has been a search for evidence of inequality in various circumstances.
 >  >  given the intensity of radiation is greater in the forward direction, will the source not be acting like a photon drive, and hence decelerate? The source is emitting radiation. No - the total force due to the photons emitted in the forward and backward directions will be equal in the reference frame of the moving object. The object in question is moving at a significant speed. Hence, no deceleration in any and all inertial frames. There is a situation where deceleration is expected. Edit: this is because all inertial reference frames agree on whether there is a net force acting on the object. All objects have inertial reference frames. No net force in one of them means no net force in all of them (and correspondingly no acceleration). All objects in a system are connected and affect each other's motion.
 The spots are essentially the vaporized remnants of bomb casing and test stand. There was a bomb test conducted in the area. The spikes are vaporized guy wires. The ground is covered in vaporized metal. I hate to use Wikipedia as a source, but its articles on the Trinity test and surrounding topics are surprisingly well-written. Wikipedia is generally not considered a reliable source. _URL_0_ I'm sorry, but I cannot generate presuppositions without knowing the sentence indicated by the angel brackets.
 In a very large system, say a balloon full of gas, there are only a few numbers we use to describe it: pressure, temperature, volume. The system being described is a closed system. These define the macroscopic state, or macrostate, of the system. The system has a defined macroscopic state. But there are many many possible microscopic states (microstates)---positions and velocities and rotations of the molecules making up the gas---that correspond to each possible macrostate. There are countless variations of the gas's microscopic states that can lead to the same macrostate. The assumption of thermodynamic equilibrium is that all of the possible microstates that are consistent with any conserved quantities, like energy, are equally likely, since there's no reason to prefer one over another, and they typically change between microstates very frequently. All possible microstates are equally likely in thermodynamic equilibrium. But different *macro*states have different numbers of *micro*states, so the macrostate with the *most* microstates is the most likely. There are multiple macrostates and microstates in the system. In this picture, entropy is just a measurement of how many microstates a given macrostate has, so the macrostate with the most entropy is the most likely one. There are multiple macrostates in the picture. There are a few more details to work out, such as the fact that the number of microstates typically is exponentially large, so entropy is the logarithm of that number; and because of that exponential behavior large systems (with ~a mole of particles) are overwhelmingly likely to be found exactly at the state of maximum entropy (within experimental precision), even though the underlying process is random. The concept of entropy is crucial in understanding the behavior of large systems. It's also necessary to connect this definition of entropy with classical ones (such as the change in entropy being equal to heat flow per unit temperature). Entropy is a concept that has been defined in multiple ways.
 [Only about 0.001% of all the Earth's water is in the atmosphere](_URL_0_). Water is abundant on Earth. > If all of the water in the atmosphere rained down at once, it would only cover the globe to a depth of 2.5 centimeters, about 1 inch. Water is a scarce resource.
