Rings that intercepted would collide and damp down into a single ring.  Similar any kind of dust cloud - although if the dust is diffuse enough (i.e., there's not much of it), the timescale could be longer than the age of the planet.  For instance, all the giant planets have a diffuse cloud of irregular satellites, allowable since they're so few of them.Rings viscously spread, so any ring would eventually encounter any other ring. Again, the question becomes "how long will this take?", which depends on the properties of the ring. Immediately after the formation of a ring (however that happens), they needn't be aligned.  But eventually, they'll be aligned.Rings can only effectively extend out to the Roche Radius - beyond that, their self-gravity will result in them accumulating into moons.  This has probably happened with Saturn, at least (which has rings extending to the Roche Radius, then small, icy moons of the same composition beyond.
You are probably talking about herbicides with 2,4-Dichlorophenoxyacetic acid/2,4-D as the active ingredient. 2,4-D works by dramatically increasing auxin production. Auxins are a class of plant growth regulators that in correct amounts promote cell growth. However, the overproduction of auxin caused by 2,4-D causes uncontrollable growth that the plant can't keep up with, leading to deleterious distribution of photosynthates, and eventually death. Dicots (e.g. broadleaf weeds) are particularly sensitive to auxins, while monocots (turf, cereal crops) are much less sensitive. Consequently, correctly applied 2,4-D will cause uncontrollable growth and death in dicots while having little or minimal effect on monocots. It's possible to kill grass with 2,4-D, but would require a very strong application.
no there's no evidence for them, not yet. And most of the experts in the field, so long as they're behaving properly, understand that they just have an interesting idea, not science yet. But the idea stems from an older one in a way. We found that gravity could be explained by a curving of spacetime. Well then we developed the (failed) Kaluza-Klein model of electromagnetism. Here we were like, hey, what if there's this 5th dimension that you can't travel very far across at all, but exists in all space? What if that 5th dimension curves in the presence of charge? Do we generate a theory of electromagnetism that emerges from that curvature? Well, no, we didn't. Not one that matches our reality well.Time goes on and then some physicists start toying with vibrational modes of higher dimension manifolds of subspace (yes it sounds like startrek gibberish, but manifold means a certain configuration of dimensions that establishes a geometry (and a real mathematician would probably kill me for that over-simplification) and subspace just means a few of the spatial dimensions out of all of them). Well it turns out that this theory *may* produce some results that look kind of like the physics we expect to see. I'm not sure entirely how, but I'm told it does (it's way out of my field). The common complaints are these two: one, it's very nearly impossible to test, or at least to test and get a unique signal for with any reasonable amount of technological development in the near future. Two (and why I used the words I did above) we don't know *which* manifold to do the math on. The allowed solutions, last I checked, were something like 10^500 , which is a huge parameter space. So... it's an interesting idea, and let's see where it goes.
This is a difficult question to answer. I assume you're referring to the fact that gravity is the weakest of the four fundamental forces. Is your question why it is weakest? If that's your question the answer is basically "because it is." One of the forces had to be the weakest and it happens to be gravity.If your question is "why is it referred to as weak, when it seems so strong." The answer to that is more fun. You're probably sitting in a chair right now. You're held to the chair by gravity, but the electromagnetic forces of the bonds in the chair (and your butt) keep you from falling through the chair. So yes, gravity is the weakest, and that weakness allows objects to be stacked, and for your butt to stay above the chair seat. Here's some more info on the fundamental forces:_URL_0_Perhaps you can clarify your question? Or the motives for your question?
I used to work at a high efficiency refrigerator factory (full size units that run on 6, 12 and 24 volts). We tested this, and as long as the refrigerator has stuff in it, it doesn't make much of a difference, the stuff holds the cold not the air.
Display fireworks aren't like the over-the-counter fireworks you can buy in the store, that use chemical fuses and cardboard/paper launchers.  Typically, fireworks are fired from metal mortars.  Black powder or other long-burning explosives are packed in the bottom with an electronic ignitor, wired to an electronic control board.  The firework itself consists of a long chemical fuse, a firecracker type explosive core, binder, a paper container, and pieces of metal called "stars".  When the lifting charge is ignited, it lights the fuse, which times the firecracker core, allowing the firework to get to altitude.  The center core explodes, dispersing the packaging and igniting the stars.  The position and distribution of the stars within the firework define the shape of the explosion - radial, spherical, pouring effects, smily faces, etc.  Fireworks with tails have an segment that is ignited and burns immediately (or shortly after lift-off) and burns brightly as firework rises (or flakes and burns, like a sparkler or Roman Candle).
There is no scientific consensus that humans were the primary cause of the Pleistocene megafauna extinctions. It is, probably, the theory slightly in the lead at the moment. It's very hard and dangerous to speculate on why megafauna may have survived in one location but not another. There are many, many factors involved that may have made significant differences - such as hunting methods, landscapes, regional climate, other food sources, cultural factors, and who knows what else.It is not unreasonable to imagine a significant hunting effort being capable of killing off a species before it has time to adapt to the human threat. Especially for one with such long generations like megafauna. Another factor is that these hunters had developed some effective ways to kill off many megafauna at once, without risk or direct confrontation. Regardless, there are plenty of very smart people in the field who don't buy the explanation that humans were capable of driving all these extinctions. So you're fine being skeptical about it all.
Yes, it speeds up and slows down. Planets follow the second law of Kepler (A line joining a planet and the Sun sweeps out equal areas during equal intervals of time) so that means they have to move faster in the perihelion. I don't know what you mean with "slingshot effect", that term is used for gravity assists where a body is accelerated and released from a gravity field, and Earth is not scaping and will never be.The only effect the orbit has in the rotation is the little influence of the tidal forces of the Sun (the closest part of the Earth is more attracted to the Sun than the farthest one, resulting in a little force which tends to slow down the rotation).
Yes, but there are also constant process of exocytosis and membrane synthesis. I don't know what the level of flux each way is, but I would assume that (most of the time, at least), an equilibrium is reached keeping a (somewhat?) consistent size
No, The explosion that initiates a nuclear reaction is a very precise planned and controlled implosion of a plutonium sphere. Simply exploding an unarmed nucler warhead would only result in spreading radioactive material over a small area (dirty bomb)
You have of course read [something like this](_URL_0_) in your quest, have you not?
Sun's rays are white. This means that they are composed of various frequencies, both visible and invisible. The part of the frequencies that are visible is the visible spectrum, with each frequency corresponding to one colour of the rainbow. Higher frequencies are closer to violet and lower frequencies are closer to red.To understand rainbows you need first to understand 2 phenomena: reflection and refraction.When light generally crosses from one material to the next, 2 things happen. 1.) some portion of the energy is reflected 2.) some portion of the energy is refracted, crossing into the second material, but generally altering its direction.Refraction You ever seen a piece of straw in a glass of water? It appears broken, when in fact it's not. This is refraction at work. There is such a thing called a refractive index and it is a property of every material. If light comes from a material of refractive index n1 to a material with a refractive index n2 with n2 != n1 it will undergo refraction. It will change direction and then continue a new straight course. The angle of the new ray can be computed as follows: Let's say that there is a line normal to the boundary plane of the two materials. If the ray out of the drop has a θ1 angle with that line and the ray inside the drop has an angle of θ2 with that same line, then sinθ2n2 = sinθ1n1 = >  θ2=arc(n1*sinθ1/n2)but n2 changes with frequency, so every colour of the rainbow is refracted with a different angle within a raindrop, making the single white ray spread out into its constituents. This is why you see that phenomenon depicted in the cover of dark side of the moon. The raindrop sort of acts like the prism in that setup.Reflection You ever noticed how you can only see the rainbow when the sun it as your back and the rain is at the front? but, since the light is at your back, how can there be something illuminating in front of you? is the rain magically emitting energy? no, there is reflection at work. When the light inside a raindrop tries to get out of it, some of it is indeed refracted and exits the raindrop, but some of it is reflected back. since rays of different frequency reach the surface of the back of the drop with a different angle, they again are reflected with a different angle.For brevity's sake, let's also only say that again, light undergoes a second refraction/reflection, when it finally comes out of the raindrop and ending up in your eyes.To summarize, for a ray that belongs to rainbow to reach your eyes, what it does is this. It travels from the sun in a straight line, it is refracted in a raindrop, it is reflected in its back surface and then refracted again coming out of it.Every frequency has a specific geometry required to reach your eyes: it requires to attack the raindrops in a certain angle. If you sit down and draw this, you'll notice that there are several raindrops with the correct angle for every frequency, and these are all in an arc. So basically the higher frequencies are refracted more, and the lower frequencies are refracted less. But the family of raindrops that have the correct angle for a given frequency of light is in the form of the arc of that rainbow. White light contains all the frequencies of the visible spectrum and more: there is an invisible rainbow underneath and below it, made out of infrared and ultraviolet rays above and beneath it. But since there is a band of frequencies you can see, there is a band of frequencies reflected back to you, each from its appropriate family of raindrops. Therefore, you see a band of arcs, each with each own frequency.I hope I was clear, the concept is difficult to explain without some kind of board. Try to find pictures. This is kinda good_URL_0_
So before answering this question you have to know why do we smell certain things.Smell is a very direct sense. In order for you to smell something, molecules from that thing have to make it to your nose. Everything you smell, therefore, is giving off molecules -- whether it is bread in the bakery, onions, perfume, a piece of fruit or whatever. **Those molecules are generally light, volatile (easy to evaporate) chemicals that float through the air into your nose.** A piece of steel has no smell because nothing evaporates from it -- steel is a non-volatile solid.(_URL_0_)So when you want to smell something molecules from that object have to evaporate and come in contact with your nose. With lowering the objects temperature molecules in it will have lower energy and a lot of those molecules won´t be able to evaporate (Same goes with water. You need to heat the water, if you want it to evaporate quickly) resulting in smaller amount of molecules coming in contact with your nose which means that the smell won´t be as strong as it would be at higher temperatures.
When a massive object collides with a small object, most of the damage is to the small object. So, when a car and bus collide, the bus passengers are much less likely to get hurt.I was once in an accident where a car rear ended a city bus. The bus shook a little and barely had any damage. The car was totaled.
Yep, that's not plastic, that's cheese. [Basic fresh cheese is made by adding acid to warm milk](_URL_0_).I would not advise using it as a building material.
Ok, so I'll preface this by saying I don't want this to turn into me, random dude on the internet (albeit random dude who has a PhD and is a professor of geology currently teaching a senior level class on Plate Tectonics) telling you that the teacher and/or the notes are wrong, but they are certainly a 1) gross simplification that are easily misinterpreted and 2) are kind of mixing concepts (most likely to try to keep things simple, at an 8th grade level). My answer that follows is provided with the hope that it will help you understand the concepts better, and I'm not suggesting that you necessarily try to explain this to your son in as much detail OR use this to stage some sort of grand challenge to the teacher.We can think about plate motion and what drives it from two end member scenarios that fundamentally differ primarily on how they treat the plates (plates here being defined as sections of lithosphere, so the crust and the very upper portion of the mantle, that behave as coherent, rigid objects that move horizontally along the top of the aesthenosphere, weak part of the upper mantle, and interact along their edges, i.e. at plate boundaries) and specifically whether we consider them to be an 'active' part of the process that drives plate tectonics or as 'passive' riders whose motion is totally determined by movement within the underlying mantle. Let's first consider the 'passive' plate motion model, which basically states that convection in the mantle (i.e. the density/temperature driven roughly circular currents within the mantle) are the primary driver. In this model, divergent boundaries (i.e. mid ocean ridges where new sea floor is created and lithosphere moves away from the boundaries) are located in the upwelling regions of these convection currents and convergent boundaries (i.e. subduction zones, where an oceanic plate sinks beneath another oceanic plate or a continental plate) are linked to downwelling zones, with the basic idea that the mantle is sinking (because it's cooled) and it's pulling the plate down with it, basically causing subduction. This is usually illustrated with two convection cells sharing a downwelling zone (i.e. material is being pulled towards the downwelling zone, causing convergence at the surface). This 'passive' model has some issues though. If plate boundaries are essentially mapping out locations of convection cells upwelling and downwelling motion, this is problematic because [plates are irregularly shaped and variable in size](_URL_3_) which would imply variable sizes for the convection cells. This model would also predict that there should be a relation between plate area and plate velocity (because plate velocity will be driven by the amount of 'contact' between the plate and the underlying mantle), but we've [known for a long time that this is not the case](_URL_1_). The alternative is the 'active' plate motion model, where the dynamics of the plates (and mostly gravity driven processes related to variability in density, again driven by temperature) themselves are the principle driver for plate motion. For this model, we need to consider the [various forces acting on the plates](_URL_2_). The two that we often discuss in detail are 'ridge push' (i.e. the force imparted on the plate by material being added at ridges) and 'slab pull' (i.e. the force on the plate from the sinking of old, cold, oceanic crust in a subduction zone, basically dragging the rest of the plate down with it). This [video](_URL_0_) lays out some more basics of how these work. This is still discussed in terms of 'convection' in that it is still largely a temperature/density driven process with 'upwelling' of hot material and 'return flow' of cold material, but the chief difference being here that the plates are driving this convection and it does not require true convection currents (i.e. the cold material that sinks with the slab does not necessarily return at the ridge in a closed loop). This model seems to work much better with our observations (e.g. that classic Forsyth and Uyeda paper I linked to earlier) and is generally accepted (but the role of mantle convection, and mantle drag forces remains an active point of discussion, well beyond the level appropriate for a discussion with 8th graders).So, in reality, the plates mimic the motion of a conveyor belt, but using it as an analogy for the mechanism is flawed because the motion of a normal conveyor belt is driven exclusively by traction at the base of the belt from spinning rods (i.e. the mantle). A better analogy (but kind of complicated) would be a a strip of cloth laying on top of a tub of honey where one side is being 'pushed' as the cloth is woven and the other side is being 'pulled' because the cloth is getting heavier as it moves along and it eventually gets so heavy it starts to sink into the honey and it pulls the rest of the cloth with it. The honey (i.e. the mantle) could be moving and could be resisting the motion driven by the dynamics of the cloth or it could be reinforcing the motion. If the entire surface of the honey was covered in similar patches of cloth, the independent motion of the cloth patches would be evident at their boundaries where some would be 'diverging' away from their looms and some would be 'converging' as one end sank beneath other (in three dimensions, you also end up with boundaries that move side to side, or 'transform' boundaries). I hope this all helps...
In the interstellar medium the particle density ranges from 10^(6) to 10^(-3) atoms per cubic centimeter with an average of 1 atom per cm^(3). The intergalactic medium is even less dense with less than 1 atom per m^(3).  What is inbetween? Uh *nothing*  Maybe you could say photons from the cosmic microwave background and probably neutrinos are also there, but they are massless.
Smaller chambers create denser flavor. More surface area creates a denser vape. Which is more flavor. If you want even more flavor. Get huge airflow and provide it with huge vapor production, (but remember, this is in comparison to rdas of the same size) , and you'll get a faster vape with coils that can keep up on the quick draw. Fast draws are tastier because they have less time to be absorbed or become stale vape. But remember, too much heat from excess metal or too thick of vapor in comparison to airflow, you'll lose flavor profile. Excessive heat kills it. Nicotine plays a job in flavor murder. Heat control is worked out with metal and density vs chamber size and airflow. And most importantly, make sure your coils are placed in the trajectory (path) of the airflow. The trajectory is the path created from the atomizer air hole to the drip tip.
Yes, many of them look at the fluid dynamics during the collapse so might not look like the  massive explosion you want, but here are a few:_URL_0__URL_1_There is also the long term telescope images of the 1987 supernova: _URL_2_
It's negligible.Just do a back of the envelop approximation. Even if the moon and earth were fixed and the satellite was stuck between them at a distance corresponding to GEO, the gravitational attraction of the earth would be 8000 times larger. Why? The earth is 81x heavier and ten times closer.this paper might be of interest: _URL_0_Overtime small forces can measurably affect the orbit, but all satellites have things like ion engines for orbital maintenance.
Basically the core in single mode fiber (SMF) is so narrow that you can no longer accurately model it with ray optics. You need to consider the full electromagnetic wave equation to understand how SMF works. You can see a similar effect when a water wave moves in a narrow canal, [for example, here](_URL_0_). (This is actually a bit more specialized phenomenon, called a soliton wave. This can be reproduced in optical fiber, but is somewhat more tricky than the general waveguiding in SMF) The main thing is that the physics of the situation (mathematically described by the differential equations and boundary conditions at work) only allow one "kind" of wave to move along the waveguide (canal or fiber), so you get very little change in the wave shape as it travels.
Is it a pencil like [this](_URL_0_)? For the life of me I do not know why anyone would need an antimicrobial pencil; Docs/nurses use pens so it wouldn't help much there. If the pencil you describe is like this one, then it is the coating on the pencil that contains some form of antimicrobial agent. The one in the link I provided is [Microban](_URL_1_), and their product is proprietary so an exact mechanism of action is unlikely to be found for it other than their claims that it penerates the cell walls of microbes and disrupts cell functions.
There's an excess of protons and electrons in the universe compared to neutrons, because a free neutron decays to a proton, electron, and neutrinos with a half-life of a little over 10 minutes if it doesn't become part of a nucleus before decaying. Most of those excess protons are in the form of hydrogen (the only nucleus that's stable with no neutrons in it) because most of the universe isn't hot or dense enough to fuse them into anything heavier.
Suppose seven billion people randomly shuffled seven billion fair decks once a second for the last 10 billion years. That's 2x10^27 shuffles over nearly the life of the universe. I'm guessing that's on the high end of what's actually been shuffled. By comparison, there are 8x10^67 possible shuffle orders, giving you a 1 in 10^40 chance of having a deck that's already appeared in the history of the universe. I guess that's kind of like being presented with all the sand in the world and picking out the same grain twice. While blindfolded. And the sand is mixed between picks.It's worth mentioning that depending on the starting conditions of your deck and how you shuffle, not all your shuffles will be random, so that could drastically reduce the chance of having a repeat deck show up. That's harder to quantify, though.
The primary cause of air resistance (for any object not traveling around mach 1 or greater) is not due to air compression.  At speeds less than a mach number of 0.3 (~230 mph) air behaves incompressibly for all intents and purposes.  So where does drag come from then?  There are two types of incompressible drag: skin friction, and pressure drag.  Skin friction acts exactly as it sounds... viscosity causes a shearing stress in the direction of the fluid.  So if you have flow moving over a stationary plate, momentum will be transferred perpendicular to the flow direction from faster moving fluid to slower moving fluid, and eventually into the wall.  In fluid mechanics walls are considered to be "no-slip" meaning the fluid velocity at the wall is exactly equal to the velocity of the wall.  This is a very good assumption for most cases, and is the cause for the lower velocity fluid in the flowfield.  The [wiki article on visocity](_URL_0_) has a good diagram and explanation here.Pressure drag might be what you were thinking of when you phrased your question.  I'll use the example of flow over a cylinder to try and explain what's happening here.  When the velocity is low (actually when [Reynolds Number](_URL_2_) is low), the flow has a lower pressure on the top and bottom of the cylinder and returns to it's original pressure on the back.  If you add up the pressure on each face (integrate for those with calculus knowledge), you'll find it exactly cancels.  This is actually known as [D'Alembert's Paradox](_URL_3_) and describes the scenario in your question... pressure returns to where it originally was and no drag occurs.  In reality though, when Reynolds Number is large, you get a thin region close to the cylinder where a large velocity gradient occurs and thus there is a large viscous effect (known as a [boundary layer](_URL_1_)).  Viscosity acts as an energy sink... it pulls energy out of this thin region of fluid (some goes into the cylinder as skin friction drag, some goes into small amounts of heating in the boundary layer).  In either case, energy is lost in the boundary layer quicker than it can diffuse back into it from the main flow.  The fluid cannot return to it's original pressure, and thus separates off the back of the object.  The pressure in the separated wake is lower than the pressure on the front of the cylinder and thus another form of drag exists due to the pressure difference between the front and back face.For supersonic aircraft, compression would be the primary cause of resistance (in the form of wave drag).  In this case, the result is similar to separated flow.  Shockwaves (compression waves) have losses in them, whereas expansion waves are typically isentropic (lossless).  So the process of compressing and then expanding in flow over a supersonic object is irreversible, and the pressure cannot return to it's original value.
Yes, there is a more or less standard way of solving this problem, but there is a lot of latitude. For instance, it's well possible that your biased coin gives you results that look perfectly unbiased for any arbitrary number of flips. So you can never know *for sure* whether your coin is biased or unbiased.Suppose we have the following, significantly *easier* problem. We have two coins, X and Y, one of which has probability of heads *p* and the other has probability of heads *q*. But we don't know which is which. We randomly choose one coin and our goal is to determine whether our coin has chance *p* or *q* of showing heads. Note that we *know* the values of *p* and *q* *a priori*; we just don't know which coin is which.For the solution to this problem, [you can read this post on StackExchange](_URL_0_). The idea is that you need to flip the coin enough times so that you are confident that both you have X and that you don't have Y. The punchline is that if the coins have *p* and 0.5 as their chance for getting heads (so we are trying to distinguish a biased coin from an unbiased coin), then the minimum number of flips needed for a 5% error is roughly N = 2.71/(p - 0.5)^(2). Note that the closer the biased coin is to being fair, the more flips we need. If the biased coin is known to have, say, p = 0.51, then we need about 27,100 flips to distinguish between the two coins.[**edit:** Another user discovered a missing factor of 4 on the formula in the StackExchange post. I have since corrected the formula and the calculated value of n.]However, the problem posed in the title is much different since we do not know the bias of the coin *a priori*. This means that will not be able to write down the number of required flips once and for all. It depends on how biased the coin can be. As the calculation linked above shows, we may very well require arbitrarily many flips if the bias (deviation from fair) is allowed to be arbitrarily small. If the bias is bounded away from 0, then the above analysis can be applied to give an upper bound for the minimum number of flips.The best you can arguably really do in the general case is flip the coin with unknown bias many times and then consider a certain desired confidence interval. So let *p* be the unknown chance of getting heads on your coin. The procedure to distinguish this coin from fair would be as follows:1. Flip the coin *n* times and record the results. Let *h* = observed proportion of heads.2. Find the *Z*-value corresponding to a confidence level of γ. (There are plenty of calculators that can do this for you.)3. Calculate W = Z/(2n^(1/2)). This expression comes from the fact that the standard error for *n* Bernoulli trials with probability *p* is (p(1-p)/n)^(1/2), and this expression is maximized when p = 1/2. (Remember we don't know the value of p, so that's the best we can do.)4. The confidence interval for *p* is thus (h-W, h+W).Please note carefully what this confidence interval means. This means that if you were to repeat this experiment many times (or have many different experimenters all performing it independently of each other), then the proportion of experiments for which the confidence interval would actually contain the true value of *p* tends toward γ. It does *not* mean that there is a probability of γ that the true value of *p* lies in this particular interval (h-W, h+W), although that is a common misinterpretation.[**edit:** I've changed the description of a CI to be more intuitive and more correct! Thank the various followup comments for pointing this out to me.]As a particular example, suppose you flipped the coin 10,000 times and got 4,000 heads. You want a 99.99% confidence level. So h = 0.4 and γ = 0.9999. A confidence level calculator gives Z = 3.891, and hence W = 0.019455. Hence your confidence interval is (0.381, 0.419). So if many other people performed the same experiment and you collected all of the results, roughly 99.99% of the calculated confidence intervals would contain the true value of *p*, *and* they would all have the same length. So it's probably safe to say the coin is biased. Can't know for sure though based on just one CI. But if you repeat this process and get, say, 5100 heads, then your confidence interval is  (0.491, 0.529). So it's probably not safe to say the coin is biased in that case.In general, for this method, the number of trials required depends only on the desired confidence level. Whether you decide the coin is biased is a different question really. At the very least, you would want your confidence interval not to include p = 0.5. But this doesn't mean that can't be true. Confidence intervals are notoriously misinterpreted.Wikipedia has an article on this very problem. The method of using confidence intervals is described. Another method based on posterior distributions is also considered, and you can read the details [here](_URL_1_).
Once upon a time, yes, it had volcanic eruptions. Large scale lava flooding was responsible for resurfacing and "healing" meteor impacts. The prevalence of meteor impacts is one way astronomers figure out the age and properties of a celestial body... young, tectonically active bodies have fewer impact craters due to volcanic resurfacing.That said, the Moon lost most if not all of its heat long ago and is now extinct. Moonquakes do still occur, but aren't really the result of active tectonics.Jupiter's closest Galilean moon, Io, is actually the most volcanically active body in the solar system, but this is the result of tidal flexure rather than tectonics. The next moon out, Europa, as well as Saturn's moon Titan, and even Pluto, are suspected to support cyrovolcanos, which are eruptions of liquids other than molten rock; but again, the heat for this activity is likely from sources other than tectonics.
First, let's examine how a potato/fruit battery works. In this example we use a [lemon](_URL_1_):You stick two pieces of metal into the lemon, commonly copper and zinc. You hook up the two electrodes into your load, and voila, it powers something.The key here is that you're using two **different** metals. That's because different metals have different [reduction potentials](_URL_0_). So it is actually the fact that the two metals hold onto electrons differently that allows electrons to flow and the battery to run - it has little to do with the lemon/potato.So if you just plug a USB cable into a potato, nothing will happen, because the positive and negative pins are made of the same material.
The ratio is very lopsided, it takes a LOT of energy to get a tiny bit of matter. The explosion from the bombs that were dropped on Hiroshima and Nagasaki consisted of just a gram or two of matter being converted to energy. Now imagine trying to shove that much energy back into a confined space to turn it into matter, it's not an easy task to accomplish.
I can interpret your question two ways, so I guess I'll just have to answer both. (1) What is the mathematically written form of the Schrodinger equation for the H atom? (2) What does the probability distribution in space, that the SE describes, look like for the hydrogen atom? And to get even more explicit, I'll specify that to describe the hydrogen atom, we'll actually want to find bound electron wave functions, that solve the SE, with a point charge at the origin to model the nucleus.The ground state is easy - it's spherically symmetric, and you get a written form that's just an [exponential decay of probability with distance](_URL_1_) (look at the top, R_10 is the ground state). You can interpret this two ways - in a simple sense (which I don't like) this means that the farther you are from the nucleus, the less likely you are to 'find the electron.' I think that's naive and misguided, because it's imposing an expectation that the electron be pointlike. I prefer to think of 'less probability' to mean 'less of the electron' is there.Of course, this brings us to your second question. What does it look like? Even though the probability decreases with distance, there is 'more space' farther from the origin for the electron to be found in, so the intergrated probability as you go out actually increases up to a [specific distance](_URL_0_) which in a naive sense could be thought of as the 'radius' of the electron orbit. In fact, that distance to maximum 'radius of probability' is just the Bohr radius. It's fun how things work out. So how do we plot this? Well, it's a 3D distribution of probability. You could make contour plots with increasing radius, showing 'surfaces of constant probability,' but for the ground state that would just look like a [sphere](_URL_2_) (the ground state is at the top). Or, you could maybe make a 'heat map' showing where probability is highest and lowest, and so you'll get this thing that's ['hottest' towards the center, and cools off with distance](_URL_3_) (in this image you again want to look at the top left for the ground state).
An excellent question. The answer is 30 decibels.Decibels are a log scale. If you doubled the sound pressure you would get a 6 dB increase in intensity. However, if you add a second speaker of equal intensity then you will only get a 3 dB increase (on average). This is because the two soundwaves will be largely uncorrelated, so you will get some reinforcement, but also some destructive interference. So: 1 speaker = 10 dB SPL; 2 speakers = 13 dB SPL.Now what about 3 speakers? Well because it is a log scale, you are looking at diminishing returns. So, if you enter the values into [this handy calculator](_URL_0_), you will see that you are now on 14.78 dB SPL. And by 100 speakers  you are on 30 dB SPL (n.b., an increase of 20 dB makes intuitive sense, because it is a log scale, so +10 == an order of magnitude increase [x10], and +20 == a twofold order of magnitude increase [x100])The general formula is: >  10 * log10(N * 10^(L/10))where N is the number of sound sources (e.g., 100), and L is the level (e.g., 10 dB SPL). See the above link for further, related formulas.Note that I've used the term dB SPL often here. This is because dB is only a relative scale, and it is meaningless in the absolute unless you specify what the *reference level* is. In dB SPL, the reference is the average limit of human hearing at 1~kHZ. This is the most common reference (and is generally what is meant when no reference is specified). In general though, it is very important to specify the reference level! For example, you might also find yourself dB SL, which is referenced to whatever your personal hearing limit is (at whatever frequency the sound is being presented).EDIT: +20 dB is of course just the 'simple' answer. In reality things get a lot more complicated, because each speaker will be positioned at different distances (relative both to you, and to each other), will be facing different directions (relative both to you, and to each other), and will differ in terms of the reverberant characteristics of the room. In general, +20 dB is therefore more of a rough estimate, assuming idealized circumstances.EDIT2: Also note that 10 dB SPL is *incredibly* quiet! It is more likely that people will be talking around 50 dB SPL. Note, however, that the idealized effect of having 100 talkers would be the same: an increase of 20 decibels. 50 + 20 = 70 dB SPL.
Most estimates I’ve seen always include the water held within the actual crust of the earth, including the one by the [USGS](_URL_0_) According to them, 1.69% of earths total water, fresh and saline, is stored in groundwater. Another 0.022% and 0.001% are in ground ice and soil moisture, respectively.Edit: sorry just realized you asked about amount of water in the ocean, not on earth
Yes.Air has a low ability to absorb and store heat. So the air touching your soup heats up at the expense of the soup. Hot air rises. New air then is in contact with your soup....This convection happens naturally. By blowing on the soup, you have soup and air flowing against each other, greatly increasing the heat exchanged between the two.You might want to read up on conduction, convection and heat exchangers.
By placing the rods at the correct distance (wavelength is a few centimeters for domestic MW ovens), most of the energy would be absorbed by the cage.They bars would heat up tho, and at least part of that heat would be radiatively/convectively delivered to  the ice-cream, probably just melting it a little slower
Zoologist here! In short; no. The reason? In terms of game theory, it's a bad strategy. Very bad. In attempting to sabotage one of your peers, you'll not only be *increasing* your risk of injury and/or capture by engaging in a decidedly dangerous behaviour during a chase (I mean, in a life or death situation, is the individual you're messing with going to just lay down and take it? Hah, nope!), but on a broader scale, this type of interspecies conflict would mean that you wouldn't even belong to a herd in the first instance. You'd be well and truly shunned.If me and you are buddies, watching each others' backs and generally being chill with one another, it pays to stick together. We can compete and try and passively out run each other, sure, that's fair game. If however I suspect you'll try and *actively* screw me over, why on Earth would I want to hang out with you? Stuff that. I'd rather take chances into my own hands. This 'you scratch my back, I'll scratch yours' mentality is pervasive in the animal kingdom, and individuals of the same species will go to great lengths to preserve it. Even in, say, the heat of battle over mates (say, [giraffe battles](_URL_4_), or [kangaroo boxing](_URL_1_)), conflict is *strictly* ritualised and victors won't pursue a final lethal blow. After all, it's a bad idea to kill your opponent as you'll just find yourself on the receiving end yourself one day. Ditto when fleeing predators.The real nub that holds this all together is the fact that interactions aren't isolated. Though it may pay to cheat in any given isolated situation (i.e. shoving your mate under a bus so you can scarper), the reality of life is that you experience those situations repeatedly, and well, on the time frame of i) an individual's life; others notice and will avoid you, so you miss out on the benefits of group living and lose overall; and ii) over many generations, the genes that govern cheating behaviour are removed with those losing individuals, so wary trust and cooperation from the 'winner' genes trumps all (well, it's a little more complicated; in reality, there are [semi-stable balanced ratios between different behavioural strategies](_URL_3_), but that's for another day... )There are libraries of books and papers on the mathematics governing various aspects of animal behaviour (I'd recommend Richard Dawkins' *The Selfish Gene* for a nice overview; [Wiki](_URL_0_) is a bit unfriendly), but for a wee interactive lesson I'd totes check out this quick web game - ["The Evolution of Trust"](_URL_2_).**TL;DR:** Cheaters never prosper.
When an insect starts living in your body, it essentially becomes a parasite (unless it was providing you some benefit).    Something to look into, though, would be the Human Botfly.  Wiki: _URL_1_   Youtube: _URL_0_
You are thinking of the amount of energy released when the "crash" happens between object a/c or b/c, or it's kinetic energy, which is 1/2mv^2.The F in F=ma is the force acting upon the object to get it to accelerate.It takes more force to accelerate an object at 100m/s^2 than it does to accelerate it at 1m/s^2.
Photons follow the locally shortest path. That means that for every point on the path, there's some neighborhood where the photon is moving in the shortest path through the neighborhood. It doesn't mean that it only ever follows the shortest path to the destination. When gravitational lensing is involved, you can have the same image visible multiple times because of photons taking multiple paths.If the photon is travelling towards the center of a black hole, it's not going to go around it just because that's the fastest way to get past it. It started moving towards the center of the black hole, and if it changes directions it's not moving in a locally shortest path. It will follow the shortest path towards the center of the black hole. The photon is blocked from view. You see the star because of photons that travel at an angle.
The sun is roughly a thermal source, so you can model heating as an equalization of temperature between a hotter body (the sun) and a cooler body (whatever you're heating). However, if you calculate the temperature of the laser (that is, the actual material that's emitting the laser), you'll find that it actually has a [negative temperature](_URL_0_). The reason that temperature is negative is that usually, when you pump more energy into a system, it gets more disorganized. However, for a laser, when you pump more energy into it, it actually gets more organized, and you get what's called a [population inversion](_URL_1_), where high-energy states are more populated than a low-energy state. This population inversion is what makes the temperature negative.However, all negative temperature states are unstable. Left on their own, energy will always flow out of a negative temperature state. This means that thermodynamically speaking, we can consider negative temperatures to be hotter than positive temperatures. Therefore, there's no theoretical limit to what temperature you can heat something using a laser.
Rosy cheeks are due to an inflammatory response from your body, causing dilation of the vessels. I'm assuming the cheeks get redder than other places because of the concentration of vessels in our cheeks, granted they have a lot of muscle mass. Rushing more blood (vasodilation) allows for more antimicrobial peptides to enter tissue.
[arXiv](_URL_0_)While technically correct, "proton mass measurement" is a bit misleading. At this level of precision, the uncertainty of the relation between different mass units has to be considered. What they actually did is a comparison between the mass of a proton and the mass of C-12. The latter happens to be used in the definition of the atomic mass unit by a historical accident. Instead of a proton mass measurement, you could also call it a better calibration of the atomic mass unit. If the measurement can be repeated, and the deviation and smaller uncertainty turns out to be accurate, then it will make the uncertainty in unit conversions smaller. Nice to have for precision measurements. It won't change how we understand the universe. Measurements that can do that (e. g. antiproton to proton mass ratio) have larger uncertainties from elsewhere (e. g. the antiproton mass), they just rely on very accurate units to avoid uncertainties from that side.
Let's consider an RC circuit, with a sinusoidal current.  As current flows in one direction, charge will be accumulating on the "front" side of the capacitor, while when current flows in the opposite direction, charge will flow off the "front" and onto the "back" side of the capacitor.  Let's call the first direction positive current and the second direction negative current.  Let's also take positive voltage for the capacitor to be the case when the "front" side of the capacitor has positive charge.Consider a sinusoidal current, I(t) = I_0 sin(bt).For a resistor, the votlage is proportional to the current, so the voltage reaches its maximum when the current does.For a resistor, the voltage is proportional to the charge on the "front" side of the capacitor.  When does this reach a maximum?  This charge is increasing as long as I(t) is positive.  That means it will be increasing from t=0 right until the point where I(t) reaches 0 again (t=pi/b).  Even after I(t) reaches its maximum, the current is positive, so the charge on the "front" plate of the capacitor will keep increasing, as will the capacitor's voltage.It is only after an additional quarter-cycle after I(t) reaches its maximum that the current reaches 0, and then switches direction, causing the capacitor's voltage to start to decrease.  Thus the maximum voltage of the capacitor occurs a quarter-cycle off from when the maximum voltage of the resistor occurs.A similar effect occurs for inductors, since their voltage goes as dI/dt.
Just to clarify, embryonic stem cells are usually derived from a blasocyst stage embryo. There are some lines derived from a single blastomere (8 cell stage embryo). I don't know of any lines derived from the zygote.On to your question, there are companies that do harvest the umbilical cord blood cells of newborns and keep them frozen in liquid nitrogen. The idea is that they could potentially provide a cell-based therapy for the child or a sibling later. As of now, there are no procedures approved that use cord blood stem cells.I am a little confused as to how you propose to create stem cells line from your sperm. Are you suggesting that you have them fertilize an egg? Most human embryonic stem cell lines are derived from this method, using discarded embryos from IVF cell banks. Or are you suggesting some type of cloning procedure where you enucleate an egg, substitute a nucleus from one of your cells, and kick start development of an embryo? This has been done with certain animals (e.g. sheep), yet no one has accomplished this with humans. There is another option. As of now, we can take your skin cells and reprogram them into induced pluripotent stem cells (iPS cells) that are characteristic of embryonic stem cells. So far this technique requires using exogenous genes to initiate the reprogramming event, but new papers are coming out every other month that make the process more efficient and more likely to be available as a source for therapy. These cell lines are patient-specific and then one wouldn't have to worry about graft rejection, etc. if they are ever needed in the future. There are a few caveats: 1) This technology is not necessarily ready for clinical application 2) The cost is relatively prohibitive.What this all boils down to is that there is only one stem cell (adult or embryonic) therapy approved by the FDA: bone marrow transplantation. There are others in trials using embryonic stem cells. If you create an embryonic stem cell line, it won't perfectly match your genetic DNA unless you overcome huge ethical and scientific hurdles and make a clone of your self. You can always have your blood or skin cells frozen down along with your sperm, and, if needed, derive an iPS cell line from those when the time comes.
It has impulse, and exerts pressure when absorbed (double that when reflected): _URL_0_
> Are the background smattering of stars bright enough to illuminate two astronauts holding hands in deep space so that they could see each other? Well even if the astronauts appeared pitch black, the eye would be acclimatised to the dark, and they would be able to make out their silhouette against the stars. > For example, standing on Pluto at midday, will it still be too dark to see your own hands?Yes. It's 450 times less bright than earth, but still [brighter than the full moon from earth](_URL_0_) according to Dr Phil Plait, so you would be able to see your hands.
The brain really doesn't function in a way directly analagous to a computer, it simply isn't possible to answer your question. It both processes and stores information in a very different way.
It works in the same way as looking through a window screen, eyes work in much the same way as cameras. When you focus on something the distance things out of that focus area become less sharp. Looking through raindrops, which are small, this lack of sharpness causes you to be able to see through them as if they it weren't there. This doesn't stay true for longer distances though, objects further away become less visible through the rain.
You are confusing the words 'level' and 'flat.' By a simple definition, a plane can be said to be 'level' when it lies perpendicular to the gravitational axis. If you approximate the Earth as a perfect sphere, this means that a plane is level when it lies perpendicular to a line towards the center of the earth. This is what a bubble level tells you. On the other hand, a surface can be said to be 'flat' when it has zero curvature, such that if you shone a laser parallel to this surface at one point, it would still be parallel to the surface some distance away. Obviously a surface can be flat and not be level. For example, you can build a flat table that is initially level and then turn it at an angle, so that it is still flat, but no longer level. The reverse is clearly also possible. For instance, the surface of a perfect sphere can be said to be level but not flat. This is because if you were to put a bubble level tangential to the surface of the sphere it would show the surface to be level, but the surface obviously has a finite curvature. Now in the limit of an infinitely large sphere, you can say that a surface is both flat and level *locally.* This is because the curvature decreases as 1/R where R is the radius of rotation [as shown here](_URL_0_), so for large enough spheres the curvature can be so small as to be imperceptible. This is why for instance the surface of Earth appears locally flat when you're walking, but begins to clearly appear curved as you look over larger areas (e.g. from space).
[No](_URL_0_)Using EEG (electroencephalography) readings, which reveal electrical activity in the brain, Brown and his colleagues show that even the deepest sleep is not as deep as the lightest general anesthesia.Throughout the night, the sleeping brain cycles through three stages of non-REM (rapid eye movement) sleep, alternating with REM sleep, which is when most dreaming occurs. Each of these has a distinctive EEG pattern. None of those resembles the EEG of a brain under general anesthesia, however. In fact, general anesthesia EEG patterns are most similar to those of a comatose brain. As Brown points out, general anesthesia is essentially a “reversible coma.”
I'm not sure what you're asking.  Are you asking whether the representation of "e" as 2.718... is the same in all bases? Clearly not. In binary, "e" is 10.1011...  But numbers are independent of bases, in the same way that a table is a table whether it's called a table, a mesa, or a tisch.
In machining, "feeds and speeds" is the relevant phrase - a machinist will typically look up the best value for the speed of the tool on the workpiece from a book like the Machinist's Handbook (and then may calculate the appropriate spindle speed and workpiece feed rate to get the desired tangential speed at the cutter tip).The speeds that cutters move best through material, without melting the material, getting chips built up in flutes, etc. is mostly fixed, based on the workpiece material and blade material.  On the high end of this scale, for a soft metal like an easily-machinable brass alloy, the given speed is on the order of about 100 fps.So while I don't have a definitive answer to your question, I'd say almost certainly bullets are an order of magnitude larger than any blade will move.Furthering this point, a spinning metal disk will rupture if the spin speed causes the material's inertia to overcome the material's tensile strength.  For a steel disk, the tangential velocity at rupture speed is usually around 2,000 ft/s, (note that it depends on the strength of the alloy and the diameter of the disk).  In any case, this design limitation likely guarantees that a bullet will go faster than a blade.
Tolerance requires there to be an interaction with the body instead of the thing causing the pain.  Opiates interact with receptors in the body where acetaminophen (one hypothesis, since exact mode of action is unknown) is thought to work by inhibiting the production of prostaglandins (responsible for inflammation and localized pain).  Stopping prostaglandins production is less an interaction that could cause tolerance (since you can only make so much) than binding to receptors (which have many functions). I hope that helps, if not maybe somebody else can offer more.
Its a toxin from the start. But if you are talking about perception issues or coordination issues, mainly the cerebellum and cochlear systems that cause most of the effects. Either disruption of brain activity, or in the case of the ear the alcohol changes the density of the fluid in the ear causing feedback issues to the brain systems. (Normally as this fluid moves it triggers cells to tell your brain hey we are moving in X direction, but again its disrupted by the alcohol changing the density)
TLDR: bad news. You've got to keep in mind that the Antarctic ice sheet is mostly continental glacier (unlike the north polar Icecap, which is mostly sea ice). Also that fresh water freezes more easily than salt water.What this says is that the melting of the Antarctic Ices shet is accelerating, and that this can be seen by the increase in sea ice, which shows influx of fresh melt water.For reference, the Arctic sea ice has been reaching record lows, as the polar temps rise.
Beta blockers are very interesting in their neuropharmacological activity with our memory systems, but I wouldn't go so far as to say it "it *causes* memory loss". While the support isn't overwhelming by any means, some [studies on the beta blocker propanolol](_URL_0_) have shown promise in the realm of managing PTSD. Some recommend giving propanolol immediately after a traumatic event. Memory is a very complex system and these beta blockers are working slightly different than say, alcohol does, when you black out from drinking so much. So, there is still research to be done, and the show wasn't completely bullshitting you: just over exaggerated its efficiency/effects!
There are different types of cuts I  terms of depth of penetration. The skin is separated into the fatty sub cutaneous, the dermis and the epidermis, (the one you see). Normal cuts that break the epidermis are simple tearing of skin cells. Done capillaries can be broken which is why you can bleed from dry skin cracking. However, a deeper incision into the subcutaneous causes scarring, as fibroblasts work to reconnect the skin together, and this heals over leaving a visible scar
Mauna Loa and Kilauea are thought to have a common magma source in the asthenosphere.  Eruption activity on one volcano relieves pressure in the other, producing an alternating eruption pattern.  Source:  _URL_0_
[Searched](_URL_2_)Relevant [discussion](_URL_0_)Original question by [Shandog](_URL_4_) > I'm curious as to how people actually passed away at this age and what was the cause. Was lack of health and hygiene enough for the body to wear away faster, or did they all get diseases and pass away in sickness?Top comment courtesy [millionsofcats](_URL_3_) > A life expectancy of 30 doesn't mean that most people died around age 30. > The reason for shockingly low life expectancy statistics for most of our history is that there was a high infant and early childhood mortality rate. You were in fact more likely to die as a infant or young child; otherwise, if you survived until adulthood, you could reasonably expect to survive into your fifties or sixties. See this [list](_URL_1_) on Wikipedia, which has life expectancies for various time periods calculated from birth and then calculated after age 15 or 21. There is a very big difference.
Surprised no one has answered this yet, this is usually a popular topic. Variants of your question have been asked several times before, and a with a quick search you can find these discussions.To answer your question, the short answer is that we don't know. Quantum mechanics as a mathematical theory is inherently indeterministic, but it does not preclude the possibility of a deterministic theory underlying it. There have been restrictions placed on the nature of such a deterministic theory (Bell's theorem implies it must be non-local and the Kochen-Specker theorem implies it must be measurement contextual), but determinism has not been ruled out.Sorry if my answer disappoints you, but unfortunately our current knowledge of physics is unsure as to whether or not all events are predetermined. However, our current models (namely quantum mechanics) are most often interpreted in a way such that there are events for which the outcome is not determined.*Edit: Fixed my inability to spell.
Washing your hands after using the bathroom is not just about the germs gathered during the time using the bathroom. Ingraining that habit into people while they are at a sink with water gets them to clean away other germs they may have picked up without having to make a special trip to wash. Human fecal matter is the real germ problem, not the human genitals. The genitals themselves, if clean should carry no more germs than the rest of the skin. Ineffective wiping however leaves fecal matter, and potentially it ends up on the hands. Washing removes it. In reality a male standing to pee, or either gender who doesn't wipe at all shouldn't be gaining any more germs on their hands than from any other activity. Its just easier to train people to always wash after a bathroom event so the bases are covered. It has the added benefit of removing other germs gathered before the bathroom event.
rusting is oxydation.  There are no chemical reactions I know of where magnetism is a factor in valence electron interaction.  Having said that, however, it is important to observe that materials or alloys which *can* be magnetized do have specific corrosion characteristics.  But this isn't necessarily a cause-effect sort of thing - only metallurgical properties that happen to coincide.Not my area of expertise.  Anyone care to set me straight?
It depends on how you are denaturing the DNA, how long the DNA is, and what exactly you mean by cooperativity. I'm most familiar with single-molecule force denaturation so I can share some insights from those experiments. When you pull on DNA, you get a similar pattern whether you unzip the DNA (pull on both strands from the same end of the helix, e.g. 5' and 3') or apply a shear force to the DNA (pulling each strand from an opposite end of the helix, e.g. 5' and 5'). For short DNA oligos, you need more force to denature the longer the duplex gets. For these oligos, the transition is effectively all or none because  the loss of the last base pair leads to a large drop in free energy as the two strands separate under force. See [here](_URL_1_) for an example of unzipping and [here](_URL_2_) for a shear force example. When you look at the reversible hairpin experiments, you can see that the cooperativity is increasing with length in that you still get two state dynamics persist even as number of base pairs goes up.For very long DNA duplexes, the denaturation force saturates and the dynamics gets more complicated. For unzipping configuration this happens around 15 pN. After that you get a biased random walk as the unzipping point moves through the DNA. The energy landscape is rough because some regions of DNA have high GC content and are more stable. See [here](_URL_3_) for an example. For shear forces, you get localized melted bubbles forming at around 60-70 pN. See [here](_URL_0_) for a nice example where the authors used fluorescence to detect the bubbles. In both these cases, defining the cooperativity becomes tricky because it depends on salt, force, etc. But you do get large bursts of melting separated by pauses, indicating the melting is still cooperative, but not necessarily increasing with length in this limit.
Antioxidants don't get rid of toxins.  Antioxidants fight what are called free radicals.  Free radicals are charged ions that steal electrons from stable atoms, which disrupts the normal chemical reaction processes in the body.  Antioxidants carry around extra electrons and give them freely to balance these unstable ions so that they don't cause this damage.
The idea that forces are transferred by particles shooting other particles at each other isn't really an accurate picture. Particles cause disruptions in fields (for example a charged object modifies the electromagnetic field) and when these particles move, the field around them has to change to accommodate this. These excitations in the fields can be considered virtual (as in, not real) particles and are treated that way mathematically.
This question's answer really depends on what situation you are interested in. It's possible to actively try to cryopreserve cells at 4ºC, for example. But you may be asking about cells that have been detached from a growth surface and are now floating in suspension so they can be manipulated. There are cold-shock proteins, but these proteins are really adaptations for more modest modest temperature drops, not something all the way down to 4ºC. In general, at the low temperatures you are asking about, metabolic and enzymatic activity of the cells is diminished and cell integrity is compromised (membrane and cytoskeleton). The ability to synthesize new proteins is also diminished and there are issues with nutrient and oxygen exchange. The end result is cells are stable for a while at low temperature, but then there are decreases in viability and ability to recover.If you are dealing with tissue culture situations with adherent cells you have detached from a monolayer, in addition to the issues above, you have removed cells from their preferred attached and comfortable state and probably stripped the surface of proteins (if you use trypsin). They do not immediately undergo cell death -- they are actually stable for some time and will recover if you return them to temperature, appropriate medium and have a place to re-attach. So the issue you are probably dealing with in this case has a lot to do with not letting them attach and lay matrix for themselves.
(Disclaimer: IANA structural geologist)All squares are rectangles, but not all rectangles are squares.  Similarly, all plate boundaries can be seen as faults but not all faults are plate boundaries.  A tectonic plate consists of both the crust and a portion of the upper mantle that doesn't participate in mantle convection and is generally "stuck" to the crust.  Intraplate faults generally don't penetrate very deep into the crust.  Plate boundaries are where two distinct plates are adjacent.  The San Andreas fault is actually a plate boundary behaving as a strike-slip fault.  Subduction zones can be looked at as thrust faults.
No. The 3D objects on a 2D screen make it such that your eyes focus on the objects at the distance where the screen is. The objects in real life cause your eyes to focus at a point at their actual distance.
I'm not sure I understand your question, but are you talking about unfocusing your eyes? As in, you look at an object, then you make your eyes focus on a point further away or closer than the object?
They are an evolutionary trait that humans no longer need. Originally it made your fur stand on end. This achieved two things: one, it trapped warm air next to your skin to keep you warm  and  two : it made you appear bigger and more frightening. This explains why you get goosebumps when you are cold and when your flight/fight response is activated.
Meiotic recombination is a process that occurs in ONE INDIVIDUAL and gametes of varied genetic structure. What happens to these gametes is either a) something (they are used to produce offspring) or b) nothing (they die before being used to produce offspring.) There are two main purposes for, or results of, meiotic recombination:1. Increasing genetic diversity of offspring2. Avoiding the accumulation of deleterious mutations in subsequent generationsAntigenic shift is process that happens between TWO VIRUSES, where two virus subtypes merge phenotypes and produce a new subtype that expresses the surface antigens of both progenitors. This is not the same thing as the sexual reproduction that is used/needed to carry forward the effects of meiotic recombination.Both of these events are a type of reassortment, but their purposes are very different.
I didn't watch the video you posted, but I have heard this before. I've probably seen that video, or one very much like it. I've heard most of these.The heart of the concept is that "Natural processes only degrade information, they never create information." This is easily falsified. Tree rings, water flowing over a substrate, stellar emission spectra, orbital mechanics, gene frequency patterns.....in fact, *all of science* is about making observations of natural processes, gathering data, and interpreting that as information. The only way it works for them is to say that a mind is behind all natural processes, and that is very easily shown to be circular reasoning.They are (in a way) correct when they say "only a mind can produce information." This is because, at its heart, information is about the communication and interpretation of facts. You can't have communication or interpretation without something like a mind. Information, in this sense, is something that we create from observation. Yes, life is the only thing that actively uses that information to do things. But saying that proves the existence of some Creator is essentially the same as saying "Life is unique in the natural world, therefore it was created by something with a mind." That's an old and easily dismissed argument (e.g., there are other proposed mechanisms by which that can happen; a Creator is certainly sufficient to generate life, but it not necessary).I am a Christian as well as a scientist. So on a personal level, it would be great for me to have some body of evidence or irrefutable theory that proves the existence of God. But this is not it.
Well, it has the same rest-mass energy. Nuclear power comes from turning a small fraction of the mass in question into energy -- indeed, plutonium is much easier to convince to convert its mass into energy, as it is unstable to runaway nuclear reaction. But the total energy that stems from the mass in the nucleons in the same.
We do have [federal management of the aquifer](_URL_2_), and each state for which it is a resource have their own aquifer management agencies. The [Texas High Plains Water District](_URL_1_) is trying to slow down the depletion while trying to get farmers to improve water use efficiency. One thing they can do is [just plant different crops](_URL_0_) that don't require irrigation. Other states have [changed some of the rules](_URL_3_) to make water conservation easier.
While exercise is very important, so are certain nutrients. Research documents a 54% reduced cardiovascular mortality from a combination of organic high-selenium yeast and CoQ10 (in the form of ubiquinone) as well as improved cardiac function in healthy seniors (this is the KiSel-10study by cardiological researchers in Sweden). In addition, studies also show very beneficial effects of magnesium. So, if you want to help your body build its cardiovascular system back up, you probably will do well by supplementing with pharmaceutical-grade selenium yeast, ubiquinone and magnesium to boost your heart and your arteries.
All vitamins and minerals work a bit differently but I'll illustrate a little of the function of the ones you list.Zinc is really important for the proper binding of several transcription factors (proteins that bind DNA at genes to promote them being coded into RNA). It's also important as a cofactor (some non-protein molecule needed for a n enzyme to work) for several enzymatic reactions. In short Zn and other metals can coordinate electron binding to contort or stabilize biomolecules. Another example is Magnesium which is involved in virtually any ATP dependent process because it functions as a cofactor to split the phosphates off ATP or to put them back on. & #x200B;Vitamin C is an important antioxidant which means that it can help keep the balance of electrons within cells (electrons that are unpaired can cause damage) by donating electrons. Vitamin C is also a cofactor necessary to add a hydroxyl (OH) group to several enzymes. This process is critical to collagen synthesis because it keeps the triple helix of collagen together via hydrogen bonds. That's why scurvy (chronic lack of vitamin C) causes increased bleeding, hair breakage, and skin weakness. & #x200B;Vitamin D is not water soluble like C or the B vitamins which means it binds special carrier proteins when in the blood. It is made in the skin or can be consumed. To become active it needs to first be processed in the liver, then it travels to the kidneys for further processing. After this it can bind vitamin D receptors within the cell (because the vitamin is fat soluble). Once bound to its receptor the complex gets converted into another transcription factor important in metabolism. It is especially important in calcium metabolism (it increases the guts ability to absorb calcium for instance as well as causing its release from bone). If there is a disruption of the balance then bones can become weak, this is known as rickets in children. & #x200B;There is no vitamin B. Instead this is a class of several compounds. Briefly:Vitamin B1: This vitamin is critical as a cofactor for several enzymes, mostly dealing with protein and sugar processing. Also important in being able to metabolize alcohol.Vitamin B2: Critical antioxidant and electron carrier. Important for mitochondria to be able to generate ATP.Vitamin B3: Critical antioxidant and electron carrier. Important for mitochondria to be able to generate ATP. Also important in fat metabolism.Vitamin B4: Turns out to just be adenine/ATP.Vitamin B5: Most important for its role in synthesizing CoenzymeA, a molecule critical to fat synthesis.Vitamin B6: Important in everything from sugar, protein, and fat synthesis. Also important for gene expression and the synthesis of heme for red blood cells.Vitamin B7: Important in fat, sugar, and protein metabolism. Also important as it (biotin) gets tagged onto proteins. Some of these tags can be "read" by other proteins are cause DNA to wind up or unwing, making genes less or more accessable to transcription factors.Vitamin B9: Works as a shuttle for methyl (CH3) groups. Kinda like the electrons for vitamins C/B2/B3.Vitamin B12: Works as a shuttle for methyl (CH3) groups. It can also cause rearrangement of other protein groups. & #x200B;Phew. In short they do tons of complicated stuff and have different functions depending on context. Buuuuuut at the most basic level they either bind some receptor or are used as a "tool" for some chemical reaction. & #x200B;
Most of the material of the solar system is [on the same plane](_URL_2_), so it's somewhere on the "top" or "bottom" of the sun.[The distance may vary greatly depending on what you consider the limit of the solar system](_URL_1_), but 0.5 light-year put you right between the sun and [the Oort cloud](_URL_0_).
Not really. Healing is an automatic process. It will start as soon as the trauma is over regardless of the condition of the rest of the body. However, healing is dependent on a couple of factor, one of which is blood flow. In that respect, your body will cut a flow to an area with a severe hemoragic trauma and try to increase blood flow to an area under ischemic stress (lack of oxygen).Keep in mind that the control over blow flow is somewhat limited. Your body won't stop you from bleeding out if a major artery is damaged, and it won't stop you from dying of a heart attack if one of your 3 coronary artery is absolutely clogged.
It is a matter of heat transfer. Specifically the heat transfer coefficient. Compare the coefficients of the two and you will see that your body (mostly fluid water) transfers heat energy more effectively through fluid rather than air.
Yes, it's the movement.  Nope, it's not KE, Kinetic Energy of electrons.   Their masses are way too small, and an electric current is far too slow a motion.We can easily store significant energy in the rim of a spinning flywheel, since the flywheel is massive and moving fast.But say we have an electric current in a thick ring of metal (or better, superconductor.)   A closed loop of conductor with a circulating electric current does resemble a flywheel.   But the mobile electrons of the metal are tens of thousands of times less massive than the metal atoms.   And, if we store kilojoules of electrical energy in the ring, those electrons move extremely slowly:  milimeters per minute.  As a "flywheel" the electron population in the conductive ring is way too slow, and way too light.What the hell is going on?Your conductive ring of course is an electromagnet.  The energy is actually stored in the surrounding magnetic field, and not stored inside the individual moving particles.  (And if we embed the ring in iron powder, we can store far more energy while keeping both the drift-speed of electrons and the value of electric current the same.)Here's a weird concept: with the above ring, if we know the electron drift speed, then we can rotate the ring backwards just fast enough that those electrons remain still wrt Earth, while the positive metal ions are now flowing in a circle.   The kilojoules of stored magnetic energy isn't changed significantly, but now the flow is composed of massive positive-charged particles, while the light negative electrons have stopped flowing. The stored energy remains about the same, yet those flowing atoms (ions) are extremely massive!   For inductive energy storage, the important thing is the charge of the moving particles, and not their mass.E & M is weird.
You don't have a nerve for numbness, it is simply a nerve not working because of damage, chemical interference, etc.
The moon orbits the Earth once every 27.322 days. It also takes approximately 27 days for the moon to rotate once on its axis. As a result, the moon does not seem to be spinning but appears to observers from Earth to be keeping almost perfectly still. Scientists call this sychronous rotation._URL_0_
Simple answer:  We do not know.We don't possess a way to meaningfully interact with other animals.  That is, we lack a common language that is expressive.  Sure, when you pat your dog on the rump, it sits and that counts as a kind of language.  But, you and your dog have no good to way communicate nonphysical/verbal actions.  We can tell our dog that their shit smells horrible, but they don't know what you're saying; sure, they may understand your tone but not the substance.Inasmuch as animals understand building, yes they understand non-natural things.  Chimps "build" tools, beavers build houses and spiders make webs.
X Ray film is essentially capturing the x ray shadow of the various body components being photographed.
Lets assume that the water molecules completely mix up in the cup over the course of a day. Then every day the amount of water molecules from the first charge that is left in the cup roughly halves. So after 365 days there are (1/2)^365 of the original water molecules left. That number is incredibly small, on the order of 10^(-110). In 300 ml of water there are roughly 10^25 molecules. So no, most likely there will be not a single water molecule from the first day left in the cup.
>  *Is there some way of determining from birth whether a person has this allergy or not? Is there something in their DNA, or something in their body that is different than a person who doesn't have an allergy?*No and yes. You can't tell what someone will be allergic to, if anything. That said there are genes we've identified as being associated with allergies. There are many types of allergic reaction (from the acute anaphylaxis to seasonal sniffles to chronic inflammation) and different systems are associated with each. For food allergies we've associated genes that correspond to immune-regulator molecules called cytokines (IL-10 and TGFB1), antigen presenting proteins (HLA-DR, HLA-DQ, HLA-DP) and a some inflammatory stuff like prostaglandin receptors (PDGER2). So yes there is some genetic basis but that isn't the whole story by a long shot.  >  *When this person comes in contact with the peanut butter, what does the peanut butter do to them? What does the body do to itself?***[Mast Cells](_URL_1_)** are one of your immune system's key players. See that image? They fill up with little gift baskets that they share with intruders. These gifts include enzymes (tryptase, chymase) which it uses like machetes in the jungle to chop through connective tissue that occludes the path. They include molecules like **histamine and heparin** which has toxic effects on some parasites, and also increases blood vessel permeability (so more good guys can get through the blood vessels and join the fight - kind of like a conscription of sorts) and causes swelling so that we back our enemies into a physiological corner and they can't get away. It also releases cytokines that further cause swelling (TNF-alpha) and Prostoglandins which cause swelling and broncoconstriction - the narrowing of the body's breathing tubes. Now when these guys get activated in your GI tract you get the swelling, the fluid, the whole deal, but it only results in diarrhea and maybe vomiting. When you get them in your upper airway you get congestion, sinus infection type stuff. When you get this reaction in your circulatory system, however, you can get a systemic response that results in anaphylatic shock. This reaction is mediated by one of the five types of antibodies your body makes - specifically [IgE](_URL_0_) and its known as a Th2 response. Basically the persons airways swell up to point where they can't breath and without epinephrine injection they likely die. >  *Is an allergy like that curable?*Unfortunately no. Theoretically it could be treated,  but we're only now scratching the surface on those types of treatments (the targeting down of specific immune molecules).  >  *Are the allergies genetic? If not, how does someone develop such an allergy?*We know the endpoint but we don't know how people get there. There is an oft misquoted theory called the "Hygiene Hypothesis" which essentially links atopy (discussed in *klenow*'s comment) with greater hygiene. Children with more siblings, children who attended daycare, were raised on a farm, or were not raised in developed countries, tend to have more regulated immune systems and fewer allergies. We have animal models and a few studies that support this but ultimately we don't know what the hell is happening.
Long story short, the brain responds best to things that are changing. If you stare at that picture for a while, your brain's going to say it's not changing, so it resets the properties of the photoreceptors and neurons in the visual pathway to adjust to a world of that color scheme. Your brain is actually doing this all the time. For example, the tungsten light from an incandescent bulb is much more yellow/orange than sunlight light diffused through clouds, yet walk from one lighting scheme to the next and your brain will adjust to tell you that the piece of paper you're holding is white in both situations (even though in each one it is emitting a totally different color spectrum). In the example you posted, your visual system analyzes the color scheme and adjusts what it considers to be white, green, blue, red, etc. (kind of like the white balance on a camera). Then, when the black-and-white picture is shown, your brain does not perceive the white as white, because it had just recently picked another value for white. Therefore it will perceive the white area of the picture as being colored. Another familiar time you may have encountered this situation is if you've ever worn orange ski goggles. The snow seems very orange when you first put them on, but in a matter of seconds the snow will begin to appear white to you again. When you take the goggles off, since your brain has told itself that orange is the new white, it will perceive things that are actually white as blue (blue being the opposite as orange).
Blue light is more bent and re-radiated by the atmosphere, leading to the blue hue of the sky. The reason the sky is darker away from the Sun is because there is less light, thus leading to a darker shade of blue, but a blue nonetheless.When light comes in from the horizon, we are looking much closer to the Sun. Even at noon, the Sun looks yellow due to the scattering of blue light, leaving yellow light. Since at sunrise and set there is a denser atmosphere and more of it, blue light is scattered away even more leading to the absolute blue of the sky elsewhere. Since almost all blue light is scattered, the area near the Sun is mostly the colors left, mainly red/orange/yellow. Hopefully that helps. If you have more questions, I am happy to answer them if I can.
It looks like [salt ponds.](_URL_0_)Edit: [Here is a video.](_URL_1_)
Growth is mediated by the hormone - growth hormone, which works through somatomedins produced by the liver to increase protein synthesis, stimulate bone and cartilage growth and make changes to glucose and fat metabolism.Growth hormone is notable as it is released most at night in periods of deep sleep - it increases secretion by 2-3x during slow wave sleep. This may be due to altered cortical activity which increases the release of growth hormone releasing hormone from the hypothalamus. Other factors which cause growth hormone release include decreased glucose, fasting or protein deficiency (both of which may occur at night during sleep) stress and exercise. Thus once growth hormone is released it will exert its effects - as more is released at night, it is likely that a person will grow more at night when they are sleeping.
When you turn a brushless motor, the magnets in the rotor induce a voltage in the windings of the motor.  If you short the windings together, a current will flow and that current will create a magnetic field that opposes the rotation of the rotor.  If you shut down your motors and they are still connected to the control, the capacitors in the control can still be charged and cause the FET's in the control to be "on," creating a short between the windings and giving it that "stiff" feel.  You can recreate this yourself by shorting the windings together with your fingers.
Capillary action, the process by which water is taken up by the capillaries of the towel, is a consequence of surface tension of the liquid and the surface free energy of the solid in question.Liquid surface tensions generally decrease with increasing temperature and so in turn the wetting of the liquid to to the towel will change. Ignoring any change to the surface free energy of the towel, and any change to the interfacial tension between the liquid and the towel surface (although the interfacial tension between the solid and the liquid is the most important factor), a high temperature liquid will more readily wet the towel surface and so more liquid will be taken up by the capillaries. I also believe that any decrease in the surface free energy of the solid due to increased temperature will be generally smaller compared with the liquid further compounding this increase in wettability and capillary uptake.Edit: Spelling
A recent [review paper](_URL_0_) has concluded that it does have an affect on lung cancer rates and the radioactive material warrants removal, though it is only one factor in increasing the likelihood of smoking associated lung cancer.
The tone control is the R part of an adjustable [RC circuit](_URL_0_).  An RC filter can either be high pass or low pass.  Basically, a high pass filter removes or blocks lower frequencies while allowing higher frequencies to pass through.  A low pass filter basically does the opposite of that.  The tone control fades between those two types of filters.
To find the oxidation number, aka the oxidation state of a particular atom, you just need to know the atomic number and the number of electrons that it has. The electron configuration should allow you to figure out how many electrons are there. Once you have these two numbers, oxidation state is the difference between the number of electrons and the number of protons. If there are more protons, the oxidation state will be positive and if there are more electrons, it will be negative. Oxidation state becomes more complicated when considering atoms inside of molecules, but that shouldn't come into play until you are studying organic chemistry.
Propensity to sleep is regulated by both circadian rhythms and homeostatic sleep pressure, which interact in what we call the "two-process model." Waking up is not due to just 'circadian cycles.'The actual wake response consists of multiple brain regions, particularly brainstem wake-promoting regions, which release a variety of neurotransmitters (eg. acetylcholine, norepinephrine, glutamate, etc.). These 'wake-on' regions can target the cortex through intermediary structures like the thalamus or basal forebrain. Waking up from an external stimuli is possible because there is still rudimentary sensory processing during sleep, but the actual 'waking up' part is likely mediated by at least some of the same circuitry that causes 'natural' waking up.
If you throw it forward with more than 3500 m/s, it will follow a curved escape trajectory and start orbiting the Sun on its own. If you throw it forward slower, it will enter an elliptic Earth orbit. If you just let it go gently, it will orbit the Earth on nearly the same path as the ISS. What else do you expect in that case? The ISS is just like the the ball.If you throw it towards Earth as seen from the ISS, you might throw it downwards at something like 10 m/s. But the ball is still moving together with the ISS - at 7500 m/s. The downwards motion is completely negligible, and the ball will still orbit the Earth in the same way the ISS does.If you throw the ball backwards with 7500 m/s, then it will fall straight down as seen from Earth.
There is no big bang location. The expansion of space happened everywhere at once. It didn't expand outwards from a central point like an explosion. It spread out from every point evenly.  & #x200B;The further you look in any direction, the younger the galaxies get. Because you are essentially looking back in time. The further you go, the more condensed what you see is. once you get around 13-14 billion light years away everything starts getting opaque and hard to see. This is known as the Cosmic Microwave Background. & #x200B;One of the oldest star we have found was only 200 light years away, in our own Galaxy. [_URL_4_](_URL_0_) & #x200B;For more info I suggest checking out these wiki pages. [_URL_6_](_URL_2_)[_URL_5_](_URL_1_)[_URL_3_](_URL_7_)
It's actually a topic of scientific interest for many social/gender psychologists. The short of it, is we still don't know. While physiological signs of sexual excitement (e.g., blood flow to the vagina or penis) are relatively easy to measure, the emotional differences that the two genders attach to sex are extremely difficult. Yes, there are theories that men are more easily stimulated visually and women are more easily stimulated verbally (which is why they are more likely to read trashy romance novels than porn), but the deeper differences between the two genders are extremely difficult. Add to that that gender is more thought of today as a sort of spectrum (than two polarized sides) and you've got even more complications. From what I've learned in various classes, this is what I will tell you. The different social attitudes in men and women towards sex are thought to be created by a variety of factors. At the root of it is biology, for two reasons. Men are more easily sexually stimulated, which is simply biology. But men and women are also treated differently by society because of their biology (i.e., social expectations differ because of whether or not you have a penis/vagina). Go beyond that, and you've got social processes. Women and men are socially expected to act differently towards sex. They are psychologically conditioned to act differently. And various cultures widely differ on expectations, and men and women can have differing attitudes because of their cultures. Especially for women, you will see a wide spectrum of interest in sexuality based on the culture they come from. It has been hypothesized that this is because mental attitudes factor more into sex for women than men; e.g., if a woman is worried that having sex is 'improper', she can't enjoy it as much--even if that is a subconscious worry. However, this barely scratches the surface. After years of gender/personality/cognitive/biological psychology, I can tell you the one thing we do know: we don't know. Different areas of psych love to say 'we can explain this'. But every different area of psychology differs in what that area is. Welcome to the fun black box that is human psychology!
"Inertia" by itself doesn't have a mathematical expression, so it wouldn't be precise to say yes, but Newton's second law states that F = ma, where F is force, m is inertial mass, and a is acceleration...so if you're talking about inertia as a resistance to acceleration, then yes, it's proportional. (So doubling the mass of an object subjected to a given force will half its acceleration.)Of course, this isn't so straightforward when discussing rotation, where moment of inertia is more relevant than actual mass.
You're going to have to clarify where you're drawing the line on what is considered "modern times", but I can tell you that old Roman cursive was used as far back as [~250 BC](_URL_0_). Cursive is a natural byproduct of writing language on papyrus as opposed to etching in stone--so most cultures had some form of cursive after the adoption of papyrus/paper. Ancient Greek cursive on such a medium dates back as far as [nearly 800 BC](_URL_2_), and there is a [cursive form ancient Egyptian language dating back to at least ~650 BC](_URL_1_.So I would say: **No, cursive characters are not unique to modern times** by the conventional definition of modern times, seeing as all the empires I'm talking about here are typically referred to as "Ancient ____".
The [wiki](_URL_0_) is actually pretty good at explaining it in this case.  Since I assume you've already searched your topic before submitting, after reading the article what exactly are you unclear about?
It's likely dependent on the medication being used. Many chemotherapy agents work by killing rapidly dividing cells like cancer, but can also affect the normally rapidly dividing cells of the hair follicles and intestinal lining resulting in hair loss and intense nausea/vomiting. However, many chemo drugs have different mechanisms of action that may not have such severe side effects; it ultimately depends on the cancer type and oncologists plan. I don't know any specifics about dogs and chemo agents, but I'm sure the vet would want to use the least risky option for treatment. Many of the potent chemo agents are given intravenously and at very specific doses based on current bloodwork. Trying to use any of those agents in a dog would be extremely dangerous and very likely to cause more harm from the side effects. I imagine the vet chose an oral medication as the safest option for treatment, so it is much less likely to cause the severe side effects of traditional chemotherapy.
The trope you're describing isn't the one present in the example. Culture does not reflect language, in real life or in most fiction. The Dothraki are not aggressive and selfish because they lack a concise way to express thanks, they lack a concise way to express thanks because they are aggressive and selfish. This happens all the time in real life. Generally not with appreciation, because there's good reason to think that gratitude is a universal part of human nature, but, yes, when a culture doesn't have a thing, the language doesn't have that thing either. Because how could it? You can't name something that doesn't exist. So, when you have some particular practice that exists in one culture and not another, you get a word in one language and not the other. One example off the top of my head, there is a word that is present in a particular polynesian language, and no other language in the world. It means "a curse upon a name or place, such that speaking it or entering it is bad luck". No other cultures do this, at least not to such a degree, and so no other cultures have a word for it. The word is "tabu". In 1777, Captain Cook visited the island, thought the practice was cool, and brought it home to England, where it caught on and survived as a word for things that are forbidden to speak. This is also an example of how goddamn hard it is to find examples in modern languages that aren't absurdly specific, because of the unlikelihood that people would lack words for basic concepts common to all humankind, and because globalization had a flattening effect: all the cool stuff from every language was borrowed into every other language.
[Hydroplaning](_URL_0_) in the terms of driving is actually a process of loosing contact with the road because your tires are riding on top of the water.your risk of this is NOT increased in the first 30 minutes of rain. probably less since there will be few standing pools of water to plane on. that said the road is indeed more *slick*. oils on the road that will eventually be washed away will rise out of crevices and cracks to mix with the water and make the road more slick.
It's actually a really complicated question. You don't process all parts of vision the same. So light, motion, different areas of the eye (our vision drops off when you get to the peripheries). Then our brains are essentially taking the inputs. And combing it with what it thinks we should be seeing. It will ignore certain things that don't meet its expectations. It will allow us to see things smaller than we can actually see (for instance if you have a line going off into the distance we will sometimes be able to see the line even after the point where it's too small to see, as our brains continue that line on)So if you're looking for a fps number for the human eye/brain, you aren't going to find one
So... this is a very tricky question. I'm going to treat it pretty loosely but there are some things we can observe.First of all: what you said about any matter inside the event horizon of a black hole holds for a single uncharged and non-rotating black hole.Charged and/or spinning black holes have a region inside their event horizon where you can move around freely (inside that region). That is, all paths do not lead to the center any more in this region.So, when the black holes start to merge, the region where their event horizons meet will behave weirdly. I'm not sure about this (since you need some very numerical calculations in order to see how this works) but I'd think if you were positioned exactly between two equally massive black holes, you would not get pulled into either one even if the event horizons merge. That is, there will be a surface (two-dimensional I think) where you should remain stationary. Like I said before, I'm not sure whether this is actually the case or not.I think this is the case since the nature of the event horizon and the inside of the black holes changes when they merge (and maybe even before they merge) due to the influence of the other black hole. Therefore the fact about single black holes that any matter inside the event horizon will have to move towards the singularity no longer holds for certain regions inside the new merged event horizon.I have to stress that this is not verified in any sense and could be completely wrong. If we have any experts on numerical relativity I'll let them explain how it actually works if it does not work like this.Edit: The last video [here](_URL_0_) shows two black holes merging and how their event horizons bend and eventually merge. The tunnel between the two black holes would have this two-dimensional surface I was talking about if it exists at all. You could stay in this surface (the surface is moving through time as well since the black holes are moving) and not be pulled towards either black hole. However, you would eventually hit both singularities when they merge as the surface disappears.
Both actually. My favorite analogy to this is RPG characters -- different classes have base stats, which then create these "boundaries" in which the stats of the character may grow. These are your genetic inheritances, but how you raise your character is what determines how you fall down the road. So while a heavy class may have a higher base defensive stat, if it neglects to raise that stat, then someone in a more balanced class who DOES raise that stat may end up surpassing the heavy's defense. So while smarter people are more LIKELY to have a child with range which includes higher values, how they raise the child, the environment of the child, (diet, play and peers, even!) are what truly determine how smart the kid ends up. But, this take a really simplistic view of intelligence as something that can be measured by IQ tests, as opposed to multifaceted intelligences, such as problem-solving skills, memorization, creativity, etc. In each of those categories, you get the exact same "base trait" ideas, but the overall raising of the child muddies the water a little bit, creating a not-so-clear-cut model of intelligence.Ultimately, it comes down to an interplay between nature and nurture, where nature comes out via nurturing. Hope this helps!
Both are linked to one another, thus both are bad. But we can only slow ocean acidification by mitigating global warming. Here is how ocean acidification works - its a bit complicated because it involves many factors, some chemistry, and interactions between the atmosphere, biosphere and hydrosphere...First I will explain some of the consequences of ocean acidification and then explain how it happens.Ocean acidification along with rising ocean temperatures is responsible for much of the current decline in the shallow tropical ecosystems. The primary producers of the reef ecosystems are made up of many corals, sponges and other aquatic plants such as algae, and single celled zooplankton. Other species that contribute to the backbone of coral reefs include but are not limited to calcareous red algae, sponges, foraminiferans, tube-dwelling polychaetes, bryozoans and shelled mollusks (Hinrichsen, 1997). A whole host of species of invertebrates, fish, and mammals take advantage of the unique coral reef structure to provide them with food, shelter, and a place to mate (Cole, 2009). Ocean acidification, and rising ocean temperatures are thought to be the most important contributors to coral bleaching, which is the main cause of for the destruction of the corals (Cesar, et al., 2003).The corals and zooxanthellae (Single celled organisms capable of photosynthesizing) live symbiotically by regulating their metabolisms so that they match one another (Obura, 2009). Stresses induced on the corals, such as acidification of the water, create and imbalance between the metabolic rates of these two organisms. This causes the corals to try and restore the metabolic homeostasis by reducing the photosynthetic output of the zooxanthellae. This is achieved through a reduction in the number of chlorophylls (structures within the cell that capture sunlight and turn it into energy - plants do this) in the zooxanthellae, or through a reduction in zooxanthellae numbers (Obura, 2009). The algae give the corals their colour and so any loss of the algae typically results in the whitening of the corals, called coral bleaching.The bleached corals may recover by taking up the same, or different zooxanthellae algae, but only if the stresses are alleviated (Obura, 2009). Therefore, the loss of the algae is only a temporary solution on the corals part to alleviate the stress imposed by a changing environment (Obura, 2009). Coral bleaching found in all oceans can only be the cause of wide spread long term environmental changes, some of which corals cannot recover from, as seen by their inability to regain algae hosts.There are two key factors play a role in coral bleaching, rising ocean temperatures, and ocean acidification. The global decline of marine pH levels is called ocean acidification. Ocean acidification begins with the carbon cycle, when atmospheric CO2 (g) reaches the water-air interface it can dissolve. It reacts with the water to form dissolved carbon dioxide (CO2 (aq), carbonic acid (H2CO3), bicarbonate (HCO3−) and carbonate (CO32−). These compounds, along with dissolved free hydrogen atoms cause the pH levels of the water to lower (become more acidic) (Hoegh-Guldberg, 1999). The carbon cycle is a natural cycle that has been thrown off balance due to the unatural increase in CO2 levels over the past 100 years. Coral symbionts are negatively affected by an increase in pH and die, or abandon the coral hosts when the pH reaches an unbearable level. Each species of Zooxanthellae can tolerate varying amounts of pH (Obura, 2009). It is also thought to affect the ability of some shelled organisms to make strong thick shells. Weak shells do not adequately protect them from predators, adding another stressor to their survival.Seawater temperature is correlated to the rise in atmospheric temperatures. The global warming effect caused by the anthropogenic rise in greenhouse gasses, such as CO2, trap the sun’s heat in the atmosphere. The oceans act as thermal heat sinks, capable of absorbing great quantities of the Earth’s atmospheric heat. Water is slow to heat and slow to cool due to its high specific heat capacity, this means the effects of global warming are slow to take effect in the oceans. Ocean temperatures have risen over 1°C in the past 100 years (Hoegh-Guldberg, 1999). Corals live in ocean water temperatures between 18°C and 30°C (Hoegh-Guldberg, 1999). Warm water causes corals to be put under stress, and they expel their algae symbionts.TL;DR - ocean acidification and rising seawater temperature are correlated to an increase in CO2 (g) in the atmosphere. This kills the symbiotic photosynthesizing cells within corals - leads to coral bleaching - coral reefs die - other associated animals and plants leave or die. The reefs become dead zones. Biodiversity of the shallow water marine systems is threatened.
Plasmids are replicated independently of the bacterial chromosome, and are not distributed evenly between daughter cells when a bacterium divides. Also, if a there is selective pressure towards not maintaining a plasmid it will be lost, it is not always favourable to use energy to keep a plasmid if growth conditions are poor.Source: Horizontal Gene Transfer, Genomes in Flux - Bahl, Hansen and Sørensen.
Depends on the Virus or bacteria. I don't know much about about virusses, but I know bacteria.For something like *Salmonella*, there would need to be cells in the order of 10^5 to establish a gastro-intestinal infection in a healthy person, mainly because our own gut microflora is good at out-competing invaders.For something like *Mycobacterium Tubercolosis*, some strains can establish a lung infection with as little as 2 cells, because they are able to evade being digested by Macrophages and can divide **within** them. Some strains of TB are also resistant to both first- and second-line antibiotics, which makes you effectively *screwed* if you live in a country where you can't receive extensive Chemotherapy.Sources: Brock Biology of Microorganisms 11th edition,Janeway's Immunobiology 11th edition,_URL_0_
The amount of blood a person has is based on his or her lean body mass and sex. Greater for males and lesser for females. So when a person loses a limb he or she also loses a portion of his or her lean body mass.Overall the loss is negligble, but yes an amputee has less blood than a person with all of his or her limbs
_In vitro_ activity != _in vivo_ activity.This is not the case of "it's been shown to do A and B in these randomized human studies and 'BigPharm' (as if it's one entity) is hiding it." It is the case of "oh, this is interesting, we should look further into it" - and the process of looking further takes decades. [Here is just one recent study on this topic](_URL_0_) - we've got a long way to go.You can find many other compounds in a similar state of research (dichloroacetate comes to mind). People love to jump all over it, blowing their efficacy out of proportion and claiming corporate cover-up.
I can't think of any immediate way where cells actively opt out of using oxygen. Cells have a different tolerance for anaerobic conditions though, neurons on one end being notoriously intolerant of low oxygen levels, and erythrocytes on the other end being altogether incapable of using oxygen for energy generation.The body solves the drowning problem by restricting blood flow to less important areas by selectively constricting blood vessels going to that specific organ. The heart and brain enjoy a priviliged position in this hierarchy, and the skin is one of the lowest prioritized organs. So to answer your question directly, organs don't opt out of using oxygen, they are more or less thrown under the bus.Cells can however adapt to low oxygen levels over time and completely change their metabolism to better suit low oxygen environments. One example of this is in patients with chronic unstable angina pectoris, meaning that blood flow to their heart muscle ceases intermittently over a long period of time, their cardiomyocytes can sometimes go into a form of hibernation. They switch from using fatty acids for energy, a process that is completely dependent on (fairly high amounts) oxygen to yield any ATP, to using more carbohydrates that can be used for energy without oxygen (albeit inefficiently). This comes at a cost to the cell though, and skimping on energy usage generally means it can't perform it's functions (hence the name '*hibernating* myocardium' for this specific example).
Smallpox: we used a huge amount of resources to track every case and vaccinate everyone around them.Polio: there are actually two different kinds of vaccines inactivated polio vaccine (IPV) and oral polio vaccine (OPV). The concept behind OPV is to infect people and spread a weakened virus in the environment to vaccinate many people who might not have contact with the health system. This sounds amazing but like you mention, a live virus has potential to mutate so in addition to wild type polio outbreaks in Afghanistan and Nigeria, you also have vaccine-derived polio outbreaks like what's happening now in Papua New Guinea and Niger. IPV is a more traditional vaccine and gives promise for eradication.Rinderpest: this is an animal disease that was eradicated and was done through a combination of culling diseased animals and a huge vaccination campaign. There is some fear that laboratory samples might be accidently released.Guinea worm: this is a disease that's about to be eradicated without the use of any drugs. A huge effort by the Carter Center over the last few decades through the use of education, water filters, and insecticides has brought millions of cases a year down to a couple of dozen. There's been a bit of a set back as the human Guinea worm in Chad is now being found in dogs and South Sudan just had an outbreak in a long eliminated area. So it'll probably be another decade or so before it's fully eradicated.Lymphatic filariasis: this is a mosquito-borne parasitic disease that's being controlled through mass drug administrations to kill parasites in people and clean up campaigns that involve habitat elimination and spraying for adult mosquitoes.Trachoma: a combination of education campaigns and mass drug administrations are being used to drastically reduce the burden of blinding trachoma with the eventual hope of eradication but given it's the same bacteria in the Chlamydia STD infection, there's a long ways to go.It's doubtful that eradicated diseases will mutate from closely related diseases but opening niches could have new diseases emerge. There's also always the threat of bioterrorism which may feel distant but is a constant looming gray cloud in public health.Also if you're interested in infectious disease news I have a sub for it: r/ID_News
Science is a *methodology* that exists explicitly because human reasoning is biased.  But whether you can maintain: > a purely rational set of beliefsIt shouldn't be possible, unless you were some sort of literal superhuman or a sufficiently advanced AI.  Even if you divested yourself of all previous beliefs and accepted only what's printed in major scientific journals as beliefs, anytime you're presented with any given situation in reality, you're still working through a medium of the human brain - and the human brain isn't rational.edit:Also here's some papers by Dan Sperber, dude who does research on Human Reasoning:_URL_0_According to him, human reasoning isn't even meant to be rational.   His argument is that human reasoning isn't an evolutionary adaptation for tool use/understanding the environment but it developed as a social tool for arguing.  Therefore, it's not just biased due to the constraints of a slow-moving brain, it's biased because it evolved to be biased! tl;dr: yes everything you know is wrong
Basically it means that it has an intrinsic angular momentum even when it isn't rotating. This is sort of perplexing because it has no macroscopic analogue.The actual value of a particles spin can be related to rotational invariance. Something that is spin-1 can be rotated 360 degrees and come back to its original orientation. Something that is spin-2 must be rotated 180 degrees to get back to how it started. Something that is spin-1/2, like an electron, must be rotated 720 degrees.
To first order approximation, both would approach 20 C at the same time.From there you need to put a correction on how the thermal conductivity and heat capacity changes. There's a *tiny* effect that higher temperatures conduct heat better, so the 30 C glass will conduct heat a little bit quicker, but more heat needs to be transferred to change the temperature as the heat capacity is slightly larger too--whichever effect wins out is material dependant--if you're really curious, look up how the thermal diffusivity of glass changes with temperature.There's also going to be a second more meaningful correction which takes into account natural convection (density changes in the air due to temperature induces motion in the air). From this, heating bulk air is going to induce more motion than cooling air as hotter air is less [dense] ~~viscous~~[viscosity actually increases which surpresses convection]. This means that the hotter glass is might actually cool quicker by a significant amount. I don't know if 30-20C is hot enough to notice without doing the math myself, (involves the heat transfer coefficient), but if we were to make the temperatures in you example more extreme, you might be able to actually see the difference.So in short, because convective effects, not conductive ones, the hotter glass might cool quicker. However if convection wasn't part of the system, then it'd be roughly the same time.
You seem to be looking for a comparision of r-selection and k-selection. It's a tradeoff between quality and quantity of offspring. I'm guessing you didn't know about these terms when you asked the question. Sorry for the wikipedia link, but it's a decent explanation of the factors involved. [r/k selection](_URL_0_)
I think you found the right man for this question. I have a airport right by my hospital and I am trained to deal with aviation emergencies. I just need to know what type of aircraft we are talking about. Also what type(s) of aircraft are you interested in hearing about (private prop plane, private jet, charter jet, commercial jet, *helicopter*? As soon as you get back to me I will be able to help you out. Also if you can give me any additional information I can give you a better answer or at least give you the most probable scenarios. I would also like to say that I am very sorry for your loss, and I hope this information can help you deal with your loss easier. If there is any details you would like me to leave out to make this easier for you, please let me know.
In short, no, there is no connection between the volcanic eruption in Chile and the earthquake in Nepal other than the fact that they are both products of active plate tectonics. Both events happened in areas where, respectively, these types of events are common (i.e. the Andes have lots of volcanoes and the Himalaya have lots of earthquakes). The temporal coincidence of a large eruption in the Andes and a large earthquake in the Himalaya, is just that, a coincidence. More generally, it has been argued that earthquakes may be able to trigger volcanic eruptions (still a somewhat controversial idea), but this is primarily argued for earthquakes on fault that are in close proximity to volcanoes that are nearly poised for eruption. Volcanoes, or more precisely, movement of magma beneath volcanoes, can cause small earthquakes (this is one of the ways in which we monitor volcanoes), but I'm not aware of any suggestions of a volcanic eruption triggering a larger earthquake on a nearby fault. Even with these as considerations, there is no mechanism by which a volcanic eruption in Chile would have any effect on faults in the Nepalese Himalaya (an area in which we fully expect earthquakes of this magnitude, and larger, to happen with some frequency).
Sometimes yes, sometimes no.  It's true that there's some selective pressure for a disease not to kill its host - after all, if all the hosts die, the disease can't survive.  So there's often a trend for diseases to become more infectious but less deadly as time goes on.  This partially explains why a young disease like Ebola is so much deadlier than a well-established disease like influenza.But on the other hand, a disease's severity is often directly correlated with reproductive ability of the disease - if there aren't many symptoms, it's because the disease isn't reproducing very quickly.  A disease that isn't using its host to reproduce as quickly as possible may not be able to easily infect another host.  So there's also selective pressure for a disease to become *more* virulent.[Here's an article](_URL_0_) discussing how a strain of avian conjunctivitis became more virulent over time, rather than less.  The selective pressure to become more infectious overcame the selective pressure to become less lethal.
Additionally, there are 16 glucogenic amino acids in humans: G, S, V, H, R, C, P, A, E, Q, D, N, and M. This means that upon digestion and metabolism, they can be used to generate new glucose through [gluconeogenesis](_URL_0_).[link](_URL_1_)
The speed of sound (compression waves through a material) are dependent on the properties of the material--how quickly force is transferred from one region/particle to its neighbor. In air, for example, sound travels more slowly than in denser materials because the molecules are far apart. The electric field, on the other hand, fills up all the empty space between particles and it exists everywhere. Changes in the electric field can propagate through the empty space at whatever speed that happens (light speed). There is no need for the electrons to physically move and contact each other to transmit the electric force. The speed of sound is limited by the physical speed at which the molecules can move around to push on one another, but the speed of electricity is limited by the transmission speed of the electric field.
For one thing, it gets above freezing in Antarctica:_URL_0_ >  The highest temperature ever recorded in Antarctica was 14.6°C (58.3°F) in two places, Hope Bay and Vanda Station, on 5 January 1974.[4] The mean annual temperature of the interior is −57°C (−70°F). The coast is warmer. Monthly means at McMurdo Station range from −28°C (−18.4°F) in August to −3°C (26.6°F) in January.[citation needed] At the South Pole, the highest temperature ever recorded was −12.3°C (9.9°F) on 25 December 2011.[5] Along the Antarctic Peninsula, temperatures as high as 15°C (59°F) have been recorded, though the summer temperature is usually around 2°C (36°F).For another, it's complicated:_URL_1_ >  The retreat of West Antarctica's glaciers is being accelerated by ice shelf collapse. Ice shelves are the part of a glacier that extends past the grounding line towards the ocean they are the most vulnerable to warming seas. A longstanding theory in glaciology is that these ice shelves tend to buttress (support the end wall of) glaciers, with their mass slowing the ice movement towards the sea, and this was confirmed by the spectacular collapse of the Rhode Island-sized Larsen B shelf along the Eastern edge of the Antarctic Peninsula in 2002. The disintegration, which was caught on camera by NASA's Moderate Resolution Imaging Spectroradiometer (MODIS) imaging instruments on board its Terra and Aqua satellites, was dramatic: it took just three weeks to crumble a 12,000-year old ice shelf. Over the next few years, satellite radar data showed that some of the ice streams flowing behind Larsen B had accelerated significantly, while others, still supported by smaller ice shelves, had not 9. This dynamic process of ice flowing downhill to the sea is what enables Antarctica to continue losing mass even as surface melting declines. >  Michael Schodlok, a JPL scientist who models the way ice shelves and the ocean interact, says melting of the underside of the shelf is a pre-requisite to these collapses. Thinning of the ice shelf reduces its buttressing effect on the glacier behind it, allowing glacier flow to speed up. The thinner shelf is also more likely to crack. In the summer, meltwater ponds on the surface can drain into the cracks. Since liquid water is denser than solid ice, enough meltwater on the surface can open the cracks up deeper down into the ice, leading to disintegration of the shelf. The oceans surrounding Antarctica have been warming 10, so Schodlok doesn't doubt that the ice shelves are being undermined by warmer water being brought up from the depths. But he admits that it hasn't been proven rigorously, because satellites can’t measure underneath the ice.
Yes, they do, even more than babies because they have really bad eyesight for a couple of months and don't have hands to poke things with. Ever had a puppy  &  it chews on everything from furniture to your feet? Its trying to figure out what they are, and biting it allows the best developed senses of smell  &  touch to come into play. Obviously, this can be a choking risk if they bite something like a plastic bag. Also if they swallow something small and hard or sharp it can hurt their stomach or gut. Basically, if something says keep away from children under 3, keep it away from baby animals as well.
I have seen completely seedless peaches, as well as peaches that were bred to have only tiny stones (the size of cherry pits.) I cannot speculate why they have not been brought to mass market.
There are two things going on here, a cause and an effect, as  you say. One (as mentioned in another comment) is that water has a high heat capacity. Spraying water on any hot object will cool it down more quickly that almost any other liquid can.The second factor is that the amount of water vapor the air can hold depends on the temperature: the hotter it is, the more water it can carry. So if there's a sudden drop in temperature (a cold front, for example), there could well be too much water vapor around as the conditions change, and it will rain or snow out. This is why the heaviest snowfalls occur closer up to the freezing point - really low temperatures (Antarctica-style) don't allow enough water vapor to be around to have big, heavy snows like that.
A few points:1.  Your body will adapt and become more efficient at burning calories, so eating the same amount is resulting in more calories per day as you lose weight.  You should increase exercise to offset this.2.  Water can be retained for up to 6 weeks.  Keep drinking water to offset this.  If you have more than your body needs, it will get rid of it eventually.3.  No weight loss is "even."  On crash diets where you can see rapid change, it is expected that in 7 days, 2 days may show no loss or even gain, and 5 days show 1 pound lost each day.IF you are accurately counting calories burned and ingested, and you ingest less calories than you burn, then you will lose weight AS A TREND.  But nothing more.Some tools:  _URL_1_  is great for tracking food eaten and exercise done.  Including driving and desk work, etc.  They have a free app to aid you as well.For a graph of your trending data, which is more realistic over a longer period of time, check out the hackers diet._URL_0_
It really probably doesn't. The lowest observable adverse effect level in rats is about 10x higher than that measured in cases of chronic occupation exposure, which was considered the "worst case" chronic exposure scenario. Those same populations also had biomarkers of fertility measured and no reproductive toxicity was observed. Further, epidemiologically studies of similarly exposed groups did not indicate any detriment to reproductive health. I have no idea what the EU is basing that classification off of beside speculation that is contradicted by multiple lines of experimental evidence.
If you mean meta-data as in data-about-the-data way, then yes. This is called epigenetics. Generally, its used to switch off genes where they arent needed e.g. eye creating genes in your spleen. Its also possible to pass on the epigenetics effects that the environment has on your DNA though. So if a woman who is pregnant with a baby girl goes through a period of starvation or is exposed to a pathogen, this will alter the epigenetics of the eggs forming within the female fetus, causing altered gene expression two generations hence from the initial stimulus. you can see that when you test for position of epigenetic markers. There are other ways epigenetics are used but they get very complicated so Ill skip those for now.
The amount of time the baby can safely stay in the womb varies a bit from one pregnancy to another but it’s generally capped around 42 weeks. After this time the risk of having a stillborn increases as the placenta essentially has an expiration date. Once a baby gets too large they can press on their umbilical cord and cut off blood flow or they can just get too large in general to where the blood/nutrients supplied by the placenta aren’t enough to sustain them.
IIRC the extinction of the dinosaurs was a slow-ish process where there was a decrease in vegetation (due to various theorised disasters) which lead to an ecosystem which could no longer support the large dinosaurs that walked the Earth.The smaller animals were among the more suited to evolve. This included the mammals that at the time where much smaller (and I think what we consider rodent-like) and the birds (which are just an evolutionary off-shoot). The 'quickest way back' to dinosaurs would have been through birds but that served no evolutionary advantage as what point was there in being big and energy consumptive in an environment where food was possibly more scarce.There is also the theory (which I think may have some new research on that I will go look for) that dinosaurs were warm-blooded (or some sort of homeotherm) which would not allow them to be simply superseded by lizards.In summary, wasn't an evolutionary advantage to move towards dinosaurs again, much more suitable niches to fill.Edit: [Apparently dinosaurs metabolism was somewhere between poikilothermic and homeothermic](_URL_0_)
Our advanced medicine does a great job of extending average lifespan, but we haven't had much success in extending *maximum* lifespan. That is to say, we can ward off all kinds of disease, but humans seem to have a biological limit around 100-110, and we really haven't improved it. Go to any graveyard with graves from 200 years ago and you will find people who lived into their 100s. You'll also find a lot who died in their 30s of diseases we don't worry about any more, but the super-old haven't changed.
Mars' sky is a different colour due to the amount of dust in the atmosphere. Dust particles are bigger than air particles and so scatter light differently. This scattering can be described by [Mie theory](_URL_1_) but doesn't work entirely as dust particles aren't spherical. There are a number of approximations that describe how dust scattering affects the spectrum of light.The size of the particles is the main thing that controls scattering. On a planet with a different atmosphere it would still have Earth-like colour dynamics because the gas particles are still the same order of size. You could possibly get colours like green if you had enough green dust in the atmosphere (this would be a slightly different mechanism though). You can get purple shades from dust scattering - [observed by Spirit on Mars](_URL_0_).
[Health](_URL_0_)A healthier diet or lifestyle would be one that promotes health more than another. Please note that health, defined by the World Health Orginization (WHO), is more than just the absence of disease. The WHO defines health as "a state of complete **physical, mental, and social** well-being."
> If it were simply malnutrition I would think if part of a family suddenly had plenty of food for several years, they would be on average taller than the remainder.You can't give an adult more food and get them to grow taller.  The amount of food you have during certain critical years during childhood and adolescence has a big effect on how tall you grow.  Outside of that, it doesn't matter so much.
As the pressure of the fluid decreases, this causes the gases in the synovial fluid to come out of solution, creating bubbles. Once the volume of the capsule is restored to original dimensions, the gases return to solution, since they cannot escape, and create the popping noise.
Humans are a very visually oriented because of evolutionary pathways to our development with some emphasis in auditory sensing.  Thus we can usually tell who is a female and who is a male by sight and some sound alone.  Females have distinct vocal sounds on the whole relative to males and we can usually visually pick out a female due to breasts, a hip:waist shape ratio, height, and overall body form.  This information we process as humans, but in other animals this is evolutionarily dependent.In fact, it might not be sight alone that captures a particular organism's attention.In many species of crustaceans, it is a combination of scent and taste that relays the appropriate information.  The antennae perform dual functions of tasting and scenting the water so as to make sure what they sense is edible or matable.  Female crustaceans usually need to molt before they can mate because they need to be soft for penetration and when they molt they have special chemical cues on their cuticle that relays that information.  When another crustacean picks up that cue by touch or fluid sensing, not only can it tell that the other is a female, but it is ready to get mated.Some fish use sights to instigate a potential partner.  Some fish like darters have dimorphic characteristics apparent in breeding seasons where they will form different color bands and sometimes produce cool nodules on their dorsal fin like the [lollipop darter](_URL_0_).Other species use vocalization or auditory cues to relay mate potential information.  Crickets are a good example of this because they will make loud songs to attract a mate and hopefully repel rivals, but will change their song volume when a potential female is near, thus communicating to a female that the chirper is a male and wants to mate.  So it is not simply looking at each other more than it is a combination of these factors.Lastly, let's look at my favorite example among the cuttlefish: the false females.  We see some differences in body forms among cuttlefish species because of diet, age, and genetic issues so some may be big brutes and others will be small and weak.  Naturally, natural selection says that these small and weak guys should die out.  But by some slap to the face of Darwin: they defy such a notion and instead have adapted a new strategy by FALSIFYING THEIR IMAGE TO LOOK LIKE FEMALES.  Often the big male cuttlefish will find a female and guard her until she is ready to mate, and when the deceiving male encounters a brute, he will adopt female coloration patterns and look just like a female.  The brute will think: "Aw what the hell, come on in baby", and will let the deceiving male come in.  Thus, the deceiver is in prime position to mate with the real female when she's ready, before the brute can recognize it.  All because the brute simply looked at the "female" and was deceived.Cool behaviors like this happen because of the exploitation of such senses and the animal world is full of these examples.  Not all animals can simply look at something and find a mate, but may rely heavily on scent cues and taste (like the lowly anglerfish).  Monomorphism provides a unique challenge to the senses, but with animals that have the developed mechanisms, it's as much difficult to recognize a female in that species like it is hard to recognize a woman in our species.
Yes, cuts, wounds, and surgery were considered life threatening before the availability of antibiotics and antiseptics. Doctors and patients were very reluctant to perform a surgery purely for this reason. By about the 1930's, some types of surgery become routine, and some doctors start to report that patients seem to be eager to have surgery when they sometimes don't really need it. What was a life threatening adventure becomes something to brag about at parties, so people will "ooo" and "ahhh" over it.In the early days doctors were trained to look at the color, consistency, and oder of the healing wound, to try to figure out if it was good pus or bad. Practically all large wounds would get bacterial pus, but some was lethal and some was considered beneficial. If it was bad pus, they might have to cut more flesh off, to get rid of it, so sometimes there were a series of operations performed to get the right pus. Similar to what is still done sometimes for drug resistant infections we have today.
There are certain plant growth hormones that respond to various environmental stimuli. Example: some plant hormones respond to light and causes growth of plant tissue toward where light is most intense (this growth in response to light = phototropism). Other group of plant hormones cause what is called gravitropism, where growth of the plant tissue is effected by gravity. This is seen especially in roots and stems, as in roots show **positive** gravitropism, because they grow in the same direction as gravity, and stems exhibit **negative** gravitropism. This can be caused by hormone inhibiting or stimulating growth. Example: a gravitropic hormone responsible for stimulating tissue growth would be found in the **roots**, makes sense because these hormones will gather at the 'bottom of the root', so to speak, of the plant and causes further growth downward. A gravitropic hormone inhibiting growth would be found in stems, because gravity would cause all of these hormones to gather at the 'bottom' of the stem, inhibiting growth downward meaning the only parts of the stem that will now grow is upward and sideways.Source: I am currently in third year immunology and this was taught in a organismal bio course. We were also taught the specific names of these hormones, but because exams are over, fuck that shit.Edit: "stem" instead of "plant"
Its very possible that the areas of the brain associated with the other senses become more active as those senses are now being used more.  More connections will develop between the neurons in those areas, and the brain may become better at interpreting the information associated with those senses.  However, I think those would be the extent of changes.  For example, I don't think someone who goes blind is suddenly going to experience an increase the in the number of odor receptors in their nose.
That's...an interesting question. First off, let's limit ourselves to human rhinoviruses- there are other viruses that can cause cold-like symptoms, so, even if you eliminated rhinoviruses, we'd still get colds, but I'm too lazy to think about them. So, human rhinoviruses, then: would they disappear? Yes, probably. The real question is, how long would we have to wait? How stable are rhinoviruses outside the body? The data I was able to find are a wee bit sketchy, but it looks like they certainly maintain some infectivity for at least a [day](_URL_1_). On the other hand, [this](_URL_3_) paper suggests a maximum half-life of 14 hours under some conditions, so it could be a good bit longer -you'd only see a 10-fold drop in virus after about 2 days. Still couldn't be more than a week, though, I'd guess.What about inside of us? Colds are acute, self limiting infections, and they rarely last more than a couple of weeks, so a bit more than that might be long enough to wait. But a quick search for 'chronic rhinovirus infection' reveals that chronic, long term infections have been observed in immunocompromised people; see [here](_URL_0_) and [here](_URL_2_). That makes things more difficult, since we can't just wait for a predetermined infectious period. They could stay infected for months, or years. Who knows? But maybe we could just identify and quarantine those patients? That would probably be very hard, but not actually impossible...certainly easier than isolating everybody on the planet for that long.Another poster brought up the possibility of cross-species transmission, and it's a fair point. It's certainly conceivable that some lucky virions could manage to infect another animal and stay alive that way. Such zoonotic infections certainly do happen, but the vast majority of such infections are a dead end for the virus -they infect one animal, but don't manage to transmit their progeny to another host. This is why bird flu so far hasn't been as disastrous as it could be. Of course, it does happen, on occasion -HIV and measles both originated as zoonotic viruses. There doesn't seem to be any evidence for human rhinovirus infecting other species, however, and there don't seem to be rhinoviruses in other species that can sometimes infect us, so I'd say it's fairly unlikely to happen. On the other hand, rhinoviruses and their relatives aren't very well studied, especially in other animals, so it could just be that we haven't looked hard enough for evidence of zoonosis.So, tl;dr: maybe, but some people would have to be quarantined for a indeterminate period of time. And we might end up just picking up some similar virus in the future from another animal. And who knows about all the non-rhinovirus cold-like infections, some of them might have animal reservoirs or something.
So the issue is the waste water. The water used in the fracking process is injected back into the ground, which is what causes the earthquakes, and groundwater issues. Fracking itself is fine, if you dispose of the water properly. But that is costly, which is why they inject it into the ground. It's hand waiving in my opinion, as one practice begets the next.
Yes, it is possible to put enough energy into the ball for this. It would depend on the ceiling and floor (shag carpet or drop ceiling would absorb too much energy).Likewise, depending on the height of the ceiling, it might require so much energy that the tennis ball simply burst on impact as well.For a normal solid ceiling, floor say 8-12ft.... yeah totally.
So I just looked up collagen supplements and as far as i can tell it's complete bunk. I'm not sure about all their claims that loss of collagen results in wrinkled skin, joint problems, etc. They could very well be true. Collagen is a fibrous protein that is a very important component of connective tissues (basically it helps hold you together). However, the collagen in your body is synthesized by your own cells (as all proteins are) and exported and integrated into the surrounding extracellular matrix in a very specific way. You can't just eat collagen and expect it to end up in the right place. It will get broken down into its constituent parts just like any other protein source and then rebuilt into whatever your body needs.
I am restating your quest to add some assumptions to make the question more tractable.How would the hydrologic cycle be affected if additional water, sufficient to raise sea level 3m, were added.The additional relevant assumptions are the water did not come from changing climactic forcing, and it is not simply additional fresh water added to the surface.  The consequences of these would be catastrophic and chaotic.1. A 3m sea level rise would add very [little surface area to the ocean](_URL_1_).  Therefore, it is unlikely to change the evaporative input to global precipitation patterns.2.  A 3m equivalent addition of fresh water to the ocean is a vanishingly small percentage of the [total volume](_URL_3_), and thus would have no discernible impact of [global salinity levels](_URL_2_), and [thermohaline circulation](_URL_0_).So, not much effect other than changing the coastlines.Now, if the water comes from melting of vast volumes of ice due to warming, the conditions that produced the warming would also have a huge impact on the hydrologic cycle.  Similarly, if it comes in the form of rapid addition of fresh water to the sea surface, it has the potential to shut down global ocean circulation patters.
Sorry, I answered this question but deleted it so I will be brief. Basically you're looking at quite a broad axis of difficulty. On the easiest and making a heat killed vaccine, or using a related pathogen to vaccinate would require next to nothing. These vaccines would have comparatively low efficacy and high side effects. From there you could do something like passage the pathogen through another species in order to attenuate it. This would take a long time and again you'd have extremely high side effect rates compared to now, though one person could do it with relatively few resources (you'd probably want animal restraints, surgical tools, maybe a centrifuge, salt, sugar, petri dishes and so on). Making a modern live attenuated vaccines where portions of the genome have been removed, or a live recombinant vaccine would both be possible but you would need an extremely large stockpile of reagents, a very very very specialized and diverse team, and access to extremely advanced lab equipment.
Depends on the bottled water, I guess? But the obvious answer here is: nope. Whiichever bottled water you're using has minerals in it (usually calcium and possibly lime.) What you want is *distilled water*. Put some vinegar in there and leave over night. It should dissolve and rinse out fairly easy!
Rocket launches are coordinated using what is known as epoch time. This means that the moment when the rocket physically detaches from the supporting structure is defined as time = 0.00. This allows for simplification of pre and post launch activities for all the personnel involved since many steps must be completed in a specific order. The "hold" being lifted means some task or check is completed at that time, then another check or task, etc. If any in this chain fails the hold is re-instated. Post launch coordination is also simplified. Even if the rocket launches an hour late, each action or flight maneuver must be performed for XX number of seconds, as referenced to time = 0.00.Hope this helps.
A pet can't crawl into your mouth, nose or ears while you sleep.
The most powerful earthquake that has been recorded was the [1960 M9.5 Valdivia](_URL_2_) earthquake in Chile that ruptured a length of about 1000 km. However the longest fault ruptured observed was during the [2004 M9.2 Sumatra-Andaman earthquake](_URL_0_) that ruptured over a length of 1200 km. Fault length plays a key role in the most powerful earthquake that is theoretically possible, since rupture length will be limited to be less than the circumference of the Earth (40,075 km). To determine seismic moment or the amount of energy released in an earthquake, you would multiply the area of the fault that slipped (length x width), the distance it all slipped (usually in the tens of meters for great earthquakes like this), and the shear modulus of the fault (rigidity or how much the fault surface can resist breaking) [[Hanks and Kanamori, JGR, 1979](_URL_1_)]. The width of a fault is also a limit, because beyond a certain depth the lithosphere no longer breaks brittlely but instead deforms ductilely. This limit varies, but the deepest known earthquakes tap out at ~700 km depth. Since the faults that the largest and deepest earthquakes occur on are subduction zone faults which dip into the earth at an angle, their width would technically be more than that 700 km depth limit but that is a huge width already so I am going to stick with that for this exercise. And since this is conjecture, I will stick with a generally accepted 3.0*10^10 N/m^2 for rigidity and 100 meters of slip as any more than that freaks me out.Putting that all together in our equations for moment M0 = (40075000 m * 700000 m) * (100 m) * 3.0*10^10 N/m^2, and subbing that into our equation for magnitude MW = (2/3) * log(M0) - 6.05, we would get a magnitude of 11.23 for an earthquake that basically breaks the full circumference of the earth like a plastic Easter egg to a depth of 700 km and twists it to shift everything by 100 m.Needless to say, that is far from what is expected to actually occur on Earth through plate tectonics in our lifetime. With current knowledge of the longest active faults a more reasonable limit on the most powerful earthquake would be a magnitude of about M9.6. It would be on a megathrust subduction zone fault probably on one of the faults in the Pacific, and it would likely have to rupture much of the shallow part towards the trench which would generate a significant tsunami impacting all countries with coastlines along that ocean with Hawai’i right in the middle of the fun.
Nursing student here! So the stomach has receptors on it that sense things like stretch/pressure as well as chemical changes, the receptors send signals to the brain, specifically to the chemoreceptor trigger zone and integrative vomiting center in the medulla, which process the stimuli and send signals back to the stomach/GI tract to induce vomiting. The stimuli can also come from receptors in other areas of the body such as the vestibular system in the inner ear, which is why you can vomit from motion sickness. During the actual vomiting the stomach is not contracting, in fact it’s relaxed; it’s actually the diaphragm which contracts and expels the contents of the stomach.
I'm just going to cut in here and thank the moderators for not using the term "blood moon" or "super blood moon". It's a "total lunar eclipse" - one that happens to occur near perigee - because that's what we've called it for centuries.The term "blood moon" is a relatively recent term popularized by crazy Christian Pastor John Hagee claiming its appearance signifies some kind of biblical prophecy end-of-days snake oil. Using that term only adds legitimacy to the recent wave of anti-science paranoia. I've had to field far more doom and destruction questions from the general public about lunar eclipses ever since that term became popular.
The coriolis effect helps cause the molten iron flows in the core that generate the magnetic field. The surface would be bomabred by charged particles and DNA would just fall apart from ionizations of its atoms. No rotation, no magnetic field, no life.
Gore-Tex and similar stretched teflon membranes are famous for having that property. But from what I understand it only works with mixtures of gas and water, so raindrops and splashes and things like that, and if the membrane is completely wetted it'll still block the liquid but no gas will pass through either.So if you're looking for something that will separate *dissolved* gases from their solvent liquid I don't think Gore-Tex qualifies.
I've removed this as it isn't a question and we prefer not to speculate on matters involving other redditors.
It certainly can. If the surroundings are the same or close to the same as your target then picking out the target is much more difficult or impossible. If it is much hotter or colder it is easier to pick out.Biological reactions do have an effect, but not huge. If it is very cold then blood flow is reduced to the extremities, but they will still be significantly above ambient temperature. However we also tend to put on clothing which would shield heat emissions and inhibit detection.If it is very hot then we sweat, but we still need to shed the heat somehow.
Where he answers your question is at 1:38:00 but I encourage you all to watch the entire talk it is absolutely fascinating. _URL_0_He mentions that an hour long power nap can actually give as much benefit as a full nights sleep. Furthermore he mentions that naps that contain REM sleep can effect ones emotional response, causing negative emotions to be desensitized and positive emotions sensitized. So the answer is no, it is not the same as sleeping 10 - 6, it can be better. However it can also be worse. There are different phases of sleep we go through each night and some phases take longer to reach. If one is to sleep in highly disjointed intervals they may not achieve all the necessary phases of sleep. Another things he mentions in relation to naps is kind of common sense but it nice to have some scientific backing to it is the concept of sleep pressure. The longer you have been awake the more pressure there is to fall asleep. If you take a nap in the middle of the day you relieve that pressure and may have a harder time falling asleep at night.Watch the video. Its longer but it is well worth it. One of the best talks I have ever seen in any subject.
We only know of one biochemical basis, carbon! Carbon is great as it can form lots of links to itself, making lots of big and long molecules. Not many other atoms can do this, but silicon can to some extent, so some scientists think that silicon based life might be possible. This is a very uncertain field though, nobody really has the answers. That's why we are so keen to get out there into the universe and find out what sort of life is out there and how it works!
It really depends on how you set it up.If you fill 2 identical buckets with equal parts of water and then freeze one, they will weigh the same.If you fill one bucket to the brim with water, and fill an identical bucket to the brim with ice, the water will weigh more since it is more dense than the ice.
As long as you keep it away from normal matter, yes - this is usually done with strong magnetic fields. CERN managed to trap some anti-atoms for [over 15 minutes](_URL_1_) a few years back - I wouldn't be surprised if they're doing even better these days.Edit: [Here's the webpage from one of several antimatter research groups](_URL_0_), and it actually provides quite a readable summary of their research objectives and achievements.
It will vary.  For example, changes in pH can trigger denaturation of the protein; in other cases, though, there might be a deleterious effect on its function. Hydrolysis of peptide bonds without the aid of an enzyme is rather slow at neutral pH, although can be tremendously accelerated in very acidic or very basic conditions.
It's complicated. Let's consider receptors that detect warm stimuli. There appear to be several, named Transient receptor potential vanilloid (TRPV) receptors, which are cation channels.         * TRPV1- 43 degrees C. There is single channel conductance in excised patch recordings when exposed to capsacian; this suggests there are no second order messengers required for channel activation. So V1 may be gated directly by temperature. Likely by changing its 3D conformation to open the ion pore. Can be activated by proton concentration, even at room temperature.       * TRPV2- 52 degrees C. May act like V1 receptors, but unknown.     * TRPV3 + 4- 33-39 degrees C. Activated by heat in whole-cell configuration but not in excised patches. This suggests the involvement of second-order messengers. So a different mechanism than TRPV1 (and maybe 2).               _URL_0_                     So, various ways. The simplest might be the ion channel changing its 3D conformation in different temperature environments which causes the ion pore to open. However, it's possible that some channels are activated by second-order messengers in a similar fashion to GPCR pathways.
"Controlling the depth of field, that is, the range of distances over which images are in focus for a given strength of the lens, is also a function of pupil diameter. When the eye is focused on objects at a great distance, the depth of field is normally large and pupil size is relatively unimportant. When focused for near objects, however, the depth of field is small and can be increased markedly by closing down the pupil, just as it is by decreasing the aperture in a single lens reflex camera."_URL_0_
If you are thinking about how you normally push something, like a pencil, the motion through the pencil, as atoms propogate your push travels at the speed of sound for a pencil, not the speed of sound in the air.  The speed of sound is different in different media.  Faster in solid materials.
In class, we had a professor address this once, saying that leg bouncing was specifically connected to intense focus.  Anecdotally, I've noticed the same: people will bounce their legs intensely during complicated portions of scholarly presentations, and stop when a less complicated slide is put up.I just did a quick literature search, and I'm not seeing where she pulled that from.  As a second mention in the classroom, although I'm also not exactly seeing any publications on this, there was a visiting scholar that mentioned that rabbits require mastication movements when learning.  She was part of a group doing EEG's during a memory task in rabbits, and they discovered this inadvertently when they were trying to find ways to decrease the noise generated by mastication.  [This paper states that it's known to help both learning and memory.](_URL_0_)
Okay, let's unpack some of this. I'll start with an aside that when searching for things relating to 'fracking' on the internet, it can be helpful to instead search for its more technical name 'hydraulic fracturing'. This will weed out some of the conspiracy mumbo jumbo and useless news articles, though you will instead find a plethora of oil and gas industry pages that sometimes verge on conspiracy theories in their own way.In reality, very few people discussing fracking even know what exactly it is, so I would suggest starting with a look through this [page](_URL_3_) which provides a relatively detailed discussion of what is typically done. Moving onto earthquakes. To be technical, whether fracking causes earthquakes is 0% controversial as the whole point of the process is to generate fractures, which by definition will produce earthquakes. However, these earthquakes are extremely tiny and thus when people start discussing whether 'fracking causes earthquakes' almost certainly they are asking whether fracking, or processes related to fracking, induce seismicity that is 1) unrelated to the actual crack generating process and 2) is large enough to be actually felt or recorded. I would say the answer to this version of the 'does fracking cause earthquakes' question is yes, under certain circumstances. The textbook case for this at the moment is really Oklahoma. You can almost convince yourself that fracking is causing earthquakes just by looking at this [time series of earthquakes in Oklahoma](_URL_4_), but thankfully we don't have to rely on just that graph as several studies have been done recently linking fracking activities to earthquakes, for example [this one](_URL_1_) or [this one](_URL_2_). In detail, it's not the fracking itself that's causing earthquakes, but pumping and storage of the waste water from fracking.Now, the final part of the question, could earthquakes related to fracking trigger an eruption of a nearby volcanic system, like Yellowstone, the apparent world nexus of conspiracy theories regarding possible volcanic eruptions. It's first useful to consider whether any earthquake could trigger any volcano, and the answer to this question is yes, it can happen, but it's exceedingly rare. This [page from the USGS devoted to this very question](_URL_0_) gives a good run down on this. There are a few documented cases of large earthquakes triggering volcanic eruptions, but the clear examples of this are largely restricted to situations where an earthquake rupture directly interacts with a volcanic system (i.e. fault under the volcano produces an earthquake). All things considered, there is probably some non-zero probability that induced seismicity related to fracking could in someway influence the yellowstone volcanic system, but it's very unlikely and even more unlikely that this change in the system would be in anyway dangerous. So should you worry, I don't know, how much do you worry about personally being struck by a meteorite or being attacked by a shark while being struck by lightning? I would suspect the probabilities are close for all of those events.
It has not been shown to work better than placebo and there is no reason to think that it should. > TCM is a pre-scientific superstitious view of biology and illness, similar to the humoral theory of Galen, or the notions of any pre-scientific culture. It is strange and unscientific to treat TCM as anything else. Any individual diagnostic or treatment method within TCM should be evaluated according to standard principles of science and science-based medicine, and not given special treatment. [Source](_URL_0_)
The energy would dissipate as an expanding ball of hot gas or whatever debris is left.       The sockwave from a blast magnifies the damage but it isn't essential. If there isn't a medium to carry a shockwave the energy simply stays in the explosive.
Endorphınes (spellıng?) the bodıes way of mediating pain are released. The good news is your brain overcompensates the amount of endorphines needed to exactly compensate for the amount of pain / damage done resulting in the 'high' most masochısts can experience.Of course there is also a classical pavovian stimulous responce - once you know pain will give you the reward of the endorphıne buzz then you will program yourself to seek the stımulous in order to ensure the responce.A better bıologıst than me can probably explaın te exact mechanısm.
We use earthquakes!When there are earthquakes, the shockwaves from them travel through the air, through the crust, through the mantle and through the core. As these shockwaves move through those layers, they travel at different speeds, and they are reflectred and bent. We know a lot about how shockwaves move through various substances, and can set up experiments to learn exactly what happens.So we put lots of sensitive seismometers around the earth. From ones near the earthquake we can learn exactly what the shockwave looked like, and we can compare it with what the shockwaves are like after they have been distorted by the structure of the earth. When we create a model of the earth's structure that produces a similar distortion to what we see in real life, we can be pretty sure that our model matches how the earth really is.And every time there is an earthquake, the measurements are compared with what our model predicts, and where necessary, the model is adjusted so it is more accurate.
The air circulation system keeps the air mixed and filtered constantly. The astronauts must use a fan in their private sleeping compartments that are sealed from the ISS circulation system to prevent co2 buildup around their faces while they sleep.
One strong piece of evidence is the conservation of the genetic code's 3-nucleotide codon - the 'code' by which DNA is translated into proteins.  Three bases specify an amino acid. C, then A, then G, for example, is code for the amino acid Glutamine. There are 64 possible base combinations to code for the 20 amino acids used in protein synthesis. With few exceptions, *every single living thing* uses the exact same code to produce the exact same amino acids.  You use the same code as an e. coli bacterium.  The odds of two separate trees of life independently developing this precise mechanism are pretty thin.
>  are there still independent mitochondria somewhere on EarthNot literally, because mitochondrial DNA is vestigial compared with their original ancestors. Mitochondria have only a few dozen genes, and have lost all the ones necessary for independent functioning.So then, in the same spirit, are there independent descendants of the independent ancestors of mitochondria?It would seem to be almost impossible to tell, due to both the dearth of mitochondrial DNA, to the fact that it mutates rapidly, and that it has been subjected to very heavy selection pressure for so very very long.We would establish relatedness by an argument based on the similarity of mitochondrial DNA to some prokaryote's, but the above issues would appear to be more than sufficient to have made any similarities to be basically a matter of chance, even if they *were* related._URL_0_
You can do the same trick. Firstly, taking logs turns this into aloga=blogb, which is simpler to work with. Set b=a^(r) and plug it in to get aloga=ra^(r)loga, or a^(1-r)=r, which means a=r^(1/[1-r]), which gives b=r^(r/[1-r]). Any 0 < a < 1 can be written uniquely in this way and any r > 0 gives such an a. And similarly for b. So this gives all solutions.If you want rational solutions, we'll need 1/(1-r)=N, an integer, which means r=1-1/N. In this case, a=(1-1/N)^(N) and b=(1-1/N)^(N-1). These are the solutions when a and b are both rational. Eg: a=1/4, b=1/2.
Here's my best educated guess:When you receive bad news a few things happen in the body which ultimately makes you feel as though your heart drops. Your amygdala signals strongly within the brain as well as your sympathetic nervous system. The fight or flight response kicks in and your blood pressure increases as well as your heart rate. Your eyes will even dilate and there are some studies I remember reading a while back that even state that memories formed during these moments seem to be "slowed down" which would imply your senses are more than likely heightened during these instances. So, it feels like your heart is dropping, but really it's you feeling your body and heart reacting to the news.
Are you familiar with Bohr's model of the atom? (If not, have a look at Wikipedia or a chemistry textbook.) In order for a material to absorb light, you need two energy levels whose energy difference is in the order of the energy of the incoming light. In transparent materials, even the smallest energy gap is larger than the energy of the incoming light. Therefore, no absorption happens and the material appears transparent.As always: This is a correct, but very much simplified explanation. If you want to know more, especially about bulk materials, the dielectric constant is what you're looking for.
If you put a charged particle through a magnetic field, it travels in a circle. The radius of the circle is related to the charge-to-mass ratio of the particle. The fundamental charge can be measured in Millikan's oil drop experiment, and this can be used to calculate mass when you know charge-to-mass.
EMP's are exactly what it says on the tin: Electromagnetic pulses. The only known way to create a large EMP is by [detonating a nuclear warhead](_URL_0_). This type of EMP has three different phases. In the most visible phase, called E1, electrons are launched from the detonation towards the earth, overloading electronic components with their vast energy. More details on the [wikipedia article](_URL_3_).It is possible to create EMP's using less dramatic means, but they are really, really, small compared to their nuclear counterparts. ~~The easiest way is charging a capacitator and hooking it up to an antenna. It's as effective as it sounds.~~ **Edit**: *It's more complicated than that, see [TheSov's comment](_URL_1_). [SuperAngryGuy](_URL_2_) also brought up flux compression generators.*
_URL_0_40kA of current through 6 solenoids of 8m diameter each and 15-20m length, to protect a habitat the same size as the coils. Field is 1T inside the solenoid, and much weaker outside.Of course, it's an engineering problem, hence there can be different tradeoff choices leading to different parameters. This is just to give an idea of the scale.
I think the problem with this phrase is the use of the term "infected." A viral *infection* implies that the virus is successfully reproducing inside the host. Someone who has been exposed to a virus, through previous infection or vaccination, has the ability to produce antibodies against said virus, which prevents the virus from being able to infect the host a second time: [adaptive immune response](_URL_1_). This is not the case for rapidly-evolving viruses (think annual flu virus). So, the short answer is NO, especially considering the [polio] virus in question. A virus can not *reinfect* a host after the host gains *immunity*. However, someone can be exposed to a virus after they gain immunity. A better way to phrase the first sentence would be, "Most would be *re-exposed to* the virus in following epidemics but due to their previous *exposure* would have some immunity."Now, the term "carrier" is a loaded one, because, as mvelinder alludes to, some viruses can incorporate into their hosts' genomes and become latent. These hosts are now *carriers* of the virus, even though they are not currently *infected* with the virus--the virus is not actively replicating. This is called a lysogenic life cycle, and is not the case for all viruses. The Polio virus [does not undergo this type of life cycle](_URL_0_), it undergoes a lytic life cycle. So in technical terms, a person can not be a carrier of the polio virus. They are either infected or not. I would be very careful with this term, because the current wording of the phrase is biologically/medically incorrect.  A more correct phrase would be, "They had not escaped entirely, they now had the potential to be infected again." This phrase is more correct because it implies that, though someone was infected, their immune system was unable to respond robustly enough to offer them immunity. So, someone can be re-infected with a virus after if, after the first infection, they did not gain immunity to the virus. Edited for format
A spermatozoon only carries nuclear DNA to the ovum. It has [mitochodria at the head of the tail](_URL_0_), to run its outboard motor, but that stays outside the ovum. Meanwhile, the ovum is a complete cell, and is fully equipped with the cytoplasm that will be duplicated for each cell in the developing creature.
There isn't any particular mechanism for inverting the visual feed from the retina.  It's just presented to the visual cortex as-is.  Direction, then, comes from the attempt to reconcile vision with proprioception - "this direction is towards my feet" - and perceived gravity.  It doesn't really matter what the labels are, but as we develop we orient ourselves against the direction in which we feel gravity's pull.  Since we're usually head-over-feet, our brain gets used to the world being oriented in that direction, and gets very uncomfortable when something else happens.
Tidal heating. Ganymede and Callisto are far enough from Jupiter that they are heated relatively little. [Europa is heated more](_URL_0_) and seems to have a deeper liquid water ocean under a thinner ice crust as a result. The innermost of the Galilean moons [Io](_URL_1_) is heated so much that it is covered with volcanoes and has lost its water.
I'm going to talk about reactors in general here.When the control rods are inserted, they absorb the majority of the neutrons and cause the reactor to be subcritical (non-self-sustaining).When you remove the control rods, less neutrons are absorbed, and the number of neutrons detected in the reactor increases. We call this "Sub-Critical Multiplication". The reactor is not yet self-sustaining, however because neutrons aren't getting absorbed as often, more neutrons will be in the reactor. By plotting the detected neutron counts as you increase sub-critical multiplication, an estimation of the critical position can be made. This allows you to have a good idea of when the reactor will go critical.Criticality in a nuclear reactor is identified when you have three things. First, neutron count rate is increasing. Second, the time it takes for the count rate to double is constant. Third, no control rod motion is in effect. When all three of those are observed the reactor is slightly super-critical, or increasing count rate. Super-critical is not bad, and all large power reactors go supercritical for around 20-30 minutes during startup to reach heating power.As the neutron count rate increases, the number of fissions occurring also increases. More fissions means more heat. At low power levels, even small amounts of heat being added to the core will cause its temperature to rise. Any increase in fuel temperature will result in a reduction in fissions occurring due to the doppler effect (also known as the Fuel Temperature Coefficient). So the sequence of events here. The core goes slightly super-critical. The neutron count rate increases exponentially. The fuel starts to heat up a little bit. The increase in heating results in the fuel doing a poorer job at absorbing neutrons. The core passively returns to exactly critical, at a higher power level.You can determine energy is being released using thermocouples. You also know energy is being released based on the neutron counts. If your neutron counts are below 1 million, you probably don't have enough energy for it to be noticible. When you get to a neutron flux around 10^10 you will definitely be seeing noticeable heating effects.Now the next few parts are my guess:Where did the energy end up. Likely it was removed through heat radiative emission and conduction. There was likely airflow paths through the core providing a natural convection heat removal method as well. Heat was transferred to the surroundings.How weren't they irradiated? ~~Shielding combined with~~ low power levels and very low quantities of fission products. The radiation emitted by a reactor is proportional to the power level and directly related to the amount of waste products the reactor has inside of its fuel. Because they were doing primarily low power testing, the radiation fields involved were very low.I hope this helps.edit: There was no shielding. Just low power levels/low fission product concentrations.
Unless your microwave is broken or extremely old, it should automatically shut off as soon as the door is opened. So no, it's not hazardous.
This is real, a lot of ice tend to form on rockets since they have giant tanks of liquefied gases. As far as I know some of the images used in Apollo 13 for the take off are real archive images.
Why does it work? Because lightning is light (traveling at the speed of light) and thunder is sound (traveling at the speed of sound). Those speeds are different, and the speed of light is much, much faster, so you'll see the lightning before you hear the thunder. The farther away you are from the source, the more ahead the light gets than the sound, so the bigger the delay between the two.So how accurate is it? Well, the speed of light doesn't change, and will essentially get to you instantaneously (light will go 100 miles in half a millisecond). But the speed of sound *does* change depending on the temperature and properties of the air like humidity (see [here](_URL_1_) for example).Practically speaking, the speed of sound on Earth can vary between about 320-350 m/s.**In very cold air, the difference between lightning and thunder will be [5.03 seconds per mile](_URL_2_), while in very hot air it will be [4.6 seconds per mile](_URL_0_). Or 2.86-3.13 seconds per km.**
They are like flies. They have four stages of life egg, larva, pupae, and adult. Mostly the cycle only lasts for a few weeks, but in cold climates the stages can last for months. Some stages can even be frozen and thawed later.
Geiger–Marsden experiment, they fired positively charged alpha particles through a very thin gold foil. they then determined what had be reflect/ penetrated the foil at various point by measuring the count rate. the result indicated that as the vast majority of the particles travelled through unaffected that most of the atom was empty space, but the backscattered alpha particles indicated that at the centre was a very dense, small positively charged nucleus. subsequent experiments have been performed to verify this.
Unfortunately, Liquid water, needed for even the most extreme plants, is extremely rare to completely non-existent. Liquid water will not last long on the surface due to the almost complete lack of atmosphere. In addition, with such a limited atmosphere, plants would not be able to survive/function properly and would be killed easily by ultraviolet radiation. Our best hope would be to start with some sort of Extremophile microorganism.This link is a decent read on the potential for plant life. The data we have on the soil suggest it could support life however we would need to protect the plants by either growing them underground (therefore requiring artificial light) or indoors. _URL_0_
Energy is dependent on reference frame.  In the reference frame of the origin galaxy that's a blue photon even when it reaches us.
It's gravity would attract objects of mass towards it.  I'm not really sure how else to answer that part of your question; the Newtonian theory of gravity is pretty straightforward.What would happen to your "marble" of neutron star on Earth is more interesting, though.  It's extreme density is a result of immense pressure that it experiences while in the neutron star.  If a small lump of this material could somehow be teleported to the surface of Earth, the removal of the pressure would cause it to expand very rapidly.  It would effectively be a massive explosion.
As NeuroBill says, if you go far enough back the chemical probably came first.  But it's not necessary to ask that question for most receptor/ligand sets in modern cells.  Most of them are members of large families of receptors -- there are [over 1000 G-protein coupled receptors](_URL_0_), for example -- that are evolutionarily related.  Genes and even whole genomes are randomly [duplicated](_URL_1_) fairly regularly during meiosis due to various errors.  Most of these duplications are lethal, most of the remaining ones are neutral and the duplicated gene sinks down into the vast mass of genomic junk, but occasionally duplicated genes, being released from natural selection, randomly evolve new binding functions.  This is where the co-evolution comes in; you now have a weakly-interacting new receptor/ligand pair, and if it's useful then natural selection takes over and pushes the interaction to more effective levels.  (Of course, there are other processes besides gene duplication that can lead to new receptor/ligand pairs, but that's a very common process evolutionarily.)So co-evolution explains how there are so many and so finely-tuned receptors, and it's only necessary to account for a very small number of initial interactions that get the various families started.
In most exothermic (cold blooded) animals body size is a pretty good predictor of metabolism. So basically the smaller you are the slower you metabolism and the less you need to eat. Spiders are special in that their metabolism is 50% lower than would be expected for their size. So if you had a cricket and a spider that were the same size the cricket would require twice the food of the spider, roughly. Add to that that spiders are carnivorous. Carnivores need to eat less on average than ye old herbivores because the metabolic energy gained from 1kg of steak is greater than that of 1kg of lettuce. They are, usually, sedentary ambush hunters also. So the energy expended to gain a meal is low. They do have to make webs, which are 'expensive' but they can eat them and gain back most of the protien used to make them. So it's kind of like buying your first house; once you've paid for it, you can use the proceeds from its sale to buy your next house.  So low metabolism, good energy conversion, and a low-energy geared predatory style make for very low energy needs. Hence, they need only eat once in a while. Sufficient explanation?EDIT - Some o' you peeps be asking for sources. I'm having a little trouble finding good ones that aren't behind a paywall as I realise that many of you won't have academic privileges. So these aren't the papers that I would normally recommend but they are at least free. As an aside, does anyone know how to take a source web address that has been accessed through a university proxy and remove the proxy routing from the http address?Mentions the lower metabolic standard of most spiders - _URL_1_ [PDF!!!!]Very old, but mentions the use adaptations part - _URL_0_ [PDF!!!]Web differences and metabolism - _URL_2_ [PDF!!!!]
The concept of the left and right divisions of the brain being responsible for different kinds of functioning is overly simplistic, but there is some solid evidence to suggest that language processes are predominantly controlled by structures within the left hemisphere, and mental rotation and spatial perception are predominantly controlled by structures within the right hemisphere. Brain hemispheres cooperate when necessary, but it is thought that tasks are completed more efficiently if a single hemisphere is able to perform all of the processing.[Rilea et al. (2004)](_URL_1_) found a discrepancy between the manner in which males and females solve mental rotation tasks. While there was no significant difference in either gender's ability to successfully solve the task, men would do so more efficiently, and it was hypothesised that while women utilise both hemispheres for spatial reasoning, men use only their right hemisphere.Unfortunately, spatial intelligence isn't that interesting, so let's talk about actual intelligence and its physical correlates. [Haier et al. (2005)](_URL_0_) subjected participants to MRI scans and found that, in men, grey-matter volume is correlated to IQ most strongly in the bilateral frontal lobes (thinking, planning, central executive function, and motor execution), and in the left parietal lobe (somatosensory perception, integration of visual and somatospatial information). In women, grey-matter volume was correlated to intelligence in the right frontal lobe (thinking, planning etc.) and in Broca's area of the brain (interpretation of stimuli, verbal processes, and coordination of speech organs for the actual production of language).Secondly, it was found that women have more white-matter areas related to IQ scores than white-matter areas. This suggests that intelligence is related to grey-matter in men and white-matter in women. These grey-matter areas in men are associated with information processing, and these white-matter areas in women are associated with  information transmission. In short, if brains were computers, men would have more powerful processors and women would have more RAM.
Sort of. The closest ancestor to the domesticated chicken is a [Junglefowl](_URL_3_), specifically the [red junglefowl](_URL_5_). Similarly, domestic cattle are related to the now-extinct [aurochs](_URL_2_), sheep to the [Mouflon](_URL_1_), and pigs to the [wild boar](_URL_4_). For a full list, check [here](_URL_0_).
Yeah, that sucks. The sound is usually real, but the timing is adjusted for some inane reason. Before people started doing this on Youtube, one of the best things about seeing a nuclear blast in a movie or on tv was waiting for the sound, because it was stock footage and you always knew it was going to take a few seconds for the sound to arrive, thus illustrating the power of the bomb even further. This was back before the 1990s.
Oxidation happens very often, even when growing crystals in oxygen free chambers, unless you put a special cap layer on it.  My guess is it has to do with the free bonds like you suggested.Your other questions are involved and I will try to help you with respect to your highschool project.What it looks like is difficult to see.  If you use an electron microscope, you can resolve to about 10nm, or 50 atoms.  I still suggest you look at scanning electron microscope images of your crystal in Google. Instead, we know a lot about crystal structures by inferring attributes from other experiments.  If you use X-ray diffraction to measure the atomic spacing, you get a result that reflects the first 10ish layers, which may include your surface oxide. (One peak for your crystal and one blurry one for the oxide)In the binary crystal I studied, sometimes the crystals I grew had a layer gallium atoms pointing outward, sometimes it was nitrogen.  It depends  on what base layer substrate was used to grow the crystal on.  I could see the roughness of one of these polarities to be larger than the other using atomic force microscopy (a surface image that can resolve 0.5nm features).There are other nuances of instrument results that can be attributed to the surface.  So I would answer your hypothesis by investigating images and results of X-ray diffraction, atomic force microscopy, secondary ion mass spectrometry, and other optical methods.
ice- most modern rockets are hydrogen based. And are propelled by large amounts of liquid oxygen in hydrogen, making the surfaces of the rocket very cold before launch, enough that ice forms on the surface, which then falls off during launch.
Plankton and the like make about 85% of oxygen.
The Earth's core is almost the same temperature as the surface of the Sun (about 5700 K), so it's color will be about the same.  [This picture](_URL_0_) shows the appearance of black bodies at various temperatures.  The Sun is actually greener than we think, because the atmosphere absorbs more of the blue end of the spectrum.TL;DR: The Earth's core is actually hotter than the orange color would suggest.
Usually one virus only infects a single locus, at random. Loci are "locked away" as chromatin topography changes during specification and then differentiation. However, there are many genes that must be on for almost all cells. Lamin A/C, Histones, ion channels, basic metabolic transport proteins, enzymes, etc. [Site specific viral transduction has been shown](_URL_0_). Triggers for entrance into the lytic phase are usually cellular stress. [In one Bacteria-Phage symbiosis, a Transcription Factor in the Bacteria activates the phage's entrance into lytic activity](_URL_1_)._________So let's play a thought game (ethics aside):We engineer a virus to specifically introduce its genetic information near one of the aforementioned "background" genes (that are almost always in a region of euchromatin) with a high transduction efficacy. Within it's code is a promoter that is de-repressed by tetracycline induction. Once the promoter is active, the viral lytic genes are expressed. Induction is not always successful but with billions of cells in the body derived from the infected zygote, we should get enough to elicit a responseWe have a collection of IVF Zygotes, prepped and ready for introduction of our "Melting Man" virus. They are freshly fertilized and introduced to the virus directly after. We impregnate several women (to get a statistically significant N size).We let the children grow up into adults, hopefully they don't take tetracycline before they are reach 18. At age 18 we give them tetracycline and essentially euthanize them in the process. If successful, viral lytic activity will most likely proceed like a severe Ebola Virus infection. A medical examiner might call it an acute viral hemorrhagic fever. Cells would rupture, prompt an immune response, inflammation ensues, fever. A mix of anaphylactic shock, global hemorrhaging and ultimately "melting." I doubt it would be melting though as there are many fibrous and keratinous tissues that will maintain their structure. _____So now you know that it's *possible.* Is it worth it? Is it pragmatically feasible?It's certainly not ethical, even with animal subjects. Can you think of a benefit to the research?
For an asteroid to get captured it just needs to be close enough to the planet and have its velocity lower than the planets escape velocity (this is a simplification).Asteroids come on close passes to planets all the time, but they're going to fast and just fly by (or hit the planet). So something needs to disturb the path of the asteroid and slow it down. There are a few ways this could happen. The asteroid The asteroid could come close to a moon which would give it a gravity assist and might slow it down. The asteroid might graze the atmosphere of the planet which would slow it down (although this would usually leave it in an unstable orbit). Sometimes the asteroid is only going very slightly too fast so it doesn't take a whole lot to capture it. Some more info:  _URL_0_
A couple of thoughts:1. Those are really very low levels of radiation2. Natural sources (Radon, etc) will account for most of the differences between locations3. It might take a long time for groundwater-based contamination (if any) to travel the 60 miles to the city on the list nearest to Fukushima.Here's a Wikipedia article on background radiation:_URL_0_
Yes, Hawking is still correct. There is still no evidence either for or against the Copernican Principle. There *are* models of cosmology that have a preferred center and which make the same predictions as a cosmology based on the Copernican Principle. We appeal to parsimony or some other sort of philosophy when we say that the Copernican Principle must be true.For more details, you can read this response of mine: [How Valid is the Theory of Geocentrism?](_URL_0_).
The big problem is that it raises the noise floor for the other radio bands that it shares.  Other technologies came along and made it unnecessary.Up until about a decade or so ago, high frequency radio integrated circuits were made from gallium arsenide, which is expensive.  As silicon technology got better (the transistors get faster, similar to Moore's law), silicon radio frequency ICs became more viable.  They are cheaper and can integrate digital circuits on the same semiconductor die.  Now, RF silicon is steadily eating up the market that GaAs used to have.Other technologies such as Orthogonal Frequency Division Multiple Access (OFDMA) are able to use spectrum more efficiently.  As RF silicon improves, it can work at higher frequencies.  A new ISM band at 60 to 65 GHz has opened up, and RF silicon ICs are being used to work at that frequency.  The bandwidth at this frequency is huge, and only works at shorter distances, which is the same niche that UWB was trying to fill.  The result is new standards such as WirelessHD.
[Here](_URL_0_) is a report on the effect of contaminants on railhead friction. It appears that wet (raining) rails are continuously cleaned by the falling rainwater while damp rails build up a film of contaminated water which has low friction. Since it rains mostly in spring and autumn then falling leaves may mix with the damp water and create an especially slippery track.
Ok so basics first. Stars don't "burn" in the same sense that a log on your fire burns. The log on your fire is undergoing an exothermic chemical reaction with oxygen in the air and releasing lots of hot gasses into the atmosphere. In contrast a star is undergoing nuclear fusion - a physical reaction when two atoms are pushed very close together.That explanation may have led you to an idea about what's happening, then. A star "ignites" when enough gas and dust accumulates that the gravity pulling everything together pushes atoms close enough together at the core. So it's a simple result of the fact that gravity pulls things together, and that is why it happens all the time.
Pertussis or whooping cough is a danger for newborns. They can literally die without showing any symptom. The first vaccine is after one month. A total of four or five are necessary for immunity, but after the first shot the baby has a bit of protection. That being said, there are kids that haven't finished their shots yet and could develop the disease, but in a milder form, or carry the disease but are thankfully not affected. A baby can easily be infected by an older sibling who brought it home from kindergarten. The disease is more eradicated, so it's still being passed around by people who just don't know they have it. You can carry the disease, transfer it to the little brother, little brother dies.A recommendation is that pregnant women get a shot so they can pass some immunity during the crucial first month. There is a sad story about a mother seeking the vaccine in Spain, not getting it for some bureaucratic rain and whose baby ended up dying of it during the first month.
Throwing the ball towards the Earth would not result in it entering the atmosphere in only a few hours. Your mistake is assuming that because you threw it towards the center of the Earth with a velocity of 50 mph, it will continue to approach the center of the Earth with a velocity of 50 mph, i.e., 22 m/s in non-middle-earth-units.You need to think about it in terms of vector addition. The ISS is moving at about 7700 m/s parallel to the surface of the Earth. The reason it stays in orbit is because it is constantly falling, and it is falling at just the right rate for the curvature of its path to maintain an orbit with an approximately constant radius.In throwing it towards the Earth, you have made an almost negligible change to its orbit. Adding together the 7700 m/s velocity vector parallel to the Earth's surface and the 22 m/s velocity vector perpendicular to the Earth's surface gives a net velocity of 7700.03 m/s at an angle still very close to parallel to the Earth's surface (off by 0.16 degrees). In other words, the change to the orbit is very small, you will just every so slightly change its eccentricity.As the other poster there said, the more important issue is the atmospheric drag even at that level. The ISS has to periodically adjust its orbit to counteract this its rockets, which the baseball will of course not do.
As a general rule, most (but not all, more on that later) of the area above sea level currently has been above sea level for a very long time (i.e. since the Earth had oceans) and most of the area below sea level has been below sea level (i.e. covered with water) since that bit of crust was produced. At the most basic level, what land is above and below sea level is dictated by the composition and thickness of that piece of crust. There are two very basic types of crust, continental and oceanic crust, and the differences in their composition and thicknesses lead to differences in height (relative to some reference frame, e.g. sea level). In lieu of describing this in detail here again, as this question gets asked a fair bit, I'll refer you to a recent [answer to this question in regards to the difference between the two types of crust and how that relates to the locations of the oceans](_URL_2_).Now, that being said, there are temporal variations in the areas that are inundated (or exposed) by the ocean. There are three main drivers for this, (1) changes in ocean level, which influence the entire globe, and more local changes like (2) changes in tectonics that can uplift or subside an area or (3) deposition of material that may expose an area above sea level. A bit more on each below:**(1) Changes in Sea Level**: Sea level is not constant, a lot of this is related to the climate (i.e. during glacial periods, more water is bound up in ice sheets and the ocean levels are lower, whereas during warmer periods less water is in ice sheets and thermal expansion actually increases the volume of the water within the oceans thus sea levels are higher), but deeper processes like extra buoyancy of the oceanic crust during periods of accelerated ocean crust production can also change sea level. Looking at [records of sea level for the last ~540 million years](_URL_3_), one can see that sea level can vary by a few 100 meters on the global scale. Independent of the type of crust, if sea level rises, low lying areas of continental crust will be inundated. Generally, oceanic crust is low enough that sea level never drops low enough for that to be exposed.**(2) Changes in Local Tectonics**: There are many tectonic processes (e.g. mountain building, rifting of crust, etc) that can either lower a piece of crust below sea level or raise a formerly inundated bit of crust above sea level. Sometimes, this change doesn't have to effect a large area for the local sea level to change. A good recent example of this is the [Messinian Salinity Crisis](_URL_1_), where the majority of the Mediterranean dried out. Some debate continues as to the exact cause, and while some of the effects are related to a climatic change, it appears that most of the drying out was driven by tectonic uplift of the Gibraltar strait area and cutting off of Atlantic inflow. Tectonics can also cause subsidence, and it is believed that the [Western Interior Seaway](_URL_4_) during the Cretaceous was mostly driven by tectonically induced subsidence of a large part of what is now the American West.**(3) Deposition**: A relatively simple way for the local sea level to change in an area is through deposition of material. This is quite common in locations like [river deltas](_URL_0_) where the deposition within the delta 'progrades', i.e. builds out into the standing body of water.
A solid is loosely defined as something which retains its volume and doesn't change its shape to fill containers, so by that definition a cell is a solid. While it certainly contains (and mostly is) liquid, it acts like a solid so we call it one.What we care about in our macroscopic description of phase of matter is the macroscopic properties, not the microscopic ones. On the microscopic level, a cell is mostly liquid with a few solid parts, but on the macroscopic level the solid parts dominate so it acts like a solid. In the same vein, a bottle of water is mostly liquid, but the solid parts dominate how the bottle behaves on a macroscopic level, so bottles of water act like solids.In general, any sort of cohesive internal solid structure - like the cytoskeleton or cell wall on an cellular level, or the connective tissue on a multicellular level - will force an object to behave like a solid even if it's mostly comprised of gas or liquid. This is because the solid parts can't change shape to fill containers, whereas the liquid and gaseous parts don't care whether they change shape or not (they don't *have* to fill containers, they just *can* and will if nothing's stopping them from it). The object thus won't change shape, and is a solid.
Not at all. The Uncertainty principle, at its' most basic, reflects the problems that physicists have collecting data (position, momentum, spin) about a particle without destroying the data (changing the particle's state). *This is the observer effect.Interesting tangent: Researchers at IBM were able to utilize quantum entanglement to teleport particle state data without reading (and thus modifying) it. [Link](_URL_0_)
Absolutely.  Though the relative sizes of the wake vortices and birds would make the effect different from that felt by other aircraft.  A bird in flight that suddenly finds itself overtaken by a portion of a wingtip vortex would be blown along with the air column just like any up/downdraft or sudden crosswind gust they normally encounter.The vortices are more problematic for aircraft that are nearer in dimension to the disturbances themselves.  This similarity increases the probability that the disturbed airflow might affect multiple control surfaces in different ways, often inducing entry into a roll.
I think the pit of despair studies on baby monkeys showed that social animals like primates innately crave affection, and become depressed and disturbed without it. _URL_0_
Mantle convection is just part of the budget of forces acting on plates. Another big one is slab pull, where the old, cold and dense oceanic crust sinks into the mantle in subduction zones and pulls the rest of the plate along with it. This mechanism is considered to be as much, if not more, of a tectonic driver than convection. Other driving forces are a bit more controversial, such as the effects of tidal forces, the Earth's rotation and other gravitationally driven mechanisms like doming and ridge push where the plates are lifted by upwelling mantle and fall away from the rising mantle at places like hot spots or mid-ocean ridges.
I know of one way it can occur - a Pair Instability Supernova is often regarded as a good candidate for hypernovae events, as they are usually fierce enough explosions to complete destroy the star that caused them, instead of leaving stellar remnants such as black holes, white dwarves or neutron stars.This type of explosion occurs in large (130 - ~250 solar masses) low metallicity (that is, a very low concentration of elements other than H and He) Population III stars.To understand what occurs in such an explosion, you need to first understand the forces at play inside a star. During most of its life, a star is a balance of two major forces - gravity, which acts to pull the stars gas down into a single point, and photon pressure, caused by gamma rays produced in the fusion process, that forces that gas away. Gravity causes the gas to contract on itself, increasing core pressure and thermodynamic temperature and thus the rate of fusion. This increased rate of fusion produces more gamma rays that push back on the gas from within, balancing it out.In those massive, low metalicity stars, the gravity is so strong that temperature is high enough that gamma rays with enormous energies are produced in the fusion process. These gamma rays can spontaneously interact with a nearby nucleus of hydrogen or helium, converting into a positron and electron pair. But here's the catch - positrons and electrons do not produce that photon pressure that is vital to the stars balance, and the star contracts further, despite it growing hotter.This contraction increases the temperature, which increases the likely hood of positron-electron pair formation, which causes a runaway thermonuclear reaction in the stars core that can burn the entire core's mass of hydrogen in a few *seconds*.This results in an explosion so powerful, it completely destroys the star, leaving nothing but a glowing nebular remnant. A Hypernova.
In short, CPU can perform only a very limited and primitive computations, like addition, subtraction, multiplication, division etc. All "high level" computations are performed as a set of low-level operations.Back to the low level computations - they are performed part of the CPU called ALU - arithmetic and logical unit. It contains electrical circuits for each mathematical operation available. Small clarification how can an electrical circuit perform mathematical operation:I will go down only to digital electronics level, so I will assume that we have digital "gates". You can check later how a gate can be built using transistors. Simplest gates are binary - they have two inputs circuits and one output circuit. On the circuit you can have high or low voltage state (understood by gate as 0 or 1). Basic gates are:- AND - it returns 1 only if both inputs were 1, otherwise 0- OR - it returns 1 if any of the inputs were 1- NOT - it has only 1 inupt and it returns the opposite (so for 0 it returns 1)- XOR - it returns 1 only if one of the inputs is 1So you put voltage on the input circuits and you get voltage on output circuit.Let's assume you want to add two 1-bit numbers. That is numbers that are represented in a computer on 1 bit, so each number can be either 0 or 1. This means that result can be either 0, 1 or 2, so we need two bits to store the result of the computation. So we have two input circuits (with voltage that represents our inupt numbers) and two output circuits.A circuit that can perform that would require one XOR gate and one AND gate. Low bit of the result (the less significant bit) will be the result of XOR gate and high bit will be result of AND gate. Therefore we get:- 0+0 = 0 AND 0; 0 XOR 0 = 0 ; 0 and binary number 00 equals 0- 1+0 = 1 AND 0; 1 XOR 0 = 0 ; 1 and binary number 01 equals 1- 0+1 = 0 AND 1; 0 XOR 1 = 0 ; 1 and binary number 01 equals 1- 1+1 = 1 AND 1; 1 XOR 1 = 1 ; 0 and binary number 10 equals 2Therefore we got the result of addition for two 1-bit numbers. This can be easily generalised for numbers with more bits. Normally computers use now 32 or 64 bits. Other simple mathematical operations are done in a similar fashion.
Since the lenses are designed to correct for bad focal mechanisms in the eye, no. What you see with their glasses on is not what they would see with their glasses off. You would be over-correcting, since you don't need the additional focal help. You can get an idea of how powerful their prescription is, but it wouldn't be the same.
Exactly humidity.  There are two reasons that humidity causes it to get very hot.  One is that your sweat doesn't evaporate as readily, and as such your body is forced to retain more heat (because evaporative cooling is a very effective way to sink heat).  The other is that water vapor is a really significant greenhouse gas.  One of the absorption peaks of water matches up quite well with the blackbody radiation from the Earth, so water vapor traps a lot of heat near the Earth's surface.
Your question assumes something that likely isn't true.  A person who has boxed or shot a gun will also retain motor skills associated with those activities.  That is, even after they stop regular practice they will be demonstrably better at those skills than somebody who has never learned how to box or how to fire a gun.  Boxing and other skills certainly require regular practice to keep those motor skills at a peak level...but so does cycling.  If you go a long time without riding a bike, you'll be much worse at riding a bike when you try again.
Let's overly simplify the situation. The metal wire of the guitar attracts a magnet. This magnet is inside of a pickup coil of wire. As the wire vibrates up and down, the magnet vibrates up and down. As the magnet vibrates up and down it generates a current in the pickup coil. That current is then passed through the various amplification processes or distortion processes that may be wanted, then converted back into sound or recorded.
Have a look at [this image](_URL_2_)The hydrogen bonds that mediate secondary structure are oxygen from the backbone C=O, and the hydrogen from the backbone N-H. (i.e., these are atoms that every amino acid has). If you made a skeleton "tinker toy" model of just the backbone, and played with it for a while, you'd find that simple geometry would allow Alpha helices and beta sheets, depending on the rotational angles of the backbone bonds (called phi, psi, and...I forget the third bond symbol...phi and psi are the ones that matter).So, depending on the rotational angles of phi and psi, the C=O and N-H groups will be near enough that the C=O~H-N hydrogen bonds can form. You can visualize this with a [Ramachandran plot](_URL_0_).Now, the differences in the different side chains of the amino acids affect and limit the angles of phi and psi.  For instance, a tiny glycine has large rotational freedom, but not a bulky trptophan.  A backbone bond in proline can't rotate at all.  This means that a given sequence of amino acids has a given set of limitations on its phi/psi freedom, increasing or decreasing its tendancy to form a specific angle.  This a thing that ramachandran plots can be used for - a computer is fed an amino acid sequence, predicts the rotational freedoms of each psi/phi bond based on sequence alone, and assigns probability. [You can then use this probability to estimate (accurately) the secondary structure of a given sequence.](_URL_1_)
If information of DNA of relatives is available, DNA tests can yield an almost 100% certainity if and how close given samples are related. There are different tests, so called markers in use, the best would be a full sequencing of specific DNA regions or just presence/absence of specific shorter sequences. If many of those molecular traits have the same value in different samples, then the people those were taken from are most likely related. When it comes to very old samples say from mummies buried b.c. then the DNA can be degraded chemically. The once continuous few strands of DNA in each cell break down over time into small pieces with many of them missing which makes the analysis extremely hard.
If it's really aluminium the surface will oxidise and prevent further corrosion, I would have thought. If you're getting visible corrosion it must be an alloy, in which case any removal of corrosion just leaves the new surface open to more corrosion.
When Uranium fissions it usually splits into two daughter nuclei. One daughter nuclei has about 1/3 the mass of uranium and is usually close to stable. The other daughter nuclei is about 2/3 the mass and very neutron rich. This makes it unstable to beta decay and even neutron decay. Now the half life of the larger unstable daughter nuclei can very from fractions of a second to days or even years. Additionally, the daughter nuclei often has to undergo numerous beta decays before it becomes stable.The decay of this daughter nuclei essentially releases heat. In a full scale nuclear reactor that has been running for a while the amount of decay heat released from these decays is about 10Mw. That is a lot of heat. And this is why, you still have to actively cool the fuel even after fission stops.The moment the earth quake hit the Fukushima power plant, all the operating reactors scrammed. Their controls blades were inserted into the core and the fission chain reaction stopped. Everything that happened since then is a result of this residual decay heat.
Here's a complete list and brief description of every scientific study of the effect of weather on headache through 2011, excluding survey studies in which subjects were simply asked if weather influenced their headaches:  1.	[Kugler J, Laub M (1978)](_URL_12_) found no correlation between headache and atmospheric pressure, temperature, humidity, and ionization in four subjects over a five-year period, but did find a significantly high incidence of headache symptoms in "biometeorologic phase 6Z," whatever that is.2.	[Wilkinson and Woodrow (1979)](_URL_11_) found no correlation between headache frequency and adverse weather conditions in London.3.	[Schulman, et al. (1980)](_URL_2_) showed no correlation between migraine and barometric pressure in Boston.4.	Nursall (1981) showed no correlation between migraine and barometric pressure in southern Ontario, but did show headache frequency increased as temperature and humidity increased.5.	[Cull (1982)](_URL_5_) found that a sharp rise in barometric pressure reduced the frequency of migraine attacks in Scotland.6.	Diamond, et al. (1990) found no correlation between headache frequency and adverse weather conditions in Chicago.7.	[De Mattels G, et al. (1994)](_URL_6_) found no correlation between migraine and humidity or temperature in 40 migraine patients, but did find a correlation between geomagnetic activity and migraine frequency.8.	[Larmande, et al. (1996)](_URL_8_) found no correlation between weather and 4,421 migraines in France.9.	[Piorecky, et al. (1997)](_URL_10_) found that among 13 subjects in the Canadian Rockies migraines occurred on 17.26 percent of days with Chinook winds compared to 14.65 percent of days without Chinook winds.10.	[Cooke, et al. (2000)](_URL_13_) found that among 75 subjects in the Canadian Rockies migraines occurred 1.19 times more often on days with Chinook winds, and 1.24 times more often on the day prior to days with Chinook winds, than on non-Chinook days. For Chinook days, the relative risk of migraine increased only on days with winds in excess of 38 kilometers per hour.11.	[Vaitl D, et al. (2001)](_URL_3_) found low frequency sferics, pulse-shaped electromagnetic fields originating from atmospheric discharges (lightning), correlated with migraines and headaches in 37 German women from October through December, but not in July and August, when thunderstorm activity had been very intense.12.	[Walech H, et al. (2002)](_URL_7_) found a small correlation between weather and headache among 98 patients in Germany, but only during the summer half of the year.13.	[Prince PB, et al. (2004)](_URL_16_) found a statistical correlation in 39 (50.6 percent) of 77 subjects between migraine and one or more of three synthetic combinations of multiple functions derived from actual weather conditions. Oddly, subject beliefs about the kind of weather they are sensitive to usually didn't correspond to the kind of weather the study found them sensitive to.14.	[Villeneuve PJ, et al. (2006)](_URL_14_) found no correlation between 4,039 emergency room visits for migraine in Ottawa and weather conditions 24 hours before those visits.15.	[Mukamal KJ, et al. (2009)](_URL_0_) examined the records of 7,054 headache patients (2,250 cases of migraine and 4,803 cases of tension or unspecified headache) who came to a single Boston hospital emergency department between May 2000 and December 2007, and found that the ambient temperature during the 24 hours before each visit was on average higher than the averaged temperature of the other same days of the week during that same calender month. Hospital visits were also associated with days that had a lower barometric pressure during the preceding 48 to 72 hours than the averaged barometric pressure preceding the other same days of the week during that same calender month. The study found no association, however, between migraine and low barometric pressure.16. [Connelly M, et al. (2010)](_URL_15_) found that headache in 25 children with chronic migraine, chronic tension-type headache, or episodic migraine with or without aura was three times more likely following precipitation or elevated humidity. Changes in temperature, dew point temperature, barometric pressure, and sunlight had no significant effect.17. [Yang, et al. (2011)](_URL_1_) "...applied an adaptive-based method of empirical mode decomposition to detrend weather data. The EMD method provides a generic algorithm to decompose a complex time series into a set of intrinsic oscillations, called intrinsic mode functions, which are orthogonal to one another and can therefore be treated as independent factors…" and, using multiple linear regression analysis, found associations between headaches and intrinsic weather components, but not between headache and raw weather data, among 52 headache patients.18. [Hoffmann J, et al. (2011)](_URL_9_) found associations between headache severity and lower temperature, higher relative humidity, and lower air pressure among 16 of 20 subjects. The authors found no association between headaches and weekends or other specific days of the week.19. [Kimoto K, et al. (2011)](_URL_4_) found that migraine was associated with subsequent increase in barometric pressure. Weather change was associated with migraine headache development in 18 of 28 patients (64%). There was no association between monthly mean barometric pressure and headache frequency.
What you're describing is the fact that light does not interact with itself. In mathematical terms, the solutions to the equations describing the propagation of light are *linear*, meaning the sum of two possible electromagnetic waves is itself a possible electromagnetic wave. You can see a similar phenomena for small waves on the surface of water: for the most part, they just pass through each other without effecting the other's progress. Actually, once waves become larger you can start to see more complicated things happen, including big waves crashing into each other and dissipating energy in interesting ways. In fact, a similar thing happens with light, where very high energy photons can interact and scatter against other photons, but this is completely negligible for visible light.
Magnetic storage was basically invented in 1898 with the first [wire recorder](_URL_0_).  It magnetized a very thin wire and used that to store sound.  It was itself a pretty logical leap from (poor) prototypes that tried to vary the thickness of a wire to encode sound.  In turn those were a very logical adaptation of the wax cylinder phonograph, which encoded sound into a line of varying thickness and depth.Tape memory (1928) was a completely logical adaption of wire memory- make it wider, so it has more area to store data, and you can record faster and more reliably.  Magnetic powder was well known and used to coat plastic film.  Drum memory (1932) was the next step, and a simple improvement.  Turn the tape into a drum, and you can put a dozen read/write heads on it, and get *really* fast operation.  Hard drives (1956) were just a matter of saying hey- since we only use the surface of the drum, we waste all that volume inside the cylinder and limit the turning speed of the drum.  We can just put that data on flat platters and spin it faster.  It's a little more complicated, but a lot smaller, cheaper, and faster.Note that for these technologies, there was very significant overlap between what is very well defined today- memory vs storage.  A lot of these technologies were *blazing* fast, and there was really no such thing as "data" like we know it today.  So while technically most of these devices were used as memory like RAM, they turned into storage in the end.  It's also worth pointing out the original core memory- [magnetic-core memory](_URL_1_).  It wasn't used until late in the computer age, but the core concepts have been universally known since the invention of motors.  Magnetize a bit of metal, and it stores that data for you.  The idea of magnetic tapes and hard drives was never that hard.Silicon (note: no e) memory like FLASH(1980s; USB sticks, SSDs) was a little more complicated.  They have their origins in PROM(1956), programmable-only memory, which was basically an array of fuses.  Burn a fuse to write a zero.  Newer types that required lower power charged capacitors or carefully altered diodes or transistors.Eventually erasable EPROM(1971) was developed, which charged a very, very long-lasting capacitor.  Ultraviolet light was required to discharge the capacitor by temporarily breaking down it's insulation.  EEPROM(1977) was the next stage, and was the direct predecessor to flash.  It allowed memory the same memory to be erased electronically, without uv light.
Great question!Blood and cells contain an enzyme called catalase. Since a cut or scrape contains both blood and damaged cells, there is lots of catalase floating around.When the catalase comes in contact with hydrogen peroxide, it turns the hydrogen peroxide (H2O2) into water (H2O) and oxygen gas (O2).Catalase does this extremely efficiently -- up to 200,000 reactions per second. The bubbles you see in the foam are pure oxygen bubbles being created by the catalase. Try putting a little hydrogen peroxide on a cut potato and it will do the same thing for the same reason -- catalase in the damaged potato cells reacts with the hydrogen peroxide.Hydrogen peroxide does not foam in the bottle or on your skin because there is no catalase to help the reaction to occur. Hydrogen peroxide is stable at room temperature.
Well, the [big bang didn't produce hydrogen alone](_URL_0_). It also produced Helium and a smaller smattering of Lithium and other elements. On top of that, consider the [proton-proton fusion cycle](_URL_1_). Along the way, some of the protons turn into neutrons. This is true more generally, as stuff fuses up, some protons can become neutrons, and neutrons can become protons.
This is addressed by a result known as Bell's theorem. In short, Bell's theorem proves the following. Suppose you build a theory in which particles' observable properties or attributes really do have definite values at all times (call this assumption R, for "realism"), and that nothing that takes place at one region of space can instantaneously affect the results of a measurement at some distant region of space (call this assumption L, for "locality"). Bell showed that, assuming these two results, the degree of correlation between the outcomes of two distant measurements of systems whose states were prepared in the same place is bounded by a certain number.  So if your suspicion is true, and one can say the spins were aligned oppositely the whole time (that is if R is a good assumption), and assumption L holds, then when we actually carry out this experiment we should see correlations that do not exceed this certain bound.However, a quantum-mechanical calculation of the results of this experiment predict a degree of correlation that exceeds that for the above case, when R and L hold. So if we do the experiment, and find that the correlation exceeds Bell's bound, then one of the assumptions (R,L) must be false, favouring the view of quantum mechanics, where things just don't have definite properties before measurement.Finally, many such measurements have been carried out, and it is found that Bell's bound is exceeded, favouring the standard quantum mechanical view. However, two things should be noted:1) many of these experiments have minor loopholes, and so don't technically show completely that the assumptions (R,L) taken together fail2) even if the violation of Bell's bound is experimentally shown without any loopholes, we may still drop ONE of the assumptions (R,L) and have a theory consistent with quantum mechanics. For example, we can drop the locality assumption, L, and build a theory that satisfies realism R, which means that things do really have objective attributes before measurement, and still agree with the predictions of quantum mechanics. Such theories exist, the Bohm-de Broglie "causal interpretation" of quantum mechanics being one such notable example. In this interpretation of quantum mechanics, causal influences really do travel instantaneously. At this point, it is a matter of taste which interpretation one chooses.
It's the vapour that is toxic, not the liquid (well not very, anyway). From Wikipedia, "Acute inhalation of high concentrations causes a wide variety of cognitive, personality, sensory, and motor disturbances. The most prominent symptoms include tremors (initially affecting the hands and sometimes spreading to other parts of the body), emotional lability (characterized by irritability, excessive shyness, confidence loss, and nervousness), insomnia, memory loss, neuromuscular changes (weakness, muscle atrophy, muscle twitching), headaches, polyneuropathy (paresthesia, stocking-glove sensory loss, hyperactive tendon reflexes, slowed sensory and motor nerve conduction velocities), and performance deficits in tests of cognitive function."If you only got a small acute dose, most of the above would wear off.  If you are an infant, or suffer chronic exposure to the river vapour there may be some permanent effects.
Yes. E = mc^(2) works in the exact same way for chemical reactions as it does for nuclear reactions.The difference is that mass defects are extremely small in chemistry, and not so small in nuclear physics.
First of all, real time TV violates the very law you're asking about.Secondly, we would see them in "slow-motion" not sped up.
There are various materials that let one wavelength range pass but not others. They are called filters ([optical filters](_URL_0_) for visible light) and there is a large number of different types. Some of them reflect the light they don't let pass, like [dichroic filters](_URL_1_).
It depends on what you mean when you say that "atoms vibrate".If you mean that the position of many atoms in a medium oscillates, then this is by definition a sound wave.If you excite an atom *in a medium*, then it can relax by creating a phonon, i.e. sound. In [fluorescence](_URL_0_), this is called "non-radiative relaxation".The other way for an excited atom to relax is by emission of light (or X-rays, or other forms of electromagnetic radiation in general). This also works in a vacuum because unlike sound, light can exist in a vacuum.
> So why are we not fracking?We are fracking. A lot. There's been a huge fracking boom in the US, especially in Pennsylvania and Ohio. From what I've seen, the major problem is that the technology and business have moved much faster than government regulators. The injection wells can be made to be strong enough to not leak into the groundwater, but there are a few cases where oil/gas companies cut corners. There have also been a lot of surface spills of the fracking chemicals. On a fracking site, there are large tanks of chemicals, and due to poor regulations and cost-cutting businesses, they can leak into surface water much more easily than the chemicals that are actually injected.Finally, unlike traditional drilling, fracking is performed on a smaller, more distributed scale. This means that it is often done in residential areas where people live. In order to frack, you need to have a lot of trucks delivering water/chemicals and constructing the well. This creates a lot of noise and air pollution in residential areas.
The very first part of the water droplet to freeze will be a ring, on the bottom of the drop where it's exposed to both cold air and the dry ice. So now you have a ring of ice holding a water droplet in place.Well, it will start freezing inward from there. But as water freezes, it expands; so you'll have a small column of ice pushing the rest of the unfrozen water upward ever so slightly.Repeat, and you end up with this little cone, built by freezing the bottom layer of a water droplet and working up.
The answer lies in the expendability of males. Sperm is cheap. Eggs and pregnancy are expensive. A male can afford to sire many offspring while a female can only have one kid every 9 months or so. (Gestation periods tended to be longer in the nomad days, but you get the point.)In our ancestors, 80 percent of women reproduced, whereas only 40 percent of men did. This meant that being a female, you had more of a "sure bet" in passing on your genes. Females had no advantage in risky, testosterone fueled behavior. On the other hand, if a male did not have high testosterone and wasn't aggressive in maintaining his status, winning fights, hunting, etc... he could easily lose reproductive privileges. If you are interested in this sort of thing, check out the book the Red Queen.
While I don't have full answers, some of the major nerves, such as [the vagus nerve](_URL_0_) have pathways that allow them to not be impacted by spinal cord injury. This nerve lets you know when you're having a heart attack or sends signals between your brain and stomach to indicate nausea (sometimes a silent heart attack).One of the most fascinating things about the vagus nerve after spinal cord injury is, oddly, the gender differences. Women can still have [vaginocervial orgasms after complete spinal injury](_URL_1_), and those orgasms are mediated by the vagus nerve.So, not all nerve pathways that are in charge of important things are impacted by spinal cord injuries.
I am not a nutritionist, so I can't really speak about the health aspect of it.  But in all of the articles you linked, the physics is wrong or worded in a deliberately misleading way.  I'll make a few points here:* Yes, microwaves can leach harmful chemicals out of containers, but so can every other method of heating.  This is not an issue specifically with microwaves.* The sun does not use 'DC' radiation.  The fact that microwave ovens have a narrow spectral line does not mean its somehow bad for you.* One of those webpages somehow claims that 400 milligauss of 'radiation' is linked to leukemia, which is absurd.  A gauss is a measure of magnetic field, and 400 milligauss is tiny.  For comparison, Earth's magnetic field is around 600 milligauss.I can't tell you if microwaving food is good or bad.  But I can tell you that those websites horribly are wrong.
More info on the network:  >  _URL_0_Voyager 1 is currently about 12 light hours away, so any communication sent takes 12 hours to reach voyager, and for voyager to reply again 12 hours to come back.  For the rest, and I'm making a bit of a guess here, it works like any other communication, Voyager (and other far away robots/satellites) stores everything it receives in memory banks and reads it out when it gets an "EOF" notification, with maybe a couple of parity bits in there to check if the message is valid.
Methadone is long acting and so a person only needs a dose every second or third day to prevent withdrawal. The daily dosing is done due to the anxiety of the patients - people like a daily dosing regimen. That is, you can miss a dose or have a dose late without a great problem. You certainly won't die, however some people who are taking methadone as a treatment for drug addiction become fixated on the dose schedule and overly fearful of the consequences of missing a dose.If you were on a high dose of methadone, heroin, morphine, or oxycodone and you  stopped taking the drug completely and suddenly, then you could become sick from withdrawal. However death is unlikely and most people in withdrawal would seek out drugs or medical assistance.If you mix methadone and alcohol or other sedative medications you are at greater risk of accidental overdose.Lastly, methadone is also used as a pain killer, but when used as a pain killer the dosing is completely different.
Gravitational waves are a prediction of Einstein's theory of gravitation, called general relativity.  In a gravitational waves, space gets distorted in a particular pattern (a circle would deform into an ellipse, alternately elongated horizontally and compressed vertically and then compressed horizontally and elongated vertically).There have been indirect measurements to confirm their existence, but a direct measurement would be significant for several reasons:(1) We would get explicit confirmation of a key aspect of general relativity.  (2) The kinds of events that produce sufficiently large gravitational waves are dramatic things -- black holes or neutron stars merging or colliding, for example.  We would be able to test general relativity and how it works in these situations.(3) Probably more important, the ability to detect gravitational waves opens up a new means of observing the universe.  For example, how often do black hole mergers occur?  Historically, new means of observing the universe have enabled us to find new phenomena that we had not anticipated and to give us new ways to examine previously known phenomena.Stay tuned -- there is an official announcement at 10:30am EST (15:30GMT) on 11 February, at which point we will all know whether the rumors are true that gravitational waves have been observed and, if so, exactly what has been seen.
> Would gravity just hold it together as normal?Yes, it would squish itself back together immediately after the cable had passed through. I'm not sure if the slice would result in new tectonic fault lines, but the general structure would be unchanged as it's not dependent on being held together with anything except gravity.
With the caveat that we still don't know all that much about dark matter yet, based on our current best understanding there already is dark matter in your living room. In fact, much like neutrinos, dark matter particles are streaming through all parts of the earth at this very moment. However, they're extremely difficult to detect, because they don't interact through either the strong force or the electromagnetic force, so there's no way for you to tell they're there with any household items.
There are a lot of steps in common every time we catch it and in fact any time we catch any type of respiratory virus for the most part it would be similar. If you're talking at the cellular level the most basic steps would be cell A getting infected, then cell A realizes it is infected (or it dies but we'll stick with simple stuff). At this point cell A will release various chemical signals to trigger the immune response and also alert it's neighboring cells to boost their defenses vs viruses. From this point there are a billion different possibilities so we will just look at one possible outcome. Cell A alerts the immune system which would cause immune cells to congregate and move to the area, increased blood flow to the area and increased temperature. More than likely cell A would get killed by the immune system and the innate (non antibody mediated) immune cells would try to eat/destroy the virus. They might succeed actually, but if not then other immune cells would eventually recognize the virus and bump up the adaptive immune response (antibody mediated) which would use antibodies and other special cells to beat the virus. This is essentially the same for every type of infection we get. However with your question about re-infection it would likely just be bigger, faster and stronger assuming there is some cross reactivity of the antibodies from previous infection. The common cold does NOT have much cross reactivity though if I remember correctly so more than likely we have to start the process over every single time we catch a cold.
Not particularly. The vast majority of oxygen comes from oceanic algae, not trees. Atmospheric gasses also rapidly mix in turbulent air, eliminating local differences. Air Quality is a different thing to oxygen content though, and is generally concerned with the parts-per-million (PPM) or parts-per-billion (PPB) of some pollutant. Shanghai for example would have far worse air quality than Copenhagen, but the same gas percentages.
DNA has a half life of about 521 years and [from this post](_URL_0_) there seems to be about 250 grams of DNA in a human (roughly, varies depending on weight/amount of cells in an individual body). Egyptian mummies have been in the ground for varying amounts of time, the earliest being around 6,000 years ago to let's say 3,000 years ago for our range. Half life is the time it takes for a substance to decay to half of it's original amount. The equation N(t)=N_0*(1/2)^(t/t_1/2) models exponential decay, where N_0 is is the initial amount of the substance or 250 grams for us, t_1/2 is the half life of the substance, or 521 years for DNA, N(t) is the amount of the substance left over after time period t. N(6000)=250g * (1/2)^(6000 years/521 years) = 0.0853 grams remain after 6,000 years. N(3000)=250g * (1/2)^(3000 years/521 years) = 4.62 grams remain after 3,000 years. I'm not sure how much intact DNA is required to produce a cloned organism, but I would venture to guess that it would be difficult to get a good sample from an older mummy. It really depends on how much sample DNA is needed to create the clone.
Your friend is very confused. Subatomic particles, say an electron, can be in a state in which its location is spread out. It isn't in a particular place until observed, at which point the wave function is said to collapse. Particles can also spontaneously tunnel through a barrier without having the energy that classical physics would require. Macroscopic objects do not exhibit quantum properties like this.
The Earth is really big relative to the asteroids.  The mass of the asteroid belt is 4% of the Earth's moon or 0.05% the mass of the Earth.  Even if we stupidly brought all the asteroids to Earth (and what would we do with all of that?) it would add a little over a kilometer of rock to the surface and the gravity would increase by maybe 0.05%.  The rotation of the earth would slow down by about 0.05% which would mess up the clocks by about 1 minute per day, but I think the people would be more annoyed by the 1 km thick layer of asteroids surrounding them.
Most of the noise is in fact due to the turbulence generated between the rocket's exhaust and the atmosphere. While the engines themselves will not be silent it's a far cry from the violence that ensues when gasses moving 4 km/s relative to each other meet.The flow inside the rocket engines is slow and turbulent in the combustion chamber, and fast and smooth in the nozzle. Neither of these will generate much noise. If fired in orbit the exhaust plume goes into vacuum, so that won't feed back any sound either. The only sound the astronauts hear is what goes from the engine, through the hull, into the cabin. Apparently control thruster firings sound like 'pings' or 'hisses' this way.
This is a slight guess but I assume it has something to do with rain bring more ozone to your area or elevation.  Ozone is very good at getting rid of smells.  This is why we have ozone generators that are often use in car and appartments that had smokers as a previous owner.  Snow probaly doesn't bring the ozone to a lower area. This is partially a guess, if it is wrong let me now and it'll go away.
Surface area to volume ratio. You lose heat through exposed surfaces by conduction/radiation/convection. When you huddle up as a single person you have less exposed area than if you are physically spread out (i.e. arms extended). If you have two people you are better off huddling in a single ball for the same reason because you'll cut down on your total surface area.The heat you generate is proportional to the volume (or mass) of your body. Since that's the same in both cases (two people together = two people apart) the set of people with less surface area will be warmer. Also a sphere is the 3D shape that has smallest surface area to volume ratio.Bonus reading on SA/V ratios influence on biology:* [Allen's rule](_URL_0_) - Longer limbs to keep cooler* [Bergmann's rule](_URL_1_) - Larger bodies to keep warmerEdit for clarity
Sleep Apnea doesn't cause heart burn and heartburn doesn't cause sleep apnea.  But it is very common for both disorders to occur in the same person.  Sleep apnea and heartburn are both found in over weight older people.  Prolong consistent heartburn can cause sleep aspiration, which is a bit of stomach fluid aggravating your throat and causing the sensation of not being able to breath.  I can see how someone might confuse that with sleep apnea.
Probably, in a sense. Insects can definitely tell up from down. Flies, for instance, have an instinct to fly or crawl upward away from gravity (this is known as negative geotaxis). This being the case, they can certainly tell the difference between hanging "upside-down" underneath an object and standing "right-side-up" on its upper surface.However, unlike for humans, "upside down" is a completely natural way for bugs to stand. So I highly doubt that insects interpret being upside down as being abnormal or opposite, the way you might.
Short answer, pretty much. The lower the air pressure, the harder it is for sound waves to propagate as there are fewer air particles to bounce into each other, so sounds will be quieter. There is a well known experiment that I remember being demonstrated to me when I was at school where an alarm clock is placed in a bell chamber, and the air is pumped out. The sound of the ringing slowly gets quieter as the pressure decreases, until you can't hear it at all in a near-vacuum. As for the ratios, I'm not exactly sure, I'm afraid.Hope this helps!
No our brains cannot overload in that sense.There isn't a limited amount of "space" in the brain as with computers and the like, rather our brain forges new neuronal connections between and within the areas where memories are stored, such as the hippocampus and neocortex. These connections are made with each new memory that is formed and are strengthened each time you retrieve it. So in that sense, the brain has an unlimited capacity for storage.
The double slit experiment with light doesn’t need to be done in vacuum, but with electrons it does.
The process is called [hematopoesis](_URL_0_).  There are two main steps: first, hematopoetic stem cells (HSC) proliferate, and second, the HSC differentiate into red blood cells, white blood cells, and many other components of blood.The red blood cell production rate is the rate at which HSC are turned into RBCs.  What is interesting here is that the tissue in your body controls how fast this takes place.  If your body senses that it is low on oxygen, it sends signals into the bloodstream that increase the rate of HSC-to-RBC maturation.  Specifically, the kidneys sense this change and secrete [erythropoietin](_URL_1_).This is one reason why many athletes train at high altitude - it tricks your body into thinking you need more RBCs!  Also, erythropoietin, or EPO, is a banned performance enhancing drug in most sports.
The parts of our DNA we're most familiar thinking about are the genes--the stretches of sequences that can be transcribed into RNA and (usually) then translated into protein molecules that make up our cells--however there are also important structural elements encoded in our DNA molecules such as [centromeres](_URL_2_) and telomeres. Telomeres are sometimes described by analogy to the cap at the end of a shoelace that keeps it from unravelling. Essentially, every time our cells divide they must duplicate their DNA, and because our DNA molecules are linear (which isn't universal--many bacteria, for example, have circular DNA) our cells must deal with the ends, where the replication machinery often falls of a little early. Thus, many genomes include a telomere cap of repetitive sequences that don't encode any genes as a buffer at the end of chromosomes. The length of that cap, then, determines how many times the cell can divide before it starts loosing important genetic information. This is why people usually think of the telomere as an important part of aging--the shorter the telomere, the fewer times, in principle, that cell can replicate.Having shorter telomeres has been [linked to disease](_URL_0_), however, it's unclear if this is really cause and effect. It could be, for example, that [cells that have been under less stress have longer telomeres](_URL_1_) (because they've divided and repaired their DNA fewer times). If telomere length is more of a readout of stress, it's no surprise it's correlated to disease. We also have specialized enzymes called telomerase that add additional repetitive sequences to the end of chromosomes to keep telomoeres from getting too short. Researchers were excited to find something that could possibly turn back the cellular clock, but having too much telomerase is bad as well. If a cancer cell, for example, begins rapidly dividing it will quickly run out of telomere protection, but a mutation that increases telomerase activity can make cancer cells able to divide many further times.
As this post is 5 hours in with only a few votes, I just wanted to comment and say that while I am note a paleontologist or ecologist (and thus not especially qualified to answer), I suspect this question is extremely hard to address. We don't even know how many species there are on the planet today ([you'd probably be within an order of magnitude if you guess like 30 million](_URL_0_)).One could likely make arguments about specific taxonomic groups, but all of life on Earth would be very difficult.
[Understanding Why Electric Car Fires Pose a Unique Hazard](_URL_0_)Thus Tesla actually designed two "first responder cut loops" into their cars--one in the front trunk, one in the back--and each year releases Emergency Response Guides for first responders instructing them on how to fight a Tesla fire.Cutting either of the loops "shuts down the high voltage system outside of the high voltage battery and disables the SRS and airbag components," reducing the risk of explosion.They also have to show firefighters where not to cut during rescue/firefighting efforts. Additionally, information is included in Tesla's guide warning of the toxic vapors released by a burning battery.It should be noted that the battery packs in these cars are made up of thousands of smaller batteries.  Not just one or 2 huge ass LI-Ion cells.
At what temperature do you intend to pull off this explosion in your thought experiment?This is pure speculation, but my thought is that if the temperature is high enough, the atoms might be jiggling around so much that it would introduce enough randomness that the shattering will not be perfectly symmetrical.However, I'm not sure what a ball of glass with no imperfections would be. Glass is an amorphous solid made of networks of silicon dioxide. If this SiO2 were perfectly crystalline, it would be like a perfect quartz crystal. And even then, you would need to cool this down to 0 K for it all the atoms to be perfectly aligned and such.Now, the explosion is presumably set off by some exothermic reaction, so it will generate heat, which will be absorbed by the atoms closest to the explosion front. I think this would introduce some randomness into the lattice. So at random points a weak spot will develop and allow a crack to propagate outwards.
Do you mean in terms of tackling the problem (adaptation/mitigation/policy/social science), or in terms of climatology research/modeling?
Short answer, yes. Providing you maintain the correct balance of nutrients in the foods you eat and properly supplement any essential nutrients don't 'fit' into your diet plan, you can, in theory, live off the same diet daily. Longer answer, yes, but it's not a recommended strategy. If you simply want to reduce the stress of deciding day to day what to eat, a meeting with a dietitian (not a nutritionist, as that term is not protected, and just about anyone can tote that they're a nutritionist - a dietitian must undergo licensing and is person trusted to give medical/nutritional advice by other medical professionals) could help you sort out a limited menu/diet plan that would meet all your basic nutritional requirements. This could be something such as a monthly menu, weekly, and (although I've never heard of such a plan, but it is possible with proper supplementation) a daily meal plan.Many populations of the world live on minimally varied diets, not as a choice, but generally due to socioeconomic standards. Now the health of these populations are sometimes severely deficient in some nutrients,  but this is generally due to a lack of access to particular foods or the ability to supplement. As 'insanopointless' has already posted, a main issue with eating the same food day after day is boredom. There is also evidence that eating new and varied foods can help increase and regulate levels of important neurotransmitters such as dopamine and serotonin that have important roles in daily activities and mental health. So you may think you are reaping the benefits of lower stress in not having to 'decide' your daily menu, but you may in fact may have issues with increased stress, emotional instability, and lowered mood due to improper regulation of these neurotransmitters.A bit of an aside, there is currently a belief in the dieting community that decreasing the variety in your diet can have benefits in decreasing your daily caloric intake, and the believed mechanism is that as you continue to eat the same food over and over, your desire for it decreases and you tend to eat less. Now I'm not sure if that is your intended goal with wanting to limit you dietary options, but thought I would include it as part of my comment.Sorry for perhaps the long-winded response, and if you have any further questions I will try to provide any further information that I can. I do want to reiterate that before starting such a radical diet plan that it is best to seek professional advice with a medical professional that can give you advice that is specific to your situation. They will be able to better provide you with an individualized approach, and can take into account any special circumstances (chronic disease, athletic committments, etc) that may change the individual needs of your diet. They can also assist in helping to monitor changes in your health, so that if signs and/or symptoms of nutritional deficiency occur, they can work with you to modify your plan.Best of luck, and hope that I was of some help.My background is senior medical student and as part of my medical school training I did an elective rotation in nutritional science with the doctor that came up with 'glycemic index' and does a significant amount of research into whole wheat bread, and controlling cholesterol with lifestyle modification. This is my first post to Reddit so if any further information is required, or if you want more details let me know. I'm not sure if I'm suppose to include a source, but since a quick google search yielded a somewhat credible news source quoting an expert I'll link it here. Note that I wrote the above prior to seeking out a source, and am simply linking the top result in the google search as I thought it was an appropriate answer.Source _URL_4_Edit - Due to the criticism of my above source being secondary, I've linked the primary review article below as well as a few others that I thought were interesting reads. Like I said, first time poster so just let me know if there's anything else you want to know. 1. Source (may need a University Library Access): _URL_0_2. Study showing dietary diversity and its relationship to nutrients: _URL_2_3. Study comparing the eating habits of different European populations: _URL_3_4. Study linking food group restriction leading to increase in overall mortality: _URL_1_
>  A force that's perpendicular to the movement of a point mass alters the direction of it's velocity, yes, but how does the direction of the velocity vector ever start pointing slightly, or even straight to the center of the nebula, making the radius between them diminish?Think about throwing a ball.  It flies forward, and gravity acts downward on it, pulling it closer to the ground until it finally hits the ground.  As it flies, gravity diminishes the "radius" of its flight.Gravity doesn't often "balance out" against velocity to create nice circular (or elliptical) motion as you're assuming.  In the special cases where it does, you get a stable orbit.  But if the object isn't moving fast enough, the gravity overpowers the velocity and the object spirals inwards.  If the object is moving too fast, the velocity overpowers the gravity, the object flies off into space.
Yeah, this is fundamentally similar to the way that earthquake epicenters are located, although you need 4 non-coplanar points instead of 3 nonlinear points.  If you had a continuous noise, you could look for identical patterns of frequency between the microphones, but if it was a constant pattern you wouldn't be able to nail it down.
The voyager probes are roughly [100 and 120](_URL_0_) AUs from the Sun right now after 34 years of travel and they are slowing down due to the Sun's gravity and pressure from interstellar gas.  The Oort cloud is thought to be 50,000 AUs from the sun.  Both probes will have run out of power long before they reach it. They will run out of power somewhere in the 2025-2030 time frame.  In any case when they reach the Oort clod it is very unlikely that they will collide with anything large for quite some time as space is very empty.
Depends on the cell type. But the common theme is there are 3 sub-units (alpha, beta, and gamma) that are bound. Some molecule affects the receptor or unit and causes the beta and gamma subunit to fly off and cause some other cascade (maybe for transcription factors etc) while the alpha subunit is now free to recruit some set of factors and have its own cascade mediated by a second messenger. Again, the cascades in question depend on cell type and organism. Common second level cascades are calcium and/or cAMP.
You're talking about the gravitational binding energy of the Earth, the amount of energy you'd need to blow it apart so thoroughly that it doesn't just fall back together under gravity. That number is 2.24 · 10^32 joules, or more than 50 million billion Megatonnes. That's a week of the sun's energy output. Good luck making a bomb that big.
No. Light follows the inverse square law because it spreads out, covering more area. Area, as you know from geometry, is all about square numbers.Light within an optic fibre is constrained within that fibre, so doesn't spread out. It is only affected by [edit here] other losses within the fibre and at joins[end edit] Communications fibres are built so that all of these losses are very small - if the ocean was as clear as an optic fibre, we'd be able to see the bottom of the deepest ocean trenches from the surface!Edit: Seems I knew less about it than I thought I did. Silly me.
We have the laws of thermodynamics. Energy is conserved and entropy increases. Once energy spreads out throughout the universe, entropy will be at a maximum, and nothing interesting will happen. This is called the heat death of the universe. There are other ways it might end, but we're less sure about those. If the universe lasts long enough without being torn apart or crushed into a singularity or something, it will experience heat death.
It "comes" from energy since matter and energy is the same thing.    If we observe a random photon (light particle) in the universe, it will carry a small amount of energy.    If this photon should bump into another photon there is a chance that [pair production](_URL_1_) occurs.    This means that the released energy from the crash is converted into a particle and a mirror particle (matter and anti-matter).   The type of particle and anti-particle created is dependant on how much energy were in the photons.    So: higher energy = heavier particles.    However, when the particle and its anti-particle react, they will [destroy](_URL_0_) eachother and be converted back into photons.    This constant cycle between energy and matter happens all the time.   Looking at this theoretically you may already see a problem: if matter and anti-matter constantly cancel eachother out, then how can matter be stable? and where is all the anti-matter?    The current theory is that pair-production will in very rare cases produce 2 matter particle (and 0 anti-matter)    - however, we don't know for sure.
Easier to visualize, but effectively the same question: Replace the rod with a tube of air. Imagine you push/pull on one end of this tube with a piston. Does the air on the other end react immediately?Most people wouldn't say yes to the question because everyone is familiar with the speed of sound. We can actually experience how "slow" this speed is (whenever you're seeing something far away but hear a lag in the sound, like baseball bats hitting the ball, or lightning).It's the same case as with a solid rod. The speed of sound in the solid rod must travel slower than the speed of light. We aren't used to thinking of solids as "lagging" in this sense because the speed of sound in a solid is usually so much faster than the speed of sound in air.
Your throat is normally closed. The act of swallowing is using your throat to push something down it. If there is nothing left in your mouth to swallow (even saliva), then you can't "push" anything through. It just remains closed. The throat muscles may *contract*, but you won't get any swallowing sensation.If you have something to swallow, like liquid, or even air, then you can swallow pretty constantly for as far as I know no limit. So it's not "*swallowing repeatedly*" that is the problem, it's not having anything *to* swallow.As an analogy, let's say you have an otter pop with a bit of ice left at the bottom. You can use your fingers to "push" the ice up the otter pop. But once there is no ice left, the otter pop is just two pieces of plastic stuck together. Even if you push your fingers over it in the exact same way you did before, nothing much will change with the plastic. That's sort of what happens when you try to swallow with nothing left in your mouth.In short - the swallowing sensation is the result of 'pushing' something through your throat. If there is nothing to push, then obviously we don't get that sensation.
It can be absorbed, bounce off or be absorbed and a new photon emitted.If it is absorbed it adds energy to the thing absorbing it (the object heats up a bit).  The law of Conservation of Energy says that all energy in a closed system can be accounted for.  It can not be destroyed.  It can change forms but in the end it is all accounted for.This will bake your noodle though:From the perspective of the photon (if it had one which it doesn't) they are absorbed as soon as they are emitted.  Even if they cross the universe.
The Pauli exclusion principle does provide an outward pressure that can balance the gravitational force, but it's not an infinite pressure, and gravity can overcome it. Any white dwarf is also made up of protons, which is necessary in order to balance out the electric charge of the electrons. Once a white dwarf is massive enough, the gravitational force is enough to push the electrons and protons together to form neutrons. The Pauli exclusion principle also applies to neutrons, though because they're more massive they can be pushed tighter together than electrons, resulting in a neutron star. If the neutron star is massive enough, gravity will also overcome the Pauli exclusion pressure for neutrons, forming either a quark star (which is still hypothetical) or causing a collapse to a black hole. All these rules of quantum physics go out the window once you've collapsed an object inside its Schwarzschild radius, or its event horizon, because it's impossible for a physical particle inside an event horizon to go anywhere but straight to the center.
you could tell, but it would be more complicated than taking a standard paternity test. identical twins can have different numbers of copies of the same genes, among other differences. [Scientific American](_URL_0_)  article explains.
There are two major obstacles to creating human speech (I assume you mean in an AI sense, such as a talking computer). The first is that we have only scratched the surface in terms of the empirical properties of natural language. We've come a long ways in the past century, but human language manifests itself in more than 6500 ways (roughly the number of extant languages in the world). We have solid generalizations for only a fraction of these languages, and only in some of the domains which coneventionally comprise linguistic research: phonetics (sounds), morphology (word formation), syntax (sentence formation), semantics (meaning), and pragmatics (how the context affects meaning). Even if we did have a robust and complete set of generalizations that capture human language cross-linguistically, this leads to the second major obstacle: theoretically modeling it. Here, too, we've made strides, but only for a fraction of it. There are two 'sub-problems': one is that we still lack a theory that can integrate all of these domains together into some kind of whole, and the second is that linguists spend a lot of there time disagreeing about points of theory. We can imitate speech fairly effectively (i.e. Siri), but this is not nearly anything like modeling natural language. The other consideration is the interactional nature of language, and how we use language to communicate things beyond the language itself. This is another pandora's box. And then how much time is it going to take to implement this computationally? I can't even guess. So, I hate to be a downer about it, but a talking computer is a loooong way off from a linguistics perspective.
At relativistic speeds the addition of velocities works differently. _URL_0_Also, speeds are always measured relative to something. So you could say, from the point of earth the earth is not moving and the rest of the universe is moving by incredibly fast.
We can do you one better than that and compute a general formula for 1 + r + ... + r^(n-1) for any r and n. Then plugging in r=2 and n=whatever big number you want, you have your formula, but you'll also have it for 1 + 3 + 9 + 27 or 1 + π + π^2 or whatever you want.To figure it out, let's fix n and r and letS = 1 + r + r^2 + ... + r^(n-1)Multiplying both sides of this equation by r, we haverS = r + r^2 + r^3 + ... + r^nNow, subtract S from both sides to getrS - S = r + r^2 + r^3 + ... + r^n - (1 + r + r^2 + ... + r^(n-1))A little bit of reflection will convince you that a whole bunch of stuff cancels out on the right hand side there, and this equation can be simplified torS - S = r^n - 1Factoring S out of the left hand side, we getS(r - 1) = r^(n) - 1Finally, dividing by r-1 gives us the general formula:S = (r^n - 1) / (r - 1)In your case, you were interested in the specific case where r=2, so you'd getS = (2^(n) - 1) / (2 - 1) = 2^n - 1
Yes. e^(0)=1, so n=0 is such an integer. But aside from this, there does not exist such an integer. This can be seen using the [Lindemann-Weierstrass Theorem](_URL_0_). A consequence of this theorem is that if r is any nonzero algebraic number (ie: a root to a polynomial with rational coefficients), then e^(r) is transcendental (ie: not algebraic). In other words: e^(Algebraic)=Transcendental.If n is any nonzero integer, then it is a root to the polynomial p(x)=x-n, which means that e^(n) is transcendental, so it cannot be an integer. Note that the n=1 case shows that e itself is transcendental. We can also prove that pi is transcendental like this. If pi were algebraic, then i\*pi would also be algebraic, and then this theorem would say that e^(ipi) is transcendental. But e^(ipi)=-1, which is not transcendental, so it must be the case that i\*pi, and therefore pi, is transcendental.
I think it might be [this bottle of hydrogen gas on the left](_URL_0_).
You mean: if you lost all your own blood and had all of it replaced by other people's blood. The answer is no, because immune cells do not only live in the blood. They are also in your spleen, in your bone marrow and in lymph nodes. Some of the cells that make antibodies and that remember previous infections or vaccinations will thus stay in your body, even if all blood was exchanged.
You are talking about two classes of materials which are relatively different in terms of cracking and brittleness. Glass, which I believe is an amorphous ceramic is made up of SiO_2 molecules bonded together covalently, (strong bond). Metals (steel) is composed of metal atoms bonded together metallically (different, relatively weak bond). The difference is that in glass you have no long range order, the atoms are bonded randomly and have no higher structure beyond the nearest bonding atom. But in metals the atoms are arranged in a long range order that is periodic (look up atomic stacking, FCC, BCC, HCP). And these atom stacking make up the grain structure of a metal which is of the order of 1 to 100s micrometers (depending on processing and I'll explain later), and these grains make up the shape of an object. Now getting to cracking. When you create a crack in glass you need to break atomic bonds between the molecules and form feee surfaces. This costs the system energy (proportional to the bonds broken, I.e. The length of the crack). However there is a point where growing the crack further decreases the energy of the system and it is favourable for the crack to grow in size (stability) and so once you form a crack of this size the material will crack completely. That's why with some glasses you can scratch a circle and punch it out, it's an application of this crack instability criterion. Look up how some people cut/break glass, it's impressive.In metals however, brittleness is related to how much energy you need to put to grow a crack that either breaks a grain up in two, or goes around between two grains. It's a complicated process but in essence when you put stress in a metal you can have two things happen, either you will grow the existing cracks in size, or put dislocations in the metal lattice, which is a way of accommodating this stress. If the metal lattice is too stressed already( from all the existing dislocations, or in case of steel and cast iron, from too much Carbon atoms) it will be much easier to grow a crack that to deform by dislocation, and so you get cracking, which again depends on the stability criterion. The opposite of brittleness is toughness ( which is a measure of how much a material resists crack growth) and in metals you achieve it by making smaller grain size, so that a crack has to go around the grains and is deflected (energy consuming) as opposed to having a nice large grain along which is can travel easily. So that's how brittleness differs in these materials. I apologise for the length of this essay. If there is anything unclear let me know, it's been a while.
Another cut shouldn't affect healing time. However, if a person suffers severe damage over a large portion of the body, healing time does increase. Take for instance a burn. A small burn on your hand will heal in a week or so, but a burn over 50% of your body will take months to years to heal fully. Your system has limited resources for things like tissue repair and extensive damage will take longer to be repaired.
Jelly fish have a nerve net. Bundles of nerves in nodes around the organism that pretty much just react to things. It's not sophisticated, but when your life is to float around and eat things. It's enough. It works something like this. Thing hurts me: Nerve net instructs muscles to move away.  Tendrils find food: Nerve net instructs muscles to move toward the food. It's mostly just reacting. There is some processing, but for the most part it's reacting when you get down to organisms this simple.
We don't completely know.  Yet.  As unwarranted_happines mentioned, we do know that some of it comes from the mother.  The birth canal is certainly not sterile, and if the baby is born via a vaginal birth, that can be the "start" of colonization.  Breast milk is also not sterile, so if the baby is breast fed, that is a second easy route of colonization.  Beyond that, most people currently caulk it up to "environmental exposure".  But there are a few things that still don't quite fit that.  We do know that there are certain types of bacteria that are only found in the lower sections of the intestinal tract.  They aren't in the vagina or breast milk.  So how do we get colonized with those?  Additionally, we're finding the uterus isn't quite as sterile as we had previously thought, so perhaps some colonization happens even prior to birth?We also know that colonization happens through a series of successions.  A brand spanking new newborn has a different gut bacteria profile (a different microbiota) than that of even a one month old, which is different from a six month old, and so forth.  We know that bacteria get introduced over time, and that different types dominate at different points in time.  Along with all this, we also know that your gut community is more likely to be similar to that of your immediate family.  We know that obviously genetics likely plays a part, as does the fact that you likely get a large portion of your inoculation from your family, in addition to eating similar foods as they do.  For me, this leads to questions about obesity.  We know that obese people have different microbial communities than thin people.  Can this be passed on?  Does something trigger one person to get obese, and can they then inoculate future children to become that way too?  Which comes first, the excess calories or the different gut microbiota (or is it a succession)?   I'll stop know, as I fear I'm straying too far from your question.  But one last answer, we do not carry the genetic information to create them in our genes.  But we may carry the genetic information that tells our body which ones are "good" and which ones aren't.
While plants do get some nutrients from the soil (most notably nitrogen), their energy-rich nutrition comes from repurposed CO2 in the atmosphere.  With the energy they harvest from sunlight, they turn it into sugars which can be transported around and then burned to create energy for growth.  I doubt they could live in just water forever because plants still need nitrogen (a vital component in creating proteins), as well as sulfur and phosphorus which they cannot extract from the air.  But obviously that hasn't been a problem yet.  And as you guessed, plants do store up nutrients inside of them, which is why they are nutritious to eat.  Therefore, I suspect that they could live like that for a little while without an issue, but not forever.
The magnetic monopoles in spin ice can be thought of sort of like magnetic strings embedded in the crystal. At either end of the string, you have something that looks like a magnetic monopole.Dirac's idea of a magnetic monopole is basically a semi-infinite solenoid, with the one end looking like a magnetic pole, but the string is undetectable due to the quantization of charge.
Yes, gravity is the main force contributing to the tides. But not in a way that most people think. The force of gravity of the moon is not enough to lift the water up against the gravity of the earth. However if you look at the top and bottom of the earth the gravity of the moon doesn't work against the gravity of the earth but makes it stronger. This pushes the water down, but is has nowhere to go, so it accumulates in de middle. That is why we have two tides a day and why tides can not form in lakes/pools. There is a very good video about this that explains this in more detail:  _URL_0_
They only provided a modest amount of protection. The radiation minimization plan for Apollo had two components. One was to pick trajectories that traveled at their fastest speeds through the worst parts of the Van Allen belts, minimizing the amount of time spent in the highest radiation environments and minimizing overall radiation exposure. They also avoided some of the worst parts of the inner Van Allen belt.The CM and LM spacecraft were also designed to shield against radiation as much as possible. While neither the CM nor LM had thick skins, thick skins aren't at all necessary to dramatically reduce radiation exposure. The use of thin layers of aluminum metal with polymer sandwiched between is about the best you can do, with 1960s technology, for radiation shielding and also serves as thermal insulation. A lot of the radiation in the Van Allen belts comes from charged particles (electrons, protons, nuclei, etc.) which don't penetrate fairly deeply and can be easily block with even something as thin as a sheet or two of aluminum foil. The materials used in the spacecraft skins specifically avoided heavier elements like Lead. Heavier elements might help blocking x-rays they would also create more x-rays from bremsstrahlung radiation when hit by high energy electrons, so on balance they wouldn't help.The astronauts generally crammed the bulk of their radiation exposure into two short sections before and after lunar orbit (and landing), usually separated by several days, which would minimize the physiological impact. In regards to solar radiation, Apollo astronauts mostly got lucky. Solar flare events that could have subjected astronauts outside the Earth's magnetosphere with huge doses of radiation are somewhat rare, and none happened during the Apollo landings.There's some research indicating that the radiation the Apollo astronauts experienced may have caused a higher rate of cardiovascular disease but because of the small sample size the results are still in question.
A bacterial population usually aquires resistance traits under selective pressure, as the resistance provides a fitness gain.Expressing the resistance genes also comes at a cost, in this case a metabolic burden compared to the wild type. If the selective pressure is no longer present, the amount of resistant bacteria will also decrease. (as in: they will be outcompeted by the unburdened, faster growing wild type)One prominent example is Finland, where in the '80s doctors usually prescribed Erythromycin, a macrolide antibiotic. As most patients used this one substance, the selective pressure was high and therefore resistance rates for macrolides skyrocketed.Only in the early '90s the authorities realized their mistake and introduced an antibiotics management system, where now several antibiotics were used to treat different patients, instead of a single one for everybody. Therefore the selective pressure for macrolidics was reduced, leading to a loss in the responsible resistance genes in many germs, making Erythromicin more effective again. Source:_URL_0_
We are symmetrical animals. A lot of early embryonic development works by mirroring left/right development of organs and limbs. Some of our organs are developing from embryonic tissue that is symmetrical and will therefore form equally left and right versions of the organ. Other organs develop later: the heart is basically just a bunch of very specialized muscles around a big blood vessel, the liver is a huge gland attached to the digestive tract and so on. We don't have two kidneys to have a back-up but because our evolutionary history has made them develop symmetrically.
Accretion disks can come in all sizes and cross-sectional shapes depending on the black hole and its surrounding environment. Typically they fall into one of three categories: thin disks, thick disks, and donuts. A single black hole can have disks from each category existing at different distances from the event horizon. A summary of the various types and where to find them can be found in [this](_URL_0_) chart.
There can be isotopes of each element, but the building blocks -- electrons, protons, neutrons -- are all indistinguishable from any other.
The short answer about heat acclimatization is yes, you would adapt differently in severe heat. In short, if we consider you do the same type of training in both conditions, and we assume recovery is made, the heat will add a considerable stressor that will, when adapted to (most sources say 14 days, but some up to 30), decrease heart rate, metabolic rate, blood lactate accumulation, electrolyte concentration in sweat, but also increase sweat rate and decrease CHO/glycogen utilisation at same relative intensities. Refer to [Tim Noakes' Lore of Running](_URL_0_), a great read and good reference.To go further, and if I get the essence of your question correctly, it's about the existence and nature of a threshold of heat stress limiting adaptations. So for the argument's sake, let's not talk about absolute temperatures: because we all are made and react differently to heat stress, we'd rather think of a range of scenarios considered hot for running, until it becomes slightly outside of what is "normally" possible one particular individual and look at what happens physiologically. As homeotherms, we humans have a fairly narrow functional range of core temperatures, but things are fine as long as we can balance that or terminate exercise before any major disturbances. However, the main way we have to shed internal temperature is by convection from skin, which is exceeded at about 33°. Then it's only sweating that cools you down, but as you know, not all the sweat evaporates and the figures decrease as humidity goes up. So first off, temperature is not the biggest problem of heat stress, it's how humid it is. And wind is a huge help, even on a hot day, to increase convective heat loss. The main thing with heat stress is that you try to shed the heat from exercise by increasing your blood flow to the skin. So yes, the cardio-circulatory component is very important, and the adaptations take a little time if you start from scratch but should be there if you are a runner. There are other important factors influencing your capacity to exercise in the heat, mainly to limit heat production at the same relative intensity, so by decreasing your cost of running: you can do by upping your VO2, lose weight and improve your form. However, there will always be a threshold. Beyond that, it is difficult to pinpoint what will go wrong at what temperature. So what is the upper threshold of relative intensity to run 4 miles?That is a problem of heat balance (production vs. loss), not an energetic one (you should not be running out of gas). Let's make some crappy projections: * let's take a normal bloke: 75 kg (165 lbs).* the metabolic cost of running is 3,7 J/kg/m (+/- 0,3): in order to run 6,44 km (4 mi) it will cost you about 3,7x75x6440 = 1787 kJ (independent of speed, that's work).* then we need a rate, so if you're running, you're at least at 8kmh (let's be conservative) covering 6,44 km in 48:20 and produce heat at a rate of about 2224 kJ/h. Jump to 10 kmh (38:40 for 6.44 km) and your metabolic rate goes up to 2775 kJ/h. At 12 kmh (32:12), the figures go to 3330 kJ/h (925 W).* sweat removes somewhere between 1000 to 2500 kJ of heat per liter of sweat depending on conditions, but sweat rates are topping at 1,5 to 2 L per hour (some higher values reported, but on very high level athletes, and limited numbers). So if we keep it "normal", let's say you can get away with 2500 to 3250 kJ/h.* overall, you can expect some problems if you try to run close to 12 kmh. If it's humid and sweat is not evaporating as well on top of that, you could [exceed your thermoregulation abilities during the run and will overheat](_URL_1_), with a range of more or less serious consequences. Under this, it's a matter of recovery and overuse injury management from the daily run.
There are two ways to consider your question.  1)loss of blood volume.  2)loss of red blood cells per volume:  1)would result in cardiovascular collapse, if rapid, the decreased pressures in arteries would not be capable of pushing/perfusing blood (with RBCs) to organs (coronary arteries perfusing the heart, and all the arteries that supply the brain).  If slow, your body can respond by releasing chemicals that will constrict your vessels (same volume of blood in smaller space), thereby increasing the pressures, ensuring perfusion of organs.  2)with RBC loss you may lose blood but still maintain pressure support.  Your organs will be perfused, however oxygen delivery will be decreased.  The main mechanism to achieve oxygen demand is to make the heart beat faster.  There are other ways, such as telling your body to create more RBCs, or to shift the oxygenation curve to release more oxygen to organs, via ph and chemical 2,3-DPG.  To answer your question, it would depend on the situation.  If you're talking about RBCs (hemoglobin), I've seen people as low as 5.0 surviving, walking around with symptoms of fatigue and fast heart rate.  But that is SLOW blood loss.  Anything fast is detrimental.  IF the normal hemoglobin for a female is say 12-14, a hemoglobin of 5 would be 58-64% blood loss, which I think is what your friend is talking about.  in scenario 1), the situation is usually something like dehydration or something that would cause you to 3rd space all of your fluid, or a combination of 1) and 2) in the case of an injury to a major artery.  Scenario 2) would be something such as menstrual bleeding, bleeding stomach ulcers, or bleeding colon ulcers.
Pretty huge. I believe that really only oceans, gulfs, and seas can have appreciable tides. The Great Lakes technically have tides but they're not big enough to force you to move your clothes if you're at the beach.
240 C (464 F).  Match heads are made from red phosphorus and potassium chlorate. When struck, they form a mixture that explodes/ignites.  The red phosphorus will ignite at 260 on its own.  Some other match heads use white phosphorus, which will ignite at room temperature, but they are covered with some material to prevent exposure to water or oxygen.  In that case, the ignition temperature would depend greatly on the specific material used to cover the matchhead
Yes. The Hawking temperature would be some 2 hundredths of a Kelvin, while the CMB is hotter at 2.7 K. The black hole gets more power in that it radiates out.
> Did the electrons lose mass...?No. > Did the electrons lose some "kinetic energy"?Yes. > (Aren't they always moving at lightspeed though?)Electrons never move at c, because they have mass. > Did the electrons lose temperature? (Do electrons even have temperature?)Two lone electrons colliding in space don't have a meaningful temperature. If you have a gas of many electrons (approximately) at thermal equilibrium, you can talk about a temperature.
The fastest it would get is the escape velocity from the surface, which is about 11 km/s.
It depends on what element you're measuring. If we're talking about carbon-14, it's pretty simple. 14C is formed from nitrogen present in the atmosphere because of cosmic radiation. Now cosmic radiation is pretty constant, so the ratio of 14C to 12C remains pretty fixed in the atmosphere. As long is something is 'alive' it exchanges with the atmosphere, like plants are taking up CO2, animals burn sugar, and because if this, their internal concentration remains constant. But once the organism dies, there's no exchange anymore, so the concentration drops. All you need to do now is look at the difference between a tree right now and a wooden object you want to date. (You can check if the 14C concentration actually remains constant by measuring the trapped CO2 in the ice on Antarctica).If we're talking about rocks, say, the 40K method, there's a similar story. A large part (about half) of the internal heat of Earth comes from radioactive decay. Because if this you can make an estimation of what content of unstable isotopes will be in a certain type of rock, and once it is no longer in contact with the molten magma, the isotopes are no longer formed so the concentration starts dropping. It's also possible that it decays to something that doesn't naturally occur inside your object. 40K decays to 40Ar, and since Argon is a noble gas, you shouldn't normally find it inside a rock so you know that if you do find it, it comes from radioactive decay.A part of it also uses calibration. If say, we find something inside a pyramid, we know how old it should be since we know the age of the pyramid without radiometric dating, so we can use that to check whether our method works.
Psychologist here.I feel this paper is relevant: _URL_1_My understanding is that stimuli that elicit a fear response act as circuit breakers. They are automatic responses to behaviorally highly relevant stimuli and they cut through the cortical, conscious control of your attention because you need to react NOW to the spider (or whatever) before it bites you.Also: Automatic responses are generally quicker than deliberate responses. Maybe you also want to look into [Dual process theory](_URL_0_).
_URL_0_See this article, and go down to the 'physical and emotional effects' heading.It isn't blowing on your thumb that activates the vagus nerve, it is the increased intrathoracic pressure caused by attempting to exhale through a blocked airway. See also Valsalva maneuver: _URL_1_Source: i am a paramedic student
Astronomers take such images all the time.[Here](_URL_0_sun.html) are images of the sun at wavelengths from X-ray to radio.You can see images of other astronomical objects across many wavelengths [here](_URL_0_).
Here's the thing with interpretations of quantum mechanics: they're just that, interpretations. They're people trying to come up with analogies for what's happening "behind the scenes". None of them contradict each other, or any established experimental results. So in that sense, they're *all* "right".You'll find that many physicists endorse the "shut up and calculate" interpretation, because the equations correctly predict the outcomes of experiments, and everything else is more philosophy than science.
It's the oblique angle of the blade relative to your skin. If you were to try and shave with the blade held perpendicular to your skin, you'd cut yourself.
From Wikipedia: > Urine is an aqueous solution of greater than 95% water, with the remaining constituents, in order of decreasing concentration urea 9.3 g/L, chloride 1.87 g/L, sodium 1.17 g/L, potassium 0.750 g/L, creatinine 0.670 g/L and other dissolved ions, inorganic and organic compounds. > Subsequent to elimination from the body, urine can acquire strong odors due to bacterial action, and in particular the release of ammonia from the breakdown of urea.Also from an MSDS (_URL_0_) about 12.5% Sodium Hypochlorite bleach (seems like a common concentration) > Common household bleach solution is 12.5 % by weight sodium hypochlorite. That translates to about 12% by weight available chlorine content.Knowing that it seems clear that the 9.3 g/L of urea is going to be our limiting reagent.So: The density of bleach is 1.2 g/mL and the density of urine is essentially 1 since it is 95%+ water.If we mix 1 mL of the two that means we are mixing 0.144 g of Chlorine with 0.0093 g of urea. Let's just assume that 100% of the Urea forms ammonia:The molecular wt. of urea is ~60.1 with 28 of that being due to Nitrogen. So to make it easy we will say %50 of the urea is nitrogen. And since two ammonia can form from 1 urea, the math simplified amazingly, we basically can make 0.0093 g. of ammonia.So, since the reaction of ammonia and chlorine is given as:2NH3 + Cl2 → 2NH2Cl (thanks _URL_1_), you can make 0.0093 g. of chloramine gas per mL of urine and bleach you mix.The human bladder can hold roughly 500 mL of urine, so if you mixed a full bladder with an amount of bleach over ~150 mL. You'd make about 4.65 g of chloramine gas. Which in any space but a very small shower would be below toxicity.Now, the Chlorine gas: I can't find a good paper at the moment describing the amount of Cl2 gas emitted for a given mixture. And since it is a factor of the drop in pH caused by the ammonia as well as other reactions in the solution I don't feel like I can speculate too much.
WHO data for nutritional needs of infants: _URL_2_ as well as the food requirements that they have beginning at 6 months old: _URL_0_ with breastfeeding continuing intermittently until the infant is 2 years old.New data suggests that 6 months is already waiting too long: _URL_1_According to that article, one of the first signs of nutritional troubles is iron deficiency anaemia "known to be linked to irreversible adverse mental, motor or psychosocial outcomes." (quote from the Guardian article) That's not to mention the lack of growth and development which every other system in the child would face.They'd be small, feeble, most likely mentally challenged, and would likely have a very weak immune system. The chances of them living for more than a decade in such a state is pretty slim.Unfortunately, it's never been done, so there's [just no evidence of the entire gamut of issues they'd have to deal with.](_URL_3_)
No. Crossover events during Meiosis 1 are required to generate tension in the meiotic apparatus.  Without crossover, division will not occur, and crossovers cause mixing of chromosomes from the grandparents.  Each of your chromosomes is a chimera of your two grandparents DNA.
Vaccines are typically given via the intramuscular or subcutaneous routes, not into the blood stream.The route of administration required for a vaccine depends on what the specific vaccine actually is.  There are oral vaccines available for rotavirus, polio (the oral formulation contains live virus, unlike the version we use in the US which cannot be given orally), and typhoid.  These three viruses are all normally transmitted via fecal-oral transmission so it makes sense that the vaccines, which consist of weak strains of the viruses, can be given orally as well.  It is similarly logical that the live influenza vaccine can be given nasally, as this vaccine consists of weakened live influenza virus, and the normal route of transmission of the flu is inhalation of droplets.The vast majority of vaccines cannot be given via these less invasive routes.  There are some injectable vaccines that are live viruses as well (MMR, varicella).  Some are killed viruses (injected polio vaccine).  Some contain inactivated bacterial toxin (diphtheria, tetanus).  Some contain proteins, polysaccharides, or proteins covalently conjugated to polysaccharides (hep B, injectable flu shot, H. influenza b, pertussis, pneumococcus, meningococcus).The underlying principle for why there are so many vaccines which can't be given orally is because they would be destroyed (broken down into their most basic building blocks) by the normal digestive processes.  Our bodies are very good at breaking down proteins and polysaccharides.  As a side note, this is why we can't give insulin or drugs that are monoclonal antibodies orally - those substances are proteins, and they'll just be broken down into amino acids rather than carrying out their function. Killed virus may simply be degraded before it has the chance to trigger any sort of immune response.I'd be interested in hearing someone who knows more about vaccine development explain why MMR and varicella vaccines cannot be given nasally - all these are live virus vaccines for viruses that can be spread via droplet transmission.  Things that come to mind here include injection being a easier and more reliable way to give a vaccine to small children and potential differences in the virulence of the attenuated viruses that result in the need to give them parenterally instead by their normal routes.
Offhand, it probably would. Actually figuring out would require actual calculations. Things get quite complicated as you go down the periodic table. First there's just the general change in the effective nuclear charge, changing the energies of the valence electrons. Then with astatine, you also have the fact that it has an f-shell unlike the preceding ones, which causes some significant changes (i.e. the lanthanide contraction). On top of that, the effects of special relativity become significant in heavier elements, which also shifts the levels of the electrons and thus the absorption. So while extrapolating here is a good guess, without explicit (and rather complicated) calculations, you can't really find out for sure.Look at copper, silver and gold metal for instance. They have three different colors for three different reasons. Copper gets its red color from having a 3d valence orbital that's relatively small because it's the first set of d-orbitals. (higher orbitals are bigger, but the change in size from the first to the second set of a particular type of orbital is bigger than between subsequent ones) Silver simply doesn't absorb that much in the visible range at all (and is thus metallic-grey), while gold is yellow (silver's UV absorption is shifted down into the blue range) because of relativistic effects.
This article from a few years back (link below) nicely sums up what we currently believe to more-or-less be the mechanism: thalidomide prevents new blood vessels from forming (i.e., one of its major effects is *antiangiogenesis*). Depending on when thalidomide was taken by the mother, this inability to form new blood vessels would either cause spontaneous abortion of the fetus (early in development) or malformation and poor development of forming limbs (later in development). Of course there were a constellation of other issues that occurred with thalidomide, but this antiangiogenic effect is the major reason why limbs were commonly affected. Happy to clarify anything if you have further questions! _URL_0_
When you heat a sugar solution, water evaporates, leading to isomerization and polymerization of the sugars into various high-molecular-weight compounds. Compounds such as difructose anhydride may be created from the monosaccharides after water loss. Fragmentation reactions result in low-molecular-weight compounds that may be volatile and may contribute to flavor.In some cases, glucose or invert sugar is added to prevent crystallization.  It should be noted that "wet caramels" (made by heating sucrose and water instead of sucrose alone) produce their own invert sugar due to thermal reaction, but not necessarily enough to prevent crystallization in traditional recipes.
They are called [shock diamonds](_URL_0_) - they are caused by pressure differences between gases in the exhaust and normal air
The simple answer is that not all land animals share a common ancestor which made a single water to land transition. The water-land transition has been completed at least six times by animals. Arthropods all independently made the transition so insects, crustaceans, milipedes/centipedes and arachnids (ticks, mites, spiders) all transitioned and did so after each of these lineages diverged from the ancestral arthropod.Additionally molluscs (snails and slugs) have made the transition and vertebrates also made their own transition.Perhaps there are some more but those are the ones I know off the top of my head.It's totally possible for animals to make the transition today, things like mudskippers might be on the way to evolving in to a species which is more land based. Plenty of species have made or are transitioning in the other direction. Whales and dolphins are fully aquatic having evolved from land mammals. The Diving bell spider has also evolved from land dwelling spiders. Otters and seals may represent animals on their way to evolving more fully aquatic lifestyles.
In simplest terms, corrosion is the destruction of a material by chemical reaction with another material(s). So the question is fundamentally, why are acids good at reacting with materials. The simple definition of an acid is a compound, which when dissolved in solution, is a proton donor. That is, it is a compound with the chemical formula HA (A could be something simple like Chlorine or something more complex like nitrate) which tends to dissolve into H+ and A-.So if we have some HCl solution, what we really have is beaker of water with H+ and Cl- ions floating around. If we pour this solution onto a chunk of metal, the H+ ions will essentially tear electrons from the surface of the metal. The metal ions (having lost electrons) bind with the chlorine ions or dissolve into solution or perhaps do something else weird. This is what we see as the corrosion, the breaking down of the metal. So it’s the H+ ions that really do it. They are very strongly charged and mobile in solution. Therefore, they are good at pulling electrons from things (i.e. ionizing) that are otherwise fairly stable and content. Not all acids are equally good at this though. What’s called the strength of an acid is a measure of how well an acid breaks down into H+ ions so it tends to be strong acids that we think of as corrosive.
It takes another body in the situation.'Energy in = energy out' applies to the kinetic energy balance needed to get a closed orbit.If an object 'falls in' from infinity it has the kinetic energy to 'fall back out', unless something else intervenes.The velocity gained falling in equals the velocity needed to escape.
There are a couple hypotheses out there, falling in two main camps. The first supports a kin selection model where the grandmother enhances the survival of her grandchildren (and thus 1/4 of her genetic material) by helping helping them rather than continuing to reproduce herself. The second asserts that, given the social structure of humans, menopause prevents competition among related females that could lead to reduced survival. Apparently some whales and dolphins also undergo menopause, and there is a paper looking at the phenomenon in both from an evolutionary perspective. Both hypotheses are are really two sides of the same kin selection coin, and I might consider your "artifact hypothesis" to be consistent with a more non-selectionist paradigm (i.e. menopause is not an adaptation but the result of other constraints on human reproductive physiology and the lack of historical selection on the fecundity of older women).
An important concept is that of [isostatic subsidence](_URL_0_). Let's imagine a really simple scenario. Imagine a lake whose level is around sea-level. It is receiving sediment from rivers draining mountains and other surrounding upland areas. Let's say that we deposit 1 cm of sediment in that lake. That 1 cm of sediment has a mass associated with it which now adds to the total mass of the column of crust beneath it. This addition of mass causes a little more of the aesthenosphere (a part of the mantle beneath the lithosphere which is weaker, behaves plastically and is able to "flow" on a geologic timescale) to be displaced beneath this column so the column sinks a tiny bit, thus creating more space, referred to as "accommodation space" within this lake. Continue this process for a long time and you will progressively end up with a column of sediments that increases in age downward, but the surface of the earth (where sediment is being deposited in your simple lake) is about the same absolute elevation referenced to some external datum (like sea level). There is also some amount of recycling that is happening as some areas are uplifted due to processes like mountain building. So you may have millions of years of deposition in an area and eventually this area may be involved in the formation of a mountain range and then a decent portion of those rocks will be uplifted, eroded and then deposited in a basin.
Sound is created by changes in air pressure. When you spin the cord, it pushes air in front of it, creating a higher pressure zone in front of the cord, and a lower pressure zone behind the cord. The sound comes from the pressure equalizing back to the standard air pressure.
"shock" isn't an evolutionary defense mechanism, it is the symptom of a lack of bloodflow to organs and tissue. You don't "go into shock' from a scary event like a predator chasing you, you go into shock from them biting you and you bleeding out._URL_0_
Broadly, long term memories are considered to be encoded as pathways throughout the cortex. Struggling to remember something might mean that certain pathways have been underutilized or have been disrupted on a cellular/molecular level.This perspective article from the journal Neuron might be useful: _URL_0_
It is best to check out [r/fitness](_URL_0_) for this sort of information.
Disclaimer: Been many, many years since I studied this. Feel free to correct me if I make mistakes, am completely wrong or just using outdated science!!In order to gain a better understanding of this, I recommend reading about the BCS theory of superconductors, as it was from this theory that the first accurate explanations for the Meissner effect were garnered.To make short of the theory, it states that electrons are attracted to the positive lattice of nucleii in the material. These establish "waves" in the lattice, where the lattice breaks from it's normal even distribution, forming regions of higher positive charge, attracting another electron to this region and establishing a link between the two electrons (which will have opposite spins to one another). The electrons now act like one linked particle (called a cooper pair), a boson (neutral spin). When the material is cooled sufficiently the electrons will all do this at once forming a Bose-Einstein Condensate. Now all the electrons have dropped from their energy levels, seemingly breaking the Pauli exclusion principle (no two electrons can occupy the same orbital unless they have opposite spin, and seeing as there are only two spin states there can only be two electrons per orbital). Every electron in the lattice is now in the lowest energy orbital possible, all of them are linked. Now it takes a surprising amount of energy to stop something from superconducting, you'd expect that if you just bumped out of the electrons out of it's pairing that any neat properties would disappear, but because they're all linked you can't just break one pair, you have to put enough energy in to raise ALL the electrons to proper orbitals (all the electrons in a lattice interact in any material, so all the electrons of the same spin will occupy different orbitals, requiring different amounts of energy to get them there, this is why large lattice based structures generally form in very, very high energy environments e.g. diamond).  An external magnetic field will exert a torque on electrons in the material, attempting to align them with the field, this would break the cooper pairings and so they will only switch when the field is of sufficient strength. Until this point "frustrated" loops form in the superconducting material, loops of current near the surface (generally between 20nm an 100nm deep) that form an opposing magnetic field. I fear I can't recall the source of energy that accelerates these loops, it may be in one of my old books (probably explained in far more detail in the paper "[Imaging spontaneous currents in superconducting arrays of π-junctions"](_URL_0_) which is freely available for viewing). The currents will accelerate or decelerate in order to set up a perfectly opposing magnetic field, thereby expelling the magnetic field from the superconducting material. Regarding your second point, any resistance in a material is due to electrons (which normally follow all kinds of crazy, interesting paths in lattices) "colliding" nucleii and losing some of their energy (transferring their momentum into vibration of the lattice, heat). In a superconductor the cooper pairs perfectly interact with their associated phonon in the lattice and are as such moved in "lanes" (only a figure of speech), never colliding with nucleii in the lattice. With nothing to collide against there is nothing providing resistance to the cooper pairs carrying the current. I hope that at least answers some of your questions, I also hope somebody with a fresher mind than mine can build on this and correct any mistakes I've made!
The responses here will be basically "*Clearly* modern humans were better, now we just need to explain why. Here's an explanation that fits my assumption".I don't think that's the necessarily the case. It's entirely possible that Neanderthals were smarter and stronger and in every sense "better" than modern humans. In fact, if you put a Neanderthal into the modern world right now, *it's possible that they'd be super-athletic geniuses with red hair and fair skin*.When it comes down to it, modern humans didn't have to beat Neanderthals in any direct competition. They simply had to out-breed them. It could be as simple as reproduction rates. Perhaps Neanderthals only had a couple kids that they raised very well while modern humans were basically trailer-trash, kid-spawners.
Consider [photosynthesis](_URL_1_): electromagnetic radiation (light) provides energy to a reaction that produces ATP.Or chemical photography: Light causes a reaction in the film. Later when the film is processed, the unexposed areas (with the original chemistry) become clear (in a black-and-white negative proces), while the exposed areas (containing the reaction products) become dark.Generally, you're asking about the field of [photochemistry](_URL_0_).
Temperature is (under certain contexts) the randomized thermal motion of particles which to a very large degree is just their translational kinetic energy, this is why Maxwell-Boltzmann distributions can accurately model the thermal properties of gases. Vibration and rotation aren't going to directly lead to temperature in free gases. However, these motions are still important for how the gas behaves.What you're referring to is the degree of freedom of a molecule and how heat is partitioned up—this affects the heat capacity of a molecule, how much energy you have to pack in to raise the temperature. So what we do is make the assumption that each "degree" of freedom can hold energy, for a single atom this is simple:   >  x, y, z motion **(3 degrees of motions)**And for monatomics, theory holds pretty well. Now let's consider diatomics like Nitrogen (N2), they have: >  x, y, z, rotating_z, rotating_y, vibrating **(6 degrees of freedom)**You'll notice that I've left out one of the rotating degrees, this is because for linear molecules, the rotation along the line that connects the two atoms contributes very little energy to the system, so we can effectively ignore it. So this explains how vibrations and rotations connect to heat—if a N2 molecule gets bumped into by another molecule, the added energy doesn't necessarily go all to speed (and therefore temperature), but to the other modes, this means it takes *more heat* to reach the same temperature!Now in real life, this isn't so simple. At room temperatures, diatomics consistently have *less* heat capacity than they should. This is because for low temperatures, the vibrations and to some extent rotational modes are "locked out" or "frozen" because they are quantized. They only "turn on" to high enough energies and for many diatomics, this is well above room temperature. Here's a chart of the temperature dependant on heat capacity:  _URL_1_  The lighter the molecule, the more spaced out the quantum vibration levels (everything in this picture is "hot enough" for rotational energy), the less they contribute to the heat capacity of the molecule and are frozen out at 5/2. For heavier things like Iodine, the vibrational energy levels are much more accessible and you're much closer to the theoretical 7/2.Look at hydrogen specifically, it's *lower* at room temperatures than it should be from theory, this is because some of the *rotational* states are still somewhat frozen, look at this graph:  _URL_0_  This shows how the new degrees of freedom become "unlocked" as you reach higher temperatures, you can easily see this curve for H2 on the first graph.
It's bulging because of centrifugal force. Centrifugal force affects the air as well, so the atmosphere bulges towards the equator too. It works out that air pressure is the same, the weight per cubic meter of air is less, and the atmosphere extends higher.
[This question is actually the number 2 all-time highest-voted in the subreddit :)](_URL_0_)
_URL_0_In this video, it looks like the iron fillings are suspended in some kind of viscous fluid, so that they aren't easily pulled down by gravity. This is pretty much what it would look like if you were to do it in a zero-g environment. However, the fillings would move faster because there would be no viscous fluid retarding their motion.
Sand is a [grain size](_URL_0_), and technically, "sand" usually has a modifier, like coarse sand or fine sand which corresponds to a specific grain size. Because it is an indicator of size, describing something as "sand" tells you nothing about composition. Naturally occurring sand size particles can be made up any number of minerals or groups of minerals, which will depend on the geology of the area from which the sand was eroded (what minerals are present in the parent material) and the distance over which the sand has been transported (which minerals have broken down during transport). Chances are, unless you're in someplace vaguely unique like Hawaii, if you grabbed a bag of sand, a lot of it would be individual grains of the mineral Quartz. This is because quartz is a common mineral in rocks on the surface of the earth and is also quite resistant to chemical weathering (so the concentration of quartz increases as sand is weathered, deposited, hardened in sandstone, reweathered, so on and so forth). Feldspars are also common constituents of sand, but they are not as stable as quartz so in many places, these will make up less of your random bag of sand. Lots of sand grains can also be "lithic fragmentss", basically bits of rock that contain more than one mineral but are sand sized. So, to answer your original question, yes, it would be possible for a grain of sand to be different on the inside than outside, providing it was a lithic clast. Quartz sand grains also have a tendency to be coated, often by iron oxides so that they will appear rusty red on their outsides, but if you were to break an individual grain open, it would still probably be a white-beige color of most quartz.
An accelerator physicist could give a much more detailed and quantitative answer, but the short story is that it would likely have to be an extremely long linear accelerator, using today's technology.Accelerators are characterized by their "gradients", which tell you the amount of kinetic energy they can give to a particle per unit length. For example, RF cavity accelerators often have gradients on the order of 10 MeV/m, meaning they can give a particle 10 MeV of kinetic energy for every meter is travels through the accelerating cavities.If you assume a linear accelerator with a constant gradient, the length of the machine increases linearly with the desired final kinetic energy. Meaning if you want to double the kinetic energy of your beam particles for all the same settings, you need to double the length of your accelerator.The reason why you'd want a linear accelerator is that at high energies, circular accelerators suffer very large losses to synchrotron radiation whereas rectilinear acceleration of charged particles produces far less radiation.Obviously the cost of the machine also scales with its size, so the bigger the accelerator, the more it costs to make.It would be very nice if we could use circular accelerators or short linear accelerators to get to very high energies. We cannot change the fact that circular motion of charged particles produces lots of radiation, but we *can* hope to increase the gradients of linear accelerators. Maybe new technologies will be developed that give us much higher gradients, and allow us to reach much higher energies in shorter accelerators.
It does in fact have to do with speed. Since wings speed up the air flowing over them, the air going over the wing can be supersonic while the airplane itself is subsonic. There are negative effects that stem from supersonic flow around a wing. However, these effects only apply to the portion of the flow perpendicular to the leading edge of the wing. Sweeping a wing back (like an airliner or business jet) reduces the component of velocity perpendicular to the leading edge, delaying these effects until the aircraft is going faster. Delta wings (the dart shapes you refer to) are good at flying at supersonic speeds, but carry penalties when flying slower. Aircraft with these types of wings need to fly with their noses pointed very high when flying slowly, which reduces visibility over the nose. [Example](_URL_0_)  There are other issues related to delta wings as well. They cannot be fitted with large flaps to increase lift, because they would be at the back of the plane, and there is no mechanism to balance them at the nose. Aircraft with swept wings mounted near the center (nose to tail wise) are readily able to counteract these forces. Delta wings do have a non-aerodynamic advantage: their internal structure can be made lighter. However, the disadvantages usually outweigh the advantages for modern fighters, which aren't all that fast in the grand scheme of things.As for slower prop-driven aircraft, none of the above apply and straight wings are lighter, simpler, and provide more lift at low speeds.
Yes because the viscosity changes the amount of energy needed to make  the substance move, in this case you are asking about wave size so you are going to need more force to make the wave grow at least the actual size of waves right now. Imagine having a sea full of pancake syrup. If you throw a rock at the sea. The rings that are created on the impact would travel a little bit of space compared to what they normally do.Fun fact: you can “hear” the difference in viscosity based on the temperature of the water at the moment you are pouring it on a cup. Temperature changes the viscosity of the water so it sounds different. I’m gonna add more knowledge: since temperature is energy being transferred to water particles “charging them”  ( in this case ) energy transmission between particles it’s gonna be easier thats why it’s easier for hot water to flow. If seawater was hotter there would be bigger wavers At high temperatures the viscosity index lowers making it more fluid.Edit: since a lot of people are worried about global warming and the temperature of the sea I’m gonna answer it: yes the oceans are getting warmer but the increase in the temperature on the seas are really low to make a noticeable change (on the height of waves)Ice caps melting would do more damage because sea level rises so more land is eaten by the sea. Temperature would affect somehow( in viscosity) but it’s too small to make an really extreme impact noticeable at first sight on the wave height ( in this case) we should be more worried about reefs bleaching and plastic destroying animal life.
Most medicines I'm aware of that should be taken at night may cause drowsiness, or other side effects that would interfere with daily living. Sleeping through the peak dosage ameliorates the bad side effects. Most medications I'm aware of that are suggested to be taken in the morning are antidepressants or antipsychotics. This is done in the hopes that the optimal therapeutic dose will be experienced during daily life, so that the user would get the full benefit of the drug when they need it, rather than while they're asleep. The only other drugs I know that should be taken a good while before sleep are cough medicines, so that any phlegm coughed up can be eliminated from the body rather than coughing being suppressed or the phlegm simply swallowed again in the users sleep.Afaik it's just due to the aims and side effects of the drug. I can't think of any reasons that a drug would not be metabolised or taken up by the body at a certain time, and haven't heard of anything to that effect. Edit: missed the part about taking with meals. As others users said, it's to do with absorption, needing more acidic condiotions/absorbing better alongside certain nutrients, or some medications need to be taken on an empty stomach for opposite reasons, also some drugs are enzymes for the purpose of helping digest e.g. Pancreatic enzymes are taken with food
They do not. There is no evidence supporting the effectiveness of the bracelet.
There isn't "more or less fluid" above a point on the bottom, the sides apply a downward/upward force equal to if they were replaced with a column of fluid with the maximum fluid height.
You should be able to get pretty close withf(x,y) = cos(r) * abs(x/r)with r = sqrt(x^2+y^2)_URL_0_Note that my function mimics your diagram, but a real antenna field would also decrease as you went further away.
There's no single "food analysis" that will spit out a nutritional label for a food (and anyone trying to sell you one on Kickstarter is lying) so we have specific test methods for particular nutrients. These range from simple chemical assays, to chromatographic methods, to mechanical separation of components. Caloric measurements start with basic bomb calorimetry, and are refined based on on digestibility studies.
Imagine you have a system of three coupled springs. If you set up the Newton's equations for this system, you will find that a change in the position of one spring causes a force on another spring. This is what makes the system coupled. It is a simple matter to express the three equations for this system in a matrix form, Mx'' = Kx. Here, M is a mass matrix (a diagonal matrix with elements equal to mass), K is a spring constant matrix (made up of the coefficients of the *x* terms in Newton's Equations), x is a vector of the positions of the three masses, and x'' is the second time derivative of x. If you convert this matrix system to an eigen basis, the eigenvectors will be the normal modes and the eigenvalues will be the natural frequencies squared. [Wikipedia has a good basic coverage of all of this.](_URL_0_)If you had a more complicated system, a bridge for example, you would do more or less the same thing. Discretize the whole thing using the [finite element method](_URL_1_) and make what is effectively a giant coupled oscillator system. Then find the eigenvalues of that system.It is also possible to calculate the resonance of a continuum system (a stretched guitar string, for example), but this gets a little more complicated because you need to solve a partial differential equation rather than coupled ordinary differential equations. Also, for any complicated continuum system, such as the bridge example, you would just discritize in finite elements and solve that way.The important thing to note is that there are almost always more than one resonant frequency. In fact, the number of resonant frequencies is equal to the number of degrees of freedom. A continuum system has infinite degrees of freedom and so infinite resonant frequencies. So if you are designing a system to avoid resonance, you need to consider all of them.
Snow on the ground makes the ground much less effective at reflecting sound waves, thereby muffling some of the sound that you would normally be hearing. Snow in the air does not affect the sound speed in air, although it may be possible that snowflakes serve to scatter sound waves and thereby mute them.
If you're standing on ice, trying to stand still, you really aren't. Your legs and feet will reflexively try to keep balance by making small movements and balance adjustments. The low-friction surface of the ice makes it possible for the subtle movements to occur. When you're wearing iceskates on pavement, there is no movement possible at all, so naturally it is harder to balance.
Even though we've been observing stars for a small amount of time, we've been observing a lot of them.  Think of an alien observing all humans for a few days.  Not long enough to observe an entire life cycle, but long enough to determine what the average lifespan is.  (Grossly simplified since human life spans have many more unknown variables.)  Astronomers can find stars of similar masses, luminosities or ages and determine relations between them.  Also for our sun, we know how long it's been around and knowing the physics of the interior (how much energy is being produced, how much hydrogen remains...) we can make a very good estimate of when the Sun will become a red giant.  Do we know it will die on a Tuesday, no. But we can be confident to within a few hundred million years at least._URL_0__URL_1_
Yes. The Schwarzschild solution for gravity is true outside any spherical object with minimal rotation But even for a rotating black hole, you would need to be very close to the event horizon to notice any interesting effects - so close that your orbit would be well inside Betelgeuse. At any large distance, gravity is just the normal Newtonian gravity.If Betelgeuse collapsed into a black hole without expelling any gas (and it actually will expel gas when it goes supernova), that black hole would be about 34 km in radius. Its current radius is maybe 600 million km. So an orbit far enough out to be outside Betelgeuse would be pretty far away from the black hole, and it'd just feel like a normal 1/r^2 gravity force, without any real time dilation.
First of all, blood is ~80% water, so the same general problems with ice bullets still apply.  In addition to that, blood has a whole bunch of stuff dissolved in it that disrupts the formation of ice crystals and mechanically weakens the frozen phase.  So, a bullet made from frozen blood would actually be worse than an ice bullet!
See [my post here](_URL_0_). The mean absolute deviation is perfectly fine, but the standard deviation is more useful because it affords the use of powerful tools like the Fourier transform. The normal distribution is also very simply described in terms of only the mean and standard deviation, and its importance in the central limit theorem should not be understated.
Your computer has a chip known as the Real Time Clock (RTC).  This chip typically has its own battery, and is able to keep track of the current time when the computer is turned off.  There was a time in the early PC days when PCs didn't have an RTC; by default booting up DOS without a valid AUTOEXEC.BAT would ask you to enter the current date and time every time you booted up the system.So the RTC keeps the time for you.  But how does your computer keep it synchronized?There are a few different ways your computer can keep its clock synchronized with the rest of the world.  It's possible, for example, to connect your computer to a GPS and synchronize your time from GPS signals.  This is (of course) how GPSs keep their time in synchronization, and devices are available for your computer to do the same.Likewise, in some countries it's also possible to pickup time signals sent via terrestrial radio waves from nearby transmitters.  Again, hardware is available for your computer to do this.However, the vast majority of the time your computer gets its time synchronized by NTP^0, the [Network Time Protocol](_URL_1_).  The algorithm you proposed is in fact a known algorithm used in time synchronization -- it's known as [Cristian's Algorithm](_URL_5_)^1.  In this algorithm, you measure the round-trip time between when a request was made and when the response was returned, and add half the round-trip time to the response time, and use that as your current time.  If network conditions are good and consistent (such as on a local network), you can achieve an extremely close result, in the millisecond or even sub-millisecond ranges.NTP's algorithm is similar but a bit more complex.  In NTP, we calculate two values:  a time offset (theta), and a round trip delay (delta), as given by the following equations:      theta = T(B) - T(A) = 1/2 * [(T2-T1) + (T3-T4)]    delta = T(ABA) = (T4-T1) - (T3-T2)...where:* T(A) is the timestamp on the client (A)* T(B) is the timestamp on the server (B)* T(ABA) is the round-trip time from client to server and back* T1 is the timestamp on A when the request was initiated* T2 is B's timestamp when the client request was received* T3 is B's timestamp when the response packet was generated, and* T4 is A's timestamp when the response packet was received.Now I'm going to backup a bit, and discuss NTP strata.  In NTP, servers are classified into a _strata_ based on how close they are to the time signal:* **Stratum 0**: These are the official reference clocks.  These are directly connected to atomic clocks, GPS clocks, or radio clock sources.  They are the most authoritative, but aren't necessarily the best servers to synchronize from (as depending on their load and round-trip time to your computer, they may have a lot more variation than a server closer to you).* **Stratum 1**: These are servers that synchronize against Stratum 0 servers.  They may also peer against other Stratum 1 servers, so as to keep their times closely synchronized.* **Stratum 2**: These are servers that synchronize against Stratum 1 servers, and may peer with other Stratum 2 servers.There are 15 strata altogether (with the 16th strata reserved to denote a device with an unsynchronized clock).  Typically your PC will fall in at Strata 3 or 4.  But the important thing to note here is that most systems synchronizing via NTP synchronize against multiple servers.Because of this, NTP uses what is known as [Marzullo's Algorithm](_URL_0_)^2.  This algorithm can take a set of values (in this case, timestamps) and confidence intervals, and compute a value that is consistent with he most sources.  In effect, it's a way to do a statistical analysis against the responses of multiple time servers, and based on their confidences come up with the most likely true value.The result is often extremely close to the actual time, with a variation in the tens of millisecond range over the public internet, and with a variation within 1 millisecond within a given network.The result, however, isn't guaranteed to be _perfect_^3.  To achieve that, you need to run your own Stratum 0 time server (i.e.: either have to get a GPS-based time source, a radio source, or run your own atomic clock).For most operations, the most important time is that between systems on a given network.  Most typical uses work just fine with a one second resolution; for any computing requiring better you want to ensure that systems peer with each other on a dedicated network designed specifically for low latency.FWIW, I implemented Cristian's Algorithm on a custom embedded system, where the peers communicated via peer-to-peer wireless running a custom protocol and a real-time operating system.  They synchronized a synthetic clock (they didn't actually bother to keep track of the real date and time, but instead had a millisecond resolution counter that started at zero when the first node on the wireless network was started up).  The system was designed to be able to synchronize robotic activities with one another via this clock, and with what tools we had available to us at the time we couldn't measure any noticeable difference in when synchronized activities activated (it's possible if we had access to one of todays insanely high frame rate cameras we might have been able to measure a difference in the millisecond range -- but we didn't have anything like that at the time).  We didn't quite meet all of the goals of our project, but the synchronization of activities based on synchronized clocks was solid and complete.-----^0 - [RFC 5905](_URL_2_).  ^1 - [Cristian, F. Distrib Comput (1989) 3: 146. _URL_6_](_URL_6_).  ^2 - [Marzullo, K. A. (1984). Maintaining the time in a distributed system: An example of a loosely-coupled distributed service.](_URL_4_).  ^3 - [Lamm, R. et al. (1969).  Does anybody really know what time it is?](_URL_3_)
Google used the opposite of this idea, having people describe pictures with words, to help improve their image search algorithm._URL_0_I'd imagine if you wrote a sufficient algorithm you could do something similar with your idea.
If someone HIV+ is adherent to their medications--meaning they are regularly seeing an HIV specialist for medical care, taking their pills every day, avoiding anything that could interfere with the medications (excessive drinking, other drug abuse)--then they can generally expect a normal life expectancy. There are some other risks too--unprotected sex between 2 HIV+ people can lead to cross-infections of serotypes, which I'm not terribly familiar with to be honest. The CDC defines AIDS as when a patient with HIV has either a CD4/T-cell count of  < 200 or has an opportunistic infection (OI). Current HIV meds--there are dozens and dozens on the US market--generally prevent the virus from replicating enough to pose a threat to the immune system, thus preventing the complications that stem from AIDS. Anyway, back to the point. Current HIV treatments are very good at preventing AIDS, and current medical knowledge shows that proper medical adherence among HIV patients can lead to a normal life expectancy. You don't even need to be super rich, even in the US, to afford treatment. Now that under the ACA insurers can't deny/raise rates for people with preexisting conditions, most plans cover the necessary care to live with HIV. All states have some iteration of the AIDS Drug Assistance Program (ADAP), which pays the cost of any HIV meds for people under a certain income threshold (it's usually quite generous, covering low-income and what would generally be considered middle-class) and (in some states) also pays insurance premiums for HIV patients. Medicaid and Medicare Part D plans cover HIV meds. So, in the US at least, you don't even need to be that rich to stay in care if you stay on top of your health. The meds are still expensive out of pocket, but the pharma companies also have patient assistance programs for people who for whatever reason can't pay/lost insurance.Edit: Just wanted to give a shout out to the Ryan White CARE Act, which provides federal funds to a lot of HIV care in the United States, including ADAP, which I mentioned earlier _URL_0_
For acoustic waves, the primary reason is that atmospheric attenuation (air absorbing a small fraction of the sound energy) is frequency-dependent, and increases with increasing frequency. So in air (and most other viscous media), low frequency waves are attenuated less than high frequencies.There's a pretty detailed answer to this question over at [stackexchange](_URL_1_).For other types of waves, like radio, other factors come into play. For instance, low frequency radio waves can diffract over obstacles and follow the curvature of the Earth.There are a lot of previous answers to this question [on reddit](_URL_0_) and elsewhere on the web.
No, because the oil/wax portion rises as it heats, then falls as it cools, forever moving parts of it up and down. No matter how long you leave the light on, the bottom will always be warmer and the top colder unless the room the lamp is in is the same uninhabitably high temperature as a lava lamp lightbulb. The only way equilibrium can be reached is if the heat source (lightbulb) stops adding energy to the system and everything reaches a constant temperature, ie turn it off and leave it off.
_CDMX: "Ciudad de Mexico"?_Downloading or uploading data on a connection uses some of the channel's capacity. Since channel capacity is [finite](_URL_5_) (because bandwidth is finite), it stands to reason that it can be exhausted. Since (mobile) networks share parts of the backbone infrastructure, it is reasonable to assume that traffic sent/received by non-disaster-struck endpoints on a network might cause congestion for endpoints near a natural disaster site - this is a typical characteristic of IP networks, the reason congestion control is built into TCP, and how DDoS attacks present such a huge [collateral damage footprint](_URL_1_). This is often the case not only during disasters, but also [mass events](_URL_3_), and it presents with different traffic characteristics. [Mass Call Events](_URL_4_) affect other networks as well, not just mobile ones.Additionally, one must have in mind that disasters might not only cause MCEs, but also damage the infrastructure put in place.There are multiple ways to prepare for an MCE; typically, operators plan ahead by organising simulations in the lab or in the field with the relevant authorities, and measuring their KPIs. Depending on the event, [additional considerations](_URL_0_) must be made - infrastructure changes, deployment changes, and so forth. Then, the operator adjusts its [capacity plan](_URL_2_) accordingly.
Not clear here.*Effect size* is an estimate of *how much* groups differ, rather than whether their difference is "statistically significant" or not. It's important to know an effect size because even treatments which achieve very low p values (p  <  <  0.05), and are *significantly different* by conventional standards, may not have much practical significance. Cancer treatment A, for instance, may significantly prolong life over treatment B—but actually only by one day.That said, effect sizes are only partially standardized. Probably the most common are *Pearson's r* and *Cohen's d*. [This](_URL_0_)^PDF article is a good primer on the subject.The paper does not say in what terms the effect size is expressed. It cites another as its source for the effect size; I can only get a copy of that paper's abstract at the moment, and it doesn't say either.That said, it seems to be relatively common in psychology research to use Cohen's *d*. As the primer article I linked to states, a Cohen's *d* of 0.30 is a small-to-medium size effect.
Unlike the descent into Jupiter or Saturn (which I've previously [written about here](_URL_2_)), the interiors of Uranus and Neptune are quite a bit different.While you still generally increase in temperature and pressure as you descend, Uranus and Neptune don't possess enough interior pressure to generate liquid metallic hydrogen like Jupiter and Saturn. However, our best guess is that they do have hot, slushy oceans of ionic water mixed with ammonia, and below that, [superionic water](_URL_1_), and probably not too far below the clouds. This is why we prefer the term "ice giants" to describe these planets.Superionic water is a weird state of matter, not exactly solid, but not exactly liquid, either; the oxygen atoms form a crystal lattice like a solid, while hydrogen ions move around freely like a liquid. Now, take note that we've never actually produced superionic water in the lab before - this prediction is just made from extrapolating the [equation of state](_URL_0_) to very high pressures. That's not to say it's just a guess - after all, we predicted the existence of metallic hydrogen this way, and we recently did produce that in the lab - just that this is fairly theoretical at this point.Exactly where this transition from thick, soupy atmosphere to ionic ocean occurs is still unclear, but we're also fairly sure it can't be too deep - maybe 25% of the way down (though that's heavy speculation at this point). All those circulating charged hydrogen ions in this ocean means that's it's electrically conductive, and capable of producing a dynamo effect to generate a magnetic field. Both Uranus and Neptune have magnetic fields that are strongly tilted and off-center, which requires substantial higher-order magnetic moments like quadrupoles and octopoles; that strongly implies this ocean starts at a fairy shallow layer if it's indeed responsible for generating (or at least altering) these weird magnetic fields we see.If you're up for a technical read, [this paper (PDF)](_URL_3_) has much more information. Figure 2 may be what you're looking for.
Assuming there is a complete circuit for the electrons to travel through yes.  The heating of the material will actually change the potential of that material.  The [Nerst Equation](_URL_0_) has a temperature component built in.
Inflation is driven by a scalar field called the inflaton. (A scalar field being a field that is just a number, at any point in space and instant in time). The inflaton lies initially in an excited state which gives a large constant energy density in space. This triggers a violent exponential expansion exactly like dark energy does now, but at a more dramatic scale.As the Universe expands exponentially the total energy grows immensely, because the energy density remains constant while the volume grows.When the inflaton switches back to its ground state, inflation ends and the energy it had is developed in the degrees of freedom we know and love, and we enter what is known as the early Universe  (radiation-dominated). The temperature is probably of order 10^(16) GeV (GUT scale), that's why one gets the prejudice inflation has something to do with grand unification (which is the unification of the three forces of the standard model).That's the general features of inflation. The different models (i.e. chaotic inflation) propose different mechanisms or details through which the above passages happen.Inflation is not per se concerned with the origin or nature of the inflaton. Where the inflaton comes from or what it is is a separate, but interesting question. There's many ideas about that too.
this was discussed a few weeks back with some good answers here:_URL_0_
Evidence? No. -- though it's been a popular idea for more centuries than I can count on my digits.A chap called Euhemerus was the first to have this idea about Greek mythology. He lived in the 4th century BCE and very little is known about his work on myth, but the style of his approach stuck. We do know that one of his ideas, for example, was that Zeus (king of the gods in Greek myth) was a historical Cretan king, and that the worship of him as a god was an overblown hero cult. (And we do know of plenty of examples of historical figures who did have cults devoted to them at the site of their tomb: the playwright Sophocles, for example, had a hero cult.)This mode of analysis of myth is still often known as "euhemerism", though the more general term "rationalisation" is more descriptive of the process. The basic idea in the rationalistic process is to take myths that relate implausible events; remove the implausibilities, substituting something more reasonable in their place where necessary; and whatever's left over gets treated as historical fact.On occasion some modern people have engaged in the same kind of analysis: for example, the division between two classes of gods, Æsir and Vanir, in Norse mythology has been supposed by some people to represent one ethnic group's conquest of another. But throughout the 19th and part of the 20th centuries, the interpretation of myth fell into particular schools of thought, and these schools weren't terribly hospitable to euhemerism. Instead we get Max Müller claiming that all gods are anthropomorphisations of natural phenomena; Andrew Lang claiming that all myths are reworked and obfuscated versions of religious rituals; Freud  &  co. claiming that myths are all about unconscious desires; and so on.There are two main troubles with euhemerism, and with Müller's and Lang's style of analysis:* first: all these interpretations are *in principle* untestable. In the case of euhemerism, if myths are supposed to be distorted versions of historical events, we have a circular argument because the myths are our only source for these supposed historical events.* second: whichever pattern of analysis you pick, there are always going to be lots and lots and lots of myths that don't fit the pattern. (On occasion some specialists have gone so far as to say that if a particular myth doesn't fit their macroscopic approach, it is *ipso facto* not a myth. That's utterly irresponsible.)We don't really have schools of thought in the analysis of myth any more, because it's become more accepted -- after the failure of the big schools of thought -- that myths need to be approached in an *ad hoc* fashion that gives due attention to particularities. There'll be exceptions of course, but not generally among the specialists (Joseph Campbell never ceases to have his fans, for example, just not among classicists or anthropologists; he suffers from the same weaknesses as Euhemerus, Müller, et al.).At most we can say that it's *possible* some myths *might* have some basis in historical events. But independent corroboration will always be needed. In particular, it is never permissible to use the myth as *evidence for* supposed historical events, because that's circular. This applies even to myths that are closely linked to historical realities: Homer still remains our *only* source for the actuality of a Trojan War, even though we know Troy actually existed; therefore, it is deeply problematic to use Homer as a historical source for the occurrence of such a war.Further reading: there are heaps of sources, but mythology tends to attract the lunatic fringe so it's hard to sort the wheat from the chaff. I recommend Eric Csapo, *Theories of Mythology* (2005); it's quite long, but far and away the best account I know of.
The acid in these drinks is not correlated to the caffeine content. The acid comes from the coffee itself and the preservatives that are added to it. The pH is likely very similar in both drinks, just the espresso shot is a smaller volume so you're taking in less volume of acid. Brushing your teeth,  using mouthwash, drinking water, and chewing sugar free gum all can restore the pH balance in your mouth.
Fronts get pushed around by high/low pressure zones and terrain, so they aren't going to travel in a straight line forever. They eventually dissipate as they mix with surrounding air, get pushed up and down in the atmosphere by other fronts, and interact with varying terrain and water.Disclaimer: I'm nothing close to educated on weather science, I just have a basic working knowledge of weather systems from flight training. I'm sure there are far more factors and better explanations that someone will hopefully chime in with.
Because the tenderising enzymes are proteases, these enzymes break down proteins so they can be used to break down the proteins in meats, which in turn tenderises it.The core of a pineapple is principally composed of plant structural materials such as cellulose, hemi-cellulose, lignin and so forth. These aren't digested by proteases.Incidentally the pineapple proteases are why you can't make jelly/jello with raw pineapple juice as the juice will eventually digest the gelatin. If you want to make pineapple jelly you need to boil the juice first.
Only two. The wavelengths of the photons passing through the crystal, and the refractive index of the crystal itself.This is the same for any material.Shorter wavelength photons are "bent" more, longer wavelength photons are "bent" less.Refractive index is a number that tells you how a certain material interacts with light. Whether the photon will be deflected or not is dependent on the difference between the refractive index of air, and of the crystal.The reason your torch behaves differently to the Sun, is that the sun emits a lot of photons of all visible wavelengths, whereas your torch emits on a narrower band of wavelengths, and so the "splitting" of the different wavelengths is harder to see, as it tends to be washed out by the diffuse light.Another difference between the sun and your torch is that the Sun's rays are essentially parallel. We are far enough away that the angle between the photons is negligible. This isn't the case for your torch. And since lots of photons are entering the crystal at lots of different angles, effects like refraction are much less distinct and harder to resolve.
It can be argued that gravity is actually an emergent feature that is ultimately caused by increasing entropy. This is still a subject of discussion though. [link](_URL_0_)Anyway, most systems where gravity is important are just discussed in terms of a few orbiting objects, and the system has too few components to be re-arranged without changing the energy. That's what entropy is: how many way you can re-arrange a system and not change the energy.
In the sense that you can write a polynomial which interpolates between two chosen points in your original polynomials? Sure, that can be done easily.Let's say that we want to interpolate between a polynomial of order m at x=a, denoted as f*_m_*, and a polynomial of order n at x=b, denoted as f*_n_*. The interpolating function f should have f(b)=f*_n_*(b), f'(b)=f'*_n_*(b), f'(a)=f'*_m_*(a), f(a)=f*_m_*(a).f*_n_*(x) = Σ*_k=1_*^(n) s*_k_*x^(k)f'*_n_*(x) = Σ*_k=1_*^(n) ks*_k_*x^(k-1)f*_m_*(x) = Σ*_j=1_*^(m) r*_j_*x^(j)f'*_m_*(x) = Σ*_j=1_*^(m) jr*_j_*x^(j-1)s*_k_* and r*_j_* are the coefficients for the kth and jth terms, respectively.What we would like is an interpolating polynomial:f(x) = Σ*_i=1_*^(l) q*_i_*x^(i)f'(x) = Σ*_i=1_*^(l) iq*_i_*x^(i-1)which has f(b)=f*_n_*(b), f'(b)=f'*_n_*(b), f'(a)=f'*_m_*(a), f(a)=f*_m_*(a). There are four equations with far more than four parameters so there is no unique solution, but there are an infinite number of polynomials which successfully interpolate between f*_n_*(b) and f*_m_*(a).
We look for the same situations as ours because we know it works. It happened at least once, so it's more likely to happen again.    As for life in extreme conditions...It still has the same basic requirements as us, only they've adapted to a differing environment. Put them somewhere else on the planet, and they have to adapt again.
I dont really think you could absorb enough water via your skin. no expert here but bear with me.Your outermost skin layer the epidermis has a layer of skin cells that are dead and are just keratin husks. This provides you with a dead cell and alot of protein and thus no mode of absorbing water. but im not 100% sure on that. There are still alive cells under that thin layer yet for cells to absorb water through passive diffusion through aquaporin  protein channels that just allow for the flow of water.your skin on the surface get wrinkly because it absorbs water. The cell is hypertonic to the hyoptonic environment. meaning that there is alot of solute in the cell versus not alot of solute outside of the cell. water flows from Low to high solute ( our kidneys to a good job at this).Anyway your skin is also bound by different proteins that allow ellasticity and actually bind your skin to the other layers below it. you are seeing the skin swell while it is tied down.As far as living off the small amount of water that is absorbed....not nearly enought to live off of even thought some metabolic processes create water as a by product. you simply cannot absorb enought. I also think, guessing, that eventually your cells will start to transport solute out of the cell and then try to become isotonic with the surrounding cells therefore going back down to normal size. In this process, i think!, that they will recollect the aquaporin channels from the plasma membrane.
The magnetopause is the shock formed at the upstream side of the magnetosphere, where solar wind impacts the magnetosphere while going faster than the wave speed in the solar wind.So the Moon never crosses the magnetopause directly.The magnetotail is the long, narrow part of the teardrop shape of the magnetosphere -- it's on the side opposite the magnetopause.  The Moon crosses through that on occasion.
Essentially, because there is a lot of material falling into the black hole. When things fall down a gravity well, they lose gravitational potential energy. Drop something off a cliff, and gravitational energy gets transformed into kinetic energy, which upon hitting the ground will partly turn into thermal energy. Of course, if you drop something off a cliff, then even ignoring air resistance it will probably only be going tens of meters per second. If you drop something into a black hole from very far away, then as it approaches the event horizon, its speed will approach the speed of light. Now, typically things don't just fall in on a single trajectory, it's usually a longer process of orbital decay and tidal forces that eventually usher the particles to their ultimate fate, but nevertheless they gain a tremendous amount of kinetic energy, and much of that gets transformed into radiation. That's why quasars are so bright.The specifics of how energy gets turned into light (and particle jets) in an Active Galactic Nucleus is more complicated. First of all, you've got a rapidly spinning [accretion disk](_URL_0_) of matter around the black hole. As you get closer to the inner edge of this disk, it gets hotter and denser, so that the inner edge is radiating mainly in the X-ray regime. Since this material is a plasma, you've got magnetohydrodynamical effects that come into play. That's a fancy term for a combination of fluid dynamics and electromagnetism. We don't yet have a precise understanding of the process, but basically the disk creates powerful electromagnetic fields which shoot some of the infalling particles out in jets rather than letting them fall toward the event horizon.
I believe all humans have these "stripes", they are just not visible. I looked this up once when my daughter and son in law (one brown, one white) were joking that their child would come out spotted or striped. _URL_0_
The "speed of light in a vacuum" is an idealised quantity. That's the key value used in special relativity for calculating time dilation etc.Honestly, it's sort of a bad name. The "speed of light in a vacuum", or *c*, is a universal constant that tells us about the relationship between space and time, between mass and energy, the propogation of information, and so on. It just so happens that, under idealised circumstances, light will travel at *c*.What's really going on here is that light is an extremely useful *probe* of relativistic physics. Light doesn't *cause* time dilation, but it's a very useful tool for understanding time dilation and for deriving the mathematics of it. So if the actual physical light is travelling slower in a material, then that doesn't change relativity.In fact, you can have electrons travel faster than light in a dense material. This is what causes blue light in the water around nuclear reactors - Cherenkov radiation.As a final note: the last time I answered a question like this, some people argued that technically the light isn't going "slower than the speed of light", because the photons are just getting absorbed and reemitted within the material, giving an appearance of a slower speed. You can think of it that way if you like, but I think the wave formulation gives a much better picture here, and gives a much simpler explanation for e.g. refraction at a surface.
Make a thousand jars, then every interval (however you choose perhaps every 15 days?), pick a sample and test it for both taste and bacteria / mold / etc contagions. You probably want to the the contagion test first. Use some statistics to figure out how many you'll need to test to get whatever confidence level you want. Less testing might mean you can only be 80% confident it will be safe after X period, more testing could be 99.999% confident.This also depends on the results of your test, as if you test 10 jars each time and 1-2 are bad, then that will affect your standard deviation and lower your confidence, whereas 10/10 jars being safe would let you reduce your sample size for same confidence level.
A zero-altitude reference surface is defined.  Depending on the body and the usage, this surface might be a sphere, spheroid, or ellipsoid whose dimensions are taken from average measurements of the planet's dimensions.The reference surface for large solid bodies with slow rotation (e.g. Mercury, Venus) are often simply spheres with the average radius of the planet.  For faster rotaters (Earth, Mars) an oblate spheroid is more appropriate.  This shape approximates the equatorial bulge caused by planet's rotational momentum.For a *tidally locked* fast rotater (Io, Europa) an ellipsoid usually provides the best fit reference surface.For the gas giants, the convention has been to define zero altitude to be the atmospheric depth at which the pressure equals 1 bar (100 kPa).
It does yes, although not by much. This is a consequence of special relativity. In special relativity, mass is the energy that a system has in the reference frame where it is at rest (up to a multiplicative constant, to make the units work out). Consequently since winding up the toy increases its potential energy, it also increases the mass of the toy by a small amount.
Your body uses a plethora of receptors throughout your body to keep tabs on its current condition. In particular, there are a class of receptors known as nociceptors that function solely to warn the body of when there is a "painful" stimuli. If you care for more detail: For instance there are nocireceptors dedicated to detecting temperature. At a certain temperature, these receptors produce an action potential that coincides with around 42 degrees Celsius, or the known heat-pain temperature. The produced action potentials can then be integrated in your central nervous system to processed in your brain.
Our models for black hole have a curvature singularity at the "center". Whether there really *is* a singularity at the center is a question that can't be answered at this time, as we don't have a working model that can describe the conditions present in the region of interest.
There’s also temperature to consider- and the seasonal flux of temps .  Some plants need the winter rest or to germinate, some die as a result of it.  Also drainage. Mountain species generally need good drainage even if they require more water than succulents.  Many of them get root rot at lower elevations. That’s why people recommend Alpine plants for window boxes, they tolerate an exposed position and intermittent dry roots.
Particles of combustible material floating in the air of the stove are igniting when they hit the higher-oxygen air in the room. They don't burn in the stove because you have the intake vents and flue closed, forming an oxygen-poor "reducing" atmosphere.BTW, in this configuration your stove is basically a carbon monoxide and creosote machine. Make sure you have the vents professionally cleaned at least once a year, and get a CO alarm.
It changes how things blur when they're out of focus. You basically see things blurred into the shape of your iris. A cat will be able to see better horizontally, which is better for hunting prey. A goat, which has horizontal bars in its eyes, sees vertically, which is better for looking for predators. A human has circular eyes which is somewhere in between.
I think the article mentioned that because of the nature of the surface it was on, it had adopted a configuration of seven strands wrapped around a central eighth strand. So not really a configuration it would ever adopt in aqueous solution.
Sure. All solids liquids and gases conduct. A quick google search shows that a molten metal is about 1.5 to 2.5 times LESS conductive than the solid state.In a solid, metal atoms are closely bonded in periodic, crystal arrangements with electrons freely associated with all the nuclei. The travel quickly through the crystal lattice of a cold, solid metal. In the liquid, this short range order is diminished so the electrons can not flow as easily through the random, molten arrangement.
That's obviously a large question - you'd generally have to take a one semester overview course to touch on all of the issues. Some of us spend our entire PhD training on just a piece of this puzzle. Let's start with the implied premise that other countries are more successful than the U.S.  This is not an uncontested assertion. The cross-national comparisons (PISA and TIMSS are two major ones) each have their own methodological issues; countries can "game" the system intentionally as well as by simply having different policies for who has access to which resources.A somewhat dated but still highly relevant book is *The Manufactured Crisis* by David Berliner.  Find it on Amazon and give it a read if you want to think more deeply about the "problems" of U.S. education.So, now let's look at differential achievement (I'll unpack "achievement" in a bit).  Let's think of everything that goes into determining how well a student learns/performs in school.  There are personal characteristics starting with simple brain development (something as basic as nutritional deficiencies can have a huge impact). Some personal characteristics - habits of mind - are instilled by families and peer groups.  Next are teachers and schools, which can have different attributes depending on community norms and resources. Community expectations matter, too (my nephews are growing up in a rural state where a minority of people go to college. They're quite intelligent and would thrive in a four year school, but they don't necessarily have an interest or see the point in going).Within the formal schooling environment we've had a ton of research on teaching "methods", curriculum design, pacing (what is an optimal age to start to teach reading, for example?  I believe Norway starts around age 7 or 8). I can't even begin to summarize findings from this literature. Importantly, "what works" is highly contingent on how you define "success" or "achievement."  Test scores, college enrollment, etc., are one metric. How about attitudes toward life-long learning? Ability to flexibly change careers? Inter-personal skills (yes, they are skills that can be learned)?  It's not much of an exaggeration that we end up testing content that is cheap and easy to assess with machine-scores forms.  That ends up driving a lot of the curriculum and instruction.You'll find sites on line like the US Dept Of Education's *What Works Clearinghouse*, that purport to answer the "what works" question. Be aware that how one asks the question can severely constrain the answers. I worked on WWC when it first came on the scene, and the question asked for mathematics was roughly framed as "what materials-based year long interventions show better results as measured by standardized tests?"  Note that hiring teachers with advanced degrees, doubling the instructional time devoted to mathematics, etc., were not even on the table as possible topics of consideration. All ED wanted at that time was a comparison of textbooks and other curriculum materials. Here's my bottom line: there are no obvious or easy answers to your question. Seriously, we've picked all the low-hanging fruit here. Most scholars believe if you want to make a dent in academic performance (even holding our current definition and tests of "achievement" constant) you have to look at significant social reforms, including changing the anti-intellectual currents in American society.(Note: I have a PhD in Ed and am working in the field)
Yes, when wood frogs freeze in the winter they freeze completely. There's no heartbeat, no neural activity, nothing. When spring comes around and they thaw, it all starts back up again. There is a neat NOVA episode dedicated to all things cold that covered this specific topic, among others.The episode was called [Absolute Zero](_URL_1_).[Link to the episode on Netflix for the lazy.](_URL_0_)
Michio Kaku ought to be dangled by his toes in the Charles River in January."Outcome changes based on the observer" is a very misleading way to put it.  (Perhaps an educator could comment on whether they think it's a good idea to continue to teach and promote it this way...)One of the core factors here is that "observation" is not actually a passive activity - observing something involves a physical interaction with the subject of observation, whether it's bouncing a photon off it, or closing a slit.  How you choose to observe it thus affects the outcome.  This has nothing to do with a living observer having some sort of magical status, but rather that observing things at the atomic level tends to involve interfering with them, which means that how you choose to observe them can change what you observe.  This isn't unusual - consider taking a photograph in a dark room.  If you don't use a flash, the result is dark and lacking in detail.  If you use a flash, the result is bright and has more detail.  How you chose to observe affected the outcome - and when you used a flash, you flooded the room with photons, causing interactions with all the matter in the room.One thing I found confusing when I first learned about the double slit experiment is that when they talk about "observing" which slit the particle went through, they may be talking about something as dramatic as *closing one of the slits*.  The reason this doesn't bother a physicist is that (nowadays) they know that even if you put some sort of particle detector at the slits, its detection of a particle entering the slit inevitably interferes with the results of the experiment - because a particle detector is not passive, it interacts with the particles it detects.  So in the end, closing one of the slits is as good a way of "observing" which slit a particle goes through as any.  But it's hardly a mystery that the outcome changes when the observer closes a slit!(Note that I'm not saying that the double slit experiment is not mysterious - but it's mysterious enough without complicating it further with sloppy "gee-whiz" explanations.)
It really depends on what caused your fever. The infectious period associated with each illness can differ dramatically, from 24 to 48 hours to several days or weeks depending on the cause. For flu-like symptoms 24 to 48 hours is ideal, but for something like Salmonella infection you can shed the bacteria (aka still infectious) for over a week after being ill with it.
[Physics] is fine for your flair, though if there were a [Fluid Dynamics] flair it would be even better./u/RobusEtCeleritas answer is pretty close, but it's missing what it really means in context of the paper you're reading.Reynolds number Re = (density\*velocity\*diameter) / viscosity, and is a ratio of inertial force to viscous force.  In the limit where Re- > 0, There is essentially zero inertia and it can be completely ignored.  This *greatly* simplifies fluid dynamics analysis using the Navier-Stokes equations, and is generally applicable for flows that are in very small dimensions or very very viscous.  Some examples where you have zero Reynolds number are:* [Microfluidics](_URL_2_)* Locomotion of microscopic organisms* [Brownian motion](_URL_1_) of nanoparticles in a liquid* [Lubrication theory](_URL_0_)In the case of blood flow through a capillary that you are reading about, the capillaries are very small so that the Reynolds number Re <  < 1, so that any inertial effects are negligent and are hence being ignored.For the case of a finite Reynolds number, that simply means that inertial effects are now large enough that they *cannot* be ignored, and have to be included in any analysis.  The flow *might* be turbulent, but it could also be laminar while still having inertial effects.  If the Reynolds number is very large (typically Re > 2000 for flow in a tube or pipe) then inertial forces will dominate, which is observed as turbulent flow.
A few thing: Just because something has probability zero, doesn't mean it can't happen. It's improbably, but not impossible. Secondly, there is a difference If you pick a particular point in the interval, then that particular event has zero probability. So if you sit and way for your favorite event to happen, you'll likely never see it occur. But to find the probability of *something* happening, then you select the whole interval on where there is a 100% chance of *something* happening. So *something* must happen, and whatever thing does happen will have probability 0 of happening, which is why you can't pin down precisely what will happen before it happens.Now, what would happen if each point on the interval did have a nonzero chance of happening? If this were the case, and the distribution were continuous, then you could find a number P so that there would be an infinite number of points with probability greater than P of happening. Add up 1+1/P of these together and you will get a value over 1. So individual points having positive probability is more problematic than them having zero probability.To fix this the probability in continuous distributions is given by *area*. If you have some set in a continuous interval with a distribution above it, then to find the probability that something in the set happens, you find the area under the graph above that particular set. The "adding up individual probabilities to get 1" thing still makes sense. To add a continuum amount of things together, we use integrals. Integrals are defined as being the limit of rectangular areas whose individual areas go to zero, yet produce an overall positive area.
The short answer is no. Let me paint a picture for you:If you go outside and have let's say a car a meter in front of you, a house 100 meters away, a tree 200 meters and a mountain range on the horiszon.Now when light hits these objects the bounce it back, to your eye in this case. The light "source" is as far away as these objects. In the case of nearsightedness the further away objects get blury because your eye is IIRC a little to long inside, which means the angles get screwed up when the light gets to the back of your eye. Now monitor is a single light source right in front of you (or a bit further if we are talking about a TV).That means the angles are fine.Its like looking at a painting, its a 2D object that you are looking at.
Other substances that expand on freezing are acetic acid, silicon, gallium, germanium, antimony, bismuth, plutonium and also chemical compounds that form spacious crystal lattices with tetrahedral coordination._URL_1_**Edit:** There are multiple MSDSs that say "Acetic acid should be kept above its freezing point (62°F), since it will expand as it solidifies and may break container."_URL_3__URL_2_But there are other sources that say acetic acid becomes *more* dense as a solid (thanks to /u/DancesWithWhales):1.049 g cm−3, liquid1.266 g cm−3, solidSource: _URL_0_Is there a chemist in the building?
It's based on measurement of the engines, of course.  But H2O gives the best specific impulse in an ideal rocket engine.  The reason is that self-contained rockets have to carry two kinds of supply:  *fuel*, which is matter that contains energy to be used for propulsion; and *propellant*, which is matter that can be loaded with negative-going momentum and discarded (thereby giving the rest of the rocket forward-going momentum, yay!).  The reason you need both is that you need *energy* to load *momentum* on the propellant.Dealing with temperature is a secondary concern -- it's easier and better (from the armchair perspective) to deal with the basics of mass, momentum, and energy.  Temperature only enters since SSMEs are heat engines, converting chemical energy - >  heat energy - >  mechanical energy.The kinetic energy of the propellant scales like *1/2 m v^2* ; the momentum of the propellant scales like *mv*.  The idea is that you want the most momentum per unit propellant you can get - that way you don't have to discard so much of the rocket.  So you give it a high exhaust speed as you throw it away (which raises *mv*, so your momentum performance improves).  But the energy price you pay is proportional to *mv^2* , so the more propellant-efficient you are the less energy-efficient you are.Chemical energy storage is so marginal for orbital propulsion (it barely carries enough energy) that the only way to make chemical rockets work is by combining the fuel and the propellant.  You react the fuel to make free energy (i.e. burn fuel to make heat!), and then you use the reaction products (which are now hot but useless) as propellant.So the most mass-efficient way to make a chemical rocket work is to use reactants with the highest reaction energy you can, and throw the whole shebang out the back of the rocket nozzle after it is fully reacted.  That gives you the most available energy per unit expended mass, and also the most available momentum per unit expended mass.If you "run rich" to lighten the exhaust products (by putting extra hydrogen in the exhaust stream) then you are spreading your available energy over more propellant - so you are more energy-efficient.  But you turn out to be less mass efficient then, since you could replace some of that hydrogen with oxygen and eject the same total amount of mass with slightly more kinetic energy.  In terms of temperature, running hydrogen-rich cools the exhaust stream more than it benefits you with the lightness of the individual particles. The molecular mass really only matters in the case where you are limited in the amount of energy you can put on each particle, but you aren't incurring a large mass hit for carrying that energy with you.  Then you want light particles so you can get them going as fast as possible.   The energy per particle imposes a negligible mass hit if you are using, say, nuclear power or solar panels to get that energy -- the former because nuclear fuels have about 10^6 - 10^7 times as much energy per gram as chemical fuels, and the latter because you don't have to carry sunlight around with you, you can just collect it and use it as you go.The direction of the trade (heavy exhaust particles, light exhaust particles, etc.) depends on the physics of your rocket engine.  Certain types of ion propulsion, for example, are energy-per-particle limited; others are exhaust-speed limited; still others are limited by esoterica like how much the fuel erodes the engine itself on the way out.  The optimal propellant choice thus depends on detailed engineering trades.Edit: that BOTE analysis is correct for an ideal engine, but neglects nozzle efficiency.  Molecular mass has **two** effects: the simple one I described and debunked above, and a more complicated one that changes the efficiency of the nozzle in converting heat energy in the combustion chamber to bulk kinetic energy at the exit aperture.  In general, you need a larger nozzle/bell for the same efficiency, with heavier exhaust molecules.  The nozzle efficiency issue is actually a big one since nozzle/bell mass is a major element of engine design, and a major mass element for the dry vehicle.  So, even for conventional chemical thermal rockets like SSMEs, the answer is really just that the optimum depends on the detailed engineering trades for the particular rocket.
It really depends on how you define "intelligent," but for most definitions the answer is that it's pretty far away.  AI's getting better, but sci-fi-style human-like AI is decades away at best and quite possibly a century or more away.  Some people think it's straight up impossible, although I, and I think most other AI researchers, strongly disagree with that, even if we don't necessarily expect it within our lifetimes.As for how it would impact our lives... it's hard to predict.  AI's already getting used all over the place, but obviously truly intelligent AI would be quite different from any of the AI we have now.  I think MandatorilyMutatinal is right that once AI starts getting close to that level we're going to see a lot of interesting ethical debates becoming very prominent in politics, and how things turn out depends on where all those debates land.  It also depends on what the AIs are actually like.  Sci-Fi robots tend to be extremely human-like, although often a bit more socially awkward and logical and much less emotional, which isn't an unreasonable way to depict them, but that doesn't mean that's what we'll end up with.  Computers are very different from humans, and creating an AI that is as intelligent as a human doesn't necessarily mean creating an AI that behaves like a human.
This is something I do research on (some of my own papers and those of colleagues are cited below).  Generally speaking, if a fluid is convecting, warm water rising and cold water sinking, its temperature will be nearly uniform, and heat will flow rapidly to bring it into thermal equilibrium with the walls of its container.In Europa's ocean case, temperature is pinned to the freezing point at the ice/water interface, but the seafloor sets a particular *heat flow*, not a fixed temperature.  This means that, provided there's convection driven by heating inside the moon, **the whole ocean should be within a degree or two of freezing**.  Computer simulations bear this out.Even near thermal vents, the hot water mixes with surrounding cold water so quickly that temperatures would be close to freezing within a few hundred meters of the vent.The only way Europa's ocean could *not* be near freezing is if variations in salinity created density differences that prevented top-to-bottom convection, or if the pressure and salinity were low enough that [the weird thermal expansion of freshwater](_URL_1_) came into play.  Unfortunately, the salinity of the ocean is still a mystery.One final thought: I said "within a degree or two of freezing", but I didn't say zero degrees C!  If the ocean is very salty, its freezing point could be lowered by quite a few degrees; if the ocean has some ammonia in it, and it might, the freezing point could be tens of degrees below zero C._URL_0__URL_2__URL_5__URL_4__URL_3_
No...both constants show up in things like the blackbody spectrum, the Bose-Einstein distribution, and the Fermi-Dirac distribution. Dividing by them without context doesn't get you anything meaningful. There is Planck temperature, which is proportional to the square root of the Planck constant, over the Boltzmann constant.
Tons. With a PhD:  You could be a professor (jobs are hard to find), you could work at a pharmaceutical or biotech company ...
It could be a biofilm caused by [Serratia marcescens](_URL_0_), a bacteria.
You can take the natural logarithm of any nonzero complex number, it just might be different logarithms that you work with. In other words, it's complicated.If you have the complex plane, that is, all real and imaginary numbers, then you can have the exponential function e^(z), where z is any complex number. In particular, e^(ix) is equal to cos(x)+isin(x), hence e^(ipi)=-1. If we try to define a logarithm in the normal way, we run into problems. The normal way to define log(x) is that y=log(x) is the number so that e^(y)=x. The problem is that  e^(ix)=e^(ix+2ipi), so if we have log(z)=ix, then we should also have log(z)=ix+2ipi. For instance, e^(ipi)=-1, but also e^(3ipi)=-1, so the log should be both ipi and 3ipi. Obviously this can't happen.What is happening here? Well, the numbers e^(ix) give the unit circle that lies inside the complex plane, the point cos(x)+isin(x) in the complex plane is the same as the point (cos(x),sin(x)) on the Cartesian coordinate grid, which is a point on the unit circle. So increasing x makes you circle around the origin by an angle x. If you go to the angle x, and then go around a whole time, then you'll end up at the same spot. Trying to take a logarithm is then trying to ask what angle a point on the unit circle is. This might seem obvious at first, just don't go around multiple times, but there are situations where we my view an angle as 3pi/2 and another where we view is at -pi/2. So it is unclear what value a logarithm should have because each point on the unit circle will have a multiple different angles to give the logarithm.We can fix this though. The issue happens because we are allowed to go around the circle a whole turn, so let's not let that happen. If we 1.) Fix a starting point, like log(1)=0, and 2.) Don't allow ourselves to go around a whole circle, then there will be no issue. To do this, we choose a ray pointing out of the origin, out towards infinity and we say that we cannot pass this line. We then say that the value of log(z) is whatever value it should be as long as we keep track of log(z) by originating at a fixed starting point and then making a path to z without crossing this ray.For instance, we can choose this ray to be the ray that points straight down, and we can have our starting point be log(1)=0. If we then rotate around the unit circle, we'll get log(e^(ix))=ix, as long as -pi/2 < x < 3pi/2. In this case, log(-1)=ipi. We're also free to start with log(1)=2ipi, in which case log(-1)=3ipi. Changing the starting point and changing the line that we shall not pass gives different logarithm function that all serve the same purpose. Of course, if you're not working with complex numbers, then negative logarithms mean nothing. And when you do work with complex numbers, you have to be careful how you work with logarithms.-----------------------------------------------------------------------You can get around this issue of having this line of no passing and starting points by moving from the complex plane to a different object. You place the positive part of the real axis where it usually would be, but instead of extending it to the complex plane by just rotating it through angles, as we rotate, we also lift. [Like a spiral staircase](_URL_1_). By the time we've gone around one whole circle, instead of winding up where we began, which would be the case if we stayed in the plane, we're actually pointing in the same direction, but a floor above where we started. We can continue rotating, in both clockwise and counter-clockwise directions to get an object that is an infinite spiral. A point on this spiral will be determined by how far it is from the origin, what direction it is pointing in *and* what floor it is on. Or, by the complex number it lives over and the floor it is on. If we're pointing along the negative direction, on the first floor and are a distance 1 away from the origin, then we're at -1 and on the first floor. Since this if the first floor, the logarithm is just ipi. If we go to the second floor, by spiraling around once more, then we're still at -1 but a floor above. The logarithm of this point is then 3ipi. On this infinite spiral, the logarithms are all nicely defined, it's just a little unclear what the logarithm of a number is because you need to also specify which floor it is on. So log(-1,1st floor)=ipi, log(-1,2ndfloor)=3ipi, log(1,5th floor)=8ipi etc.There are related issues when talking about square roots and cube roots, etc. These all have new, different surfaces that classify them, like this staircase does for logarithms. These objects are called [Riemann Surfaces](_URL_0_), and they're super important for everything.
Molecules not atoms are sensed by [olfactory receptors](_URL_0_)things do not have a smell per se , certain molecules activate receptors causing the sensation of smell in the brain.Think of a receptor as a lock and the odour molecule as the key. If the key fits and unlocks the lock then an odour is smelled.
Temperature increases volatility, and taste is roughly 75% olfactory. On top of that it affects texture and color, which also play a role in flavor. Taste in foods with a temperature higher than 86 degrees F or lower than 68 degrees also becomes more difficult to distinguish- Hot coffees taste less bitter whereas slightly melted ice cream tastes sweeter. Other variables include time of day it was eaten, age, gender and degree of hunger of the taster.
Yes, different ones are used not only for different missions, but also for different purposes within the same mission. This is mostly important for the attitude control system because each sensor gives information in a different reference frame, so the onboard software must be able to convert between them.Rather than "rotating" or "stationary", we call them inertial or non-inertial .Earth-centered reference frames include [WGS84](_URL_0_), used by GPS, which is non-inertial; and [ECI](_URL_1_) when an inertial frame is required. Similarly there's a SCI (Sun-centered inertial) frame, commonly used for interplanetary trajectories.In inertial frames, the x axis usually points in the direction parallel to the vernal equinox, given by the intersection of the ecliptic plane and Earth's equatorial plane. However this changes very slowly due to the precession of the equinoxes. I've seen some efforts to define more precise reference frames based on well-known pulsars that lie close to that point as seen from Earth. The y axis points 90° ahead along the frame's fundamental plane, which is the ecliptic plane for the SCI frame, but ECI frames can use the equatorial plane instead. The z axis points north following the right hand rule.For Rendez-Vous and Docking manoeuvres, a body frame has to be defined for each of the participating spacecraft. This is normally done at design time. It's important so that docking ports can be aligned, though a small error is tolerated.
Without having the cones ourselves, we can never know exactly, but without getting into philosophy, one method of trying to perceive what their vision is like is via metaphor. This Radiolab podcast (partway through it) does just that, using a choir to build the metaphor for the vision of a butterfly and a mantis shrimp: _URL_0_
[Global energy consumption is on the order of 200 TWh per year (= 720 petajoules).](_URL_0_)[Total solar energy absorbed by the Earth is about 3,850,000 exajoules per year.](_URL_1_)Divide the two and you get about 2E-7. The amount of energy humans use per year is about 2 ten-millionths of the amount of energy absorbed from the Sun. Primary energy consumption, then, is negligible compared to something that affects how much energy is absorbed from the Sun.
The active ingredient in most non-medicinal, non-sunscreen skin lotions is lanolin._URL_0_There is a *small* amount of evidence that applying lanolin does help minor skin wounds heal somewhat faster. It is not well known how that occurs--if there is some chemical action upon the wound itself, or if the lanolin just keeps the skin more supple which prevents tearing the wound open as much. You can buy pure anhydrous lanolin online; there are sellers on eBay. The smell is rather,,, animal-like. But it does work well as a skin softener. It softens your skin better than petroleum jelly does. It doesn't leave your skin greasy like petroleum jelly does, but it does leave your skin "waxy".
It's an innate characteristic. If you have a very small child, you can tell if they are left handed or right handed by handing them a crayon and asking them to draw a picture. They'll use their dominant hand.
First: steroid hormones are a large class of hormones with widely different effects. Even look at the two you named. Testosterone is a sex hormone involved in reproduction, while cortisol is a glucocorticoid, involved in energy regulation and stress responses. Weirdly enough, high levels of either can suppress the other. Anyway.Check out [this](_URL_2_) paper. Even if you don't have access the whole thing, you should be able to see the abstract which should give you an idea.Its an issue of resource partitioning. Animals have a limited set of resources (energy, carbohydrates, amino acids, whatever) that they have to divide up between body maintenance (including the immune system) and reproduction. Normally an animal wants to keep itself together, so most of those resources go towards body maintenance. When its time for some of that sweet sweet lovin', testosterone and estrogens are increased. Among other effects, the immune system is suppressed, freeing up resources for reproduction, including courtship, mating, pregnancy, and supporting the offspring (assuming they're not left to their own devices). The paper I linked above seems to imply that this trade-off only occurs when resources are limited. If you have plenty of food, enough to support both full body maintenance and reproduction, there's no trade-off to be made and you get the best of both worlds. I didn't look too much at glucocorticoids because I couldn't find a straightforward paper like the other right off the bat, so this is going to be a bit of speculation. My work is about glucocorticoids, so hopefully this won't be too far off the mark but if someone knows better please correct me.Glucocorticoids are released under stressful conditions like exposure to a predator, new environments, or unsafe environments like the open arms of an [elevated plus maze](_URL_0_). Acute (short-term) elevations of glucocorticoids actually boost the immune system, while chronic elevations are immunosuppressive. ([Source](_URL_1_)) The acute part makes sense-if you get hurt running from a predator, your immune system will be ready to go. But if you're in a constantly stressful situation, your energy needs to go to getting you *out* of that situation. An immune system won't do you any good if you get eaten, so the immune system is suppressed, freeing up more energy for whatever else needs to be done.
Sound speed actually goes *down* with density. The only reason why materials like steel or water have a higher sound speed than air is that sound speed increases in materials that are *less compressible.* Because fluids and solids are usually *much* less compressible than gases, this offsets the increased density and causes an increase in sound speed.In case you are curious:v^2 = B/ρWhere v is sound speed, B is bulk modulus, and ρ is density.Now, on to your real question: Can a material have a sound speed higher than the speed of light? The answer to that question is a resounding **No.** Even setting aside the question of causation, it turns out that the maximum sound speed that can be achieved is actually the sound speed of a relativistic fluid. The sound speed in such a fluid is equal to *the speed of light over the square root of 3* (c/√3). If this seems random, just keep in mind that the 3 in the denominator comes from the number of spatial dimensions in our universe. (Source: [Relativistic fluid dynamics](_URL_0_))Does this figure into the observable universe in any way? Surprisingly, yes! It turns out that neutron stars (which are highly incompressible, because they're essentially oversized atomic nuclei) have *very* high sound speeds near their core. The sound speed is determined by the star's mass, which in turn, means that one upper limit of the neutron star's mass is given by its internal sound speed. If the internal sound speed would break the limits of causality and go too high, the neutron star collapses into a singularity instead!Hopefully this answers your question!
Essentially it’s density.  Packed snow has more snow in a smaller area so there is less surface area for heat transfer. for example, a ball of snow is exposed to the sun less than an equivalent amount of snow laid out flat.Also the snowball can disperse the heat it’s absorbing much more because there are more particles nearby and they are closer than snow laying flat
You can check out [these past posts](_URL_0_) regarding blood iron in a magnetic field. The short answer is that iron in our blood isn't ferromagnetic, and won't be drawn to a magnet like iron filing would.There can be effects on the nervous system as well - that is the basis behind [transcranial magnetic stimulation](_URL_1_).
The [wiki](_URL_1_) article actually has a surprisingly decent summary of the basic timeline. Quarks in particular can exist up to arbitrarily high energies (i.e., arbitrarily early times after the Big Bang) in the standard model of particle physics, though above a certain energy (such as the Planck energy) we don't *really* know how things behave anymore.The key event for this is [cosmic inflation](_URL_0_), a period of accelerated expansion believed to have occured in the very early Universe driven by a type of exotic matter. When inflation ended, the energy driving it went into fundamental particles like quarks and electrons. This would be the origin of most of the quarks (and other matter) in the Universe today.
The whole "interfering with itself" part - when considering light as a particle - is probably what throws people off.The mantra about light is that it travels as a wave, but interacts as a particle. If we follow that, we'll see that "interfering with itself" isn't weird at all - that's what waves do. And it only acts like a particle when it is time for interaction with the detector - meaning at any time, there can only be an excitation in one location. >  I'm lost because most sources online just say ,"Oh this is how it works isn't is weird?" "Its both a particle and a wave!" I can't find a straight explanation.Well that is pretty much _the_ straight explanation. Light is something that exhibits behaviour of both particles and waves.
> What observations did Newton make that lead him to believe gravity acted instantaneously?Tycho Brahe and Johannes Kepler had detailed observations of the motion of the planets. They were incredibly precise for the time, but were nowhere near the precision one would need to observe deviations from Newton's laws due to relativistic effects, and indeed these deviations are very small. Newton's law of universal gravitation describes the motion of the planets incredibly well, and certainly within the experimental error of the measurements available at the time.In his era, there were no experimental observations to indicate gravity takes time to propagate, his laws agreed incredibly well with available data, and they were based on some very rational first-principle ideas, so there simply was no reason for him to think them wrong.[There's a list of some experimental evidence for relativity here.](_URL_0_) The level of necessary experimental precision and knowledge of other fields like electromagnetics necessary to actually observe these things simply didn't exist at the time. > What problems would his theory have if gravity took time to propagate?Basically everything that relativity corrects. Realize that Newton's laws aren't "wrong" per se, but taking the limits general relativity for speeds much less than light, and instantaneous gravity, you arrive back at Newton's laws.
The long answer is fairly intricate, but basically, a finished mRNA that is present in the nucleus will have a sequence that indicates it is ready to be exported into the cytoplasm. This sequence is added or modified during post-processing of the raw mRNA transcripts. These signals are recognized by transport proteins called the nuclear pore complex that are present in the nuclear membrane. These complexes are responsible for all of the transport of large molecules in and out of the nucleus. If you want a way more intensive look at it, here is a review article _URL_0_If you have trouble viewing it, you may need to visit a college library. Some journal articles are not available online to the public, and since I'm on a college campus, most are available to me that may not be visible to you.
Some things are Lewis acids that aren't Brønsted,, e.g. boric acid or aluminum trichloride. They can react with Brønsted bases in ways that is quite similar to how H^+ can, so it makes sense to classify them as acids.For example, many organic reaction that run faster in acidic medium also runs faster when a Lewis acid is present.Lewis acid-base reactions aren't redox reactions because the electrons are not completely transferred, but end up being shared between the acid and the base, meaning that a bond is formed. For example:2Fe^3+ + 2I^- - >  2Fe^2+ + I*_2_* is a redox reaction, as the electrons are completely transferred,  and no bond is formed.Fe^3+ + Cl^- - >  FeCl^2+ is a Lewis acid-base reaction, as the electrons are not completely transferred, and the reactants end up being bonded to each other (sharing the electrons).**edit:** typoes.
Well, in base 1369.003, you would get a 10:1 ratio. This is applicable to any proportion you want.
Entropy is not a simplification, it is a quantifiable measure of the stability of a certain lattice structure. In quantum mechanics, the higher the local potential is, (the Energy is the spatial/reaction path integral across that potential), the higher the probability that the wave function of a particle displaces at a higher rate, (faster reaction rate) to a new stable configuration.This physics is what is encompassed in the Gibbs fundamental equation: T * dS = dU + P * dV - sum_{i \in Set of possible configurations} \mu_i dN_iwhere \mu_i is the chemical potential of a configuration and dN_i is the set of particles moving to that configuration.The Gibbs dU is directly related to the probability that a certain configuration appears, (a word like "affinity" would be appropriate as well, but unncessary :P), because, as stated earlier, it affects the local potential.I personally am not a biochemist, but I would surmise from the above that the proton moving across the membrane and facilitating the oscillation of the ATP synthase has the highest affinity/probability of any reaction that could happen with that ATP synthase, and so, it is what is observed 99.9999999% of the time.Take some 2nd or 3rd year QM classes, should clear things up.
The human genome project sought to develop a reference genome for humans.  ~10 people were sequenced for the project, and because of this there are alleles in the human genome reference (by which I mean the reference actually contains a rare allele, not the common one most people would have).  So I'd have to say that the HGP really was just out there to find "what could vary".Another project, started about 6 years ago was the "thousand genomes project".  TGP sought to sequence several hundred people from different populations (Africa, Europe, Asia, America) to find all common alleles in these populations. Really the goal of TGP was to find much of the natural variation in humans.  There are a number of large scale sequencing projects on-going (ESP, CHARGES, UK10K (UK100K?)) that are also going to uncover natural variation in healthy adults.FYI, the human genome reference is updated every few years.  Release 38 should be out before the end of the year.
>  25-30% of our total calorie intake for the brain seems like a lotThe typical estimate is that your brain uses about 300-400Kcal per day (typically around the upper end) which is about 18-20% of an average height man's daily calorie intake. Yet the brain is only about 2% of your body weight. It is often erroneously cited that the brain requires these calories in the form of glucose and in turn this is used as justification that you should consume at least 100g of carbohydrates per day (as there are 4Kcal per g of carbohydrate). >  How is that even measuredFlux in oxygen consumption (masks over people's faces), changes in neural blood flow and pressure have been used to estimate how much more calorie burning is being done while thinking hard. Today Magnetic Resonance Spectroscopy (MRI) can be used to directly measure oxygen flow/consumption in the brain from there you can directly calculate the amount of respiration and calorie consumption. >  Do thinkers and dreamers burn more calories via the brain than a "stupid mindless person"?It turns out that the brain's energy consumption is somewhat constant irrespective of the cognitive load. To my understanding it is changes in the neuron firing patterns and connectivity that represent changes in thinking. It is not simply that increased thinking increase the amount of neuron firing across the board, however this is not my field and perhaps someone with deeper expertise can fill in more details there. >  Again how is that even measured if research is done on it?To do the experiment about the effects of thinking hard you have someone lie at rest in the MRI machine to get baseline data and then you get them to solve hard problems (often arithmetic) while still in the MRI machine. >  On a brain to calorie% ratio, what animals are in the top with us humans?To my understanding energy consumption per neuron is not that much different for most animals. What is usually seen as an important measure is the brain-to-body-mass ratio. Humans are nowhere near the top here. Ants can have 15% of their body mass in their brains. Animals which are similar to humans (ratios within the same order of magnitude) are small rodents, small birds, many primates. Animals towards the bottom are things like hippos and whales where there brain might be less than a 2000th of their total body weight. >  What parts of the brain functions spends the most energy?I don't know this but from the info above it seems unlikely specific bits of the brain use much more than other bits. I hope someone can infill some more information hereCitations:_URL_0__URL_2__URL_1__URL_3_
The human circadian rhythm is a little over 24 hours.  At night, we have signals in the brain that make us sleepy; blue light can screw up the release of melatonin. Things like testosterone and cortisol follow this diurnal rhythm.Sometimes people are forced into abnormal sleep schedules, either by work (shift work) or because they want to stay up playing video games (social jetlag). Military personnel on submarines used to have to stay up for 6 hour shifts and have 12 hours off, to make an 18 hour day.  However, that really negatively affected their sleep schedules and quality of life.  They have switched it to 24 hour work days (8 on, 16 off) and quality of life has improved, as well as mission execution and alertness. People weren't nodding off anymore.   _URL_0_Circadian misalignment, ie sleeping at 2am to 10am every night instead of 11pm to 7am, has been shown to have a lot of negative effects on the body.  Shift workers who work at night have higher rates of heart attacks (possibly from inflammation), diabetes and obesity (changes to appetite hormones and cortisol and metabolism are all possibilities), psychiatric issues, and other things.  This is a pretty big field of research   _URL_1_
You determine the weight of an object by weighing it in a vacuum chamber. For the gas you compare two measurements. One of a container filled with nothing (vacuum), and the other with a container filled with gas. The difference in weight of the two measurements is the weight of the gass in the container.
It depends on the shutter speed, first of all. Assume the shutter speed is 1/60 s. Also, you have to factor in the size of the tire, not just the rims. 17" rims can easily support tires with 25 inch diameters. If you're going for a full rotation, the car has to travel 25pi inches (one full rotation of the tire). So 25pi inches x 60 = 1500pi inches per second  (slightly more than 4700 inches per second), which is close to 270 miles per hour.However, as you can see, there are a ton of variables, like shutter speed, tire diameter, if you're going for a full rotation, etc etc etc.
A basic principle of heat transfer is that the bigger the temperature difference is the faster heat will transfer between the two through conduction. This means that by keeping his apartment colder than he would with his heat on, he will be absorbing energy (heat) from his neighbors at a faster rate. Since they're maintaining the temperature in their apartment, this costs them more money. So yes, his decision does affect his neighbors.This also means that the warmer his apartment is the less money he is saving by "stealing" from his neighbors, until he eventually makes the temperature at his floor higher than their ceiling, and he starts giving them free heat. Most people already understand this principle without realizing it. Keeping your heat at 70 is going to be more expensive than keeping it at 50. In a perfectly insulated house (no heat transfer between outside and inside) they would cost the same once you got to that initial temperature. Obviously this isnt the case though, just going to show you how important insulation is to heating bills
A board that can hover over an arbitrary surface? probably not. You'd need some kind of antigravity. And gravity *not* being like electromagnetism means that we know of no way to get a repulsive gravitational effect. So, in short... not any time soon. Maybe some day in the distant future when we have an understanding of what dark energy is, as that's the closest physical thing we know of to antigravity.
Your nasal cavity is designed to humidify and heat the air you breathe in.  It also traps dust and other things so that they don't enter your lungs.  It doesn't matter as much when you're breathing out, and it's easier to expel air from your mouth.
An optical circulator is typically a 3-port device where light incident on port 1 goes to port 2 and light incident on port 2 goes to port 3. This "nonreciprocal" operation is possible because the circulator uses a magnetic field to break the symmetry of the propagation direction.
Well...yes, it is possible, *but:*Space is not entirely empty.  Even the void between galaxies contains very diffuse ionized gas.  It may ve only a few particles per cubic kilometer, but it's there.  It's mostly hydrogen, with a bit of helium and a tiny, tiny scattering of lithiumWe know this because we can see the absorption lines it leaves in the spectra of distant galaxies.  We know it's not antimatter because it surrounds our own galaxy, which is *not* made of antimatter, anthers is no sign of matter/antimatter annihilations occurring near the galactic rim (the annihilation reaction tends to produce gamma rays with a very specific energy level:  511-kev).Likewise, we know that none of the galaxies we can see is made of antimatter because of the lack of this 511-kev emission anywhere in the sky.  If there were large amounts of antimatter out there, it would be obvious:  matter and antimatter are strongly attracted to each other through electromagnetic and weak nuclear charge forces--and then they convert each other entirely into energy.  Lots and *lots* of energy.
Your parking voucher is likely printed on a thermal printer.  This means that there is no ink.  Instead there is a chemical that changes color when heated.  It also changes color when exposed to UV.  So it doesn't go anywhere, it just changes color.
We can measure the velocity of all the other stars and compare it to the center of the galaxy to express everything relative to the center.
Bacteria are EVERYWHERE. Even the statement that fetuses remain sterile in the womb has recently come under scrutiny (_URL_0_). This aside, the majority of bacteria arrive during and after birth (within the first 24 hours). Almost immediately exiting the uterus, babies are exposed to a number of microorganisms from the mother (bacteria in the vaginal tract and even faecal matter) and immediate environment (handling physicians, surfaces, etc) which rapidly colonize the surface of their skin. Interestingly, the colonizing microorganisms can vary on whether the baby is delivered naturally, or via caesarian section (_URL_2_). Organisms can subsequently gain access to the digestive tract following the first meal in a process which can vary from individual to individual depending on whether formula or breast milk is provided. Colonization early in life, such as following birth, may have lasting impressions on the health of an individual throughout their lifetime. The statement "we are said to be 10% human and 90% bacteria" arises from the fact that bacterial cells outnumber human cells 10:1 (approximately 10^14 - (100 trillion) versus 10^13 bacteria:human). We physically appear 'human' because the size of a eukaryotic human cell is much larger than the size of a typical bacterial cell. What is really interesting is that the genetic diversity and functional capabilities of all these combined bacteria is MASSIVE. Bacteria add about 8 million genes to our normal set of 22,000 human genes. We are just beginning to understand what a huge role these organisms play in regulating normal functions of human physiology, and appreciating the fact that the microbiome of an individual functions as an independent organ in its own right. Disruption of microbial communities has been associated with many diseases including diabetes, obesity, nutrient deprivation, and inflammatory spectrum disorders like IBD, colitis and diarrhea. (_URL_1_)
Yes! Because mass has two effects:(1) Mass gives you how strong your gravity is (i.e. how much it weighs)(2) Mass is "resistance to force"In zero-gravity (or free-fall, which is what astronauts are actually in), number (1) doesn't really matter. An astronaut can stand with a 200 lb weight above him or her and will of course not feel any particular force.However, (2) does matter a lot! If an astronaut throws a 2 lb hammer, it will fly fairly well. If however, an astronaut shoves another astronaut (weighing say 200 lb including the suit), that astronaut won't go as fast - and the astronaut would definitely feel it takes more effort to get them going. Similarly, if an astronaut floated up to the space station and gave it a shove, it wouldn't really budge at all - the astronaut would feel like they're pushing off a solid object really.
Being pedantic, objects don't emit light rays at all, they emit photons. Light rays are mathematical constructs which help us solve some problem. But, the heart of the question remains- does a light source really put out an infinite number of photons? Well- no, because that would require an infinite amount of energy. However, they do release photons in random directions, and the photons are dense enough that for your case, it is a good approximation to say that the photons "fill" the space. Some math to show this:Imagine you have a single Compact Fluorescent Bulb (13 W), and you're about 3 meters away from it. [Reading up on CFBs](_URL_2_) we see that they are about 10% efficient (so about 1.3 Ws are actually making visible light) and they put out their light at a color of about 4000 K. By looking at the charts on that graph, you can see that the average wavelength of a photon emitted from a CF is about 600 nm. A photon of this energy has an energy of about [3E-19 Js](_URL_0_) which means a 13 W CF bulb (at 10% efficiency) releases about 4.3E18 photons per second. Ok, if you are 3 meters from that bulb, then those 4.3E18 photons are spread over a surface area of [113 m^2 ](_URL_1_). That means that every square cm, 3 meters from the bulb have 3E8 photons passing through it, per second (that's 300 million!). So, there is not an infinite number of light rays, but it might as well be. There are 300 million photons coming through any square mm piece 3 meters away.
Probes like the Voyager are actually just following a pre planned trajectory, NASA never has to send them coordinates of where to go. When a probe like that is launched it is given enough velocity in order to escape the gravitational pull of the Sun, this is called the escape velocity. NASA just timed the launch such that it's escape trajectory would take it by certain planets on it's way out of the solar system.Messages are still sent and received to and from deep space probes though they just serve other purposes. Information is sent by something called the Deep Space Network which is a group of large radio antennas separated around the Earth which was designed to communicate with deep space probes such as the Voyager. Information is received on the spacecraft by a radio antenna, a probe like the Voyager has a pretty big dish in order to receive signals that far away from Earth.
Many animals, especially mammals, not only have sex in multiple positions but also partake in oral sex, masturbation, and homosexual sex. [Bonobos](_URL_0_) for example, will even use sex to diffuse tense social situations.
A [rum cake](_URL_0_) apparently has about 1/2 a cup of rum in it, meaning 41 ml ethanol at a typical 35% (volume) alcohol content, equaling 32 grams of ethanol. That requires 32*841/1000 = 27 kJ to vaporize. By comparison that's the amount of energy required to heat 1 kg of water by 6.5 degrees C. It's not an insignificant amount, but it's not a lot for an oven, which puts out around 2.5 kW - enough power to vaporize the ethanol in 11 seconds (in a fictional scenario where all the power was going to that one thing) So without going into more detailed calculations, all or most of the alcohol in that case is almost certain to vaporize.Measuring ethanol content in food is possible, I strongly doubt your assertion that food labs _wouldn't_ have standardized methods and protocols for assaying it. But doing it accurately would require some fairly sophisticated chemical methods (like GC or HPLC) in order to separate the ethanol out from the thousands of other compounds present. You can't do it at home.There's nothing for a 'reputable study' to prove, or even study. Alcohol will vaporize if you heat it above its boiling point of 78 C, I'd think that much should be obvious. Whether or not _all_ the alcohol in some foodstuff vaporizes depends entirely on how much heat you're transferring to it, which depends on a whole bunch of things but most significantly the cooking time and temperature. There is no reason to think you could reach any general conclusion. Besides which, there is no real 'zero' ethanol content. Most food contains ethanol anyway, especially stuff like bread that have yeast, but also almost everything else that's not pasteurized because there are yeast spores everywhere. [This study](_URL_1_) measured 1.662 g ethanol/100g in a Bourbon cake, which one might expect to have a minor amount of alcohol in it, and 1.066 g/100 g in an Apple Walnut Roll, which many would probably _not_ expect to have any alcohol in it. They used GC to determine the alcohol content.
Eventually you get something called nonlinear propagation where the air is squished so much that it changes the squishiness.
Well, if we ignore the other aspects that'd make an "oxygen lighter" hard to create, then yeah, it'd pretty much look the same. Many reactions use a stream of oxygen to create an exothermal reaction in an enviroment filled with the reactant, which looks a lot like the lighter you described.
It's because of the rotation, so the core sample from the pole will be less massive.
The oxygen sensor in your engine will tell the computer in the engine how much fuel needs to be provided for combustion in stoichiometric proportions. Colder oxygen/air is more dense, so more air per unit volume enters the engine, whereupon the oxygen sensor directs more fuel to be used, which leads to more power.
It's not going to hurt you. The pH of baking soda is about 9. 'Milk of Magnesia' a laxative you can buy from your local drugstore, and drink. It has a much more 'caustic' pH of about 10.5. Many commercial soaps/shampoos have pHs that are 10-11. In fact, with regard to industrial chemicals, stuff with a pH of 9 is still considered 'neutral'.As for the other worries: Skin oils are very slightly acidic, but I'd hardly call that an 'acid mantle'. Disulfide bonds are broken by acids, not bases.I wouldn't worry about the 'pH balanced' advertising hype.
You get a "[domain wall](_URL_0_)" with two (potentially [false](_URL_2_)) vacua on either side, and the vacuum with the lower energy wins. Associated with a domain wall, of course, there is a lot of energy (the cost for continuous fields which have to go through the large potential barrier between the vacua). A domain wall can be modeled as a classical surface with some tension. Much of this was worked out in a classic [paper by Coleman and de Luccia](_URL_1_).EDIT: I forgot to say that the domain wall will (probably) expand outward at the speed of light. What I meant by the lower vacuum winning was that the bubble with lower vacuum energy will "eat into" the other bubble.
The elements whose atomic emission lines are most commonly used to generate green colors are copper, barium, and boron. Sometimes just lining the combustion chamber with copper or barium chloride salts is sufficient if your flame burns hot enough, but you can get a stronger green color with volatile boron compounds such as [boric acid esters](_URL_0_) which burn with a green flame.
Alien life could be, well, totally alien to us.  So alien that we might not even recognize it.  But when you're searching for life in the vast emptiness of the universe, you use what you know as a starting point.  As fun as it is to speculate about alternatives, we have exactly one confirmed life-supporting planet and it's full of carbon-based critters that need liquid water.
Terminal velocity for a tiny object is quite low -- they fall slowly.
What might some reasons that digital storage is constrained by 0  &  1? i.e. there either isn't, or there is a charge? Why cant there be 'degrees' of charge (strength of field) so you end up with 0, a little bit of charge, a lot of charge or 1?
I deal with microwaves more than full spectrum visible, so..One thing you can look at is firn (old dense snow on glaciers). It, and glacial ice can start looking quite blue. _URL_1_, _URL_2_ That's more from transmission through the snow.Certainly, these shadows will be illuminated both from diffuse sky light, as well as light transmitted through the snow. Transmission of light is pretty good for visible wavelengths, roughly speaking at least half a meter (dependant on grain size, density, impurities, frequency, and what you consider to be enough light to count). It's best with blue-green, so you can't explain what you see here by calling snow a filter. (see _URL_0_ for example). If the snow were thick (the distance the light has to travel through it gives many more opportunities for scattering and absorption of red-green).Actually, that paper probably answers your question: Rayleigh scattering in the snow is not driving the colour, as snow scatters visible light basically equally. It's a very good reflector too.
Copper gives a sort of [bluish-green flame](_URL_0_).Boron gives a [brighter green](_URL_1_).There are other elements that give a greenish flame, but they're all either yellowish or almost white. Which one of these looks closest?
This is almost identical to the "lighted Marquee" thought experiment for exceeding the speed of light - the idea that a sequential series of bulbs could be timed such that it appears that the "light" on the marquee is moving faster than the speed of light. The issue is that the light itself is not moving - it is simply turning on and off at a point in space. The movement is an illusion - the light is not traveling "around" the marquee, it is just that individual bulbs turn on and off.In the same way, the beep is not moving *along* the rail, but rather each individual speaker is simply emitting a beep, in sequence. No sonic boom would happen, because at no point is any single speaker breaking the sound barrier in any way.Edit: I should also point out, because some are talking about constructive interference, that constructive interference in this case could possibly lead to the beep getting *louder,* but will not fundamentally cause the compression into a shock wave that constitutes a sonic boom. That sort of compression necessitates something moving through the medium faster than the medium can move out of the way. A sonic boom is not simply a "loud noise" which you could achieve with constructive interference, it is a very specific kind of physical phenomenon.
If I understand it correctly, at higher than atmospheric pressure (i.e. underwater) your central nervous system is affected by higher than normal partial pressures of oxygen. At normal atmoshperic pressure other body systems are affected with different symptoms. Free radicals form from the oxygen overload. These free radicals do damage to cells on a molecular level eventually causing irreparable cell damage and death. The death of CNS (brain etc.) cells results in seizures and death. This addresses it in depth. See the mechanism section if you want the detailed "why."_URL_0_
[There have been many devices made that have large touchscreens.](_URL_0_)  In fact, I've used a couple of them before.  You don't see larger tablets because they're more expensive to produce, and inconvenient to carry around.With regards to an absolute limit - I'm not sure exactly what this would be.  But is far larger than the screens in tablets on the market.
You can't. Any interactions that would change the probe to create an image would cause a change in the atom. That's how forces work. If you're talking about making it not move around, you can try to use a probe that will only excite the electrons, which just changes the orbit the electron is in instead of changing the momentum of the nucleus
For some perspective, the natural color of [enamel](_URL_1_) (hard outer part of the tooth) is light yellow or grayish white, and [dentin](_URL_0_) (porous stuff inside the enamel) is usually yellow. Due to the fact that enamel is slightly translucent, especially in areas where it is thin, "normal" teeth appear as slightly yellowish or off-white. Also, many dental imperfections due to wear or food staining are benign, so white tooth color is probably not a good indicator of oral health.
Although this thread seems to be a downvote magnet, no one has really answered the question.Although there are other factors at play, the main reason your body feels tired is because an increase in the neurotransmitter gamma-Aminobutyric acid, or GABA. This is an inhibitor that blocks the normal excitability of neurons throughout the body. When you are sleep deprived your body still produces GABA. Caffeine or other energy stimulants typically work to increase excitatory neurotransmitters, but the effects of GABA will ultimately outwork these supplements, especially in the brain. As your body attempts to fall asleep (despite your paper being due tomorrow morning) GABA begins to shut down your brain's control of the physical functions it uses when awake.The cerebellum is a major brain segment that controls really basic tasks, such as walking and talking. Since these are only useful when awake and the cerebellum is at the bottom of the brain, it gets targeted first by GABA. It's clear to see why when someone gets overly tired, their abilities to walk and talk would become a bit impaired. If they became even more sleep deprived, their abilities to think and reason would also begin to shut down.Not surprisingly, alcohol also increases the production of GABA, which is why it is a depressant. All the same consequences of sleep deprivation are equal to and amplified by the intake of alcohol. From losing "inhibitions" to losing balance and slurring speech, GABA increase leads to the shutdown of basic brain functions.
I wouldn't think of them as failures of the brain. Our brain does a lot of processing on the raw data that the eyes collect. This processing is very important to our ability to understand the information we get from our eyes. Optical illusions exploit that processing; they set up situations where what our brain tells us doesn't match up to reality. These types of situations are rare and in general the brains image processing gives us a huge advantage in our ability to interact with the world.Since understanding or "seeing through" optical illusions is probably less important (in the evolutionary sense) than the information processing its very unlikely that we will evolve to see through them.
No, because the fault and direction of mass movement is likely not perpendicular with the center of gravity of the earth, nor is it likely equally balanced.Additionally, imagine a figure skater spreading her arms out to spin slower, or drawing in to spin faster. Earthquakes that disrupt large quantities of mass vertically will do the same thing, but on a proportionately smaller scale.
[The triboelectric effect](_URL_0_) doesn't necessarily create heat. When you walk across a carpet and you then get a shock when you touch the fridge, that's friction manifesting itself as an electrical charge.
This depends on both the strength of the laser, and the reflectivity of the object. An object that is a perfect mirror will not heat up at all regardless of the strength of the laser, while a black body (100% absorption) will heat up until the incoming laser energy and outgoing black-body radiation balance out.Note that perfect mirrors and perfect black bodies do not exist in nature, so the actual effect will be between the two extremes.
Medications (and foods for that matter) are actually absorbed from the intenstines. The stomach serves to break apart foods using mechanical force of churning and acids, then it releases them slowly into the duodenum (first section of small intestine).Food doesn't generally stay in your stomach for hours either, but it must first be broken down into absorbable components whereas medications administered orally are desgined to be absorbed. Depending on the medication a reasonable onset time would be about 30 minutes.
I believe the term you are looking for is [sublimation](_URL_0_). In short the ice/snow would turn directly from a solid to a gas due to the excess amount of heat caused by the nuclear reaction.
it would probably be effective for some microbes/viruses but unlikely to be as effective as it is today. Even going back a few decades and you had small pox, a few more and HIV did not exist and every winter bring new flu strains.Things change fast.Don't forget geography ; Traveling around the world today, each new continent and country brings its own immunological challenges, ( hence travelers diahorrea ),  so its a safe bet that things were very different 2000 years ago.
There are a combination of methods.  One is maceration.  Basically, it involves removing as much of the soft tissue as is practical, then allowing the rest to decompose under controlled conditions, often in temperature-controlled water, until the rest of the tissue is soft enough to be cleaned away.  Another method can be used in combination with this.  Dermestes beetles will eat flesh, but they prefer not to eat the bones, so they will clean a skeleton for you.  Care has to be taken because they will move on to the bones if they exhaust the soft parts, but it saves humans a bit of work.edit: a bit of clarification.
Larger groups tend to have lower rates of evolution because it takes forever for something to spread through a large population. Of course, very small populations have less raw genetic differences to work with and small probability of new mutations to help out.
They generate high-voltage AC electricity. This can be useful for many things, including testing for leaks and starting up larger electric arcs. However, their main use is just to look really cool.See: _URL_0_ > Today, although small Tesla coils are used as leak detectors in scientific high vacuum systems[9] and igniters in arc welders,[57] their main use is entertainment and educational displays.Originally, Tesla planned to use them for power transmission, although this would be somewhat impractical and dangerous.
With modern Lithium Polymer batteries? It is not needed, its a hangover from the old Nickel-Cadmium days. Along with the old "discharge completely every few weeks".Lithium based batteries are best kept between 25% and 85%.
We tried this with Javan rhinos (captive breeding in zoos).  It went quite poorly.
To help answer your question Are you talking about differences between different animals, or between different people? By bone structure and size do you mean length of bones or cross sectional area? What do you mean by muscular potential? Size? Speed? Strength? Power?
There wouldn't be any good way to gauge this. My gut says no, and many people dislike the rationale but bear with me:Human infants are still developing in many many ways. Depression isn't well understood but we know it is a derangement of mood and emotion. Infants and even children are still forming and developing their emotional systems. It isn't just a societal conditioning thing we are talking about. The pediatric brain is actually different than the adult brain. As such it would be difficult to characterize such diseases in those at the extreme end of under development (infants). Now... You said "clinical" in your question. Depression , like many clinical diagnoses, is difficult for many people to understand because it is based off a fulfillment of specific criteria. So aside from the biology I mentioned, an infant would have to describe decreased mood, alterations in sleep, loss of interest in daily activities ("Doc, drooling just doesn't give me the enjoyment it used to") , and/or a number of other "clinical findings" in order to meet the criteria. In that sense, an infant wouldn't ever meet the definition of "clinical depression".
The short answer is that geologists sat down and created models to show how the surface features could be created by tidal movement.  A person I've had the pleasure of working with over the years is, quite literally, the top authority in the world on this specific subject.  He was the one who discovered this.  I was just chatting with him, and he provided this insight as well:  "The real smoking gun was that the magnetometer on Galileo measured a dipole during close flybys of Europa.  If Europa has an ocean (with salts) then an induced magnetic field should be detectable.  And it was"  I'm trying to see if he can create an account and provide a more detailed answer.
It depends vastly on the spider in question. Orb weavers will spin webs where prey is most likely to get trapped, as their hunting method relies on the webs. The most extreme example of this is one of the smallest species of spider, that spins the largest webs of any spider, spanning the entire width of rivers: _URL_0_ Seriously that video is hilarious watch it.Anyway, on the other end of the spectrum there are spiders that don’t rely on their webs and instead actively leave them to go hunting. Wolf spiders for example are really common sights in bathrooms, as they are a nice warm moist spot to build a web, but they are active hunters, so they leave the web in search of food.There are even spider species that build their webs as a team, working with hundreds of individuals to form one gigantic web, but to answer your question, spiders choose a web location based on their hunting behavior.
How sharp a material is will define how neat the cut will be, but beyond that has very little bearing on deciding what cuts what.Hardness is the variable you're looking for if you're trying to decide if something will cut something else. Simply put, hardness is a measure of how much force a material can take before it begins to plastically deform. Hence, if you push two materials against one another, they will exert an equal and opposite force/pressure upon one another and the one that is less hard will "give" first, and be cut by the other, more hard material.And that's really it in a nutshell. There are of course extreme cases of exception. These occur when the two materials are drastically different in dimension from one another.One extreme case is that one material is much larger than another, such as say, steel cutting into a huge block of aluminium. If the aluminium block is too large, or the cutting area is not sufficiently cooled, then the build up of heat combined with the local deformation of aluminium (which increases it's hardness) could result in dulling the steel blade.One of the other extreme cases, as you mentioned, is where a materials is extremely thin. Having a thin piece of metal does two things to it's properties. Firstly, the thinness means that the macrostructural properties will be affected. (For example, a pencil is harder to snap the shorter it is), and secondly if you reduce the thinness to the microscopic level then you increase the effect of imperfections in the lattice on the overall properties of the material.PS: The [Mohs scale](_URL_0_) is a easy, albeit slightly simplified way of tackling the problem.
Is it truly feasible for human life to ever inhabit another planet?  It seems as any adult would be long dead by the time we reached a habitable planet.
It's a physics problem. Kinda. When you combine a bunch of known physical laws, typically expressed as differential equations, and apply them to fluid flow, you get the Navier-Stokes Equations. A solution to the Navier-Stokes Equations then represent a possible way that fluid can flow. These equations are applied all over the place to generate models of fluid flow. But these are all numeric approximations, or restricted in some way to provide a solution. None of these provide a general solution to these equations. If you look at the fluid without really zooming in that much, then you'll have a fairly coarse view of the fluid. This can allow you to approximate solutions to these equations and get good models of physical things because fluids are not, in reality, infinitely fine, they are made of things of discrete size. But if you take these equations and allow for infinite zoom, then you're treating these fluids as infinitely fine things. Since these equations allow for turbulence (because that is a thing that happens to fluids), this infinite fineness can produce some chaotic results. A small nonuniformity at one point in time can blow up into a hugely compounding distortion that breaks the smoothness of the fluid. You can get infinite peaks of density or velocity within the fluid and loose nice things like differentiability. So far, every attempt at solving these equations looses one of these nice things we typically associate with fluid. We either lose the smoothness or it can become unboundedly energetic. The Navier-Stokes Millennium Prize Problem is then the question of whether or not this differential equation can be solved without losing these nice things we associate with fluids. It could very well be that these equations admit no actual solution, so they don't actually describe how fluids behave. But we already know that they don't, because fluids are not infinitely fine. The question is whether or not this assumption is a thing that breaks the model. Details of the problem are [here](_URL_1_), and a good exposition about the troubles involved with solving it are [here](_URL_0_).Overall, though, differential equations are really hard to solve, and we have no real general method to attack them. The reason why this problem is so important is because a solution to it is expected to provide us with new, more powerful and more interesting tools with which to study differential equations.
In the sense that math is the basis for a lot of other fields, certainly.More concretely, Godel's results are deeply entwined with and are the inspiration of Turing's theorem on the noncomputability of the Halting problem (see the [discussion in Turing's original paper](_URL_0_), page 29 of the pdf and 259 of the original source), which is a very real result telling engineers not to bother trying coding up absolutely-perfect debuggers and so on.
Gas is a mixture of hydrocarbon chains, and the chemical reaction which digests food is very similar to the combustion reaction. I'm not saying you should go on an all-gas diet, but it's likely your body got some usable energy from it....mixed in with all the toxic additives and non-digestible compounds. Just curious, but did your stool or urine seem strange for a few days after the gasoline feast?
Normally, a slingshot involves a maneuver while within the gravity well.  That is, you burn fuel deep in the well, and get an extra delta-V kick from it.
Welcome to the wonderful world of psychophysics! Psychophysics is the study of how the physical world maps onto sensory and perceptual qualities / experiences. It most certainly is NOT "all subjective" as /u/zombieantfungus suggests. There has been about 150 years of psychophysical research done with many beautiful findings. Unfortunately, with the exception of Weber's law, it is rarely covered in regular psychology or cognitive science courses (that I have seen). Here's an example of a relationship between a physical property and a psychological one: amplitude is a property of a sound wave, a physical stimulus; loudness is a perceptual quality, it is how we experience a sound. How do changes in amplitude affect their perception (loudness)? The answer isn't obvious! Changing from 10 to 20dB might not be perceived the same as going from 20 to 30. Also, what one person may hear, another may not. A cool example is the loss of sensitivity to higher frequencies as you age. Some kids have phone rings that are at a very high pitch that adults can't hear so you can get away with having a phone in class. I'm sure there's an app for your phone that you can play with.I work in vision. Some classic experiments that have been done are on spatial frequency and contrast. It turns out that our sensitivity to contrast and spatial frequency interact. Check out [this](_URL_1_) contrast sensitivity function. On the x-axis spatial frequency is increasing as you go left-to-right; on the y-axis contrast is decreasing as you go bottom-to-top. Note how crisp the lines are in the bottom middle of the image and how it gets kinds of blurry to the right. In the upper-right corner, it's pretty darn gray, but in the upper middle you can still see individual lines. The upper-right corner isn't actually gray! You can't perceive (your visual system can't resolve) high spatial frequency gratings at low contrast as well as it can those of a medium spatial frequency. Again, this function varies from person to person, but the general shape is the same. As /u/MarlingDarling pointed out, there are lots of reasons why our sensitivities and perceptions may be different. We can measure all sorts of stuff, like sensitivity to different kinds of illusions, stereoacuity, motion sensitivity, sensitivity to orientation, hue, saturation, you name it. The same holds for all senses, although making controlled stimuli for the chemical senses (taste and smell) is a little harder because experimental control can be tricky. You may be interested in so-called [supertasters](_URL_2_) (I don't think the wiki is very up do date; we know more about this now, I think).Touch, like vision, is a sensory system that we can study. There are also some pitfalls here that can make it difficult to study. For example, for cold sensitivity, I suppose that it would depend on the surface area, material, and temperature of the object, as well as the location on your body, pressure, and duration of contact. That's a lot to control or parametrically vary to make a careful study. This isn't my area, so there are probably lots of clever ways that people have thought about how to test this. A very simple experiment (touch acuity / two-point threshold) that you can do yourself is to take a paperclip, bend it so that the two ends are parallel to each other and make a kind of fork (you could also just use a fork). Now gently touch the tip of your finger with the two prongs of the clip/fork. You should be able to feel both points individually. You can confirm this by rolling your finger so that it's only touching one of the prongs; you should be able to tell the difference between when there is only one prong touching your finger vs. when there are two. Now do the exact same thing on your elbow. It should feel like just one object! Rolling the clip/fork so that only one prong is touching your elbow feels exactly the same! If you are using a paperclip, you can try to find the largest separation between the two prongs that you need to be able to detect both of them. It should be much larger (maybe an inch or so apart) on your elbow than on your finger. We have different concentrations of receptors in those two areas and so our sensitivity to touch varies. Our fingers, tongues and lips are extremely sensitive. You can see a funny looking touch sensitivity map [here](_URL_0_). The size of the body parts is proportional to their sensitivity to touch. Again, there are some differences across individuals.Edit: fixed a link and a typoAddendum: There is also a very close relationship between traditional psychophysics (i.e., psychophysical functions) and signal detection theory. For details, see wikipedia or ask a question =)
If the Earth vanished, the moon will simply continue orbiting the sun with minor changes to its current trajectory. Since the moon is currently orbiting the Earth, its velocity relative to the sun is already close to the orbital velocity required to maintain an orbit at this distance. It won't fall into the sun.
Kind of, but it depends on how you define "stronger" immune system.Put simply, Type I hypersensitivity reactions (allergic reactions) involve B-cells producing antibodies against harmless antigens.  These antibodies will bind to Mast Cells  &  Basophils, and when that cell encounters the antigen (an allergen such as pollen in this case) the antibody recognizes the allergen and activates a signalling pathway within the cell.  The cell then "degranulates" which basically means it takes a load of chemicals kept inside it (the major mediator being histamine) which are supposed to neutralize the antigen and recruit other immune cells to clean it up, and dumps them all over the antigen.  The chemicals involved cause itching/redness, the cell recruitment causes swelling.If your immune system is "stronger" in the sense that:- Your titre of antibodies against the antigen is higher (B-cells produce more of the antibody than is typical)- Your titre of Mast cells / basophils is higher than typical- Your Mast cells / basophils secrete more of the histamine  &  other compounds than is typical- Your other immune cells are more responsive to the chemokine recruitment than typicalYour "stronger" immune system (can be just one or a combination of the above) will result in a larger  &  more robust response to the same quantity of antigen than someone with none of the above qualities.  In this sense your allergic reaction will be more severe.Keep in mind there are numerous ways your immune system can be "stronger" that don't impact type I hypersensitivity at all, and that some would argue because type I hypersensitivity is essentially a mis-firing of the immune system, a larger  &  more robust reaction should be considered a weaker immune system, not a stronger one.As for AIDs, people with AIDs can still experience allergies.  HIV primarily attacks Macrophages, T-cells, and Dendritic cells. T-cells are tangentially involved in type I hypersensitivity (The CD4+ sub-family of T-cells is involved in the B-cell production of antibody) and Macrophages can be involved in cleaning up the reaction, but the loss of these cells do not prevent the reaction from occurring.  The CD4+ T-cell involvement can occur years before the allergic reaction itself (usually at your first lifetime exposure to the allergen) and the Macrophage has no role in causing the reaction, only in cleaning up the damage.  Dendritic cells aren't really involved at all.  The arm of the immune system attacked by HIV leading to AIDs can be totally destroyed, but allergies can still function because they operate through a mostly-different subset of cells.
If it is a pure EMP (no highly energetic particles), all you need is a faraday cage (wrap some aluminium foil around it). If you have HE particles, you need the bunker as well.
If we know how far away the moon is, which we can figure out from how long eclipses last, and we know how long it takes to orbit (a month), we can figure out the product of GM from Newton's equation (or we can just consider the gravitational acceleration at Earth's surface, since we know the radius). Cavendish measured G independently using giant lead spheres, and used his measurement to divide it out of GM to get M.
Gum disease can lead to bacteria in the blood, and can cause endocarditis.
Yes, there are cases where the action is indeed maximum. In fact, the Lagrange formalism indicates that the action should be stationary, so strictly speaking, a solutions can be neither maximum nor minimum, it can be an inflection point, or it can be a saddle point.A concrete physical example where the action is maximum is the [reflection of light by a concave mirror](_URL_0_).
So the pathogen that causes Lyme disease is Borrelia burgdorferi. It's a gram negative spirochete, and their shape allows them to penetrate tissues very well. The initial red center is inflammation from the bite mark from its carrier, most likely the Ixodes tick. The cause of the red center is obvious, and the spreading red ring, called erythema migrans, is a sign of how far B. burgdorferi is spreading. The bacteria will start from the center of the bite, and then spread through tissues in all directions, and the outer surrounding circle of red caused by inflammation is a direct result of how far the pathogens have moved from that initial bite mark.
Rational thought occurs in the neocortex, while self-preservation instincts such as fear are handled by the primitive brain. Your fight-or-flight response, therefore, can't directly avail itself of your best reasoning skills.
Other features, such as oceans and mountains, greatly affect the weather in a region, so that lattitude isn't the only thing determining weather/biome
This is a fantastic question!  Though, I will preface this answer with 1) it is extraordinarily complex and we are still learning so very much about the intricacies and signaling pathways the many different types of white blood cells use to recognize "self" from "not self" and how they attack, 2) I am just a lowly surgeon, not an immunologist so I may make some small mistakes that I would hope my Allergy and Immunology colleagues get expand upon, and 3) I'm going to try to make this as simple as possible so please ask more questions if you'd like clarification or more information on anything else I touch on! & #x200B;First, lets look into what is a white blood cell.  In the bone marrow, pluripotent stem cells are constantly replicating and differentiating.  What this means is a constant population of stem cells that have the ability to become a whole host of different types of cells in the blood are living in the bone marrow waiting for specific signals that tell them the body needs a certain type of cell now be it red blood cells, platelets (in the form of megakaryocytes), B-lymphocytes, neutrophils, eosinophils, etc.  I won't go into the signaling pathways for the differentiation of the stem cells but there are some factors that act on the bone marrow, that we have been able to synthetically create too, like G-CSF (granulocyte colony stimulating factor) that we can give to patients with cancer or other types of diseases that reduce the number of granulocytes (a specific type of immune cell) that help increase their white blood cell count! & #x200B;When it comes to immunity and infection, there are two different pathways that the body fights infection.  The first is the innate immune system.  This system is endogenous, non-cellular mechanisms that help fight infections.  This includes things called "complement" which is a series of proteins that basically cover an antigen (something that activates immune cells) and can start to destroy it itself and things called immunoglobulins which can cover and mark an antigen to be recognized by immune cells to be destroyed.  The innate immune system also encompasses other functions but that is a little too specific for your question so I'll not go into detail unless asked later. & #x200B;You also have the cellular immune system which encompasses all the different types of immune cells.  These include, but are not limited to, lymphocytes ("T" and "B" cells), leukocytes (macrophages, neutrophils, eosinophils, basophils, etc.), APCs (antigen presenting cells such as dendritic cells), plasma cells (activated B cells), natural killer cells ... the list goes on.  This part of the immune system is the cellular arm and each population of cells within this system has specific jobs.  Neutrophils can be considered the workhorse and first line of defense against pathogens. Let's say you get a splinter in your finger and some bacteria is introduced into the dermis and starts a local infection.  The cells where this infection is occuring will upregulate an enzyme known as cyclooxygenase and start to produce a type of molecule called prostaglandins.  These start the inflammatory process.  Inflammation is defined as the process by which rubor, tumor, calor, dolor, and loss of function occur -- redness, swelling, warmth, and pain.  These prostaglandins, as well as other inflammatory signals, are released into the dermis and causes upregulation (increased production) of other proteins but for this example it upregulates these little proteins that can line the inside of the vasculature that can help neutrophils grab, roll, and eventually stop on the vascular wall.  There is a whole bunch of them and some are called selectins, integrins, and other CAMs.  When these proteins are upregulated, the chances of passing neutrophils coming into contact with them increases.  This process is called margination, rolling, adherence, and diapedesis.  Once a neutrophil is stopped on the vascular wall surface in the area of inflammation, neutrophils rely on chemotaxis (sensing of inflammatory mediators) and follows this "trail" of inflammation to the source -- the infection.  Once there, they are activated and essentially kamikaze themselves against the bacteria.  We know this process colloquially as "pus."  Pus is just a giant mess of activated, dead neutrophils.  This further increases the inflammatory process and more and more white blood cells are recruited.In addition to neutrophils, macrophages diapedesis through a similar method as neutrohils into the tissue where inflammation is occurring, and utilizing chemotaxis, can encompass a bacteria and engulf it.  Once engulfed, the macrophage will release harmful enzymes that help "kill" bacteria or whatever pathogen is causing the infection.  They also release a whole mess of inflammatory mediators called interleukins.  There are many interleukins and they activate other responses in the body in a very sophisticated but complex way that I do not trust my own knowledge of in fear of making some grave mistakes.  I also think that this is way above the level of detail you would like but I'll say it's extremely interesting but incredibly complex with active research in this area still occurring! & #x200B;This would not be a good answer if I did not talk about lymphocytes.  These are my personal favorite population of immune cells.  These come in two flavors, "T" and "B" cells.  Before my immunologist friends get their pitchforks out, I know NK cells are considered lymphocytes but I do not feel comfortable enough discussing their role in depth as it's been many years since I took I & I.  First, let's talk about T cells cause I think they are very cool.  "T" cells stands for "thymocytes" because they grow and mature in the thymus.  When we are developing, T cells migrate from the bone marrow to the thymus where they undergo a very rigorous process called tolerance.  Tolerance is a system of checkpoints that all T cells must pass that says each cell understands what "self" is and what "not-self" is.  I believe up to 98% of T cells fail tolerance and are destroyed once they fail.  Tolerance is a two step process where first positive and then negative selection occurs.  Positive selection is a check to make sure T cells can interact with a very important cell surface protein called MHC (major histone compatibility complex).  Almost all cells in the body express MHC however there are two classes of them, MHC-I and MHC-II.  All T-cells must be able to interact with MHC and if it cannot, it is signaled for apoptosis (signaled, controlled cell death).  If the T cell interacts with MHC I then the T cell is further differentiated to a CD8+ ("Cytotoxic") T cell and if the T cell interacts with MHC-II it differentiates to a CD4+ ("Helper") T cell.  Next is negative selection where the T cell must be able to recognize "self" and to not activate to "self."  If a T cell strongly interacts with it's corresponding MHC protein (CD8+ with MHC-I and CD4+ with MHC-II) then the T cell is marked for apoptosis because it is reacting to strongly to "self" and can cause unchecked damage to our own body.  Negative selection wants T cells that weakly interact with MHC so that it will check MHCs in comes into contact with but will only strongly interact with MHCs from other organisms, not "self" MHCs.  Then these cells are released into the blood stream and start their life checking MHC throughout the body looking for "not self" to become activated and signal whatever it is recognizing as "not self" for destruction. & #x200B;B cells mature in the bone marrow hence why they are called "B" cells.  These cells have a really cool receptor called "B cell receptor" or BCR that rearranges its gene so many times that it can produce 3x10^(11) different combinations!  That is an insane number of different, specific combinations that the BCR can recognize and cause B cell activation!  It boggles my mind how incredibly adapted at recognizing ANYTHING the B cells are!  Anyways, once the BCR is developed and the B cell enters circulation, it will become activated by either another activated B cell or by a CD4+ "Helper" T cell.  Once activated within a lymphoid tissue (Spleen or lymph node) the activated B cell turns into either a plasma cell or a memory B cell and starts producing tons and tons of immunoglobulins (IgM and IgG) that stick to the antigen (bacteria, fungus, virus, whatever) that initially activated the B cell and marks it for destruction. & #x200B;I hope this was informative and answered all questions you had.  If you'd like clarification or more information please don't hesitate to ask!  I wanted to touch on a lot of things but the simple answer to your question is these cells "sense" chemical signals produced by the antigen ("not self") thing in the body and either directly kill it or tag it with chemicals that allow other cells to notice it and kill it. & #x200B;Also I just noticed what you said about platelets.  Platelets are NOT immune cells.  In fact, platelets come from very large cells called Megakaryocytes and deal with coagulation (the bodies ability to make blood change from a liquid to a solid).  If you'd like more information about that let me know and I'd be happy to give you a crash course in coagulation!
I'm not sure in the general case, how more common nutrients such as carbs and fats are enzymatically treated. I do know that when certain less common nutrients (i.e., lactose) enter the environment of cells who mean to use them for energy, the presence of the nutrient molecule is detected by receptors on the outsides of cells, which when activated bring the nutrient into the cell to be a signaling molecule, activating the genetic sequences relevant to digesting that molecule.That's a very wordy and technical way of saying "at least sometimes, yes."
Houseplants can provide numerous [mental health and psychiatric](_URL_0_) benefits.
Early in the co-evolution of plant-animal relationships, some arthropod species began to utilize the chemical defences of plants to protect themselves from their own predators and parasites. It is likely, therefore, that the origins of herbal medicine have their roots deep within the animal kingdom. From prehistoric times man has looked to wild and domestic animals for sources of herbal remedies. Both folklore and living examples provide accounts of how medicinal plants were obtained by observing the behaviour of animals. Animals too learn about the details of self-medication by watching each other. To date, perhaps the most striking scientific studies of animal self-medication have been made on the African great apes. The great ape diet is often rich in plants containing secondary compounds of non-nutritional, sometimes toxic, value that suggest medicinal benefit from their ingestion. Chimpanzees (Pan troglodytes), bonobos (Pan paniscus) and gorillas (Gorilla gorilla) are known to swallow whole and defecate intact leaves. The habit has been shown to be a physical means of purging intestinal parasites. Chimpanzees and man co-existing in sub-Saharan Africa are also known to ingest the bitter pith of Vernonia amygdalina for the control of intestinal nematode infections. Phytochemical studies have demonstrated a wide array of biologically-active properties in this medicinal plant species. In light of the growing resistance of parasites and pathogens to synthetic drugs, the study of animal self-medication and ethno-medicine offers a novel line of investigation to provide ecologically-sound methods for the treatment of parasites using plant-based medicines in populations and their livestock living in the tropics.source - _URL_0_
Most of our knowledge of cardiovascular shock in humans comes from Nazi Germany during the 40s. They also found out exactly how cold you can get before you die. Does that answer your question?
There is not such thing really as an "opposite" frequency.  I think the thing you are thinking of is opposite phase (edit: out of phase...not opposite phase!).If you think about waves in the conventional sense as sort of an oscillating sine wave.  The frequency is related to the number of peaks (or troughs, or any other distinct part of the wave) that traverses a certain point in a unit of time.  Meanwhile, the phase of the wave represents the relative location of these peaks and troughs.  If you are in any way versed in trigonometry you can see that a cos function is just a sin function shifted by a phase of 90degrees.  So, let's say we generate a wave with a certain frequency and a certain phase.  Now, let us say we generate a second wave (from a source very close by) with the same frequency but alter the phase just so all the peaks line up with all the troughs of the first wave.  If you use the principle of super-position you will find that the net wave is flat.  The wave is gone!  If you apply this to a sound wave, you've basically canceled out all the sound.This is exactly how noise-canceling headphones work.  They have a little microphone on the outside, it analyzes the frequency and phase of incoming ambient sound and then outputs the same frequencies with a phase advanced by 180degrees.  The reason you see noise canceling things like this in headphones and not in other areas is because this technique is only really useful when the ambient noise you want to filter out is coming from the same area as your noise-cancelling wave is.  If they are separated by some distance (like in your example with the fans) you will find that in some areas the noise is canceled out, and in some areas the noise is louder regardless of their relative phase (it comes out of the math).  This is actually an experiment you can do at home.  Get two speakers, separate them by some distance and have them place a pure frequency (with no harmonics, like a prolonged beep you would here from a computer).  If you walk about the room you will be able to hear distinct places where the sound is very quiet, and others where it is quite a bit louder.Anyways, that was a bit of an essay...hope it helped...
Global estimates of the annual present-day CO2 output of the Earth’s degas- sing subaerial and submarine volcanoes range from 0.13 to 0.44 Gigatonnes per year.See Eos, Vol. 92, No. 24, 14 June 2011Carbon dioxide emissions from energy production are about 33 Gigatonnes per year.See _URL_1_The amount of CO2 produced by volcanoes is insignificant compared to burning coal,gas and oil.Volcanoes commonly emit sulfur dioxide which has a temporary *cooling* effect.  See _URL_0_
Following on from Neato's latter clarification of the question 'or to simply take advantage of nuclear decay energy?' The area around Chernobyl has evolved life that feeds on radiationExample - _URL_0_It gets its energy from gamma radiation released from the area
Hunger is not a strictly physiological process. It is mediated by a slew of hormones and chemical changes in the brain. Some of the factors that come together to determine when you will be hungry is the time of day and if you have a habit of eating at that time, how much and how recently you last ate, if there is a stimulus around you to make you think about food (smell, sight, etc) and your emotional state. If you want to know more about hunger, look up the leaky barrel model. In my opinion its the most accurate description of hunger.
You can't "feel" a nuclear weapon going off nearby *not* because it happens too fast in the "span of time" sense, but rather, because the shockwave (which in the case of a nuke instantly vaporizes everything it touches) moves faster than neural impulses.  It happens too fast in the "movement" sense for the signal to make it past the wave front.In terms of "duration", we can discriminate between visual events 15-20ms apart - Though that doesn't mean "you" will have noticed a single event by then.  That takes up to around 150ms before the first flickers of conscious awareness of a visual signal form (and that *also* differs from primed response time, which can do a good bit better than that even though you can't consciously acknowledge it by then).We can actually do a *bit* better than that, in that we can (learn to) perceive "lag" between two different modalities (synchronized sound and light, for example) down to under 5ms.  The coolest part about that?  It takes [up to **thirty** milliseconds](_URL_0_) for signals to travel from the retina to V1 (the first "stage" of the brain's visual cortex, ignoring a brief stop at the LGN).  So we can compare the arrival time of signals from two different senses while the "data" hasn't even travelled 1/6th of the way to the brain!
It's way outside my field of study, but I vaguely remember reading somewhere that the more you drink, the less your body retains it because it feels it won't be going without for a while.  Conversely, your body retains water when you're not drinking as much.  I think it works the same way with storing energy in fat; the less you eat throughout the day, the more your body hoards the energy. Again, I hope someone else can give you an answer more confidently than I can.
Yes. [Vegetarianism](_URL_0_) involves eating what is mostly a plant-based diet, and since vaccines aren't food, you wouldn't turn into a non-vegetarian by getting a flu shot. You're probably thinking of [veganism](_URL_2_), which is a movement involving people who believe in the avoidance of animal products.I am unsure whether or not vegans also avoid the flu vaccine, and it is probably useless to make a generalization since there are varying degrees of practice within the movement. However, it should be noted that with regards to medicine, a lot of pharmaceuticals undergo animal testing before human trials, and (perhaps a better analog to the flu vaccine) [insulin](_URL_1_) is sometimes harvested from animals.
This might help someone else, or you, get started on figuring this out:"The total mass of the asteroid belt is estimated to be 2.8×1021 to 3.2×1021 kilograms, which is just 4% of the mass of the Moon. The four largest objects, Ceres, 4 Vesta, 2 Pallas, and 10 Hygiea, account for half of the belt's total mass..."  I suspect it is far under the minimum size to form a spherical object but I will refrain from speculation.
At least as far as the rovers go, keep in mind that they're in different directions. We're pointing [huge radio telescopes](_URL_1_) at Mars and the Voyager probes, and they're not in the direction of the sun. So noise from the sun isn't coming from that direction.I did find a great example of the sun being a problem, which was the [Huygens probe](_URL_0_) landing on Titan. When that was occurring, the earth was transiting the sun from the perspective of Titan. So that means that the sun was directly behind the earth, and this meant that there was so much noise from the sun behind it that they couldn't send signals to Huygens. However, the reverse direction, since the sun wasn't behind Saturn, it didn't interfere with signals coming from Huygens back to us.
We don't know. We have no evidence to say so either way.At present there is no known common parent language. There have been a bunch of theories over the years, but so far none of the big supergroupings has held up. We just don't have enough information to make that kind of claim.In fact, we're not certain how human language came about. It's one of the biggest if not the biggest question in the field. It's possible that there is no one single parent language and that language developed separately in different places at different times.To add to that, a *lot* of language families that might seem pretty well accepted might actually not be. Sinotibetan, despite being widely accepted, still has a bit of controversy, and it's still possible that Sinitic and Tibetoburman are not in fact related, but that their similarities instead are the result of things like borrowing contact or areal features. I'm a Siniticist and and while I personally accept that they're related, that's not really an absolute certainty.So, we just don't know.
if you're a dichromat ('color blind') you will, sadly (not really, don't be sad, there's nothing wrong with dichromacy), never see what a trichromat sees. for you, looking through red filters will just make an image dimmer, and take away most of your dichromatic color vision.looking through colored filters can't *add* anything to your color experience, since the filters are removing light from the scene.so in a way, looking through a red filter will make your color vision a lot like the color vision of a trichromat (a person with 'normal' color vision) looking through the same filter, because the filter is reducing both of you to *monochromats*, at least functionally. phenomenally, though, the monochrome 'redness' of the red filter will still look very different to you versus to a trichromat.looking through a green-blue filter.. hm... if it had broadband transmittance, letting through medium to short wavelengths, looking through a green filter *might* not affect your color vision very much - if you're a *protanope* (one of the two types of red-green color blindness - i'm guessing you're a protanope because you see purple as a darker blue), but it would effectively turn a trichromat *into* a protanope. but it still wouldn't be the same..so no, there aren't any measures a dichromat can take - [aside from changing the genetics of their retinas] (_URL_0_) - that will let them see, in any phenomenal sense, what a trichromat sees (and even with the genetic fix, you still have to rely on the machinery of the brain to 'see' the colors, and it may already be fixed to interpreting your dichromatic vision).
Considering the fact that we have done this with a considerable number of animals and plants, the easy answer is yes. [Selective breeding](_URL_0_) is what I'm assuming you're asking about here. Not all animals are equally amenable to being forced into mating with particular partners that humans pick, so there are sure to be difficulties with certain species.An interesting topic that is related to but not directly addressed by your question is whether we can genetically manipulate large animals in a more direct fashion.
Yes, we have.Just as an example, here's a drug that essentially cures most cases of hepatitis C._URL_0_In general, we have quite a few antiviral drugs, which are drugs that (as the name suggests) target viruses or their activity. Tamiflu is a well known one for the flu, and of course there are tons of antiviral medications for HIV. Antiviral drugs don't necessarily cure an infection (HIV being an example), but they can help the body clear the infection faster for certain diseases. There's research into antivirals now for a lot of different diseases, like Dengue fever._URL_1_So short answer: yes.
The derivation is outlined [here](_URL_0_). There is not really a way to understand it without having some of the necessary mathematical background.
Shivering is an involuntary response to stimuli, so no you can't control it for the most part. As I say that though I realize that to some extent you can force yourself to stop shivering assuming you aren't to the point where you are so cold it is overwhelming. I have always found that to stop myself from shivering actually requires contracting a few various muscles as opposed to relaxing them. Again though this is only really masking the shivering response, not stopping it all together. Eventually if you stay cold, or get colder, you will start to shiver again regardless of your willpower.
Prions are simply misshapen proteins that have a rather unique ability to change their counterpart normal proteins around them into more misshapen variants. Because they were normal proteins there is no immune response against them so they are allowed to just sit there eventually turning your brain into Swiss cheese and ultimately killing you.
It would actually depend on what type of animal you would be referring to. Most commonly in mammals there is a leader of some sort that leads the group depending on several factors. For mammals the most common factors would be learned or instinctual patterns, following a resource, or searching for resources within a defined range. Birds are typically following resources, or instinctually drawn to a location depending on natural cues. The running thought is that they have a way of “reading” or following the earths magnetic field. Usually this is triggered by daylight cycles and has even been tested on birds that have never seen the light of day before  zugunruhe shows. (General restlessness before migration)As for fish, I don’t honestly know. I would wager to guess it follows along the same lines, an underlying natural instinct, or the following of resources.
I don't imagine you'd be in any danger, at least nothing proven, aside from a fire risk. You're bathed in electromagnetic fields every day just by being in a house filled with electrical items, so a blanket isn't going to change anything.
The answer is that a single transistor failure can bring down an entire computer. However, modern consumer electronics are remarkably stable and robust, as long as they're not overheated. A major part of electronics manufacturing (especially processor manufacturing at Intel and AMD) is verification and quality control. Chips are extensively tested before they're sent to market, and anything that looks bad or borderline is trashed. There are a lot of physical indicators that chip makers can use to determine whether a processor is functioning normally and to predict future failures, such as the resistance through different paths in a chip. Chip manufacturers also practice "binning", which is when high quality chips and lower quality chips are separated and sold as different products. High quality chips have really good physical performance and can be run at high clock speeds and cope with higher temperatures, while lower quality chips may have borderline performance and the manufacturer limits them to slower clock speeds to ensure that they don't get close to a possible failure zone. & #x200B;Also consider that computer hardware doesn't generally need to last forever, it just needs to last until it's considered obsolete and replaced. Most people replace their electronics after three or five or seven years just because they start to get slow or the battery life becomes terrible or the device gets damaged. Even on the resale market very few people want and are going to buy electronics that are 5+ years old.  & #x200B;In applications where reliability is necessary, often called "safety-critical" applications, there are different techniques for dealing with hardware failures. If someone's life depends on the correct operation of a computer then it's not unusual to replicate that machine three or four times and have the group of computers "vote" on what is the right thing to do- this technique has been used in commercial aviation and manned spaceflight for a long time. For less demanding applications it's possible to design systems to "fail safe" so that even if the computer unexpectedly stops working the system stops or shuts down gracefully instead of becoming uncontrolled. For something like industrial automation and robotics you might have a main power hub that is continuously kept alive through repeated signals from the computer, so that if those signals ever stop then the system automatically cuts power and brings the entire system to a stop. & #x200B; Hardware can fail for many reasons, not just random transistor failure. It's possible for stray radiation to randomly flip bits of memory (this is especially problematic in space). Loose cables or connections can also cause data corruption. A weak point in chip manufacture can leak current from one circuit to another at unpredictable times, especially at high voltage and high frequency operation, etc. There are lots of reasons to guard against hardware failures, and the general field concerned with such computing is called "[fault-tolerant computing](_URL_2_)". A more specific subfield of software engineering that often deals with safety-critical systems is called "[real-time computing](_URL_0_)", because they historically  have dealt with computer systems that interact with the real world (the computer system must keep up with the real world in "real-time", because the physical world keeps evolving regardless of whether or not the computer is ready). Safety and fault tolerance is often a concern in "[cyber-physical systems](_URL_1_)" research for similar reasons. & #x200B;Sometimes hardware devices have redundancy built in. Physical hard drives have had the capability to identify and stop using "bad sectors", regions of the magnetic platter that no longer behave properly, for a long time now. Newer solid state drives can have bad sectors as well, and similarly identify and stop using that region of memory. RAM modules can have Error Correcting Codes (ECC) built in, which allows the hardware to identify and fix many simple and some more complex hardware faults. Whole processors usually do not have redundancy built in, but the technique of whole-machine replication can be used to provide this if you really need it. Moreover, there are lots of software redundancy mechanisms that will hopefully give you an idea of how healthy your computer is before something goes wrong. Lots of tools exist to check processor correctness as well as memory and disk consistency.  & #x200B;But, I can tell you from experience that hardware can and does randomly fail. Electronics manufacturers are getting exceedingly good at quality control, even compared to just ten or twenty years ago. If you work in computer support you will see failures like this happen all the time, but for individual consumers you're unlikely to see frequent failures. I personally have had memory, processors, and video cards all just stop working for no apparent reason, but the last time this happened to me was in 2008 or 2009.
It is a limitation of your brain.Control of your extraocular muscles (the ones that move your eyes) is extremely complicated.  There are two main pathways that control the two things you mention.The [smooth pursuit pathway](_URL_3_) uses visual input to track objects and follow them.  Because it relies on visual input, you cannot force yourself to make smooth movements with your eyes.  The voluntary eye movements use...The [saccadic pathway](_URL_1_), which makes darting movements.  These position your eyes very quickly.The pathways involved in these are still being studied.  For a more detailed discussion of the pathways, I recommend [Martin's *Neuroanatomy*](_URL_0_)EDIT: there is an interesting disorder called ocular motor apraxia, in which the saccadic pathway doesn't function.  These people (usually children that grow out of it) rely entirely on their pursuit pathway.  Once they fixate on an object, they can't look away unless they turn their heads so far as to force their eyes to refixate.[Here's a video showing a toddler with the disorder.](_URL_2_)  Notice how she has to turn her head 90 degrees to look away from the ball.
Primary deposits of native element minerals like gold are found in hydrothermal veins associated with volcanic plumbing systems.  As a magma starts to crystallizes, it will crystallize typical igneous minerals like olivine, amphibole, pyroxene, and plagioclase feldspar.  These minerals have crystal lattices that require ions of a particular charge and size (with some wiggle room).  Some trace elements can replace the "usual" element in a lattice more easily than others (Uranium can fit into Zircon easily).  Other trace elements like gold and silver just don't really fit anywhere, so they continue to be concentrated into the remaining liquid  portion of the crystallizing magma.  Eventually, they can escape with fluid in high enough concentration that they form gold deposits.The way an element behaves in magma is described by its partition coefficient, where Kd = (Concentration in Mineral) / (Concentration in Magma).  A number less than 1 means that the element doesn't fit well in the mineral and will be concentrated into the magma.  You can view different elements and what minerals they like at the [GERM database](_URL_0_).  Notice that gold (Au) has nearly no minerals it forms, and MUCH prefers native gold (Kd = 155) or a sulfide compound over other forms (Kd = 0.7 to 0.000011).
Convection cells on earth are not driven by the oceans. The most basic circulation of the Earth's atmosphere is that air is heated near the equator, which rises because it is less dense, causing air from the poles to move equator-ward to fill the void. The actual process is more complicated than that due to Earth's rotation ([there are actually 3 different basic circulations](_URL_1_)) but the main gist is that differential heating causes the large-scale wind patterns.However, just as on earth, there are storms on Mars. On earth, the basic storm that most of us are familiar with ([extratropical cyclones](_URL_2_)) typically form due to much stronger, local temperature gradients caused by cold air from continents moving over warm water from western boundary currents (e.g. the Gulf Stream). As you mention, Mars has no such oceans to create temperature gradients, but it does have large ice caps (mostly dry ice), which transition from being almost non-existent in the summer to almost halfway to the equator in the winter. At the edge of these caps, in the spring and fall when the sun warms the nearby ground, you can get the same kind of large temperature gradients that are found on earth. This causes a pressure gradient, which causes winds.This is not the end of the story, however! Mars's lack of surface water means that the entire planet is as dusty as the driest terrestrial desert. Therefore when you do get wind, you get dust storms. Dust is lifted high into the air, and, for somewhat complicated reasons, heats up the atmosphere much faster than a non-dusty area would in the sun. This serves to create another temperature gradient, which causes more winds, expanding the dust storm further. This is why every few years a dust storm will cover [the entire planet](_URL_0_).**tl;dr: Temperature differences cause pressure differences which cause winds**
That book is a good intro, but it is a bit dated. The supernatural being Hawking is referring to is also known as [Laplace's Demon.](_URL_5_) It's the idea that if something has complete knowledge of the state of a deterministic universe, and the rules by which it operates, then the future can be unerringly predicted. This has been shown to be [mathematically impossible](_URL_7_)([paper](_URL_8_)). Now [Hawking agrees with that.](_URL_9_) Turns out, a deterministic system is one in which each state has exactly 1 possible immediate successor, not necessarily perfectly predictable. Also, the uncertainty principle is not due to our inability to measure a system without interacting with it, that's known as the [observer effect.](_URL_0_) An uncertainty principle is encountered wherever certain sorts of math are used, not just in quantum mechanics. It's due to the fact, that position and momentum are [conjugate.](_URL_1_) So when transforming between domains, [locally concentrated features in one domain become globally dispersed in the other,](_URL_3_) and vice versa.  There are [many ways that uncertainty can be interpreted](_URL_4_), but we don't know which is correct. Bell's theorem shows there is a fundamental incompatibility between the [principle of locality](_URL_6_), and [counterfactual definiteness](_URL_2_), but we don't yet have a means to decide which, if not both, of those assumptions are unjustifiable. Most physicists tend to assume CFD and discard locality, because not assuming CFD undermines the purity of science, in that an experimenter can never choose to make measurements which are truly independent of the state his experiment.
Depends how you define 'more fluid'.  It seems like what you're thinking is 'less viscous'.  In which case, yes, absolutely.  The 'sludgy' fluids you're thinking of are non-Newtonian, like corn-starch and water, which gets thicker (more viscous) when you apply a force to it.  There are also shear-thinning non-Newtonian fluids which get thinner (less viscous) as you apply a force to it.  It doesn't really make sense to compare these different classes of fluids to water, at least in the context of this discussion.   However, there are Newtonian fluids (fluids with a constant viscosity) that have a lower viscosity than water at room temperature.  For example:  Acetone and Diethyl Ether.  We could be pedantic here and include gasses in our list since they are technically fluids, and they have very small viscosities, however they are not liquid of course.On the extreme scale there is Superfluid Helium, which is a fluid that looks like a typical liquid but has zero viscosity. Very cool stuff!
When you talk about sending high frequencies through wires, you can no longer talk about a single wire. You need both a signal path and a return path to effectively carry a signal (This is also true at low frequencies, but the return path can be convoluted and still be good enough, so it's often more-or-less ignored). The signal wire and return wire together form a [transmission line](_URL_0_). Generally the frequency limits of a transmission line are determined by several factors: * resistive loss and skin effect. As frequency increases, the current tends to bunch up at the surface of the conductor instead of flowing through the middle. This reduces the effective cross-section of the conductor and increases its resistance. Resistance causes loss, which limits how far a signal can be carried and reliably received. * conductive or dielectric loss. At high frequencies the dielectric material between the conductors can start to carry current or otherwise absorb energy from the signal. Designing a transmission line for very high frequencies (GHz and up) requires paying extra for a dielectric material that minimizes this problem.* geometry. At low frequencies, for a well-designed transmission line, there is only one "mode", or solution to the electromagnetic wave equation, for signals to travel on the line. At some high frequency, additional modes will begin to propagate. These high-order modes might be very lossy causing the line to lose power over distance, and/or they might (almost certainly will) travel at a different speed than the main mode, causing the signals to be garbled at the far end of the line.    Also under the heading of geometry, the cross-section of the line must be uniform throughout its length to maintain a constant *characteristic impedance* and reduce transmission losses due to back reflections.
Ooh, interesting question! Most multicellular organisms have a circadian rhythm, or 'body clock', that regulates many behaviours including sleep, and this rhythm itself is usually regulated by exposure to daylight and nighttime. So what of creatures that can't detect this shift in light levels, or photoperiod?Alas, there are no published studies as far as I'm aware that have investigated circadian rhythms, or lack thereof, in deep sea fish. Not really surprising, as they're awfully difficult beasties to find and study anyway, let alone in the lab!What you might find interesting however is that we've done a buncha' studies on sleep in cave fish. [Mexican blind cave fish](_URL_1_) have two forms - a surface-dwelling sighted form that lives outside, and a blind cave form that lives in perpetual darkness. What's interesting is that the blind form has completely shut down it's circadian rhythm, and therefore saves about 30% more energy by default, compared to it's sighted form which 'gears up' every day in response to daytime.In the absence of light, the blind fish therefore don't have a 24-hour cycle and don't need to 'tell' whether it's day or night. Living in perpetual darkness, it's also disadvantageous to conform to a day-night sleep cycle anyway. Given food is scarce, it makes sense to try and remain awake and alert as much as possible - just in case a tasty morsel floats by. They therefore rarely sleep, and do so only in very short bursts, throughout a 24 hour period.I expect what applies to these cave fish applies equally well to many deep sea fish. They largely don't care what time it is up on the surface, and sleep in quick snatches whenever and wherever. If that answers your question?There are, however, interesting caveats and some exceptions; I'll discuss in another post below!____^**Sources:**[^(Duboué, E.R., Keene, A.C.  &  Borowsky, R.L. (2011)^) ^(Evolutionary Convergence on Sleep Loss in Cavefish Populations. *Current Biology*. 21 (8)^), ^671-676](_URL_0_)^. ^Press ^release ^[here](_URL_3_).[^(Moran, D., Softley, R.  &  Warrant, E.J. (2014)^) ^(Eyeless Mexican Cavefish Save Energy by Eliminating the Circadian Rhythm in Metabolism. *PLoS One*. 9 (9)^) ](_URL_2_)
Since most of the Earth is not transparent, the fastest data transfers would occur at the speed of sound through the Earth which is approximately 10km/s [(order of magnitude estimate)](_URL_1_). Satellites communicate at the speed of light, which is about 300,000km/s (30,000 times as fast as the speed of sound through the earth).So communicating directly is not worthwhile. What if we drilled a hole? That would make the path much more direct. Lets assume an ideal situation - we want to talk to someone directly on the other side of the world. Lets say there's a tunnel through the center of the earth with a fiber-optic cable running through it, and that heat and gravity are negligible. The earth is about 12,000km in diameter (rounding down), so light would take **0.04 of a second** to get to the other side of the planet.Lets use an inefficient network of three [geostationary satellites](_URL_2_) and see how much slower that network is. In [this diagram](_URL_3_), each satellite is about 35,000km above the earth (x). That means that the signal must travel 35,000km to get up, then sqrt(35,000^2+35,000^2) = ~50,000km  twice, then back down 35,000km. That makes for a total distance traveled. Total distance traveled is 170,000km or so. That's about a half a light-second (**0.5 seconds**), or about 10x as long as going through the center of the earth. When you include the fact that the deepest we've ever drilled was about [12km](_URL_0_), and that took a national-level effort, it's clear why we use satellites.
Quartz crystals when pretty much perfect are nearly transparent. They are translucent most of the time though. crystals form by repeating patterns. In quartz its silicon dioxide, when you have impurities or changes to the crystals it alters the physical structure and causes a change in characteristics. So the change in transparency most likely is caused by some disruption whether contaminants or physical shock.
This isn't a linguistics question (*per se*), but I researched my heart out and found nothing of value. And nothing in my education has ever really mentioned this sort of effect (besides dyslexia and simple ignorance).In fact, taking a look at that sub, there's nothing that really replicates the "phenomena" of the Berenstain Bears meme. And that's exactly what the "Mandela Effect" is— a meme. It's a flash in the pan we call the Internet.However, looking back at my education, I did study child language acquisition and I feel like that's probably the closest place to start. I'm not saying this is definitively *why*, but we learn language as children in two key steps: (1) Verbal language and then (2) written language. Many of us read Berenstain Bears as children, probably out loud by our parents or painstakingly sounding out the words individually to relate it to our verbal language. In fact, I recall hearing it pronounced the way it's spelled. But as we learn written language, we make shortcuts, leading to words spelled phonetically or referencing a similar word or making assumptions. *Ying-yang*, for example is in fact *yin-yang*, but we assume 'yin' should reference 'yang'. When we, later in life, thought back on the Berentain Bears, we made an assumption that *Berenstain* should reference other last names that are similar such as Edelstein or Brownstein, so in our heads, we remember it as *Berenstein*.So when it comes down to it, the "Mandela Effect" is probably not that much different than why so many people thought it was "all *intensive* purposes".
Yes!  There are intergalactic stars, not bound to any galaxy.  Most likely they formed in a galaxy and got ejected, either when two galaxies collided or by gravity assist from a large object like a supermassive black hole.There are probably other intergalactic objects too, but if they don't give off their own light we'll probably never find them._URL_0_
Species is a bit of a tricky term to apply in cases of two different animals which are closely-related.  While it's easy to look at a snake and know it's not the same species as a cat (and everybody agrees on that), it's harder to look at closely related species like zebras and horses.  They're generally considered separate species but (like early human species) can interbreed.  One the other hand, you have animals like dogs and wolves that were considered different species for a long time but advances in categorization and genetics have allowed us to move them to the same species.  Dogs are now considered to be a subspecies of wolf.  It's similar to how the concept of clade (which is based on the earliest common ancestor) moved birds under dinosaurs.  Given the complexity in the variation of life (and the odd paths that evolution has taken it) it's become a more meaningful term for differentiating living things.
With the exception of some very very exotic and speculative reproductive technologies, no.Evolution is just long-term adaptation to our environment. If, say, our brains start getting smaller because we can offload thinking to technology, then that *is* the process of evolution in action. If the main standard for mate selection becomes having a great OKCupid profile, then there will be an evolutionary pressure for good  writing skills.
Apollo 13 was never moving slow enough relative to the moon to go into a closed orbit so al that material would have remained in a highly eccentric orbit around the Earth until it hit either the Earth or the Moon. It is possible but unlikely that some of it could have been ejected into a solar orbit by a gravitational slingshot around the moon on a subsequent orbit.It is remotely possible that some of that material was ejected from the spacecraft at just the right velocity to go into lunar orbit however that orbit would have been very unstable and it is almost impossible that the material could still be there today.tl;dr: I think it is possible but unlikely that some scraps are still orbiting the Earth in an orbit which takes them close to the orbit of the moon.
There is a lot that goes into the formation of blood. In your blood you have: water, rbc's/wbc's/platelets, plasma proteins, and electrolytes (there are some other things, but they are not as fundamental). When you lost that pint of blood, the first thing that happens is constriction of the blood vessels and activation of your sympathetic system. This activates the renin-angiotensin system in your kidneys which will now absorb many Na+ ions that would normally be excreted. Water will follow the Na+ ions and will also be recirculated in the blood. Also, the water you drink after you donate blood will quickly enter your blood stream. Your kidneys will also be able to restore K+ levels in the blood by absorption of more K+. Now you have a good blood volume and a good Na+/K+ concentration. In a state of hypocalcemia and hypophosphotemia, your kidneys can reabsorb any Ca2+ or PO4 that may be secreted. Also, your parathyroid will secrete more parathyroid hormone which will signal the break down of bones and release of Ca2+ and PO4 into your blood stream. Now your calcium and phosphate balances should be fine. Because you had less blood, your body was in a state of hypoxia. When the kidneys enter hypoxia, they will release erythropoietin which stimulates the synthesis of blood cells. This eventually fixes your blood cell counts.Finally, your liver will begin producing plasma proteins because of the deficit in proteins in your blood. Now your blood is back to normal. All of this happens at the same time.
They are all real as long as you understand how they all differ from the core body temperature.Rectal, ear, and temporal artery temperatures are closest to core body temperature but more importantly they are less likely to be affected by environmental conditions.For comparison, stick with the same method of measurement each time.
The answer is if you are going to transition between two bound states (energy levels) the energy of the photon and energy of the transition must match *exactly* for non-scattering interactions.That being said its not "rare" because we are typically measuring ensembles of many many atoms.  These ensembles have statistical broadening effects, as well as uncertainty effects in the light field that make them more probable.  For example the precision something can measure a frequency of light is going to be inversely proportional to the time it can interact with that light field.  Meaning most systems can only interact for a set amount of time before the light field is turned off.  This innately gives the light field some uncertainty in frequency.These uncertainty effects give both the atom/molecule and the light field a distribution of available frequencies.  Now the probability that the light will interact (be absorbed) but the object will be proportional to the overlapping area of the two frequency distribution functions.  There are more factors at play here but thats the basic point.Additionally you can have scattering events where only part of the photos energy is absorbed due to induced fields.
The idea is that changing magnetic fields induce the current in the other coil. Only a changing electric current can create a changing magnetic field. Direct current only sets up a magnetic field once when current is turned on and whenever it changes strength. AC is needed because AC changes many times a second (or however often according to its frequency).
The green outline is a camera artifact since each image is actually originally taken in monochrome and has to be composited together.   > EPIC’s “natural color” images of Earth are generated by combining three separate monochrome exposures taken by the camera in quick succession. EPIC takes a series of 10 images using different narrowband spectral filters -- from ultraviolet to near infrared -- to produce a variety of science products. The red, green and blue channel images are used in these color images. > Combining three images taken about 30 seconds apart as the moon moves produces a slight but noticeable camera artifact on the right side of the moon. Because the moon has moved in relation to the Earth between the time the first (red) and last (green) exposures were made, a thin green offset appears on the right side of the moon when the three exposures are combined. This natural lunar movement also produces a slight red and blue offset on the left side of the moon in these unaltered images.* _URL_0_
> So I guess I'm asking if there have been many psychological studies based on our perceived intelligence and depression rates.*Perceived* intelligence??  No, I highly doubt that's been researched.  Actual intelligence (or at least as best we can define and measure it) and depression?  That's been studied quite frequently.  However the findings will surprise you; there is an inverse relationship between depression and IQ meaning that **people with higher IQ have lower rates of depression.** Same is true for suicide. Some people have hypothesized that depression and IQ is somewhat different in adolescence, but that the association is not between depression and IQ, per se, but depression and some measure of social functioning that may correlate with IQ.  Again, that is just a hypothesis and needs more research to better understand.
It depends on the type of plant, but in general they do this by pumping water into themselves.  They pump water through osmosis.  They also have much more rigid structures in their cells, and connective tissues (cellulose among others).If you break them over too hard, you break these structures and no amount of water pumping will right them again.
With your naked eye, none. Geostationary satellites are really too small to be seen at apr 24,000 miles away even under the best conditions including them reflecting maximum sunlight.All the satellites you might see are in low orbit. And the ones you see with the naked eye tend to be pretty big, like the ISS or Hubble. There are web sites that [predict visibility](_URL_0_). For my location tonight there are a predict 47 objects that will reach naked eye visibility. Of those  I see about 3 that will be bright enough to be noticeable unless I was making an effort to see the specific object. And all of the happen in a 3 hour window around sunset when sunlight can reflect off them but its dark enough to see them.With a telescope I am more likely to see more of the above 47, but they are so small and fast its a rare occurrence.  Even taking photos you can eliminate the one or two frames a satellite appears in or just wait to do photography after the sun is low enough it doesn't reflect off them which is probably a good idea anyway since  you want it to be really dark. Geostationary satellites are still not a concern for the typical amateur observer even with a telescope.Planes with lights are more of a concern and more likely to spoil your view of the night sky. The 3 days after 9/11 were magical with all the planes grounded.
In the past, hominids used to have very large guts, mouths, and smaller brains. The theory is that in the past when we had to hunt for food, we had to have large guts to process all the food, and a lot of energy went into to eating and survival. We also had large teeth and mouths, so we could chew foods (like grains) that were hard on our teeth and still survive. Then, when agriculture was introduced, humans could eat a better diet, and there stomachs started to become smaller, and their brains became bigger. The body started to put more energy into the brain, and less into the gut, making us be able to have more complex thoughts. Since the start of the Roman Empire we have gotten taller (and fatter!) and this is due to more access to foods. We eat more often, and therefore, our body has more energy to grow taller and fatter.
You threw around a lot of different terms that don't really relate to each other. Like /u/carpecaffeum said, replication occurs at many different origins along a genome (they're called "bubbles").    Both strands of DNA in both directions of the bubble are replicated simultaneously. One is the "leading" strand, which moves in the same direction the bubble is expanding (see [this](_URL_0_) diagram). The opposite, "lagging" strand, is synthesized at the same time in a discontinuous fashion.    Both the leading and lagging strands can be considered "template" strands, as they template the synthesis of a new piece of DNA. Both strands of DNA can be a "coding" strand.     I have no idea if I answered your question since I'm not sure what your question is.
Some types of glue contains a solvent that evaporates. After the solvent has evaporated, the glue hardens and binds the pieces together. An example would be white glue.Other types undergo a chemical reaction that binds the pieces together. Superglue is an example of this.Yet other types of glue are heated to flow easily to fill in the gap between objects, and hardens when cooled. Example includes hot glue.Other adhesives like tape don't contain solvents - rather, they use something with strong intermolecular attraction, often in a malleable substrate so they can fill in crevices of the pieces and strengthen the adhesion.
Sadly we currently are not able to detect individual stars that far away. The farther we get outside our galaxy the harder it is to detect individual stars. There are certainly millions and billions of stars out there but we can only see a small fraction of them. We detect galaxies instead and estimate the number of stars.
Software engineer here. There are many factors which contribute to a secure operating system. One is intent. Is the company trying to write a secure system? This may sound silly, but remember that a corporation is made to make money, not software. If they could sell an insecure system for the same price and less effort you will be getting an insecure system. The difference is like the one between a hardened battleship and a pleasure cruiser. They are made for much different reasons even if they do sail the same oceans. Consumer operating systems are made to be easy to use and to play well with certain types of software. Secure systems can be more inconvenient but are hardened.Second, is design. A secure system requires a rigid set of security protocols. This is usually done through a interface. There are many such interfaces, however one of the most popular is POSIX (UNIX if you can pay for the brand name). This is a well thought out, seasoned interface between the operating system and other software. Most open source software uses POSIX though Linux or FreeBSD (which are implementations of POSIX). Apple even uses POSIX. Windows however, does not. When you have a set interface your main concern is to make your operating system more closely conform to that standard. Then comes making it faster, more secure, etc. Windows doesn't have a set API and now has several layers of interfaces which may or may not conform to any standard.Finally, the real question: Does hiding your sourcecode hide security issues. In a word No. Most exploits are not found by looking at the sourcecode anyway, but rather playing with the code while it's running. You send a few packets and see what it does. You send a few broken ones and notice it takes a while for it to return the error. You send a huge message and see that you crashed the server. You try different combinations until you have a viable exploit. And it's not as if hackers can't read the code, they always have access to the assembly language which the computer requires. It's just not as readily understandable. So what causes "bugs" in the first place? Mostly, it's the developer not completely understanding what their code is doing. Often times we are dealing with layers upon layers of complexity. Sometimes we lose track of it all. In a recent case, they mixed up the names of two different memory locations, of thousands. What do we do to combat this? We have other programmers look at the code. Often times they will notice things we don't. It's similar to proofreading. Companies need to do peer reviews but often don't due to schedules, cost, lack of personnel, etc. The nice thing about open source is that anyone can peer review the code. Considering people don't get paid (usually) to review it (thus the licenses which state you can't sue us) it might not get reviewed at all. However, most popular software *is reviewed* because programmers want to learn how it works, students are assigned to look at some real code, or maybe a company who uses it actually pays someone to audit it. In fact, most code for Linux (the most popular open source OS) is written by corporate programmers.I would argue that open source is generally more secure than closed because "security though obfuscation" is no match for a well thought out, well implemented solution. For example, the Heartbleed error was discovered and will soon be fixed. The entire library will be upgraded. Then we can all check it for errors. Microsoft has sued people for finding such errors and exposing them. I firmly believe there are bigger errors, exploited errors, inside such systems which we will never know about because it's bad PR. And that's before considering the NSA has already been caught manipulating closed source security. After all, would you trust a bridge without an inspector? Would you trust an architect that hid parts of the bridge to make it "stronger"? Or would you prefer to know how it was designed and constructed? Imagine a world where Microsoft built bridges. Would you feel secure driving on it knowing they won't share their design?EDIT: Spelling and Grammar
Ice behaves somewhat transparent, depending the frequency used. [They use this to map underneath ice sheets.](_URL_0_) - although the signal gets attenuated a lot so you have to do a lot of signal processing. But.. if our knowledge of Europa turns out to be true, that its a solid core with ocean covered with ice, then we can't just parachute a submersible down there - we'd have to land some type of drilling rig that would drill through the ice to insert the submersible. So in that case, it would be easier to just run a relay station mounted to the underside of the ice that is connected to the surface with a cable. Or, have a communication relay use sound vibrations THROUGH the ice with a surface relay.
There is no ratio between a predator's population size and the population size of it's prey that applies generally to all predator-prey systems. This is because the ratio of predators' biomass to that of their prey is known to vary greatly between ecosystems. For example, in forest ecosystems often there is a very small ratio of predator-to-prey biomass (meaning a lot of prey biomass relative to predator biomass) because forests have large amounts of plant matter that is difficult for herbivores to consume. This creates a pyramid-like pattern of biomass where each step up in the food chain has less biomass, such that primary producers (plants) have much more biomass in an ecosystem than herbivores, which in turn have more biomass than primary consumers (consumers that eat herbivores). However, in many aquatic environments, predators can have more biomass than their prey, creating an 'inverted pyramid' pattern of biomass where the biomass of phytoplankton at any given time is less than that of the herbivorous organisms that consume them. This is because the phytoplankton that act as primary producers in the system reproduce extremely fast and have relatively short lifespans. One pattern that is well established is that less energy is available for each increased level in a food chain. This is because some energy is always lost between trophic levels. It is sometimes suggested that about 10% of energy from one trophic level makes it to each subsequently higher trophic level, but this is not true in all cases. If you want to learn more, I recommend you read about biomass pyramids and productivity pyramids (both of which may also be referred to as ecological pyramids or trophic pyramids) as well as trophic efficiency (also called biomass transfer efficiency in some cases).Also, it should be noted that predators can influence the population size of prey, and prey can influence the population size of predators. Read about predator-prey dynamics to learn more about this.
So before the umbilical cord is developed, the new embryo is already implanted onto the mother's uterine wall. Basically in early development, the zygote has gone through several divisions to become a blastula. This ball of cells makes its way to the uterus and will eventually make contact with the uterine wall and implant itself into the mother's cells. The site that this occurs will eventually develop into the placental attachment in later development, but the initial contact happens very early, well before 5 weeks. At this point, the embryo is attached to the mother but there's no real circulation happening and is instead passive diffusion from the mother's body is the biggest factor.With regard to ethanol: since ethanol is an ambipathic molecule, it can easily pass through cellular membranes and disrupt them along the way. Now I don't know how much passive diffusion would allow the ethanol and resulting acetaldehyde to affect the embryo at this point, but there is definitely a route that the embryo could be affected by alcohol consumption before placental development.
If you are referring to subjectively perceived brightness, then there can certainly be a difference in brightness between a monochromatic light source and a white light source emitting equivalent numbers of photons. If the wavelength of the monochromatic source is around the peak of human sensitivity, around 555nm, then it would appear brighter than the white light source. Conversely, if the monochromatic source is emitting a frequency that is not well absorbed, then it would appear dimmer than the white light.
I'd like to add to /u/zorbaxdcat's post. Firstly, you're looking at the Pleistocene not the Holocene! The Holocene is only the past ~11,700 years, since the end of the last glaciation.Generally for the past ~800,000 years, it has been orbital eccentricity that has dominated the climate signal. This is essentially how oval or circular shaped the Earth's orbit is at any given point. Exactly why eccentricity, which has a very small effect on isolation, appears to control glacial-interglacial cycles has been debated and has been referred to as the ['100,000 year problem'.](_URL_1_)Regardless, it's widely accepted that climate change occurs due not solely due to orbital forcing (i.e Milankovic cycles) but because of the associated feedbacks as the previous poster said. It's often been pointed out that CO2 lags temperature changes- that's not coincidental, CO2 levels in the atmosphere are largely influenced by ocean productivity. It's been demonstrated that many ocean regions, particularly the Southern Ocean, are dependent on wind blown dust to fertilize. It's been [demonstrated](_URL_0_) when climate is cooler, more dust blows to the ocean (due to less vegetation, drier climate etc) and thus more productivity occurs in the ocean. This helps 'suck up' CO2 from the atmosphere, and helps to keep temperatures low. Then, when eccentricity or another orbital parameter increases temperature a small amount, it can suppress this dust flux and cause a significant drop in CO2 intake by the oceans, causing atmospheric CO2 to rise and a rapid 'runaway' greenhouse effect. As mentioned, ice albedo feedback is also important. Permafrost thawing may also release significant amounts of methane into the atmosphere, another potent greenhouse gas. Then there's the further fact that warmer air can hold more moisture, which intensifies the greenhouse effect of water vapour, another GHG.Essentially the prevailing theory at the moment is that small changes in insolation or perhaps the timing of seasons (e.g shorter/less intense Northern Hemisphere summers favour ice ages) become big changes due to feedbacks associated with the change.
Large enough celestial objects acquire the spherical shape when gravity overcomes the rigidity of the rocks they're made of. This is known as hydrostatic equilibrium. In fact, the International Astronomical Union has used this as part of the definition of planet and dwarf planet._URL_0_Therefore, a large natural satellite like our Moon can't be stable with a hole through it. It would collapse into a non-hollow sphere.A smaller object, like an asteroid with an irregular shape, could be stable with a hole through it. The strain of a material does not depend on how much time the force is applied for (assuming it's had enough time to settle, but this is so fast that it's normally taken for granted). Therefore it could be stable for its entire existence. (This is also assuming that there are no big perturbations like tidal forces causing excessive flexing).
From a what I could find in [this paper from NASA’s archives](_URL_0_), they used silver-zinc batteries. They are apparently very similar to silver-oxide batteries, but instead of being one time use, they are rechargeable.
Seems like this is a perfect opportunity for you to do your own measurements. The label includes a mass as well (usually says "per 3/4 cup (100 g)" or something.) If you have a kitchen scale, you can scoop your own 3/4 cup and weigh it.
There are any number of reasons why a calculator would display thing differently.  First would be that it could be programmed to work in decimal instead of binary.  If that's the case, then numbers like 0.2 and 0.4 can be stored exactly, and operations on them can yield an exact result.  The other main possibility is that it is programmed in binary floating point, and just rounds answers that it displays so they appear cleaner in decimal output.A computer can of course be programmed to behave the same way as the calculator.  You could even run a calculator emulator on the computer the replicate the experience exactly.  "Java" doesn't do math and output numbers on its own.  It does what a programmer tells it to do.  If a programmer writes a program to do math using 32 bit floats, then the results will have the limitations of 32 bit floats.  But if the programmer uses some other expression of his problem, he can get whatever answer he needs.  It may be more work and run slower, but any Turing complete computer can do whatever kind of math you bother to tell it to do.
Depends on the reason for the stones, chances are yes at the beginning if the stones are caused by a systemic factor. But once you have stones in one kidney you are more likely to have stones in the same kidney due to wall damage and presence of stone fragments which become a nidus for more stones to form
Shifting tectonic plates, changes in the earth's orbit and better measurement technologies since the prime meridian at Greenwich was created in the mid-1800s mean that the strip in the ground is no longer exactly on 0 degrees. The prime meridian is (as your phone says) several hundred feet east of the strip.
Pretty sure there's been no research regarding a falling balloon with water. But this sounds like a perfect opportunity to set yourself up a hypothesis and conduct yourself an experiment.
After a blow to the chest your diaphram (a muscle which contracts causing a vaccuum in your chest [pleural space] which causes your lungs to expand creating another vaccum within the lungs which then sucks in air) seizes and you can't breath for a few moments.  It's the same muscle that twitches to cause hiccups.A collapsed lung is different and due to air in the chest around the lungs [pleural space again] which prevents the lung from expanding when the diaphram contracts as detailed above.
Yes.  We actually do this in my lab to heat things in vacuum.  We call it electron-beam heating.  I've heated small objects to 2000 degrees celsius by that method.  You can calculate the power delivered pretty easily -- for example, 100mA at 1kV is 100 watts.
The simple answer to the general question, "How do we theorize the existence of phenomena before they are observed?" is that we have constructed mathematical models of how the universe behaves based on other observations.  We can plug other numbers into these models to make predictions about how as yet unobserved events will transpire.  We then produce this event, and observe what happens.  If our predicted outcome transpires, then the model based on other observations has been supported.  If the outcome is not predicted, there's a chance our model is not accurately describing how the universe works.In the case of these theorized molecules, we have a pretty good understanding of how atoms interact with each other.  We can use this understanding to say that it should be possible for a certain set of atoms to arrange themselves in a certain manner.  It's not unlike the blueprint for a building.  Until it was built, nobody had ever observed the Eiffel Tower.  Based on what we knew about iron and lattice towers, someone said, "We can totally build this tower."  Producing a molecule nobody's ever seen before but whose existence should be possible is the same way, they just need different equipment to build the structure.
I don't know what you mean by equilibrium reaction, but in order to convert methylmercury into elemental mercury, you need to add a reducing agent, because the Hg in [MeHg]^+ is in the +2 oxidation state.  I don't think there are any biological processes that will go in that direction; the ones I know of go the other way.
There're multiple guidance methods.Beam-riding is the simplest. A narrow signal is bounced off the target, the missile seeker points the missile at the reflection. Fine for slow-moving or stationary targets, not so great for air-to-air combat when the launcher and the target are both moving at incredibly high speed. The russians still use this for modern anti-tank missiles, in a rather brilliant system, where the seeker is actually located at the rear of the missile, and steers the missile so that the beam is centered in the seeker, making it immune to almost any kind of jamming/countermeasure, whereas seekers that follow the reflection can be jammed by vehicles which deploy smoke or aerosol clouds when they detect the guidance beam, or outright blind the seeker(like the russian Shtora system)An infrared-homing missile is essentially a rocket with steering fins and an infrared camera of varying complexity. The earliest seekers could only tell whether something really hot was there or not, and would chase the hottest thing visible to the seeker, be it a jet exhaust, a flare or the sun. These early missiles were 'rear-aspect'- they could only be fired from behind a target, because they were only sensitive enough to see something like a jet exhaust, and were easily decoyed by using heat sources like flares, or simply flying towards and then away from the sun. Modern seekers, like on the Israeli Python missile, have actual CCD imaging infrared cameras, which visually identify the target as an object, rather a point-source of infrared radiation. Then there're the two types of radar guidance, active and semi-active. Basically the same concepts apply, except using bounced radar signals rather than infrared. Semi-Active listens to the bounces from the launching aircraft's radar, Active has a radar in the missile itself. Source- I'm a goddamned nerd.
sucrose has a density of 1.587 g/cm3._URL_0_
Since black holes don't emit light, we can't see them directly.  That means the only way to find them is by "indirect detections."  One common way to do this is by watching other objects orbiting the black hole (or having their orbits around other things disturbed by the black hole).  Another way is what you described; gravitational lensing.  In this case, we'd be talking about what is called "strong lensing." The black hole is a dense massive object.  So dense that even light bends a bit as it passes near the black hole.  So if there's a light-emitting object behind the black hole, when we look at light from that object, it's distorted in a particular way.  We can search for objects that have that kind of distortion, and then you know that there must be a dense object inbetween you and the distorted object.  If you can't see any big object there, then it's probably a black hole.  If things are lined up just right, you get what are called "Einstein rings" like [this](_URL_0_).  In that picture, the central object is the lens (in this picture it's not a black hole, but just imagine that instead of having a light-emitting object in the middle, there's nothing visible there), and the bright circle is distorted light from a galaxy behind the lens.
[Paper](_URL_1_) and [Review](_URL_0_). 1) This is in non-human primates. Will it work in humans? The people to whom ZMapp has been given and survived - is their survival due to ZMapp or just the fact that Ebola isn't 100% fatal?2) The drug is not made in a high-throughput method. This will be required for mass production. These antibodies rely on odd glycosylation status which in all likelihood will not be replicated in a bacterial system. Challenge!Previous answer of mine w.r.t drug development: > This is a hot debate currently w.r.t ebola. This [graphic](_URL_2_)  shows quite nicely what a marathon effort it is to get a drug to market. It also shows where the cost in pharmaceuticals is - note how little time a drug on the market is still under patent for costs to be recouped. > A drug normally must go through three species - rodent, dog, non-human primate for example before progressing into Phase I clinical trials. Phase I is a very small sample size (of the order 10) and is simple to see whether the drug is safe in humans (efficacy data is not really the aim). Then Phase II (of the order 100) and subsequently Phase III (of the order 1000). Each phase takes of the order a year and is extraordinarily expensive! > Ebola has thrown the system somewhat - what happens in the case of an unexpected, highly lethal emergence? Ebola treatment is being fast tracked because of the nature of the disease but realistically it's probably not going to be the key in stopping this particular outbreak.
The egg proteins are denatured and get long and loose, this allows them to interact with other ingredients physically , such as flour, crumbs, etc. Once the proteins start to set in place, the ingredients are essentially “bound” to the proteins, and to one another.Oils and fats are long carbon chains (esters, specifically) and do no denature the same as proteins so they wouldn’t be able to “bind” the ingredients
I did a quick search for previous studies on the subject of neem cream use and found a couple things:* Dua *et al.* 1995 found that neem cream application resulted in 65 - 95% protection against a number of different mosquitoes, including members of Aedes, Culex, and Anopholes. One application, however, was only effective for about 2 - 4 hours.* Singh *et al.* 1996 achieved 90 - 95% protection against culicine and anopholine mosquitoes over the course of an entire night.* Finally, Nagpal *et al.* 2001 found that a 5% cream resulted in 75 - 100% protection for various mosquito groups. They also found the effective protection period to be around 2 - 4 hours.
The short answer is that it depends on the atom.  Atomic nuclei have what's called a "nuclear binding energy", which means an atomic nucleus has a lower potential energy than the sum of its constituent parts, and that holds the nucleus together.  When talking about binding energies, physicists commonly use units of "energy per nucleon".  You can plot the energy per nucleon for different elements, and you'll end up with something like [this](_URL_0_).  As you can see, iron (Fe) has the highest binding energy, and acts as a sort of "turning point" in nuclear reactions.  Elements with atomic number less than iron release energy upon fusion, while elements with atomic numbers greater than iron require energy input for fusion, but release energy upon fission.  This is the reason the sun is able to sustain itself through various fusion reactions (H- > He, He- > C, etc.), while fissile nuclear weapons use uranium or plutonium.That all being said, in fission processes where free-traveling neutrons induce fission of atoms, the mechanism of action is not overcoming the atomic binding energy.  Rather, the capture of a slow-moving (low energy) neutron by a nucleus changes the isotope into one with a much shorter half-life, that then radioactively decays into lighter elements plus additional neutrons, which carry on the reaction in other atoms.
Well forming a different element and forming a different isotopes of the same element are different processes because they have different final states.Whenever a nucleus captures a neutron, it becomes the next heaviest isotopes of that same element. Then sometimes that new isotope can subsequently beta decay to the next higher element. This is a way to produce heavier elements [like so](_URL_0_).
First it helps to think that objects, as defined and perceived by humans, are fundamentally manifestations of fields in space-time; you can't separate them.Now if you draw a circle on a piece of paper it is only a circle because the paper is flat.  If you curl the paper up  it is still the same drawing, it is still a circle if one considers only the surface of the paper, but it is not a circle if one considers the projected image on another flat surface (yet the circle itself has not changed).  Likewise if we have a really long pole in space that is curved only to the right (space itself curved that is), standing at one end and looking down its length it will appear straight, but from above it will appear to bend to the right.  In fact the only way to define the pole as straight is to choose a co-ordinate system that makes it such.So the answer to your question is that there is no 'shape of a local object' to change.
Upward cloud-ground strikes are uncommon, and mainly occur on sharp objects or topographic features.  This is because lightning initiates where the electric field is the strongest, which is generally between the charged layers of the cloud, or between the lower (negative) charge layer in the cloud and the ground.As far as the effect it has, lightning is lightning.  It doesn't matter whether the leaders go upward or downward; it's still about 20 kA flowing through the strike.
At least some of the lead will wind up in the air. [Source referring to lead in fumes from burning paint](_URL_1_). [Source referring to lead in particulates from burning paint](_URL_0_).I hope that your uncle is taking proper safety precautions.
While it is almost certainly true that roads will act as isolating barriers and eventually drive the formation of new species, I know of no study that has actually shown that yet. There are certainly studies that show how animals interact with roads in interesting ways and road-avoidance is common (see the work of [Dr. Jesse Barbar](_URL_0_)). But actually showing that a road is the primary cause of speciation is a very difficult task especially since the large, heavily-traveled roads that would effectively isolate things are actually a relatively recent development. It takes a long time for species to form, normally on the order of millions of years and major roads have only been around for a couple hundred years if that. Furthermore, it doesn't actually take a lot of migration to keep populations genetically connected (and thwart speciation), in fact a single migrant per generation who successfully breeds will often be enough. As such, the small, rarely-traveled dirt roads in the backcountry are unlikely to have a large effect, while 12-lane superhighways are likely more important. So, while theoretically it's *possible*, and I would argue that given enough time it may even be *likely*, we don't have any convincing examples of road-driven speciation at present.
Lightning is able to to generate extremely high voltages. In theory the energy could be absorbed by an appropriately sized capacitor, but in practice there is a problem with maximum voltage capacity. The size of a capacitor scales with maximum voltage and capacitance. The maximum voltage is determined by the material and geometry of the capacitor, and once exceeded the current just self discharges within the cap. Capacitance is determined by the area between the terminals, and the material used to separate them. In practice, high capacitance is sometimes achieved by separating conductive films with a dielectric material, folding the film into a large stack to fill up a 3D boxlike space. Peak current carrying capacity is dependent on the thickness and area of the conductive film used, and the physical strength of the container holding the film.Lightning bolts transfer around 50 to 350 Coulombs of charge, reaching currents of 50 - 300kA, with energy in the 500MJ range. The largest cap bank in the world is at the [National Ignition Facility](_URL_0_), can store around 330MJ and costs about $2 billion. Unfortunately, lightning strike energy varies, so some type of high voltage bypass like a spark gap would need to be present to prevent exceeding the banks peak voltage, otherwise the caps will go boom. If one major lightning strike hit the facility per second and was quickly transferred to a flywheel or some secondary energy storage, one could have a power output in the 500MW range, similar to a standard size power plant. Unfortunately, this power plant would only run when a storm was directly over the cap bank, since lightning can generate a billion volts and defeat nearly any imagined insulating cable designed to channel the power over long distances back to the plant. It would be a real challenge to ensure that some rouge larger than average lightning bolt does not overcharge the cap bank, though certainly possible.Another major issue would be strike frequency. Any time the cap bank was full, it would need to be discharged before receiving more energy. It is possible to build the cap bank to be 10x larger than any known lighting strike, but then the facility is getting into the $20-200 billion dollar range, very capital intensive.
That's not [precession](_URL_0_), precession happens to a spinning body. The Earth spins, it's an oblate spheroid with water and a Moon, so its rotational axis rotates with a 26,000 year period - that's precession.The solar system bobs up and down through the galactic plane over a period of 60 million years, but there's not a helical motion as shown in that video. For that to happen the solar system would have to be orbiting something that's orbiting the galaxy, and to have a period like 26,000 years, it would have to be pretty noticeable.
"About 70,000–100,000 years ago some modern humans began to migrate away from the tropics to the north where they were exposed to less intense sunlight, possibly in part due to the need for greater use of clothing to protect against the colder climate. Under these conditions there was less photodestruction of folate and so the evolutionary pressure stopping lighter-skinned gene variants from surviving was reduced. In addition, lighter skin is able to generate more vitamin D (cholecalciferol) than darker skin so it would have represented a health benefit in reduced sunlight if there were limited sources of vitamin D.[3] Hence the leading hypothesis for the evolution of human skin color proposes that:**1. From ~1.2 million years ago to less than 100,000 years ago, the ancestors of all people alive were dark-skinned Africans.2. As populations began to migrate, the evolutionary constraint keeping skin dark decreased proportionally to the distance North a population migrated, resulting in a range of skin tones within northern populations.3. At some point, northern populations experienced positive selection for lighter skin due to the increased production of vitamin D from sunlight and the genes for darker skin disappeared from these populations."_URL_0_
Could be a mix of all of the above.The immune system is split into the innate and active/adaptive systems.  The innate are, to use a video game analogy, all the non-specific "passive" defenses of the body.  For example, inflammation, skin, and enzymes designed to digest viral-specific dsRNA are all innate portions of the immune system.  Like passive systems in video games, the innate system is designed to slow down pathogens until the active system comes into play.The active system is the hunter-killer of the immune system.  Immune cells are basically split into 3 important types: killer T cells, helper T cells, and B cells.  Killer T cells recognize cells that are infected with viruses and destroy them.  Helper T cells bind to "trash collector" cells that go aroud digesting cellular debris.  B cells are recruited by helper T cells to produce antibodies that bind to the recognized pathogens and act as "kill me now" flags.The one flaw of the active system is that since each killer and helper T cells are specific to only one pathogen, it can take a very long time for a specific T cell to be able to detect and recognize the pathogen and create an immune response.People with stronger immune systems may have more immune cells, systems able to better move immune cells around, or may be just lucky (since the protein on T cells that recognize pathogens is randomly generated).This is a ridiculouslu simplified version.  There are dozens of other nuances and steps in the immune system.
It might help to think of the partitions that carbon can take within [the carbon cycle](_URL_4_). The movements between atmospheric, biomass, and oceanic carbon compartments is very fast in comparison to the conversion to coal, oil, and gas. The rate of fossil fuel formation is slow enough that we can consider them to be zero on the human time scale. Using fossil fuels will permanently (human time scale) increase the amount of carbon in the atmosphere unless we can find a way to "take it out of circulation" (which is where your question comes in).The process you're calling is called [Carbon Sequestration](_URL_1_) [[epa page](_URL_6_)]. While it's conceptually a great idea, there are some major limitations. A major problem with capturing carbon dioxide from the atmosphere is that it has to go [somewhere](_URL_0_). Storing CO2 in depleated oil fields is one of the easiest ways but has been (controversially) repeatedly linked to earthquakes [[1](_URL_5_)] [[2](_URL_7_)]. Storage alternatives such as storing CO2 (or the carbon itself) in the form of organic carbon in plant matter is only a temporary buffer, as that material will eventually break down and be converted back to CO2 by bacteria and fungi. Another problem is the energy required to remove CO2, either directly from powerplant stacks or from the atmosphere. It's an energy intensive process and the US [overwhelmingly](_URL_3_) uses fossil fuels for energy generation, just like the rest of the [world](_URL_2_). We would need to produce more energy just to treat the waste of the energy we are producing. In reality, we need to shift more of our energy production to carbon neutral or renewable energy sources. I don't mean to poo-poo carbon sequestration because in the long run (decades) it is going to be an important part of protecting the climate. My argument is that we shouldn't let carbon sequestration's potential to overshadow the urgency of reducing carbon releases or the movement to renewable energy sources.
Please everyone remember this is not the place for anecdotal "me too" answers. This is asking for scientific literature and case studies. Please do not comment unless you have sources to back it up.
1. They aren't Newtons laws of thermodynamics.2.  Glass is not a perfect crystal.  In fact its not a crystal its an amorphous solid.
>  Are black holes really infinitely dense? AFAIK, we don't really know. All we know is that in a black hole, currently accepted models don't really work. Hence the term "singularity."
Bipedalism has less to do with it than being upright does. Lots of animals are bipedal (birds etc) but humans uniquely center their head over their shoulders, shoulders over hips, hips over knees and knees over feet in a balanced fashion. This means when standing, our weight is supported on bones. Contrast this with any other tetrapod where the leg bones zig zag between the torso and the feet, necessitating muscle tension to support the animals weight and prevent collapse. Our muscles simply hold the bones in our back and legs in proper alignment and never actually take much load unless we are squatting. When walking, the weight bearing leg remains very straight, again transferring weight along the bones, while we shift our weight forward, and begin to fall forward. We catch ourselves on a straight leg again and the energy from the slight fall is transferred into forward momentum. This is why people sort of bob up and down as they walk, and also why we can easily trip. Other tetrapods utilize muscle input to induce forward motion and that eats a lot more energy.
How are geology studies completed for areas?  I can find maps online showing geological regions, [such as this](_URL_0_).  How are the surveys to define these borders on the map completed, and how are the borders placed on the map?
The Planck units are the best system of units for this; they get rid of the speed of light, Newton's constant, Coulomb's constant, Boltzmann's constant (related to the ideal gas constant), and Planck's constant. All of those have a value of 1 in Planck units.Planck units however are not necessarily "funamental", for example if you calculate the Planck unit of charge it's something like 11.3 fundamental charges.
Although this is presumably negligible, when a plane flies in the direction of motion of the Earth, the centrifugal force acting on it would be higher, pushing it upwards, which means it can use less fuel to stay in the air. (Another way to think of this is that, ignoring air friction, if the airplane traveled sufficiently fast in the direction of rotation of the Earth, it would enter orbit, meaning it could travel without expending any energy. As the speed of the plane goes from zero to orbital speed, the force needed to keep the plane up goes steadily from g (the force of gravity) to zero.)Relatedly, the centrifugal force reduces gravity near the equator compared to the poles (or more precisely, it cancels some of the force of gravity).
There's a general method of constructing a number that ends repeatedly in some arbitrary sequence of digits.*x* = 0.373737…  100*x* = 37.3737…  100*x* – 37 = 0.373737… = *x*  99*x* = 37  *x* = 37/99
Gravity doesn't increase at all with that small altitude change. What's happening is the center of mass is moving closer to the tip of the tape, thereby causing the normal force moment about the center of mass to decrease. Think of it as less weight being applied at the point it would most likely bend.
Part of the explanation may be that folks are dying of other things first. Also consider that available information can only include cancer that is *diagnosed*.The rate, naturally, may very well be the same, they're just walking around oblivious to it. People need to see a doctor first for anyone else to know (and record) that they have cancer. There are many reasons a visit to a doctor may be unlikely. Price, distance, health, and general availability are primary factors in lessening the frequency of diagnosis. All of these thing are accentuated in 'less developed' countries.Check out this [life expectancy estimate put out by the CIA in 2012](_URL_2_) and this [chart from the WHO regarding cancer rates in 2015](_URL_1_). [This correlation is not unnoticed](_URL_3_), although [the disparity is shrinking](_URL_0_) due to a lessening of the aforementioned causes.
In terms of the thermodynamics, (ignoring the kinetics or activation energy required to initiate a reaction) deciding whether a reaction will be exothermic or not is dependent on the energies of the products and the reactants. Carbon based compounds tend to be highly combustible due to the large energy gain from creating carbon dioxide and water (if hydrogen is present, as is typical with carbon based compounds). That is, the products are more stable and so the reaction is driven towards creating them. Even diamond burns under the right conditions.TNT is a good example of this. Upon detonation is forms nitrogen gas (N2) as well as water and carbon dioxide. Nitrogen gas is extremely stable (let alone the water and carbon dioxide) and so the reaction is energetically driven forwards.
Inertia is an ill-defined concept. In terms of linear motion, it usually either means mass or momentum.If you take inertia to mean "resistance to change", then I suppose the "inertia for temperature" would be [heat capacity](_URL_0_), which is the amount of thermal energy required to change temperature by some fixed amount.
Your image is mirrored. more important, i think, is the factn that you only see yourself from a few angles. Use a second mirror to get different angles which are somewhat less familiar.
I have a degree in nuclear engineering, although it isn't my current area of study (i.e. my tag).I imagine you are talking about the current hysteria over the reactor 4 spent fuel pool? A sitting US Senator visited the site, saw the extent of the damage, and wrote a letter to various Japanese and US officials urging them to look for a quicker solution to the problem of re-locating the spent fuel. For reference, the current plan is to transition the fuel to dry-cask storage on a ~10 year timeline.So what is dangerous about the spent fuel pool?  As we all probably know, when fuel is burned in a nuclear reactor the leftover material is highly radioactive.  In fact, it is so radioactive that it requires cooling for ~4-6 years after being removed from the reactor.  However, so-called "passive cooling" is sufficient - the fuel bundles are placed in a large pool of water, and natural convection keeps them cool.  After some time has passed, and the radioactivity has subsided somewhat, the fuel bundles can be transferred to "dry-cask" storage - basically encased in a large concrete container.  So that is where we are.  The fuel rods are sitting in their pool.  The problem is that the earthquake destroyed all the cranes that are used to transfer fuel out of the SFP.  So, in the near-term, there isn't much we can do to the fuel bundles.Now here is where the controversy starts, and it requires several leaps of logic.  You may have read many recent articles that claim that the SFP#4 is a threat to humanity - [here is one such article](_URL_2_).  This story was picked up by the alternative media and promoted in anti-nuclear circles.  And it is a real eye-catching headline - I can't blame people for being worried after reading an article like that.  I've even seen some articles that claim that the radioactivity in the rods could cause the deaths of *billions* of people, although I haven't seen any credible calculations to back that up.  The articles all seem to reference the same scenario - an earthquake (somehow) drains the SFP, and from there every last bit of radioactivity in the rods is released into the air, travels across the ocean, and causes mass extinction in the US.This scenario is so implausible that it still boggles my mind that it gets any coverage at all.  *If* an earthquake happened and *if* the fuel pool drained, all that is needed is to pump water from the ocean, 30 meters away.  SFP are at atmospheric pressure, so there aren't pumping problems like what led to the original accident.  And even then, *if* there was no water and *if* the debris in the pool caught fire, they are still encased in zirconium cladding, which holds the fission products within.  The release of radioactivity from the original accident and chernobyl were because the cladding melted inside the heat of the reactor.  In chernobyl especially, the large cesium release was due to burning graphite, which can undergo self-sustained combustion at very high temperatures.  The SFP#4 rods are radioactive, but there isn't any mechanism that can cause that kind of release.  If you are skeptical, you can [watch this video](_URL_0_) of a zirc rod being hit with a blowtorch, and not burning.I'm not saying the SFP is something we can just forget about - there are rods there that need to be dealt with in the long term.  But the hyperbole about this pool causing the extinction of the human race is ridiculous.  The mainstream media doesn't cover it because it is a non-story - "fuel pool somewhat dangerous but not that bad" isn't a winning headline.  But the story circulates with even wilder and wilder predictions in the alternative media, and then people start thinking it's some kind of conspiracy or cover-up - "why isn't anyone talking about this horrible threat?!"  I think the echo chamber is building up so loud that we will see organizations like the IAEA or the NRC try to address it publicly.**edit:** I was just made aware of an effort by the American Nuclear Society to address the SFP#4 concerns.  [Here](_URL_1_) is a very thorough and well-referenced article by a former reactor operator that explains much better than I did why this isn't a credible threat.
Because the aftershocks were still essentially due to the same fault rupture. Let's try an analogy. Pretend you broke your leg. The doctors set you up in a cast, but one week later you fall down on your leg again! You have to go back to the hospital because you just "rebroke" it. Is it an entirely new break? No, in fact it *wouldn't* have broken except for the first break! You really just made an existing break worse.
Data to be encrypted generally has some order that can be discerned.  Many file types have a header that allows programs to identify it given nothing more than the first few bytes.  If the attacker knows that the encrypted contents is such a file then they can look for known headers and identify a correctly-decrypted output that way.Many filetypes are sparse, meaning there are large chunks of space filled with zeros.  This would be an extremely good indicator that you've found something interesting, even if it isn't the plaintext. > Would a brute-force program be able to notice the difference between guessing the correct and incorrect keys for the second level?Ideally, no.  Encryption algorithms generally strive for output that is indistinguishable from random data.In reality an attacker may be able to mount statistical attacks or use other advanced cryptographic techniques against the combined cipher.  One such attack against this exact setup is called a [meet in the middle attack](_URL_0_), you can look at that for further resources on the subject.
I'm a physicist, not a food scientist, but I don't imagine that you're breaking chemical bonds. It's probably not correct to think of a loaf of bread as a single molecule. Rather, the diverse high-molecular mass molecules that make up the bread are held weakly together by forces like van der Waals interaction and dipolar forces, similar to a polymer. Edit: some back of the envelope math. Let's estimate that the molecular spacing of the bread is similar to water. Water has a density of ~1g/ml and a relative molecular mass of ~18. This means that 1g of water, which occupies 1cm^3, has 3x10^22 water molecules, and thus the average spacing between molecules is 3x10^-8cm If your loaf of bread is 20cmx20cm cross section, the number of molecules along the interface is (10*(1/(3x10^8)))^2~=10^17. Carbon-carbon single bonds have a bond energy of around 300kJ/mol, which means that shearing across the loaf requires 0.2J. That's not much, but this isn't what determines whether or not the bond will break. The energy per covalent bond is huge compared to the relatively weak interactions that hold separate molecules together (dipolar/van der Waals). The molecules would much rather slide apart from each other than break apart.
The fact that you can't see it is because the intensity you observe goes down with distance according to the [inverse-square law](_URL_0_). So it's just a consequence of your eye-brain not being able to register it when there are few photons. In an empty Universe, a single photon will keep going forever.
If by chance you know something about maxima, minima, and the slopes of functions (standard fare in a calculus class, so perhaps you've seen this), the answer to this question is reasonably straightforward.Imagine you plot the number of hours of daylight as a function of the day of the year.  It will reach a maximum on the summer solstice and a minimum on the winter solstice, and so will be shaped sort of like a sine curveThe rate at which the amount of daylight is changing is the slope of this curve.  At a maximum or a minimum (i.e., on the solstices), the slope is zero (the tangent line is horizontal), and so around the solstices you have the slowest rate of change.  The maximum rate of change in sunlight occurs at the time when the graph switches between an upward "U" shape and the upside down version of that shape (this is called a *point of inflection*).  These points of maximum rate change are somewhere around half way between the two solstices (which also means somewhere near the equinoxes, although the equinoxes are not at the exact halfway point either).
By my rough calculations, the three stages of a Saturn V with no payload unencumbered by gravity or air resistance would be able to achieve the following speed relative to their initial velocity: 5.7 km/s + 5.6 km/s + 10.3 km/s = 21.6 km/s which is 48,000 mph.
There are several reasons, but the primary reason for the dominance of deciduous forests in the East and evergreens in the West is precipitation and temperature. The eastern United States experiences more extreme variation in precipitation and temperature throughout the year than do western states. During the winter months in the East, the ground is typically frozen solid and there is no precipitation that can be readily utilized by trees (i.e. rain). Therefore, whether you are an evergreen or deciduous tree, photosynthesis is severely restricted during the winter months. Therefore, the best strategy is to simply shut down during these months, which is essentially what deciduous species do. You can think of deciduous species as making up for lost time during the spring and summer months. In contrast, in western states where there is enough precipitation for there to be forests in the first place, winters are much more mild, and precipitation in the form of rain occurs year round. In fact, in places like the Pacific Northwest, rainfall is actually greater in the winter months than in summer. Therefore, species who are able to take advantage of these year round resources (i.e., evergreens), will have the competitive edge. Again, this explanation if for your question about eastern US vs. West. The reason for why evergreens become dominant as you head north is a bit different.
Quantum mechanics is all probabilistic. "Cool enough for recombination" means the bound state energy was just larger than the thermal energy. The thermal energy for an electron gas is an average energy. Some have more some have less. There also wasn't a perfectly  even distribution of protons and electrons at that time.
Unfortunately, the answer is never.  We can approach this question in two ways: gravitational lensing, and object resolution.A distant black hole, or even the one at the center of the galaxy, may in fact have the perfectly perfect angle where the photons from millions of years ago  (other galaxy), or thousands of years ago (milky way) would loop back and come back to us.  Unfortunately, black holes aren't just hanging out.  They are surrounded by disks of gas and matter moving at up to relativistic speeds and emitting tons of radiation in all wavelengths of the spectrum.  Any photons lucky enough to make the round trip (not quite round trip as everything is in motion) will be lost among all the other energy.  Our galaxy is a better candidate because of the angular perfection required, but it would just be noise.Now, lets say we find that perfect local black hole that happens to have swallowed up everything nearby and is just "hanging out" in our solar neighborhood and curving spacetime. Physics dictates the minimum resolution of an object based on the aperture and sensor size.  The amount of light coming back from the black hole from our ancient past would be coming from such a minute point in space that even if it weren't lensed beyond obscurity, our only bet would be to pray for a faint atmospheric signature if we happened to eclipse the sun.  Even with a futuristic atom-grid sensor, we still wouldn't have the power to resolve any details of the planet.There are just too many factors working against this.
An atom is about 10^(-10)  m, an ant is about 3\*10^(-3) m, so the ratio of their sizes is 3\*10^(7). You're therefore looking for something that is about 10^(5) m or 100 km in size. So if an ant is to an atom, the large island of Hawaii is to an ant.
There is a 1/(2^23) chance of that happening, not counting crossing over.
You can't easily create them as that takes nuclear fission or fusion (though something useful could be a byproduct of power generation in the future).  However, it is pretty easy to convert other substances into the stuff you need as long as you have some good hardware and a lot of energy.For example we can make oxygen out of pretty much anything that has oxygen in it, notably water or carbon dioxide.  It takes a lot of energy input but we know how to do it.  If you don't have those present there are thousands of other things we could use that have oxygen like dirt which often contains a lot of metal oxides (rust is iron oxide, limestone is calcium oxide, etc).Some things are definitely harder than others.  For example if we want nitrogen to grow plants with then we need to convert elemental nitrogen (N2) into a form plants can use like ammonia (NH3).  We can get the nitrogen and hydrogen from a lot of places but turning N2 and H2 into NH3 requires a ton of energy and pressure, and that might be much harder to do out in space.  However, there are always other pathways and we could do something like make ammonia through a biological route (bacteria).
There are many different kinds of dwarfism, so I'm not sure about all of them, but achondroplasia (the most common kind) can be detected via prenatal ultrasound.  [Wikipedia has details](_URL_0_).Another very rare form of dwarfism, [Primordial Dwarfism](_URL_1_), results in a smaller-than-average fetus and continued small stature, but tends not to be diagnosed for years because it does not cause obvious skeletal changes.
They died. It happens a lot in the wild to herbivores especially, they can't eat anymore so they starve.
[Ferroelasticity is a phenomenon in which a material may exhibit a spontaneous strain. When stress is applied to a ferroelastic material, a phase change will occur in the material from one phase to an equally stable phase, either of different crystal structure (e.g. cubic to tetragonal), or of different orientation (a 'twin' phase). This stress-induced phase change results in a spontaneous strain in the material.](_URL_0_)A primer on toughness: "toughness" is actually kind of a weird thing (its units are MPa & radic;m, how weird is that?) but it's kind of a measure of how much plastic deformation a material can accommodate before it fractures.  This is an oversimplification, but basically, low-yield-strength(to-UTS-ratio) materials are often very tough, because a lot of work goes into deforming them before they snap, while high-yield-strength(to-UTS-ratio) materials are often very brittle, because they can't accomodate any plastic deformation.  So - ceramics are high-yield-strength(to-UTS-ratio) materials.  They have a very small fracture strain. That means they're brittle.  They tend to shatter rather than stretch or tear.  But some ceramics are less brittle than others. Tetragonal zirconia is an example.  Remember that materials are brittle if they don't undergo plastic deformation (i.e. they break without changing shape permanently)? The reason ceramics can't undergo plastic deformation is that their bonds don't allow the formation and movement of dislocations (holes/extra atoms in the crystal lattice).  That's the main mechanism for plastic deformation in metals under usual conditions.  It turns out, though, that there are other ways to accommodate plastic deformation.  This article is talking about stress-induced phase changes.  It turns out that for some materials, if you subject them to enough stress, that will allow the material to "pop" into a new crystal structure.  Compared to the old crystal structure, the new crystal structure will always have atoms in different positions (or it would be the same).  This causes a strain - a deformation - relative to the old shape of the material.  These phase changes are only sort of plastic (in principle they're reversible, but they are "permanent", which is really what plastic means), but what they do is allow the materials that exhibit them to undergo plastic deformation - change shape permanently.  As we noted above, the more plastic deformation you can accommodate before breaking, the less brittle you are - so if you can exhibit this ferroelasticity, you can accommodate more strain, and therefore you're less brittle.
Aside from hypothetical odd situations like physical memory that is destroyed upon reading, there is no "move", it is just copying and deleting.Even if it were possible, since transfer (e.g. copying over a network) is unreliable, it would be incredibly error-prone to do that.  Packets can fail to reach their destination, so sometimes they need to be sent again.  In order to do so, you still need the original data around. >  This question comes from me wondering if a full sentient artificial intelligence could actually transfer itself somewhere or if it would just be cloning and killing itself.One of the more cringe inducing sci-fi tropes to a computer scientist.  Even though technology so much more advanced than our own could be entirely different, it's really hard to imagine a computing system where such a concept makes any sense.
I think what most people will tell you is that white matter does a lot, but we don't know what a lot of it is yet. So much neuroscience research so far has focused almost exclusively on neuronal activity (grey matter), and has assumed that white matter [(particularly glial cells)](_URL_0_) is a support system for grey matter. Lots of more recent research has been documenting the role white matter plays in various activities (and has implicated differences in many clinical conditions like schizophrenia and autism), but I don't know too much about what that research is actually positing cells like glia and astrocytes (that make up white matter) are doing. Maybe someone else can add to this!
The answer is "minimum ground clearance".  The flat bottom of that cowling will be parallel with the ground when the wing tanks are fully loaded.  There are FAA regulations requiring a particular minimum ground clearance between the engine and the ground, and that cowling shape is necessary to comply with them.e: The reason this was necessary is that the newer 737s are fitted with physically larger engines than they were originally designed to accommodate.e2: I just looked up the ground clearance for the engine cowling on the 737-800 and the minimum clearance (i.e. the clearance at max takeoff weight) between the engine and the ground is only **1 foot, 7 inches (48cm) nominal**, with a tolerance of +- 3 inches to account for loading variations, oleo and tire pressures, center of gravity, etc.
Molecular structure gets changed in glaze firing, called vitrification. Bisque firing burns out organic matter and clay undergoes quartz inversion: bisque isn't needed, but is very convenient for glazing and is less fragile than bone dry greenware. There are many many different types of firings and clay composition. I will try to refer you to some literature tomorrow if I remember. some really fantastic resources:_URL_1__URL_2__URL_0_Rhode's book is the one I had in college; very comprehensive and informative.Leach's book covers a lifetime of observations from perhaps the most influential potter of the Western worldLawrence's book starts to get into the really interesting side of technical ceramics: exploring topics of firing chemistry and chemical tailoring.
There's different levels you can look at it from. The simplest is conservation of energy. If it didn't turn slower under load, you'd have more energy when you give it a load than when you don't. It could be creating energy, or it could be destroying it when you don't use a load, but either way that's not conserving energy.But looking at the underlying physics itself, it's because when it's under load, you have a magnet moving through coils to generate electricity, and the electricity moving through those coils generates a magnetic field in the opposite direction.
The difference is due to something called kinetic isotope effects. Bonds to deuterium are just a tiny bit stronger and shorter than bonds to hydrogen. This is a result of the deuterium being twice as heavy.The toxicity stems from the fact that enzymes are very finely tuned systems and the small change in bond strength is enough to really mess with how fast some reactions proceed. Do this on a large enough scale by drinking a bunch of D2O and your whole biochemistry goes out of whack leading to death.
It depends on what the material is and what the acid is.Most metals that get "eaten away" by acid turn into a salt form. For example, zinc reacts with hydrochloric acid to form a solution of zinc chloride. Organic materials (carbon-based) that get "eaten away" by acid might become completely oxidized to CO2. Others get converted into a carbon-rich charcoal-like substance. Again, it depends on the acid.There are some very specific reactions of some materials with some acids. Glass is attacked by hydrofluoric acid to produce silicon tetrafluoride, but no other acid reacts with glass in this manner. Aqua regia (a mixture of nitric and hydrochloric acid) reacts with gold and platinum to form complex metal salts, but these metals are completely unreactive toward less potent acids.
The rest of Reddit needs to be exposed to this.
If there was a planet just like Earth orbiting Alpha Centauri, we couldn't detect their normal radio/tv transmissions from more than a light year away. But if they aimed a powerful directed signal at us, and we were listening to Alpha Centauri at the time, then we might be able to detect it.
Some of the light is scattering off of something in all directions. In air, e.g., some fraction of the light is scattered per meter traveled. The more intense the laser the more intense the scattered light will be. So a laser is visible from the side once this scattered light passes whatever intensity level you need to be able to see something. Often some sort of smoke or dust is used when people want to be able to see a less powerful laser beam. Having something like that in the air increases the fraction of the light that is scattered.
When observing the universe from a "high level" view (above scales of ~100 megaparsec), the homogeneous and isotropic distributions of things like galaxies and clusters becomes evident. In other words, it is remarkably "sameish" everywhere you look: a nice even distribution.At smaller scales, a "lumpiness" is observed, where the clusters and superclusters of galaxies are arranged along "filaments", surrounded by enormous "voids" which are comparatively free of matter. As noted by the OP, the universe at this scale is often depicted as a web or a foam.As for the source of this surprising "clumping" distribution of matter we observe in a universe which started from an *unimaginably* consistent and homogenous state, my (non-expert) understanding is that this was caused by tiny density fluctuations in the early universe, and the effects of cosmic inflation and gravity.Perhaps someone with some cosmological creds could formalize the details of my comment somewhat :)EDIT: I can't spell.
When the ice sheet passes over water it flattens out; ice is slowly flowing inside the ice sheet, and though friction with the underlying rock can cause an irregular surface when over land, over water it settles into something closer to a hydrostatic equilibrium.
Magnets create a magnetic field. Magnetic objects in this field have _potential_ energy. The situation is similar to masses on earth. They gain potential energy when you lift them up. However, the earth itself (or the magnet) does not create the energy. No, its _you_ who does the work, by lifting them up.
Assume you and your boyfriend are both spheres at 37 Celcius.The ratio of his total radiated power to yours is just the ratio of your surface areas: (M^BF /M^you )^(2/3) .So if he weighs 80 kg and you weigh 60 kg, he radiates 21% more heat than you.
Unless I'm missing something - the answer is really "there is no scientific answer."Some group finds certain ratios and geometric forms to be important, and so uses them in various ways.  While there are certain ratios and geometries we find in nature and that come up all over the place, that makes them no more sacred than, say, a cow, or a piece of french toast with the image of a saint on it.
It is possible, yes.Clouds affect UV rays the same way they affect rays of visible light - rays are scattered by reflection  &  refraction, and a lot of energy just ends up being absorbed - so if it's getting visibly darker as the clouds roll in, UV levels are dropping just as much.So if it's 1/10th as bright under the clouds as it was under clear sky (which you could measure with a camera, if you were so inclined), it will take ten times as long to develop a sunburn.That said, though, we're *hopeless* at estimating light levels visually, because our pupils are always dilating  &  contracting to compensate, so you can easily be fooled by light or sporadic cloud cover into thinking that the risk of sunburn (or worse) is lower than it really is - and if you think you're not getting burned just because it's cool  &  cloudy, you might end up staying outside longer than you should and getting burned *anyway*.So whenever you expect to be outdoors for a while, regardless of the weather, apply some sunscreen and carry some clothes you can cover up with.If you or your cousin are trying to tan, by the way - I know I won't be able to talk anyone out of tanning - you can still reduce *burning* by applying sunscreen that's been diluted with baby oil, or even vegetable oil. Way too many people refuse to use sunscreen while they're trying to tan, and they end up badly burned because of it. SPF 15 or higher is *best* for your skin, but diluting that to SPF 5-ish with something that'll prevent your skin from drying out is still better than getting a debilitating sunburn.
The Maternal Effect is when a zygote recieves mRNA, proteins and other molecules from the mother's eggs. These are gene products but not actual genes. Nevertheless, since this occurs right at the start of development it can have long lasting consequences.Cytoplamic inheritance refers to the offspring recieving actual genes (DNA) from the mother that are not in the nucleus, mostly from the mitochondria, chloroplast and possibly from any viruses. This is actually part of the new zygotes genome and is inheiritable.Source: Biology college classes, Wikipedia
I'm an otolaryngologist-head and neck surgeon.The most common reason I'm asked to do a tracheostomy is to either relieve an acute or chronic airway obstruction or to take the stress off of the larynx (voice-box) of a patient who may need respiratory support in an intensive care unit for a prolonged period.In the first instance, patients with a compromised airway due to infection, cancer, trauma or even severe cases of sleep apnea may need a temporary bypass when their larynx becomes nonfunctional. The removal of the tracheostomy tube varies but in most cases is only a temporary measure. In cancer cases, the dependency on the tracheostomy depends on the location and length of treatment. In trauma cases, removal of the trach tube depends on the extent of the repair and the degree of scarring. Patients with severe OSA that is not amenable to any other therapy may have a permanent tracheostomy to use at night when they sleep. For ICU cases where the patient may need prolonged intubation, a tracheostomy is often requested from our service because the presence of an endotracheal tube for over a week may lead to serious complications to the patient's voice box - scarring, granulations, ulcers that can lead to permanent voice changes and long term difficulties.The decannulation process is usually straightforward in acute non-cancer cases. Once the patient's condition improves, a tracheostomy tube can be changed to a different type of tube that will allow a patient to use their voice and breathe with the tracheostomy tube "corked", or plugged so that they can use their own natural voice apparatus. I hope that answers your question somewhat, I tried to minimize the medical-speak!Edit: Thanks very much for the gold!
What you're essentially asking is, "how much fuel mass is there in a naval nuclear reactor?" And the tricky part of that is... it tends to be pretty classified! Even for old reactors.Amusingly, the one source I've found that describes a military naval reactor core is [a CIA report on Soviet reactors from the early 1980s](_URL_0_), which discusses reactors that the Soviets apparently used in both submarines and nuclear icebreakers. If we assume this has some degree of truth to it, it describes a VM-14-5/02 core as having two types of fuel "pins" — "heavy" 16 g pins of 40% enriched uranium and "light" 12.9 g pins of 30% enrichment. They say it contains "about" 10,000 heavy pins and "about" 2,200 light pins, and give a total count of 197.5 kg (435 lbs) of uranium total (which is a little more than what those numbers add up to be, so there might be some rounding going on in the number of pins). If all that uranium was formed into a ball, it would be about 0.9 feet in diameter. The core diameter in the reactor is stated as 1.5 m (~5 feet). Another reactor, the VM-14-5/03, contains more highly-enriched uranium (113 kg of 55.6% enrichment and 158 kg of 68.6% enrichment, for a total of ~270.5 kg of uranium). No diameter is given. Another, the VM-149M core, had about 109 kg of uranium at both 6.5% and 5% enrichment.There is probably some variance between these cores and the ones used by the hardcore military subs (probably higher levels of enrichment), but this gives you a rough estimate of what they were like. These are relatively compact compared to the kinds of reactors that would power cities, which is what we would expect.
That's weird, I've never seen that. For some reason this is bugging me, so I've spent a good 15 minutes trying to find out the answer to this. So far I've found [this magnet](_URL_0_) that has the same symbol in the middle, except now it's rotated 90°. There's also the possibility that you are holding the magnet upside-down, since the letters are symmetrical—just to keep you thinking outside the box :)I'll keep thinking about this and let you know if I find out anything else.
1. Same reason that even though your monitor is made of millions of pixels, but you still see it as one continuous image. The raindrops are the pixels of a rainbow.2. Each water droplet refracts sunlight into concentric circles of color. So if you could look at the light that comes out of one raindrop after a ray of sunlight goes in, it'd be a circle of red light rays, then inside that a circle of orange light rays, and so on. That's what makes rainbows circular. The apparent size of the rainbow is determined by the angle at which the light refracts. Red light changes its direction by 42 degrees, IIRC, so you see the red light from the droplets which are positioned at 42 degrees away from the direction of sunlight.
It's speculated that, in an airtight room, you'd need around 300-500 decent sized plants. Each leaf gives around 5ml o2/hr, the safe level for a human is about 50 liters per hour. Seeing as you're not in airtight room, I'd say anything from 30-50 would be an improvement.Some things to consider, though, it wouldn't be quality, as much as quantity. Plants don't do a great job at filtering impurities in the air.Hope it helps.
Aristotle demonstrated the spherical shape of the Earth in 350 BC, and gave the following supporting arguments:* There are stars seen in Egypt that aren't seen in more northern regions* The shadow of the Earth during a lunar eclipse is round
Yes there is, but much less noticeable. Even from the voyager 1 probe (which is much father than any planet) the sun is still about as bright as the full moon. It would appear much smaller in the sky, but would still be very obviously far brighter than any other object in the sky, and the only thing bright enough to cast visible shadows (at least to our eyes.)
Theoretically, the pool of water will have a density gradient (albeit very small) from the surface to the bottom, and so the stone will find a equilibrium at a depth where the rock's density matches the liquid at that depth.In reality, the gradient will be so small that the stone will probably stay where it's put, or follow any currents the liquid may be experiencing.
As you make an object hotter, the peak frequency of the emitted light shifts towards the higher frequencies. However, the intensity of the source will increase for every given frequency. This means that any object hotter than a few thousand degrees will emit radiation in the visible spectrum, no matter how hot it gets.I don't know enough about the classification of stars to know if one can be cold enough to not emit a noticeable amount of visible radiation, whilst still being classified as a star.
In the double slit experiment for example, the uncertainty means a given particle could go through both holes, we don't know which one. The odd thing is, even allowing one particle at a time through the experiment, the resulting pattern on the detector after the double slit indicates that the particle went through both slits and interfered with itself. The particle then struck the screen and interacted with only one phosphor atom, instead of splashing against the screen and imparting its energy across many atoms.
For these kind of distances the most popular way is to use a particular type of super novae. The progenitor system of these SN is usually a white dwarf and a larger companion. The white dwarf sucks in matter from the companion star until it reaches some critical limit and then goes super nova. This happen always at the same mass threshold, thus they always explode with roughly the same luminosity (there are a few caveats, but they are fixable and it all works pretty well). Thus, by identifying these specific SN via spectrum analysis, we know how far away they must be by measuring their apparent luminosity as seen from earth. These measurements have to be interpreted and a specific cosmological model, which also allows us to use these SN as a means to probe the expansion history of the universe.
The simple answer would be that 4 dimensional objects are in the fourth dimension. I know this doesn't really answer the question that you are asking and I imagine you are wondering why we cannot not perceive these objects. The answer to this question is that from a lower dimension you simply cannot perceive a higher dimension. Think about a 2 dimensional object trying to perceive a 3 dimensional object passing through its plane (if that where possible). The 2 dimensional object could not perceive a 3 dimensional object, just as a 3 dimensional object can not perceive a 4 dimensional object. The interesting part is that we, as humans believe we can perceive a lower(2d) object when in fact all we can do is conceptualize a 2d object. So look at your computer screen, right now you are conceptualizing a 2d image, when really what you are looking at is a 3d object. We cant possibly perceive a 2d object in the 3rd dimension because we are stuck in the third dimension.This same concept applies upwards except with one little difference. We can conceptualize 4d (and higher) geometric shapes. But what we conceptualize is either a 2d or 3d rendition of what this object would look like passing through a lower plane [check](_URL_0_). It isn't the actually object itself because it is only a rendition. [double check](_URL_0_).Side note: we can conceptualize the entirety of a 2d object easily, but to conceptualize a 3d object in its entirety is very hard(look at cubism). If we apply this concept upwards, from the fourth dimension it would be easy to see all sides of a 3d object easily.
Stars and dust. Lots and lots of stars and dust. It's estimated that there are about 100 stars per cubic parsec in the galactic core, wich is 100x more than in our neighborhood. The central cubic parsec around Sag A* has about [10 million stars on its own](_URL_0_).
_URL_0_I know its probably not what you're looking for, but i wouldn't be able to do a better job than wiki. main things: attaches to opioid receptors(has similarities), activates GABAa which is also what benzodiazepenes do, ie anti-anxious medications. The eurphoric effect, in rats at least, is due to the induction of dopamine release from the ventral tegmental area and nucleus accumbens, presumably through antagonization of NMDA receptors localized in the system.[52][53][54][55]
you are part of the system of the bus.  you are moving at 40mph too.  if the doors and windows are closed, there's nothing to change your velocity.  now if you were in a convertible with its top down moving at 40mph and jumped up, the air, which is not moving at 40mph in the same direction, will hit you and reduce your velocity and you will likely fall out of the back of the car.
As a first step, I would refer you to this great [video from IRIS on foreshocks, mainshocks, and aftershocks](_URL_1_) to make sure you (and others) generally understand what is meant by these terms. What is nicely highlighted there is that large earthquakes rupture large areas of a fault (and in detail, the magnitude of an earthquake is directly related to the amount of energy released which in turn is directly related to the surface area of fault that ruptured, [e.g. the classic relationships presented in Wells  &  Coppersmith, 1994](_URL_0_)). Aftershock sequences are restricted to areas directly influenced by the mainshock rupture, so generally, if a small earthquake occurs in the region that ruptured during a particular mainshock, chances are that it is part of the aftershock sequence. Also nicely highlighted in that video is that for very large earthquakes, aftershocks can continue for years to decades (even centuries in extreme cases) after the mainshock, but that the rate decreases dramatically with time since the mainshock. Because designating an earthquake as a foreshock, mainshock, or aftershock is all relative (i.e. there is nothing distinctive about the earthquake besides its location, magnitude, and timing relative to other earthquakes) you can't say with 100% certainty that a given earthquake is an aftershock, but it's more likely to be an aftershock the closer in time you are to the mainshock (assuming it's in the right region to be an aftershock with respect to a particular mainshock). Given the magnitude of the Nepal earthquake and that it's only been 4 years (which is actually not that long when considering aftershock sequences), a small earthquake that occurs in the area that ruptured originally has a high chance of being an aftershock.
I think you would feel no force anywhere inside the giant hollow metal planet (assuming it is spherical), and outside the planet gravity would act so that it would be the same as if all the mass of the planet concentrated at the center.***Proof:*** (WARNING: MATH):We will use Gauss's Law for Gravity:_URL_0_We know that the gravitational field inside the sphere must be radially symmetric, since the planet is radially symmetric. Hence, by Gauss's Law for gravity, integrating around a closed shell of radius r  <  R of the shell, we have that4 pi r^2 |G| = -(4 pi G)* 0 = 0,and hence |G| = 0, since 0 mass is contained inside this Gaussian surface of radius r. Further, for r  >  R,4 pi r^2 |G| = -(4 pi G)* M,and hence|G| = -GM/r^2,which is just the gravitational field for a point mass M at radius r.
It's not universally true that "electronics are rated in watts". Some components are rated in amps, some in volts, and some in watts. Some have different ratings for two or three of these values.The difference is, what conditions might cause the device to fail.Some devices might fail from a high voltage when that voltage causes arcing between parts of the device that are meant to be isolated. In this case, the current and power being handled is irrelevant. For example, a wall power socket might fail due to arcing when you apply 600 V to it, even if there's nothing plugged in, so that no power is passing through it.Some devices might fail because the current through them causes internal heating that melts or burns them. While this internal heating does have a power associated with it, we give the rating in amps when the power that contributes to its failure is different from the "power characteristic" we normally associate with that device, which might, for example, describe how much power they deliver to some other device or circuit. For example, a transformer might be designed to deliver 100 W to a load, but fail when current through it's coil causes an internal dissipation of 10 W, so we give the maximum rating as a current.Some devices might fail when too much power is delivered to them. This is a similar behavior to the parts that fail due to excess current, but we give the rating in watts because the power being measured *is* the power we normally associate with the device. For example an rf attenuator is rated to dissipate a certain amount of power.
In a sense, yes. You generally need a certain amount of excitation to make an action potential, so a little noise doesn't do anything. Motor neurons often work in agonist-antagonist combinations, so that rather than just one firing making a muscle move, you have to both excite AND inhibit in the right measure. In the basal ganglia, a collection of groups of neurons in the brain, you have to break a constant inhibition to allow motor signals to get through to the spinal cord and on to muscle. The overall effect is pretty nice: You can think about moving without actually doing it, and execute movements smoothly or stay still without lots of twitching. (People with Parkinson's have losses in the basal ganglia, with resulting difficulties in motor coordination.)The eyes are actually particularly oriented towards noise reduction. While most sensory stuff is geared towards neurons depolarizing only when they get a stimulus, photoreceptor neurons are constantly depolarized and firing; light HYPERpolarizes them, reducing their firing rate, and starting a signal to the visual cortex. This avoids sending a lot of random noise from ion channels, and helps ensure that only real stimuli get through.
This is actually a big debate in modern physics. The standard model, in its current formulation, says there should be a graviton, or quantized excitation in the gravitational field. However, general relativity says that the gravitational "field" doesn't really exist, and replaces that notion with space-time curvature. In GR, the curvature of spacetime is what sends the signal.
In electroplating, the metals chemically react together.The nickel paint is actually a nickel salt made of a positively charged nickel ion and a negatively charged non metal, the negatively charged copper, zinc or iron attracts the positive nickel ion and substitutes off the non metal by donating electrons to the nickel, and the non metal is released into the air.TL:DR the positively charged nickel bonds to the negative metal.
Depends on your frame of reference. Will the rocks that currently make up the summit of Mt. Everest ever be at low enough altitude to casually hike up? No, not unless you count the sediment that these rocks will eventually become and be deposited in a low lying area. The mountain building event that is creating the Himalaya and the Tibetan Plateau is ongoing, driven by the collision of the Indian and Eurasian plates. Thus, rocks beneath Mt. Everest are being pushed towards the surface by various processes associated with the mountain building. The rocks exposed at the surface anywhere within the mountain belt, and the topography these rocks create, represent a balance, or competition between erosional processes (rivers, glaciers, landslides, etc) and the uplift of rocks. So, in a very simple sense, you can think of the topography of a mountain range like the Himalaya (one that has been going for quite a while) reaching some sort of steady state with rocks being "advected" (i.e. eroded and replaced by uplifting rocks from below such that the rate of erosion equals the rate of uplift) to maintain the topography. In detail, this doesn't really apply to individual spots (or perhaps individual summits in this case) but is a reasonable approximation for what is happening at the scale of the whole mountain range. So instead, we can ask will the Himalaya ever be a relatively subdued mountain range that we could casually hike up? Sure, but not until the collision between India and Eurasia stops and the topography is reduced by some process, a big role for erosion surely, but maybe also gravitational collapse. We can think of some analogues. The Appalachian mountains of the eastern United States [last experienced a mountain building event ~260 million years ago](_URL_1_) and there is still topography, though topography that we can casually hike up. The Appalachians might be cheating a bit, or at least more complicated, as there is evidence that the topography was rejuvenated (i.e. a new source of uplift not directly related to mountain building processes in the traditional sense) [sometime during the Cenozoic](_URL_2_). More likely though, the western United States may provide a glimpse of the fate of the Himalaya and Tibetan Plateau. There is has been argued that the current Basin and Range (i.e. Nevada) was formerly an elevated plateau much like the Tibetan Plateau, often referred to as the [Nevadaplano](_URL_0_), a take off on the Altiplano within the Andean mountain belt, which realistically is a better analogue for the Nevadaplano than the Himalaya, but some of the processes may be relevant. There are lots of ideas as to what triggered the collapse and extension of the Nevadaplano from a high standing plateau to a low lying region of small ranges and basins, but one primary driver was likely gravitational collapse. In simple terms, collisional processes built up a thick stack of continental crust, which produces heat and makes the lower portions weak. Once the collisional processes cease, or slow, this weak lower crust can't really support the weight of the overlying plateau so it begins to rapidly deform, leading to crustal extension and collapse of the plateau. Rapid here is 10's of millions of years for those not accustomed to geologists slightly odd sense of time. It's reasonable to think that this may play a big role in the demise of the Himalaya as well, along with erosion unchecked by as much uplift. So yes, at some point in the distant (10-100's of millions of years), you (or someone) could casually hike up the remnants of the Himalaya, but there will likely not be a peak in the spot that Everest was exactly. In general, the timescale of what geomorphologists would refer to as "post-orogenic decay" is an interesting question, i.e. how long would it take for erosional processes to grind down the Himalaya to something that we could easily walk up? In short, it takes a long time, estimates vary and will depend on lots of factors, but ~100 million years might be a reasonable guess. It mostly takes so long because of [isostasy](_URL_3_). Even if you completely shut off uplift driven by collision, for every bit of mass you remove from the surface, you will get an isostatic response, i.e. uplift, and because most large mountain ranges have extensive roots (big masses of continental crust shoved beneath them during the mountain building process) it can be a quite gradual process to remove the topography of a large mountain range.  As for the artifacts of human conquest on the slopes of Everest, it will, like the rocks, eventually make its way down to lower elevations. Since much of it is on top of glaciers / ice fields, a lot of it will probably come down in avalanches and/or landslides. Not really sure on a time frame, but as climate change is devastating glaciers in many of the earth's mountain ranges, I wouldn't be surprised if these were cleared out in the 500-1000 year time frame, at least to substantially lower elevations, but I don't know offhand the rates of glacial retreat (or if glaciers in this area are retreating, as local climate can cause some areas to buck trends in terms of ice mass loss) in the Everest area.
If you're talking about orbiting the Earth, it can't, *that's too fast* for any altitude. It's also too fast to orbit the Sun and too fast for the galaxy.Typical speeds for nearly circular orbits are 7.6 km/s around Earth, 30 km/s around the Sun and 200 km/s around the galaxy. Of course, that varies a lot depending on the altitude (though the galaxy is a special case), but the speed of light is almost 300000 km/s so the difference is several orders of magnitude.
Nothing prevents it, in fact this is what cold-welding is and does.However cold welding only works with flat surfaces.Before you say you have two flat pieces of metal... you don't. You would NOT get consumer level metal that would have properties to allow cold welding to occur.Cold welding occurs at different levels, the flatter the surface the better. Micro and nano level cold welding manufacturing processes exist now.Why does your two pieces of metal not adhere? They aren't flat, are probably coated, have some level of oxide layer, and many many many other factors. You also need much much more pressure to get these pieces to adhere/bond, push with a couple tons of force if your pieces are not flat/clean enough and they will most likely cold weld together._URL_0_
Imagine two people holding the ends of a jump rope, with one person shaking their hand up and down but neither of the people moving their arms much. There are only so many shapes waves can take along the rope. [These](_URL_0_). This is the principle behind the wavefunctions: there are only so many shapes they can take and still satisfy all the necessary conditions.
As far as I know, water absorption is dependent on the solute gradient. Water goes where there are more solutes. So I guess that means it's always passive. Water is a very small molecule which makes it very easy to pass through membranes.Also, aquaporins are found only in kidneys.
Electromagnetic fields shouldn't cause any ill effects. In fact you are basically swimming in them all the time anyway.Even light itself can be represented as an oscillating electric-magnetic field that propagates in the form of a wave. Extremely strong magnetic fields are used in NMR machines as an extremely powerful magnet is used to perform imaging of your body.Electrostatic repulsion is what keeps you from falling into the floor, so you wouldn't exist without the presence of electric fields.A magnetic field can be so powerful that you'd actually feel an repulsive or attractive force, but such magnets are absurdly powerful and the most they've gotten was to levitate a mouse.Strict electric fields can be dangerous however, if the voltage potential across the field is strong enough current will take any means to flow. You could end up electrocuting yourself.
Women go into menopause because they run out of eggs (follicles) that are sensitive to follicle stimulating hormone (FSH) and luteinizing hormone (LH) which make a follicle mature and eventually ovulate.[According to the American Society of Reproductive medicine:](_URL_0_) > The number of oocytes decreases to approximately 1–2 million oocytes  at  birth;  300,000–500,000 at puberty; 25,000 at age 37 years; and 1,000 at age 51 years, the average age of menopause in the United StatesSo yes there are follicles still around but they no longer create the levels of estrogen and progesterone a pre-menopausal is used to.
Let's imagine the worst-case scenario: a warhead containing plutonium misfires at a relatively low level, creating a cloud that contains a few kilograms of plutonium aerosolized inside of it. Is that a health hazard? It will contaminate the area beneath it, sure. We've seen this kind of thing before — the Palomares accident, for example (H-bomb jettisoned, high explosives fired irregularly), and the Bluegill Prime accident (a Thor missile explodes on the launchpad, dispersing plutonium). The result is a place that you have to spend a lot of money and time to clean up safely — remove layers of topsoil over a relatively large area. Is that a good thing? No. Is it as bad a nuclear weapon going off? No. It is basically a "dirty bomb" scenario — a contamination threat that, if people were exposed to it, would have some adverse health consequences, but there are worse things to be accidentally exposed to that plutonium (e.g. nerve gas). So it's not ideal, no. But it's not the real threat of a nuclear armed missile. Dirty bomb casualties might number in the hundreds of long-term fatal cancers if detonated in a major city. Not great. But a 150kt nuclear warhead going off in the same area would have short-term fatalities in the hundreds of _thousands_. What would happen if said warhead broke apart higher up? You are still going to eventually get plutonium on the ground, but it's going to be dispersed over a wider area. On the one hand, that's bad — wider area of cleanup/exposure. On the other hand, that's good — less plutonium per square meter means less intense contamination. Actually modeling this stuff is a little tricky without the right tools but my guess is that there is probably a "least good" height that would result in a large area moderately contaminated, but above that and you end up with low-enough contamination that it's not a big deal, and below that the contamination is intense but localized. But that's just a rough guess based on how these kinds of plumes tend to work out. As for "how is this avoided" — the main way to keep this from happening is to use insensitive high explosives. These are hard to set off without specific intention (i.e., they require a specialized blasting cap or something like that), so that even if they were hit with great force, or even set on fire, they shouldn't explode. The US started using insensitive high explosives in the late 1970s. I don't know if warheads like W87 use it or not, and I have no idea whether North Korea uses it (I doubt it). The main difficulty in using IHE is that they tend not to be as powerful as "normal" HE and so if you are really worried about a good yield-to-weight in a small volume, you can't really afford to use it (which is why I am not sure if W87 uses it — it is a very compact little thing, and is tricked out for compactness and efficiency; there is a JASON report that talks about the safety of various current warheads and I think it indicates that some use IHE and some don't, but I don't have it at my fingertips; update: it seems the main US missiles that still uses non-IHE are the submarine warheads, W76 and W88 — that makes sense giving that they are even more tricked-out than the ICBM warheads; W87 does use IHE). Since DPRK is likely worried about such things more than it is worried about safety, I would suspect they aren't using them. But I don't know. Again, I don't think this is really the thing to worry about when thinking about DPRK missiles. It does come up with their supposed threat of testing a "mated" warhead/missile, because the chance of the missile having a mishap is not minimal (how's that for an alliterative reply?). [But that is just one of several possible problems with such a test.](_URL_0_) Frankly, it strikes me that the plutonium contamination threat is actually _most acute_ for the North Koreans themselves — they could suffer a Bluegill Prime accident that would contaminate their launchpad and own personnel. So hopefully they won't try it, not so much because they care about other people, but because presumably they care about their own facilities...
Pernicious Anemia (macrocytic anemia) has many causes including intestinal malabsorption and poor diet, but it is most often associated with autoimmune gastritis which damages parietal cells in your stomach leading to decreased levels of intrinsic factor.  Intrinsic factor is required for B 12 uptake in the ileum (small intestine).  If this is the case, simply adding B 12 to the diet will not help, it must be directly introduced into the blood.  Other options for B 12 uptake include pills, oral/nasal sprays or gels and shots.  I'm not sure exactly how the pills work, as intrinsic factor is needed to bind to the B 12, but they are an effective form of therapy.  I assume they are absorbed directly into the blood at some point, possibly sublingually, or maybe the pills include a form of B 12 already bound to intrinsic factor or something, I'm not sure.  Technically, sublingual would count as skin absorption, so the answer to your question is yes.  A patch on your arm or something may work, as you only need a few micrograms of B 12 per day, however I don't know if this has ever been tested and if B 12 can be efficiently absorbed through keratinized stratified squamous epithelium.  **The key here that relates back to your question is that pills, gels and sprays can be effective forms of therapy, although severe B 12 deficiency often requires injections.**
As far as vertebrates go, the vast majority of venomous and poisonous species are reptiles and amphibians. The diversity of both groups is highest in the tropics, and they are generally excluded from climates that are cold the majority of the time because reptiles and amphibians are both ectothermic (cold-blooded), meaning that they cannot be active when the ambient temperature is low. The fact that most venomous vertebrates are snakes combined with the higher richness of snakes in warmer climates means that most of the venomous vertebrates tend to be found in warmer climates.In addition to the Massasauga, the copperhead (*Agkistrodon contortrix*), cottonmouth (*Agkistrodon piscivorus*), timber rattlesnake (*Crotalus horridus*), western rattlesnake (*Crotalus viridis*), and Pacific rattlesnake (*Crotalus oreganus*) all occupy temperate habitats in regions of North America that get fairly cold. edited for clarity
So, this is a pretty complex answer, but I'm going to give you the short of it. Let me know if you want me to dive into any more individual part.So, broadly speaking our body has two separate but deeply connected immune systems, the innate and the adaptive. There's plenty of bridges between them, but typically the more sensitive innate system reacts first then through various mechanisms recruits the more specific adaptive immune system to come and help. But how does the innate immune system know when something that isn't supposed to be in the body is in the body. Traditionally people talked of self vs. nonself recognition but this is an old paradigm and talking about 'danger signals' might be more accurate. The first layer in your innate immune system is the first layer in you. Your skin and your gut mucosa. Your gut is actually in a lot of ways external inasmuch as the GI tract is an external tube open to the external world. But once a pathogen gets through that initial layer, let's say in the skin, it may start causing damage and generally just existing. Let's for the sake of discussion say it's a gram negative organism. Gram negative bacteria have something called lipopolysaccharide (LPS) on their surface. Humans don't have this. It's a danger signal. We have cells stationed like guardians all around our skin called macrophages. They have receptors on their membrane known as Toll-like-receptors. They have one called either TLR-4 or CD14 which recognizes LPS. This ignites a signalling cascade which ultimately leads to the production of cytokines (signalling molecules) and chemokines (think attractants) that ultimately lead to local inflammation, upregulation of various acute phase proteins, etc. This will lead to neutrophils entering into the tissue and helping the macrophages eat up the bad guys. If further help is needed dendritic cells can go off to secondary lymphoid organs, and show off the danger signals they capture from battle to B and T cells which can come in with specific and strong attacks to clear out the infection.  & #x200B;So, let's review. How did the body know the gram negative bug was bad? It sensed something unique to LPS, which lead to an inflammatory response to clear it. But how does this work in the gut where unlike the skin there are bugs you want there. And unlike the skin you can't have a keratinized squamous epithelium to seal it tight. You need to transfer actively in and out. The gut is unique in many ways immunologically inasmuch as there's a lot of work done to make it an anti-inflammatory milieu as you can imagine if it started reacting to every bacteria you'd have a mess. This is the pathologic basis of many inflammatory bowel diseases.  & #x200B;There's a couple of ways it does this. One is that the intestines secrete a mucus layer that keeps bacteria physically separated from the epithelial cells of the gut. You can't have an inflammatory reaction if you don't come into contact. But sometimes some bugs, good or otherwise, make it across. The gut poses special non-inflammatory macrophages to eat the bacteria without doing their traditional extra-role as cytokine producing cells. Additionally, IgA, an immunoglobulin, is actively secreted into the the lamina. It binds to bacteria and makes them easily swept away with the rest of the gut contents. It is also non-inflammatory. The gut is more locally segmented than the body as a whole in terms of the adaptive immune system unlike the rest of your body, and is more compartmentalized lymphatically so that the larger body doesn't respond. Furthermore, the entire environment in terms of chemical signals is anti-inflammatory with cytokines that tamp down responses like TGF-B and IL-10. Additionally, these cytokines may even be triggered by anti-inflammatory toll-like receptors. When something bad does happen the helper T cell response may be different with an Th-17 response when the dendritic cells that are testing the environment to make sure there aren't danger signals start to sense danger signals. Finally, the presence of good bacteria help prevent the growth of bad bacteria (e.g. E Coli). However, antibiotics can whip out good bacteria leading to iatrogenic E Coli infection.  & #x200B;To sum up, the way the immune system tells the difference between the two sorts of bacteria (and to be clear there is no such thing as a good bacteria in the blood). Is to work really hard to keep all bacteria in the gut through its mucosa, the IgA, etc. and when a stray guy does get through to minimize the inflammatory response unless it is super serious.  & #x200B;Source: & #x200B;*The Immune System* by Parnham *How the Immune System Works* by Sompayrac*Robbins and Contran's Pathologic Basis of Disease* by Kumar et al.
Yes, it's both. Just being still in a gravitational field (like we are now, on the Earth) causes time dilation relative to freefall, and orbiting satellites have to take both into account (this is the famous GPS relativity correction).
I would [read](_URL_1_) about actin and myosin, especially the sliding filament theory.  Essentially myosin heads grab onto actin and use energy from ATP hydrolysis to move along actin, generating a contraction force. The ATP, which is kind of a chemical energy currency, is generated by metabolic pathways and a process called [oxidative phosphorylation](_URL_0_) but, ultimately, that energy is coming from food.This myosin-actin cycle can be initiated by electrical signals from the brain via a pathway that involves calcium release via a [troponin/tropomyosin](_URL_2_) control mechanism.
It's all pretty minor stuff. You don't have any major hotspots like the Yellowstone caldera, and you also don't have a subduction zone south of San Francisco, so you don't really have active volcanic arc volcanoes like Ranier and Helens farther south.Major volcanic activity really has no real chance of returning for a very long time either. The Pacific and North American plates are going to remain a transform boundary for the foreseeable future, and you don't have any major restructuring of the North American plate that could cause moderate volcanism farther inland (such as you had with the formation of the Basin and Range province).The sorts of volcanism you DO find in the American Southwest are more along the lines of minor lava flows, cinder cones, and hydrothermal activity such as hotsprings. All pose quite small hazards.
Oceans and mountain ranges. They influence wind and ocean currents, and the influence how humid the air is (if it moves over the ocean, it gets more humid for example). You get the most rain if you have wind coming from the ocean and hitting a mountain range, e.g. south of the Himalaya for the rain season: The humid air has to move up, it cools down, the air can hold less water and it rains.
Even if sperm were able to penetrate ovum, there are a host of issues past that.First would be discrepancy in chromosome number. This would lead to cells with different numbers of chromosomes after mitosis. These cells would be unlikely to "work together" when it comes to signalling, chemotaxis, etc.Secondly, different species express different genes at a genetic level. If you were to create some zygote between species different enough the gene expression would most likely result in cells unable to function, and it'd be a miracle if they progressed past a clump of cells.
The article you quote is really complete rubbish. There is basically not a single correct statement in it.Teleportation works the following way:You have Alice who has some qubit in an unknown quantum state and you have Bob who wants to know that state. Alice cannot just measure the state and tell Bob what it was, as single measurement does not reveal the complete state of the qubit and alters it in the process so that any subsequent measurement does not contain any useful information about the original state.Alice can still send the quantum state to Bob if they have a classical communication channel between them and share an entangled pair.What Alice does is performing a measurement that reveals the relation between the state she wants to send and her half of the entangled pair. Here quantum weirdness strikes for the first time: Even though there are infinitely many states, there are only four possible outcomes for this measurement. If Alice knows the relation between one half of her entangled state and unknown qubit had, then she knows the relationship between Bob's half of the entangled pair and the unknown state is. So she calls Bob and tells him what the result of her measurement was. Then Bob knows that the state of his qubit differs only by one out of four transformations from the unknown one. He performs this transformation and holds this qubit.Note that only information was transferred. This kind of "teleportation" cannot be used for transmitting matter/energy and further note that no information was transmitted instantaneous or faster than the speed of light. The information transfer needs to include classical communication between Alice and Bob. If Bob doesn't get the message and doesn't transform his qubit accordingly, then the qubit will just behave completely random when measured.
The word "ground" is used in two different ways in electrical engineering.  So first, to clarify: The "ground" you are referring to is called "Earth ground" or "safety ground" and it must be connected to the Earth (eventually). If something goes bad with electrical equipment, it will hopefully shunt the electricity to the Earth rather than through your heart.  (Earth grounding has some other benefits, such as helping to reduce unwanted electromagnetic emissions.)     But every circuit has a "ground", too. That ground doesn't need to be connected to Earth ground, although it can be.  This ground is simply a reference voltage to compare all voltages in the circuit against.  So we call one part of the circuit "ground"=0 volts. (A voltage is a relative value, so you have to have something to compare to.)    It is very possible that you could have two electronic devices, and if you compared their ground voltages, you'd find that they weren't the same. This is actually quite common.       This is also true of Earth grounds.  The potential across the planet is mostly the same, but you can have small local variation.  Some soils are not very conductive and so will take time to equalize their charge.       The biggest source of such potential differences are when a fault exists at something like a power substation. This can lead to a localized ["Earth potential rise"](_URL_0_) that can be quite large.  This can be so big that the potential difference between a person's feet can become hazardous.       I believe that there are also some long-standing small potential differences caused by things like the Earth's magnetic field, cosmic radiation, etc.  (I'm not 100% certain of this.) But if so, the magnitudes of such differences will be quite small. In general, Earth ground is Earth ground.
The answer is that we are not limited to a single electric field/wave. Unpolarised light is unpolarised not because it doesn't oscillate, but because it is formed from a whole bunch of waves that oscillate in all directions and hence has no preferred polarisation direction. Polarised light can then be formed by filtering out all waves except those that oscillate in a particular direction.Your picture of circular polarisation is not quite right since it is not a single rotating wave but instead two perpendicular waves which are superimposed and delayed with respect to each other such that when one is at the maximum of its oscillation, the other field/wave is at zero, and visa versa. When these two oscillations are added together the net effect is that the direction of the TOTAL electric field rotates. In the case that the magnitudes of these two fields are the same, then you get circular polarization, but in the case one of the fields is stronger than the other, the electric field magnitude will vary as it rotates, leading to an elliptical profile._URL_0_
Someone asked a very similar question a few months ago, [and this is a fairly frequently asked question,](_URL_0_) so I'll copy paste what I wrote there, since that user specifically asked about 'Newton's Laws' vs 'Einstein's theory' as well.-----------------------------------------------------A lot of people make the mistake of thinking, "Gee, I know what the words *law* and *theory* mean. You can't break *laws*, so those must be the things that are really solid, but a *theory* is just a like some kind of guess, I can come up with my own theory right now!" So let's try to tease out why these people are wrong. To scientists, words like *law* and *theory* have very specific definitions, so we need to do some semantics.**A law is a declarative statement, based on observation, that seems to describe some behavior of some naturalistic phenomena.** Newton's Laws are exactly that. "Objects in motion remain in motion, and objects at rest remain at rest unless acted upon by an outside force." This statement seems consistent with every observation we've ever made, and it has a great deal of predictive power. Basically, a law is a statement of a fact that can be experimentally falsified. One experiment that shows a body accelerating under its own volition, for no reason and with no discernible outside force, and this is refuted. Now for *theory*. I have a definition of theory that I like, and others are free to disagree. **A theory is a testable explanation of some set of natural phenomena that explains all the best currently available evidence.** Basically, a theory explains the laws or some bundle of them and it offers some *reason* for them. Einstein's *theory* is that we live in a four dimensional universe, and that space and time are related in some nontrivial way, and things get curvey which is the source of attraction between masses. The 'theory' provides a mechanism by which the 'laws' act. Einstein's theory explains the results of tons of experiments or makes predictions (mathematically) that are consistent with them, such as the Michelson-Morley experiment and Gravity Probe-B. The theory *explains* the facts. A bunch of laws, together, form the pillars that a theory stands on. If one of those facts turns out to be bunk, (like in Einstein's theory, that nothing goes faster than light), it will have to be modified or entirely replaced in order to account for this new evidence. Furthermore, now that we have our definition of a 'theory' we can see that a theory is a fundamentally different thing from a law, so it wouldn't make sense to take Newton's law of inertia and try to promote it into a theory, because it's just a single statement about *one specific type of observation.*  Another good example is evolution. Darwin's theory of evolution by natural selection is a *theory*. It explains the *fact* that organisms aren't the same as their parents, that new traits can emerge, and these traits can proliferate through the population over successive generations if they prove to be beneficial. Natural selection is the mechanism so maybe (as much as I hate the phrase) we should call 'survival of the fittest.' Species changing over time is the *evidence* from experiments and the fossil record, and Darwin's *theory* ties it all together. It's amazing that Darwin came up with his theory before DNA was even known about, but was found to be very consistent with the microbiological understanding of genes and mutations.Bottom line: Theories don't somehow graduate into laws after they get proven, because they're different beasts entirely. Laws are statements about specific phenomena, and the laws, together with the evidence and facts, are explained in aggregate as theories.
The matrix is a linear transformation of the vector; it takes one vector as an input and gives a new vector as the output. [Here](_URL_0_) is a list of examples of what the matrix elements look like for some different kinds of linear transformations, and what the transformation does to the vector geometrically.
Heat generally causes materials to expand. It is possible that it caused the crack to close. Alternatively the tea dust particulate could have formed a seal within the crack.
Simplest explanation is the foundations are built very deep, which makes the center of gravity of the structure beneath the ground so it is impossible to topple it over without decoupling it from the foundation.[Here is a link explaining with pictures](_URL_0_)
All the light you see in pictures of galaxies, whether it be in the form if visible light or other frequencies, is produced by stars in that galaxy.  We see a bright spot simply because there is a dense accumulation of stars close to ~~the supermassive black hole at~~ the centre of the galaxy (whatever they're rotating around - [there's quite a debate about it](_URL_0_)).  There are more light sources and they are closer together at that position.
A transmission line is constructed with two conductors separated by a dielectric insulator. The properties of both the conductors and the dielectric are important, as well as the overall geometry.In principle there would be no difference between an ionic conductor and a metallic conductor of the same conductivity and geometry -- conductivity is the only material property involved. However my understanding, and a quick search turns up [this paper](_URL_1_) and [this table](_URL_0_), that ionic solutions typically have a much (10^6 times) lower DC conductivity and a much quicker decrease with frequency than most metallic conductors.So your ionic transmission line would likely be very lossy.The cutoff frequency on the other hand is decided first of all by the geometry of the transmission line, not the materials; for example a rectangular waveguide will have a very different cutoff to a circular/coax waveguide. My experience is that changing material is only a small correction on top of the overall shape of the electromagnetic modes; however I've never before thought about 10^6 change in conductivity so perhaps it would be more significant in this case. I'll have to think on this.In summary, I think an ionic transmission line works, but would be much more lossy, and unless it's so lossy the EM modes are significantly changed, would have a similar cutoff frequency (for each mode) to a metallic transmission line of the same geometry.EDIT: the cutoff frequency which is geometry dependent is a *lower* limit for the frequency of propagating modes, not an upper limit. the rolloff at high frequencies due to the increasing resistance can also be described as a cutoff frequency.
[This gif](_URL_0_) is basically your proposed experiment on a much larger scale. The star at the center of the image released a large pulse of light, and what you are seeing isn't the gas expanding, but rather the pulse of light itself moving through a large cloud of gas around the star. [Here](_URL_1_) is another video you might find interesting as well.
No.  They are completely unrelated.  Polar migration is a result of convection in the outer core,  about 3000 km below us. In contrast,  earthquakes are a result of deformation in the brittle crust - mostly within the top 15km. This is driven ultimately by convection in the mantle (between the crust and the committee) but they are decoupled enough that mantle effects only exert themselves on geological timescales.  And the mantle is itself decoupled from the outer core.
I've never heard this about water, but there is an example of this made famous by Richard Feynman involving the charge of an electron.  Millikan used an experiment involving measuring charged drops of oil as they fell. However he had the wrong value of the viscosity of air, so his number wasn't quite right. Later experiments, which shouldn't have had this error tended to report numbers between Millikan's number and the 'real' value, converging towards the real value over time (i.e. later values were closer).
The way to get the resolution needed to image a planet at that distance would be to have multiple space-based observatories.  Two coordinated observations separated by a distance D give you resolving paper comparable to that of a single device of radius D.  Using Rayleigh's criterion, the smallest details we could imagine would be on the order of R lambda/D, where R is the distance to the object we're studying; lambda is the wavelength of the light we're using; and D is the size of the detection device.  Having a D of around 50,000 km would yield a resolution of about 1 km at a distance of 10 light years.
When networks (be it fiber or polymer, etc.) become solvated, they will expand to accommodate the addition of solvent molecules and a mechanical equilibrium is reached in the tension between network linkages and the osmotic pressure of the solution. When linkages are stretched out completely, they become pretty brittle and will break easily (chains/fibers are fully extended and can't extend farther without breaking). Breaks at the molecular level cause defects and you get a positive feedback process that leads to crack formation and propagation. Additionally, adding a solvent lubricates the motion of fibers that are adjacent to each other weakening the overall structure. With paper towels, the later probably plays a bigger role since cellulosic fibers are pretty tough and not easily solvated in water.That was all a bit jargony, but the important thing is that you stretch out network forming components and dilute their volumetric concentration and lubricate their motion as well as making the chains/fibers more brittle.With paper towels, I would assume that there is some adhesive present as well that is somewhat water soluble which may be a larger factor than any of the other things I mentioned, but I'd guess it's a factor of all these things added together.
####**Q:** Could I still get measles if I am fully vaccinated?**A:** Very few people—about three out of 100—who get two doses of measles vaccine will still get measles if exposed to the virus. Experts aren’t sure why. It could be that their immune systems didn’t respond as well as they should have to the vaccine. But the good news is, fully vaccinated people who get measles are much more likely to have a milder illness. And fully vaccinated people are also less likely to spread the disease to other people, including people who can’t get vaccinated because they are too young or have weakened immune systems._URL_0_If anyone likes infectious disease news, check out r/ID_News
In a practical sense, I'm not aware of any liquids light enough or gases heavy enough to allow this to happen. If you take one of the densest gases, radon, its density is something on the order of 10 g/L, and if you take a very light liquid, say an alcohol, they have densities on the order of *800* g/L. This is all at STP, obviously. Gases are compressible, so you could probably fiddle with pressure to get the densities higher, but we're talking about heavy gases being orders of magnitude less dense than light liquids, so I doubt it's possible.
The answer to "where does that energy go"? is almost always *heat*, and batteries are no different.  The potential energy in a battery is "locked up" in chemical bonds.  An unused battery undergoes self-discharge, which is an internal chemical reaction that breaks these bonds, releasing the energy in the form of heat. Of course, batteries are specifically designed to have a low self-discharge rate, so the resulting rise in temperature is extremely small.
I think this is hard to judge because most of the images where you see a map of "lights" of the US or world  or other country are usually done in upwards of 200 passes of the satellite. this means that it'll more than likely take longer than the christmas season to complete. if it could be done in a night I believe there would be a difference in the light maps.P.S. sorry everyone hijacked your question with power consumption facts. WTF mate.
> the choice of words implies consciousness has an influence.  Would it be accurate to say "observe" simply means the photon interacting with anything at all, even some random molecule in the air?Correct!  The important thing that has an influence is *interaction*.  Interaction with anything; man, animal, machine, dirt, doesn't matter. > What exactly did observe mean in this context?You can treat it as a synonym for interaction. > How did they measure a single photon without absorbing it?They did absorb it; it was incident on a detector screen.  That's how they know what the distribution is. > And since by now similar experiments have been performed without collapsing it, what is the main difference there?What do you mean, "without collapsing it?"  Just because the photon is not measured or interacted with at the *slit* does not mean the photon does not pass through one or both slits, diffract or not diffract accordingly, and then ultimately be absorbed by the detector screen behind the slits.  When it is interacted with at the slit, no diffraction pattern is measured; when it is not interacted with at the slit, one is.  Either way it still hits the detector afterwards.Hope that helps!
Are you talking specifically about birds? Because they're not the only flying vertebrates, but they are the only (living) vertebrates with feathers. One thing to keep in mind that a lot of people confuse: birds are dinosaurs. Also, pterosaurs are not dinosaurs. They're archosaurs, like modern crocs and dinosaurs - including birds - but they're not dinosaurs.The evolution of flight (in dinosaurs), the evolution of feathers, and the evolution of birds are very much decoupled from each other; flight seems to have occurred in non-avian dinosaurs as well. Basically, all the parts were there. If you look into the origin of flight in dinosaurs, you may hear that the dichotomy for the origination of flight is either ["tree-down" or "ground-up"](_URL_8_). This widely regarded by paleontologists to be a pretty gross oversimplification of things, in large part because there was a lot of diversity in the group. There were both [cursorial feathered dinos](_URL_3_) and [arboreal feathered dinos](_URL_0_). [Here](_URL_12_) is a source on the origination of flight, although keep in mind that at this point more fossils have been found.More recently paleontologists [have reconstructed the brains of birds](_URL_1_) and non-avian dinosaurs and found that the enlarged forebrain that we associate with the neurological ability to fly shows up earlier than we thought (the original paper is [here](_URL_6_). This enlargement shows up multiple times to create an overarching trend.There are a few characters we strongly associate with flight: feathers, hollow bones, and a [unidirectional airflow system in the lungs](_URL_11_) that makes respiration highly efficient. All of these show up prior to the emergence of birds; these unique lungs even [show up in crocodylians](_URL_2_) and are likely the ancestral condition for [archosaurs](_URL_4_). While they do create the perfect scenario for flight, they also clearly conferred their own advantages individually, and they're also deeply entrenched in these dinosaur lineages.Because many of the traits we associate with birds show up much earlier, there's actually very little to distinguish birds from their non-bird relatives. Here are some dinosaur characters that birds possess:- [Furcula](_URL_7_) (wishbone) and hollow bones (Theropoda).- Feathers (for sure at least Coelurosauria, and either feathers or a similar integumentary structure show up even earlier in some dinosaur lineages and even into pterosaurs, which are related to but *not* dinosaurs). Feathers could be used for display and for thermal protection (Norell and Xu 2005; [also linked above](_URL_13_)).- [Semilunate carpals](_URL_14_), a backwards-facing pubis, and a bony sternum; pinnate feathers on the forelimb (Maniraptora). [This paper](_URL_9_) looks at the evolution of the semilunate carpal and says: >  The original selective advantage of this enhanced mobility is not clear, but cannot have related to pennibrachial folding unless relatively basal tetanurans had elongated feathers on the forelimb. [Note: the pennebrachium was basically the wing, but termed differently because the authors weren't sure it was used for flight.] Such a possibility should not be dismissed entirely. Specimens representing this grade of evolution have not been recovered from sediments that preserve extensive soft tissue, and filamentous integumentary structures [e.g. feathers] have recently been reported in a basal ornithischian (Zheng et al. 2009). However, it is likely that mobility of the wrist was initially associated with other functions, such as predation (Padian 2001). - Asymmetrical flight feathers (Aviale).One thing that sets crown-group birds (the common ancestor of all living birds and all of that ancestor's descendents) apart from their immediate relatives is the [complete loss of teeth](_URL_5_) in the beak. However, teeth are lost multiple times in theropods, so even that isn't a great distinction!I talking more about the evolution of feathers [here](_URL_10_).
I think you want to take a look at something like a [Ragone Plot](_URL_0_). There are other similar plots for comparing energy storage technologies. Here are two examples with data for flywheels vs batteries:_URL_1__URL_2_The challenge is that you need to meet the overall energy density requirement (e.g. range in a car) while still providing good power density (e.g. accelerate a 2000 lb vehicle from 0-60 in 10-15 seconds). These plots give you some sense of that.
It doesn't feel good for everyone.The current leading theory for what happens when you crack your joints is that the sudden increase in space between the two joints causes a decrease in pressure and the dissolved gasses in the synovial fluid come out of solution to form a bubble (much like what happens when you open a slightly shaken soda can).  This bubble then cavitates (pops), resulting in the distinctive crack you hear.Now, one can make many different cases for why this can feel good, but it's likely a combination of stretching the connective tissues around the joint and the sudden increase and release of pressure within the joint caused by the cavitation process.
Although I do not personally know of any that do *not* use ATP for metabolic purposes, we can come to several conclusions:1. All eukaryotes, because they rely on Mitochondria for energy production, must use ATP for their primary power-source, interconverting to the other NTPs. Thus, multicellular organisms must rely on ATP.2. All known prokaryotes (as defined) also rely on ATP, as the ATP synthase is very old, evolutionary - they functionally operate like mitochondria, but free of any surrounding cell, in that their ATP is produced at their cell membrane.3. This leaves archaea. Probably the only chance for non-ATP based metabolisms, but apparently [the ATP-generation machinery is so old evolutionarily that it is inescapable.](_URL_0_)So, until a new form of life is discovered, essentially everything operates through ATP, metabolically.
String theory is a misnomer. It should not be called string theory. But sting framework does not sound cool.
There are various factors in play (such as heart rate) that explain the mortality rates of varying sized fauna. Firstly, smaller animals must satisfy the order of the food chain to maintain balance; more small animals means more food for larger ones and so the quicker they die, the quicker they are encouraged to reproduce, and the quicker they reproduce, the quicker there is more food. While heart rate seems to be a direct answer, it is only so for closed circulatory animals (not arthropods). So essentially, smaller animals are evolutionarily programmed to reproduces efficiently and die quickly (which actually also makes more room for advantageous mutational changes).
The lions eat all the parts, including the organs, which are high in nutrients. We don't. Aside from that, We don't need to eat from all the food groups to survive. Only to thrive. Balanced diets are the result of scientific research and we only know about the concepts of nutrition now. What nutrition is for humans is the best possible combination of foods to completely supply all of our needs with no deficiencies, allowing us to be developmentally healthy.
In VSEPR theory, bond angles are determined by the orbitals' desire to maximize distance between bonds (specifically between orbitals). Since electrons repel each other, bonds and lone pairs would try to get 'as far apart as possible'.As for water, keep in mind that it is sp^3 hybridized. So even though its geometry is 'bent', it still has 2 bonds and 2 lone pairs. Since not all four of these hybrid orbitals are unique, so to most effectively spread themselves apart, they do not uniformly move to 109.5 degrees (as it would seem that the lone pairs repel each other more than the two sigma bonds do in this case).As for the series, I would guess that is is coincidence. If you consider an sp^3 d hybridized atom, you note that not all bond angles are unique. The bond angle between axial and equatorial orbitals is 90 degrees while the bond angle between two equatorial orbitals is 120 degrees. So it doesn't fit nicely into the progression. The other thing to note (as I mentioned earlier) is that water is 'tetrahedral' when you consider it's hybridization.
Electromagnetic radiation encompasses a range of different wavelengths (of which visible light is one section), and at a specific wavelength will correspond to a specific quantised energy as given by E = hv. The second idea is that molecules are not static, rigid entities that highschool chemistry can sometimes portray. Instead, molecules have translational motion, rotational motion, vibrational motion along or perpendicular to the inter-nuclear axes and finally electronic states which all have energy associated with them.In terms of greenhouse gasses, the region of electromagnetic radiation of most significance is infra-red radiation, which is almost always of suitable energy to cause absorption of this energy by molecules to become more vibrationally excited. Part of the reason the Earth's climate is so specific is because the Earth emits radiation itself as a black body, which means it emits an continuous spectrum of electromagnetic radiation itself which it has absorbed from the Sun.This outgoing radiation is IR radiation, and it turns out the the greenhouse gasses, especially CO2, absorb IR radiation at the maximum intensity "window" of the Earth's emitted radiation due to their molecular and chemical structure. In fact, the most important greenhouse gas is water as it absorbs far more strongly in the maximum emitted window. Sorry if this is a bit ramble-y but in my mind your question has quite a few bits in it.
Arachnids like some spiders and scorpions especially pseudo-scorpions secrete corrosive and dissolving enzymes over their prey and wait until the prey is reduced to a fine pulp which is then sucked up.This is an example of external digestion.
[Here](_URL_0_) is an easy to read paper by a very well respected research engineer that tackles not only the voltage involved but the disbelief by people that it is so large.
You can alter (i.e. de-enrich) weapon's grade uranium for use in civil reactors, in fact this has been done: the Megatons to Megawatts agreement between Russia and the USA.Reactors use about  <  5% enriched uranium (5% U-235, 95% U-238) whereas nuclear weapons are  >  90% enriched uranium.  Since natural uranium is about 99% U-238 you can combine weapon's grade uranium with natural uranium to get a greatly reduced enrichment.  Note that only the U-235 actually fissions (significantly) in a reactor.Using weapon's grade uranium directly in nuclear reactors would be unnecessarily risky: it would pose a risk of people stealing the fuel for use in a bomb, and it would (depending on your reactor design) allow for the possibility of a dangerous meltdown occurring.
You can't talk about infinity like that. You can say that as the number of coin flips approaches infinity, the probability for any *finite* sequence approaches one. But you cannot extend that argument to infinity.
Yep. See [space filling curves](_URL_0_) for examples of mappings between an interval and multidimensional spaces.
Here is an approximation-heavy perspective.Suppose quanta of heat jump around the lattice [randomly](_URL_1_). Thus the distance traveled after a time t is **d**\*sqrt(**R**\***t**), where **d** is the average jump distance and **R** is the average jump rate. By analogy (explained on the wikipedia page) **D**, the diffusivity, or **A**, the thermal conductivity, goes as **d**^(2)\***R**.In popular usage, the jump distance **d** is assumed to be the mean free path while the jump rate **R** is assumed to be approximately constant (actually, it is often assumed to rely on an energy barrier and the temperature but I am skipping this for now). This tends to give a good agreement with experiments, but it implies that the time spent jumping is negligible (so the jump rate does not depend on jump distance).What if we instead assume the jump rate depends on jump distance? Specifically, what if **R** goes as **V**/**d** for some average velocity **V**? For [**electrical** conductivity](_URL_0_) that is a perfectly reasonable assumption that also gives good results. We find that **V** is proportional to **d** (plus some constants), so after cancellation **electrical** conductivity once again scales as **d**^(2). However, this is because there is an external driving force and we find the average velocity by integrating over the distance **d** assuming we started at a stand still.There is a "force" for thermal conductivity (called the thermal driving force, and it is referenced [sometimes](_URL_2_)) but it is a side effect of the thermal gradient so the "force" only exists as a statistical effect, not a true force acting on a single particle. Because of this the explanation I gave about electrical conductivity doesn't seem like it should apply here (though the result is correct).Regardless, the fact that the conductivity scales (very roughly) with the mean free path has plenty of experimental evidence. All the models I have discussed are pretty simply approximations and phonon/electron simulations would give much more accurate results.
Yes in principle, but brain death implies the person isn't breathing spontaneously anymore.However there are a lot of brain damage situations that involve permanent unconsciousness or quasi-unconsciousness and where the rest of the body may be fine as long as the person is given food and waterAlso it's normal for people with major trauma to be put in an artificial coma for a few days or weeks while their injuries heal a bit
When you're thinking of the ["cartoon oasis"](_URL_1_) pool of water with some trees in an endless sand-scape you're likely thinking of something in the Sahara. The area that is north Africa has been slowly getting drier for something like 10,000 years. But all the water that was trapped underground is still there. Aquifers, springs, underground rivers, etc. are all still there, just under a lot of sand. [Link.](_URL_2_) IN some places the hard rock layers come closer to the surface of the sand, and the thousand year old water can leak out; this is your oasis. [Link.](_URL_0_) The sands do shift, and sometimes oases get buried, but once trees and plants have taken root I imagine it's kinda hard to truly lose one to the desert. Some big ones have been trading posts and military bases for centuries.Of course there's lots of ways a place can become a desert and lots of ways water can be forced to the surface; every oasis is going to be a little different. The geology and history of the Sahara lends itself to this kind of thing.
During a panic attack some regions of the brain become hyperactive. These can be identified using a functional MRI (a special type of MRI that shows what parts of the brain are active in real time).Multiple regions have been found to be affected, these include: The amygdala which is involved in our perception of fear  &  parts of the midbrain that are involved in how we experience pain. If these parts of the brain malfunction (for example by giving a larger or more sustained response to a perceived threat) then you can experience a panic attack. These areas and possibly even some we have yet to identify cause the downstream effects that people call associate with a panic attack.
Sure. Apparently [silphium](_URL_0_) (a plant related to carrot and parsley) was driven to extinction by ancient Romans and Greeks, partly because they used it as a contraceptive. It induced menstruation, and therefore abortion.And there are many other plants that have abortifacient effects: bitter melon, wild carrot, blue cohosh, pennyroyal, nutmeg, mugwort, slippery elm, papaya, vervain, common rue, ergot, saffron and tansy. Animal studies have shown that pomegranate may be an effective abortifacient. These were known even before modern times.
There is a whole field of research dedicated to this, it's called Operations Research. In many (simple) cases, theoretcal optima can be derived. If the system becomes more complex, simulation might be easier to optimize your system. However, this does require accurate parameters for your simulation model.Basically it all boils down to linear programming and (heuristic) solutions. You can look up Inventory Control, Routing Problem, Spare Part Management or Shortest Path Problem for more reading.
The water content of hair is really low. The water that is there is associated and adsorbed to the keratin that makes up your hair, so it won't be able to crystallize at 0 C. In otherwords, hair doesn't freeze at the same temperature that water would. If your hair is wet, then the water on the outside of your hair can freeze. What your hair does in this situation when you bend it depends on how strong your hair is and how thick the ice is.
Yes. Identical twins have the same genomic sequence.
Conventional hard drives store information by changing the magnetic orientation of a thin film of material on top of the spinning platters. Solid state drives (SSD) trap charges (electrons) inside special transistors. Dynamic RAM (DRAM) stores electrons in tiny capacitors. Static RAM (SRAM; used for CPU registers, caches etc) uses a couple of transistors arranged in such a way that they hold a set state (0 or 1) as long as power is applied.
Small oscillations about **any** stable equilibrium will behave like simple harmonic oscillations. And a simple harmonic oscillator, by the very definition of it, has a natural frequency determined by the mass of the oscillator and the shape of the potential energy function near that equilibrium point.
The sound in that situation would be more like just a pressure wave, since there is almost nothing keeping it contained in the gas.  If you increase the pressure in the center of a balloon, that will cause a push to move through the air molecules that bounces off the latex surface.  If the latex wasn't there, the air molecules would just shoot off into space.  As the wave reaches the edge of the cloud, a burst of molecules/atoms will be pushed away by the pressure at a higher speed than the wave.  Some of the energy will bounce back but most will go into the increased velocity of the escaping particles.
This is indeed possible, though quite rare.  This phenomenon is called [uniparental disomy](_URL_0_), and you can read a bit about it at that link.  I would imagine that in some cases there would be no noticeable effects, especially if you received two different versions of the chromosome from one parent (heterodisomy; i.e., you got both your maternal grandfather's and maternal grandmother's chromosome) so that you are not fully homozygous across that chromosome.  However, there are some defects associated with uniparental disomy as the above link indicates; both Prader-Willi syndrome and Angelman syndrome can be (but are not always) caused by inheriting two chromosome 15's from the mother or father respectively.
Are you asking how we know what the composition of materials is? I.e. how we know it's CaCO3 and not CaCO2? Or how do we know it has Ca in it?Or do you mean how do we know what minerals are present in a rock?These all have different answers, and I can do my best to answer what you want to know!
It's the fact that different types of waves travel at different speeds. The P waves (compression waves, like what we normally think of as sound) travel the fastest. Then the S waves (transverse waves) travel a little bit slower. Slower still are the surface waves, Rayleigh and Love waves.Every earthquake generates all of these types of waves, so the duration of the quake is a function both of the actual duration of the quake and the time between the first and last wave arrival, which naturally increases with distance. Essentially, the fast waves have more space to get a lead on the slow ones.There are other effects, too, like the number of reflected paths that exist at long distances, but the main thing is probably the different wave speeds.Hope that answers your question!*Edit: Also, there's dispersion, where waves of the same type (but different frequencies) travel at slightly different speeds as well.*
There is indeed a n2 gas laser emitting at uv wavelength(it is quite popular too _URL_0_). What the article you refer to is taking about construction of ir lasers. IR range light is produced in those by transitions between different vibrational levels in co2. In co2 certain vibrations of a molecule change its total dipole momentum (caused by having different partial charges on carbon and oxygens) while in n2 both atoms are completely equivalent and as a result there is no electric dipole momentum. Without electric dipole momentum it is much harder to excite electric field.
If you're just looking at straight population counts, it could be said that domestic livestock, like cattle, pigs, sheep, chickens, etc. have benefited from human dominance. If you are considering quality as well as quantity of life in the term "benefited," then it's harder to make that case. Certainly, as others have said the animals we domesticated to keep as pets, such as cats and dogs, have benefited, as have urban pest species and the invasive species we have introduced to certain areas.
A strong acid is based on the bond between the H+ part of the molecule, and the negative ion. So HCl is totally fine separating into H+ and Cl- which makes it a strong acid. When we measure pH, we are talking about the amount of H+/H3O+ (which is H+ + H2O - >  H3O+).  The greater a concentration of H3O+, the more acidic.Molecules like H2CO3, are much less likely to dissociate in water (of course there will be a little, but that is what makes it weak).
Weeeell... > If we break that down to its individual elements or nontoxic compounds, it will no longer be a pollutant, correct?Not necessarily.  You can't really take all pollutants and pollutant systems together, but for things like photochemical smogs, smaller molecules are not necessarily more stable.  Chlorine gas degrades under UV light in the atmosphere to produce chlorine radicals, which go on to catalyse a whole family of nasty radical chemistry and leads to formation of atmospheric nitric acid, PANs and hydrogen peroxide.  All of these are pretty bad to get in your lungs.Carbon particulates are pretty much pure carbon - doesn't stop them being carcinogenic.That's all really just background though.There are a few problems with this suggestion - first, I'm not really sure what kind of 'electron attractive' thing you're talking about.  If you mean electronegative molecules, unfortunately these only act on tiny scales and would not effectively pull out atmospheric pollutants, which are extremely diffuse.I think this question might stem from a misunderstanding about the problems of pollution - most of the harmful chemistry stuff happens in the atmosphere itself.  It would be far easier to reduce emission of chemicals (like nitrous oxides, volatile organic chemicals and the like) than to try to deal with the products once they're up in the atmosphere.
The celestial sphere can be thought of as two dimensional, and so stars are located on it using either right ascension, a description of their distance from the prime celestial meridian, and declination, their distance from the celestial equator, or using azimuth and altitude, which obviously changes as the stars seem to rise and set. Stars are so distant their relative motion is undetectable for the most part, but not entirely, so their relative locations are updated periodically, and about every 20 years new star catalogs come out. Observational astronomers don't generally worry about how far away a star is since you don't need that information to find it.
The thing you're calling the energy (E) of the canonical ensemble is actually the ensemble **average** internal energy. When you derive the equilibrium distribution for the canonical ensemble (Boltzmann distribution), you do so using a Lagrange multiplier to constrain the average internal energy to a constant value. But you're still allowing the actual energy to fluctuate around that average.
So first of all, the things that spin that we are interested in are not the whole atoms themselves, but the nuclei of these atoms.  When a nucleus has non-zero nuclear spin, it will align itself to an external magnetic field (provided by the MRI).  There's a list of common isotopes which have non-zero nuclear spin, but the main one for most MRI imaging is hydrogen, since there is so much of it in the body.When you want to take an image, you send a radio pulse which kicks some of these spinning nuclei so that their axis isn't aligned with the magnetic field anymore.  After the pulse, these nuclei gradually realign with the field (gradually is milliseconds).  As they do, they will emit a radio signal, whose frequency is related to which isotope it is, and the strength of the field.  Basically, we grab a bunch of radio antennas and catch this signal, which tell us the relative density of hydrogen atoms in a particular area of tissue.  This is where the contrast comes from.On a very simple level, you could say that basic MRIs respond to tissue water density, so tissue with differing water density gives you contrast.I've glossed over a lot of details, but this is basically it.  You can inject various contrast agents (that have non-zero nuclear spin), or read other naturally occurring isotopes as well.  Also, figuring out which radio signals came from which section of tissue is a combination of engineering and math involving the magnetic field, the radio pulse, and the antennas.
It's entirely possible that supernovae have formed "manmade" elements in the past, but because they decay so quickly (Uup-289 has a half-life of less than a second), they are essentially impossible to detect in the wild.
It's the rate of heat transfer that makes something "feel" cold, so in the first instance thermal conductivity that's more important. The specific heat capacity (and also other properties of the substance) influence how the rate of heat transfer changes over time, and therefore how it feels on longer time scales. So if you put your hand on a steel block, it will initially feel cold but quickly stop feeling cold and even begin to feel warm (as you warm up that patch of steel, and heat is only relatively slowly transferred to the rest of the block). Conversely, if you put your hand in a bowl of cold water it will feel cold for much longer, not just because of the higher specific heat capacity but also because the heat will transfer quickly around the bowl of water and so you will, in effect, need to heat it all up rather than just a patch around your hand.
The Earth's magnetic field does not shield us from gamma rays.It can only divert charged particles towards the poles (those form auroras).Cosmic rays refers to high energy massive (having mass) particles, not gamma rays.
It is somewhat lke Jurrasic Park you need a good sample of DNA and a suitable host womb to use our currently available cloning technology. We do have preserved Mamoth DNA and Elephants. We don't have either for reptiles. But the same process could conceivably be used.
Some bitcoiners (is that a word?) have calculated that you'd need 15 of them to achieve 51% of the current bitcoin network power. According to Bitcoin, the average is targeted to be 7200 bitcoins total mined per day. So 15 Titans could mine 3672 per day, and 1 could mine 245 per day (rounded up). At current exchange rates, that would be almost 34 grand per day.Titan uses 9 million bucks in electricity per year, which works out to $24,657 per day. So, you'd make 10 grand a day. Of course, that doesn't count the startup costs - Titan costs $100 million, which means you'd need to run it for more than 27 years just to break even. That's going to be risky, because the jury's still out as to whether or not bitcoin is going to go anywhere from a financial point of view, and of course it also assumes Titan will run for 27 years without ever requiring repair, which would cost you both in loss of bitcoin output and the cost of the repair.(sources:  _URL_0_ (15 Titans per day statistic) , _URL_1_ ($9million / year in electricity bills statistic and the purchase price of Titan) , and math for the rest).
Yes, they can.[Relevant information from the Harvard medical school](_URL_0_). It refers to microwave-safe plastics, but if something is not microwave-safe, it *definitely* is not safe for pouring and reusing a presumably very hot hydrophobic liquid.
No, one molecule does not have a state. You need "many" molecules to define a state. There probably is no specific minimum number.Consider for example a droplet of fluid : the smaller it becomes, the larger the fraction of molecules that are at the surface of the droplet, and the more its behaviour becomes determined by surface effects (surface tension) as opposed to bulk effects (fluid behaviour).
An orbital represents a standing wave, so you are right that it does not change with time. However, the electron still has angular momentum and kinetic energy in an orbital. This might seem contradictory, but we only need the values for these quantities to be constant with time, they don't need to be zero. The average velocity must be zero of course, since the electron remains in place, but that isn't the same as saying the average speed of the electron must be zero.You can ~~roughly~~ think of an electron in an orbital as obeying the virial theorem, where if the total energy is -E, the potential energy is -2E and the kinetic energy is +E. Therefore, the lower the total energy of the electron gets the more kinetic energy it has. This is also true of the orbit of planets - close orbits have more kinetic energy even though they have less total energy than a similar mass planet in a larger orbit.Rather than asking if the speed is close to c, we can focus on the kinetic energy and the rest mass. If the kinetic energy becomes large compared to the rest mass of the particle, then relativistic effects become important in your calculations. For a hydrogen atom, the ground state is -13.6 eV, giving a kinetic energy of +13.6 eV, which is very small compared to the mass of the electron (0.51 MeV/c^(2)). But this energy scales with Z^(2), so for a massive element with Z=100 (Fermium) that has a single electron, you get a kinetic energy of 13.6\*10,000 = 0.136 MeV. That is now a pretty large fraction of the rest mass of the electron. Therefore our back of the envelope calculation suggests that relativistic corrections are going to be important for the lowest orbitals of heavy elements.
Some would argue that gender is different from sex, as sex is defined/determined by the presence of large or small gametes and gender goes beyond that. From my understanding, there are no examples of a species having more than two sexes. There are asexual species, species that change sex over time (parrotfish), species that determine sex by temperature of eggs (alligators), but none that actually have 3 sexes.The reason for this, as it has been explained to me, is that the probability of an organism meeting a fertile member of the opposite sex is difficult enough already in a two-sex system, that adding a third sex to the mix would then make it much harder and more complicated to find a compatible sexual partner. Thus, there has been no evolutionary pressure for a third sex.
Matter isn't really solid. All interactions involve the fundamental forces: electromagnetism, strong force, gravity, and the weak force.Neutrinos are electrically neutral, so they don't interact with electric charges. They are color-neutral so they don't interact through the strong force.The mass of neutrinos is currently unknown, but very small to zero, meaning they interact only slightly through gravity.That leaves the weak force which is short range and, well, weak. In order to react through the weak force, collisions need to be dead on. Given that an atom is essentially empty space with an insubstantial amount of volume at its center taken up by the nucleus, (the electron is almost certainly not going to be hit) this leaves almost no chance for a neutrino to interact with anything, thus it passes straight through.
Transformation, as you describe it, occurs between prokayriotic bacteria, not eukaryotic body cells. Bacteria have evolved to swap around DNA, sharing beneficial genes, but human body cells have no such mechanism.   There are actually attempts to use bacteria as vectors to help deliver tumour antigens to create cancer vaccines, but that is a completely separate area.
Chimps and gorillas have a gestational period just under humans which implies that ~9 months was a commonality likely shared with early hominids.As has been mentioned in order to stand upright our pelvis has rotated and shortened to accommodate the range of motion needed in our legs as well as narrowing which better supports our weight. This is the reason childbirth is such a problem for us, female pelvises being unfused so that they can flex in labour and baby's skull plates unfused so that they can move and squish a bit.When compared even to our closest great ape cousins we are born spectacularly immature and under developed, some say that's an advantage because we have more time to learn which is uncertain. But for sure we would be unable to walk upright without it or major changes in reproduction.So it's probably fair to assume that with the trend from quadraped to biped follows difficulty in labour and premature young.More recently we know that several other subspecies of homosapiens interbred, including Neanderthal and Denisovan man as we can still find remnants of Thier DNA in the current Human population. So it's reasonable to assume that they had nearly identical reproductive habits to us although we don't KNOW.One of the big issues with studying this field is a real lack of data, we can study our own genetics and discover our familial links with sub species of homo but this was still relatively recently.Fossilisation being a rare process anyway we do not have complete fossil records of all hominids and homo though all stages of development. Enough to comfortably decuce common ancestry but lacking the detail to easily study subtle changes in how young develop and are born.Even after the consolidation of homosapiens sapiens from earlier sub species our earliest written languages are only a few thousand years old and aren't detailed records of pregnancy and childbirth. This how much ideas about it have changed since then and vary even now around the globe. We can be fairly sure that pregnancy had a higher mortality rate and infant deaths were higher but how high they were we don't know.
There was a ride very similar to that at Six Flags Over Georgia called the [Freefall](_URL_0_). It has since been torn down though.
Yes, this is commonly done in research using few-turns coils and large capacitor banks.  See the pulsed-field equipment at [LANL](_URL_1_) and at [FSU](_URL_0_) for a bit of info.
Some foreign body (an antigen) is activating cells on your skin (IgE antibodies probably) to cause your mast cells to degranulate releasing histamine, causing inflammation and release of bradykinins which cause pain and itching
There are two main ways that tissues are absorbed.  One is where they die by apoptosis, programmed cell death. In that case the cells themselves take care of their own dismemberment into basic chemicals and cellular fragments.  The other is by necrosis and this is a much dirtier process, attracting macrophages and generating reactive oxygen species and potentially an inflammatory response.  Eventually all of the cellular fragments are engulfed by macrophages and disposed of.
You basically have it correct since smokers are already at higher risk the *relative* risk of death caused by obesity is less than in non-smokers. Keep in mind that Figure 1 is showing risk within each smoking category and not comparing risks across smoking categories. If you look at table 2 you will see that death rates in obese smokers is indeed higher than death rates in obese non-smokers. There is nothing surprising about this observation. Let us assume that being a smoker increases your risk of death by 25%. Let us also assume that BMI of 30+ also increases your risk of death by 25% and is independent of smoking so that the risks are additive (i.e. being obese and a smoker results in a 50% increased risk of death compared to a normal weight, non-smoker). So compared to normal weight non smokers the relative risk (RR) of death in each category would be:* Normal Weight, Non-Smoker: 1.00* Normal Weight, Smoker: 1.25* Obese, Non-smoker: 1.25* Obese, Smoker: 1.5The RR of death for normal weight, non-smokers versus obese, non-smokers would be 1.25/1 = 1.25.The RR of death for normal weight, smokers versus obese, smokers would be 1.5/1.25 = 1.20. Obesity can cause the same number of deaths in smokers and non-smokers. Since smokers are already dying at higher rates the increased deaths caused by obesity have a smaller effect, percentage wise, on the overall death rate.
When measuring these things, scientists are not looking at just the overall color of the star. Rather, they are looking at the spectral lines emitted by the elements in the star. These [spectral lines](_URL_0_) are discreet with some width, and are spaced a certain distance apart depending on the elements. We know all the major elements that any star is made out of (it's mostly hydrogen and helium, and for more exotic bigger, older stars, they will have elements up through carbon or iron). When there is a red/blue shift from the motion of the star relative to us, all of the spectral lines will be shifted up or down the same amount, regardless of wavelength. So as long as the laws of physics do not change across the vast distances of the universe (which is a central tenet of physics), we will see the same pattern we see when examining the elements here on earth, but shifted. A star that is "redder" by color, will have different elements in it than our Sun, so the spectral lines will be differently spaced, rather than all shifted in the same direction.
To answer this question, we first have to understand what birds are actually excreting vs mammals.  Generally, urination is used to remove nitrogenous waste from a biological system.  Nitrogenous waste is generated from the metabolism of amino acids that make up proteins, usually resulting in a free amino group(R-NH^2).  In the body, these free amino groups are quickly oxidized into ammonia, which is both highly toxic and very soluble in water.  The toxicity of ammonia is what drives the variance in forms of nitrogen excretion.  There are three common forms of nitrogenous compound that various vertebrates excrete: urea, uric acid and just ammonia.  Which compound a creature excretes is usually impacted by its access to water.  The great majority of fish excrete pure ammonia.  As mentioned before, ammonia is very soluble in water, so flushing ammonia out with just water is a very energy efficient model for excreting nitrogenous waste.  Since, generally, fish are not concerned with access to water, it is no trouble for them to excrete ammonia.  So, urea excretion is not as energy efficient as ammonia, but it is much more efficient at water conservation.Mammals and amphibians excrete a different form of nitrogen, urea.  Since mammals are land-going and not always near water, they have to be more conscious of how much water they waste.  They will not want to waste the amount of water it takes to excrete nitrogen one atom at a time, so they concentrate it.  Since ammonia is toxic, what it is concentrated into must also be less toxic so that it can stay in the body for longer.  Ammonia has one nitrogen atom per molecule, while urea has two, so it is twice as efficient and requires less water to excrete.  Many sharks also use urea since it can be concentrated in the animal to make it hyperosmotic to sea water, which is full of dissolved minerals.  This allows water retention in the shark to be much easier.  Lastly, we get to uric acid, which is also where we can try to answer your original question.  Uric acid is the nitrogenous waste of choice for birds, saurian reptiles and a very few desert-dwelling mammals like the kangaroo rat.  Uric acid has four nitrogen molecules and is synthesized by a much more complex metabolic pathway that costs more energy, but can be eliminated using almost no water.  Many desert reptiles excrete uric acid with feces as a dry mass, losing no water along the way.  So, since a uric acid is observed not only in birds, but also saurian reptiles, which also derived from dinosaurs, it is likely that the use of uric acid as nitrogenous waste came about before birds split off completely from reptiles.  Of course, we will never know for sure, but two groups who have a common ancestor using the same form of nitrogenous waste that is by far the most difficult to make is a strong piece of evidence.
Black holes have no insides, so there's nothing in them.It's basically impossible to give a short, succinct description of black holes that is also in any way even vaguely correct. They are so completely different from anything we encounter in daily life that even metaphors fail.So the best way to think of it, for the layperson just going about life wanting to be essentially educated as to how the universe works, is to imagine a very large, very old star. This star has used up all its fusion "fuel," if you will, and will soon collapse, exploding spectacularly in an apocalyptic cataclysm of radiation that will, briefly, outshine its whole galaxy.Inside the very core of that star, there's, well, more star. The end hasn't come yet; the star is still being a star for the moment, so the interior is still star. But it's *fantastically* dense. In a minute, when the star explodes, it's going to become denser still. Because you see, the thing that explodes when a star goes supernova is the *outside* of the star. Imagine a bowling ball coated in cake icing … made of plastique explosive … and wired to a timer … okay this metaphor isn't very good. But the point is, it's the outer layer of the star that's actually going to do the exploding here in a minute.So let's wait.And wha-boom.Okay, that was a supernova. Nice one, right? It happened kind of fast, so you might've missed it if you weren't watching carefully: The interior of the star reached the point where it no longer had sufficient pressure to hold the outer layers of the star up, so it essentially collapsed. The outer layer, meanwhile, began to drop like a rock, because all the pressure that had been supporting it suddenly vanished. This caused the star's outer layer to heat up *unbelievably* quickly, which caused lots of violently interesting things to happen. There was a stupendous outrushing of radiation, first, and matter shortly behind it — helium and lithium ions mostly, and some other stuff. But what you *couldn't* see was that that same explosion also went *inward.*A spherically symmetric shockwave propagated inward, down toward the core of the star, compressing the already hellishly dense matter that was there until … well, the world came to an end.There is a limit to how much *stuff* can occupy a given volume of space. This is called the Bekenstein limit, after the boffin who figured it out, and I won't elaborate on it here because maths. But suffice to say, there's a limit.When that limit is reached — and in this case, due to the simply incomprehensible pressure exerted by that inward-focused shockwave, it was — the volume in question simply goes away. Poof. It ceases to exist. If you like, you can imagine God Almighty being offended by the ambitious matter and willing it out of existence in an instant. Just pop. Gone. Forever.What's left, in its place, is a wee tiny … not. An isn't. Part was, part isn't, part won't-ever-be, in the shape of a perfect sphere that doesn't exist.The boundary between where that sphere isn't and where the rest of the universe still continues to be is called the *event horizon.* The event horizon is not a surface. It's not an anything. It's an isn't. But it *behaves* like a surface in most respects. A perfect, impervious, impenetrable surface. If you threw something at it, that something would shatter into its component bits — and I don't mean chunks, or even dust, or even *atoms,* or even *protons and electrons.* I mean *individual discrete field quanta.* And those field quanta would spray off into space in all directions like bits of strawberry out of a liquidizer that has been unwisely started with the lid off.That's what happens to all the *stuff* that was in the centre of that star, as well. Eventually, it'll be sprayed out into the universe in the most fundamental form possible, as little individual quanta of energy and momentum and spin and charge.Except due to a combination of relativity and thermodynamics, you will not actually witness that happening. Because the process takes a while. For a typical stellar black hole right now? The process will take on the order of a trillion years. So don't wait up, is what I'm saying here.So black holes? They have no insides. They aren't. That's their defining characteristic, qualitatively speaking: They *aren't.* There's nothing in them, because there's no in, because they aren't. There's *stuff* which is, even right this very moment as we sit here talking about it, in the process of *scattering* off black holes. You can't see, observe, detect or interact with any of that stuff, but we know it's there, because it has to be. And we know eventually it'll spray out into the universe, first and for hundreds of billions of years as photons — a few a day — with such long wavelengths that they can barely be said to exist at all. Later, *hundreds of millions of millennia* after we, our species and our solar system have long since ceased to exist, black holes will start emitting radiation we'd recognize as radio waves. Then, in an accelerating process, all the way up through the electromagnetic spectrum until finally, in the last tiny fraction of a second before the black hole evaporates entirely, the potential energy available will be in the hundreds-of-electronvolts range, and we'll get the first electrons and antielectrons, then a few protons, and then a cataclysmic burst of short-lived exotic particles that lasts hardly longer than a single instant, then the black hole will have ceased to not exist.
I'm not a botanist/biologist so hopefully somebody can give you a better response than mine. But, from my understanding in a haplobiontic life cycle the organism never switches between multicellular haploid and diploid phases and there is no alternation from one generation to the next. While in a diplobiontic life cycle both phases are represented by multicelluar phases and alternate by generation.The haploid phase would be a gametophyte with one set of genetic information, while the diploid would be a sporophyte with two sets.What your notes are probably referring to is that in an organism with a haplobiontic life cycle the diploid phase is not a full fledged life form, if that makes sense. An example would be something like a zygospore that is waiting to be triggered by environmental conditions to start producing the haploid phase of the organism, which in this case represents the "mature" phase of the organism that collects energy that it uses to produce more diploid structures by mating (two haploid structures fusing) to continue the cycle; it will probably be the phase of the organism that we are most familiar with.In a diplobiontic life cycle the organism will have a haploid form and a diploid form that may or may not be similar in appearance, structure, etc. but will differ in the genetic information they contain. The haploid reproductive structure would be a gametophyte that produces male and/or female gametes that later on fuse to form a diploid structure that developes into a multicellular sporophyte which will develop and produce the haploid form to continue the cycle.What your notes are probably referring to when they say that in a diplobiontic life cycle the haploid gametophyte is suppressed is that the haploid form is often purely for reproduction like the diploid form of a haplobiontic organism I described above, while the dibloid sporophyte phase is the phase that collects the energy for the process. I'm not sure this is true in the same way that it is in the case of a haplobiontic life cycle, so hopefully somebody more knowledgeable can clarify that.In either case "completely suppressed" might not be the best term because it might imply that they are absent. They are not necessarily absent, but it is more a matter of the role they play in the life cycle of the organism. I'm also not sure that it in every case the stated phase is the one suppressed, I think those are just the more common cases.haplontic would mean that the organisms cells are haploid, while diplontic would mean they are diploid and haplodiplontic would mean they can be both. An organism that qualifies as the two former would be haplobiontic, as it each generation exists in the same phase. Humans, diploids, produce humans that are also diploids (and they use the fusion of haploid (single)cells to do this). An organism that qualifies as the latter would be diplobiontic in that it produces copies in one form that then produce the next form, and so it possess both haploid and diploid cells (not necessarily at once).To summarize, a haplobiontic organism does not alternate generations between haplontic and diplontic forms and a diplobiontic does alternate. So for the former, the organism lives as one or the other and produces the alternate form in order to produce its next generation. Growth/cellular mitosis only occurs in one phase. In the latter, the organism lives for a while as one and then produces the other which lives as that form and produces the other and so on, alternating between the two. Each phase contains a process of cellular mitosis in order to continue the cycle.Hopefully that makes sense and I didn't mix anything up... Hopefully if I got something wrong somebody will take the time to correct it.
in general, camouflage morphologies arise like any other aspect of development. The DNA sequences that mediate them primarily arise in the regulatory elements of genes controlling development rather than at the level of the protein sequence. This then results in alteration of when and where certain genes are expressed and allowed to interact with one another to effect local developmental processes. Assuming that some morphologies allow their carriers greater reproductive success (by not getting eaten), the DNA sequences permitting those morphologies get passed on and become more frequent in the population. Over time, other mutations may improve on the morphology from the standpoint of camouflage and also spread through the population. Give this process a few million generations, and you can get something like the picture. Also note that other factors such as epigenetic patterns and the environment will affect the development process, leading to variation on the camouflage theme in any given individual. Unfortunately I'm not an expert on the genetics of camouflage, but I'd recommend reading work from Sean Carroll's lab if you're interested in the genetics and evolution of morphology (especially in insects).
Yes. There are at least three ways to boost brain executive function broadly. The first is aerobic exercise. 30 minutes at a challengingly high, but sustainably high, heart rate for three times per week.The second is brain training. Not all training is equal, and this is a developing field, but the Dual N Back task has good evidence of effects on IQ. Again, this is something you have to commit regular time to.The third is cholinergic boosts. Nicotine, Donepezil, Rivistigmine. The cholinergic boosts have side effects and tend to have weaker effects overall than the first two.
Each atom can behave like a little tiny magnet (a little rotating charge, if you will), but if you have a bunch of atoms all pointing in random directions, the total magnetic field is zero. In magnetic materials, the magnetic moments of each atom align to point in the same direction. The material property that embodies this is called magnetic susceptibility.
There is a way to analytically find a function that transforms between a uniform random variable and a random variable distributed according to some other PDF.If you have some random variable x, distributed according to the PDF f(x), and you want to find some function a(x) such that a follows some given distribution g(a), you simply require that the probability of finding x between x' and x'+dx' is equal to the probability of finding a between a' and a'+da', where a' = a(x').This amounts to setting the CDFs equal to each other and solving for the unknown variable.So now let's consider the special case where we're starting with a uniformly-distributed variable. These are easy to generate (approximately) using a standard PRNG algorithm like a multiplicative linear congruential generator, or something similar.So let's say we have some random variable r, uniformly distributed on [0,1]. The CDF for this distribution is F(r) = r.Now we want to find some x(r) such that x is distributed according to some PDF g(x). The CDF for g is denoted by G(x), and we just apply the transformation rule above by setting G(x) = F(r) = r.For this method to be convenient, you have to have some functional form of the CDF G(x). An example would be x distributed according to an exponential distribution. In this case, g(x) = e^(-x/k)/k. If you evaluate the CDF of this distribution, set it equal to r, and solve for x(r), you'll find that x(r) = -k ln(1 - r). Since r is uniform in [0,1], (1 - r) is as well. So you can just as well use x(r) = -k ln(r).Now, generate r uniformly in [0,1], and if you calculate x(r) for each value and histogram the results, you'll find that x(r) is distributed exponentially with mean k.This is just one particular example. Another example is the [Box-Muller transform](_URL_0_), which takes two uniform random variables and generates a Gaussian random variable.If doing this transformation analytically is too difficult, or if no simple functional form of the CDF is available, you can always use a Monte Carlo acceptance-rejection method. This can be kind of computationally wasteful, but it's guaranteed to work. If some analytic transformation exists, you should use it, but even if one doesn't, this is a way to generate random variables according to an arbitrary PDF.
This begs a few questions....what makes you say that a worm will sometimes come out of an apple with no entry holes? Have you seen such a thing? What makes you say that an entry hole must be visible?
Technically the speed of the planet *would* have an effect on the time dilation but it would be relatively tiny; planets and stars move too slowly to notice the effects of Special Relativity (i.e. time dilation due to speed) or such effects are vastly outshined by those of General Relativity (i.e. time dilation due to gravity).To notice time dilation due to speed you have to get much closer to the speed of light than any planetary body we know of does.
It depends on the kind of study, sometimes they do._URL_0_ >  No significant difference was shown in energy excretion in stools between lean and obese subjects who consumed the 2400-kcal/d diet [134.3 ± 48.9 kcal/d (lean) compared with 133.2 ± 44.8 kcal/d (obese) (P = 0.96); 4.9 ± 1.8% compared with 4.8 ± 1.4% (P = 0.87), respectively] or 3400-kcal/d diet [145.1 ± 42.7 kcal/d (lean) compared with 173.7 ± 65.0 kcal/d (obese) (P = 0.21); 3.8 ± 1.1% compared with 4.6 ± 1.8% (P = 0.240), respectively]. However, there was a large interindividual range for the percentage of calories lost in stools (2400-kcal/d diet: 2.1–9.2%; 3400-kcal/d diet: 1.6–7.6%).So between 1.6% and 9.2% of calories consumed are lost in the stool... >  The change in the percentage of urine calories between the 2400- and 3400-kcal/d diets was not different in either lean or obese subjects [−0.5 ± 0.5% (P = 0.34) and −0.6 ± 0.5% (P = 0.15)]. In addition, calories in urine were not different between lean and obese subjects when expressed as total calories or as the percentage of ingested calories with either the 2400-kcal/d diet [88.4 ± 30.8 kcal/d (lean) compared with 99.3 ± 31.2 kcal/d (obese) (P = 0.48) and 3.2 ± 1.1% (lean) compared with 3.5 ± 1.1% (obese) (P = 0.56)] or the 3400-kcal/d diet [106.0 ± 34.1 kcal/d compared with 112.6 ± 28.4 kcal/d (P = 0.64) and 2.8 ± 0.9% compared with 2.9 ± 0.7% (P = 0.72)]....and between 0.7% and 1.1% of calories consumed are lost in the urine.Assuming I'm reading that correctly.
I am not a NASA flight surgeon, but I can talk about how quickly they could get home.  The ISS makes 16 orbits around the earth a day.  Essentially the world turns beneath the orbit, which means each orbit is over a different part of the world.  Twice a day or so, on two sequential orbits, the Soyuz could return to its primary landing site in Kazakhstan. If there is a crew emergency that cannot wait up to a day, there are contingency sites in North America, wide open prairies or farmland that would be considered, depending on the weather that day.  These sites are usually within a helicopter ride of a hyperbaric chamber... useful if an astronaut had too low air pressure in his or her spacesuit while on a spacewalk.
I think you're reasoning that a large bird could obviously beat a small bird, so why bother defending the nest if the large bird knows that? Well if the two bird were to enter into conflict, it would come at a cost to both of them (energy, risk of injury, risk of predation, etc.). Now a bird defending its nest is going to be more likely to risk these costs, because its fitness is tightly linked to offspring survival. A large bird might just be sacrificing dinner. It's an extension of the life-dinner principle. I'll add that, although size is very important in determining the outcomes of conflicts within species, it's not always a great predictor between species. Sometimes smaller species are better/quicker/meaner than larger species.
It means exactly that: out of the four forces, gravity is the weakest one. Gravity only seems strong because we live right next to a giant mass of rock and experience gravity all the time. When an entire planet worth of gravity is opposed to a small fridge magnet worth of magnetic force, the fridge magnet usually wins. That's how weak gravity is.
The short answer to this is no.  All living things (I am excluding viruses from this discussion) are composed of cells surrounded by a membrane. They also all use DNA to store the instructions necessary to create proteins. Given these similarities, scientists have concluded that all life on Earth shares a common ancestor. It is important to note that this does not preclude the possibility that life *originated* elsewhere however.  Since all life must perform many of the same functions (DNA replication, protein synthesis, metabolism), there is a subset of genes that all currently known living organisms possess. One of the most well-described of these genes is is the ribosomal RNA (or rRNA) gene. Similarities in this gene are used to determine the "relatedness" of two species since parts of it are not under selective pressure and can mutate at a (somewhat) predictable rate.
Depends on who you ask. Most of the time a lake is a natural freshwater body with an inlet and an outlet, a pond is usually a man-made water body that doesn't necessarily have inlets/outlets, and a lagoon is usually a body of ocean/sea water that lies behind a barrier such as a reef. Those are the general definitions, but there are exceptions depending on who you talk to, what the history of the water body in question is, and personal preference.
In terms of structure, soaps are long, nonpolar (oleophilic/oil-loving) alkane chains with a polar (hydrophilic/water-loving) end. The nonpolar section of the molecule solvates (grabs onto) oils and greases and surrounds and isolates them as a [micelle](_URL_3_) with the polar ends pointing outward. upon flushing these micelles with water, the polar interaction between them sweeps the soap and oils/greases away and down the drain.[Here](_URL_1_) is a typical soap, Sodium Stearate. You can see the long nonpolar region and the polar end where the sodium (Na) ion is.The function of detergents is fairly similar, ~~but some detergents use surfactants rather than soaps~~. [The wiki article](_URL_0_) for detergents gives pretty good details on some different varieties.I'm not sure if this is quite what you meant by "effect of soap and detergents on the environment", but in terms of biodegradability, it seems the trick is to make the soap without using additives (only fats/oils, lye and water). Surfactants and detergents are, in general, less biodegradable than soap molecules.It seems to me that most of the recent improvements have been a matter of doing [the same things, but better and faster than before](_URL_2_). I wish I had some more information on a big and new industry improvement, but it seems like more or less, soap is being made as it has been for a while.The reason to skip on the additives for biodegradability is that many of the artificial additives and fragrances are environmentally persistent, generally getting where they ought not be, or they degrade into pieces that are harmful to the environment. If the degradation products are very harmful, they're generally left out altogether for obvious reasons; most companies that value their PR would screen these out in the R & D process.Perhaps someone else has a bit more info on this topic who is closer to the industry...Let me know if that answers your question, and if anything is unclear! ~M-----------------------------------------------------**Tl;dr**: ~~There doesn't appear to be any earth-shattering new advances in the soap making process; it's a pretty mature industry.~~ The industry has not changed *tremendously* in recent years, but see below for details pertaining to enzymes, additives, Phosphorus addition (or recent lack thereof). See also /u/meandyouandx 's post with some insights on the industry.edit: Thanks /u/ucstruct and /u/yoenit, I've been straightened out: soaps and detergents are both surfactants, and soaps are a specific type of detergent. edit 2: Many additional comments below just go to show my passing knowledge on the subject; keep reading, there's good stuff below!
No. Even though the image on your retina is upside down relative to the object you're observing, the brain doesn't actually do any 'flipping'. It just knows (through early development) which neurons connected to cells on your retina are associated with which direction, and so in that sense it is hard-wired into your brain.
> where as in America it seems to be a linchpin of society. While my expertise is not in cultural studies, as an American psychiatrist I would argue that this is not really the case.  There is actually quite a stigma towards psychotherapy.  Anyway, I wouldn't use your phrasing (i.e., "works"), but yes, psychotherapy can be very helpful in reducing the symptoms of some psychological disorders.  One of the most researched therapies is an approach known as [Cognitive Behavioral Therapy](_URL_0_).  Obviously studying a treatment method like this is fraught with methodological limitations, however there is evidence that it can be beneficial for symptom reduction in some psychological disorders.
For vertical loads with the same diameter steel bars, the four pillar towers would be stronger. The stress in the pillars depends on the cross sectional area of the steel. Same with the deflection due to bending from the wind forces, which depends on the moment of inertia (and therefore the cross sectional area and distance from the centroidal axis). The triangle trusses are lighter and sufficient in many cases, but the box trusses are definitely stronger.
It explodes in all directions uniformly. Because it's so far away and there's no shadows, it's hard to see depth. So rays that are coming a bit more towards you just look like shorter/slower rays moving to the side.It's kinda like a photo of an atmosphere, which look like a colored circle around the planet while it's in fact an orb.
Any acceleration would effectively be an “error” term on both your velocity and friction factor. How large and meaningful that error is depends on the magnitude of the acceleration compared to the magnitude of the fluid velocity. What matters more is what the span of velocities are. A good exercise would be to find the pressure loss at the expected minimum and maximum fluid velocity. How different those two number numbers are should give you a decent idea of how good of an approximation you have.
There are some relations that might be interesting to you from investigations of hopper flow. The discharge rate through a hopper may be described by:W = C*ρ*g*(D−k*d)^2.5 ,where ρ is the particle density, g is the acceleration due to gravity, D is the aperture diameter, and d is the particle diameter (for a monodisperse particle system), while C and k are unitless constants.See _URL_0_ and references therein. All grains in the hourglass are subject to gravitational acceleration. If you look at grains in the top of the top half in the center, their downward velocity is related to the discharge rate. However, this rate increases as the level in the top half get low. There is friction between the particle in hourglasses because the grains converge toward the center (slowing down the flow which would otherwise free fall)
To try and put this in perspective:There is an experiement which demonstrates something called the casimir effect. This is basically where two very very thin (Low mass) metal plates are placed very close together. The gravitational attraction is designed to be almost 0, and so is the electromagnetic, and van der waals forces etc. Ultimately there is no interaction between the plates. However what we find is that the plates are pushed together slightly. This is caused by the "Energy Density of the Vacuum" which spontaneously produces particles at all points in space, existing for miniscule amounts of time and then disappearing, not violating Heisenberg's uncertainty principle (Not Breaking Bad :P). We observe this effect because inside the plates, only certain size wavelengths of particles can exist (half wavelengths to be exact). However outside the plates there is somewhat "more vacuum" than inside the plates, and so the spontaneous creation of particles causes a pressure on the plates pushing them together. This effect is well documented, and has an associated "Energy density of the vacuum". When we discovered that the universe was accelerating in it's expansion, and we reignited the cosmological constant as this force, we hoped this casimir effect might be the answer. However, our observations show that the energy densit of the vacuum in the casimir effect is approx.~ 120 orders of magnitude larger than the apparent cosmological constant required to explain Dark Energy! This is an incredibly large error (Stupidly large). So, I hope this gives you some real world idea of the most likely candidate for the cosmological constant, despite the error hopefully we can fix that. Source: Dissertation on Dark Energy and the Cosmological Constant. (I can send you my paper if you want).
Let's consider the Fourier transform (the Laplace is slightly more complicated, but only slightly).The basis functions of the Fourier transform are sinusoids. However, a sinusoid is more than just a frequency; it is a frequency *and* a phase. This is often not the most convenient expression to work with, so you can apply a trig identity and instead represent the sinusoid as a sinewave plus a cosine, each having the same frequency but a different amplitude. This is also not the most convenient expression to work with, so you can apply Euler's identity and write the sinusoid as a complex exponential. There is your (e\^something).The transform gives the "amount" of the function present at a given frequency. This is obtained by *correlating* the function with a sinusoid of the frequency of interest. There is your "multiplied by (e\^something)".Easy peasy.[Here's the full story with pictures](_URL_0_) if you're interested. However, if you're into compact abelian groups, read what the other guy wrote.
Bars, and indeed spiral galaxies in general, are formed by density waves - that is, the structures are stable, but the placement of a given star within the structure varies. Mutual interactions between the stars keep the structure stable.This is hard to get your head around, so here are a couple of animations - _URL_1_ _URL_0_ These don't show bars, unfortunately, but the same general theory applies (as described in the paper linked in one of the other comments).
There are programs that do this, you can search for automatic image vectorization.  Plenty of web services.The basic algorithmic approach is to trace the outline of the image (or of each solid colored block).  Then you fit parametric (bezier) curves to your trace, and you have a vector outline that can be scaled as desired.There are heuristics involved in the tracing process, but generally works very well as long as you have good inputs.  On the other hand, if your input is super low resolution, the trace becomes more ambiguous and your output is less likely to be what you want.  Similarly, it works well for large blocks of solid color, but if you try to feed in something with lots of noise, gradients or textures, most approaches will do poorly.Here's a paper from 2003 that covers some of the techniques used for the tracing portion: _URL_0_
Water always freezes at the same temperature. The stream and the pond just have different ways of distributing the heat and ice that allows the pond to freeze over first. In a pond, as you get close to freezing, the warmer water sinks to the bottom. This is because the [density of water peaks at about 4 C](_URL_0_). The water at the surface is exchanging heat with the air, so once the air gets below 0 C and the surface water is at 0 C, ice will form. Without strong currents, the ice forms a smooth sheet on the top with liquid water below.In a stream, the flow ensures the water is mixed and the temperature is more uniform from top to bottom. So you need to cool the entire volume to 0 C, not just the surface layer. And you need to cool it before it flows out of the stream. Once the water gets down to 0 C, ice can begin to form. But any ice will be pulled along with the current, so the stream deposits the ice at its edges first.
Pre-telescope astronomers didn't know the order and size of the planets. Around the same time as the telescope was introduced,  Copernicus, Brahe, Kepler, and Newton came up with ideas about gravity, planetary motion, and planetary orbits that enabled people to figure out the orbits (position and speed)  of planets. The planets that are travelling around the Sun faster are closer to the Sun,  and the planets that are travelling around the Sun slower are farther from the Sun.  After the introduction of the telescope astronomers were able to begin seeing planets much better - through telescopes they didn't just look like moving stars in the sky,  but rather astronomers could actually see them as discs or round objects.  Pre-telescope astronomers didn't know about any moons other than Earth's Moon. After the introduction of the telescope astronomers were able to begin seeing moons.  By looking at the actual appearance of planets via telescopes,  and  by  calculating the orbits of moons around planets,  astronomers  were able to begin  calculating the mass and size of planets.
Every SSD I've come across supports actually erasing the entire drive by issuing an ATA Secure Erase command: _URL_0_The problem with other erasure methods is that the wear leveling and compression algorithms in the controller will transparently remap your writes, so you won't be writing to the memory cells you think you are, and will leave some memory untouched, either because the data was compressed or just because the SSD has a physically higher memory capacity than it exposes externally.If you use a piece of software that just tries to write zeroes to every logical sector of the drive and then read the whole disk back afterwards, it will appear that the entire drive is empty, but there's a translation layer between the logical data storage that your operating system depends on and what's physically happening inside the device.ATA Secure Erase is an instruction to the drive firmware that asks it to internally erase all blocks, bypassing all the tricks the controller performs for performance and reliability reasons during normal operation.
I assume you're talking about saccadic masking, rather than the broader saccades, which is the whole process of looking at different parts of whatever you're looking at. Masking is the part of the process where the brain masks out the motion blur in the transition between two focal areas. It's important in any question about why something evolved to note that there is no such thing as an "evolutionary reason," because that suggests that evolution is a deliberate process - i.e. that a lemur at some point decided to start a process to evolve into humans and so that's why humans are here. Evolution is simply passing on or weeding out of genetic instructions based on how effective those instructions are at making a life form that can survive. So, for instance, if you were a mutant cheetah who's mutation helped you run faster than other cheetahs, you'd be more likely to catch prey, therefore more likely to eat, therefore more likely to survive long enough to impregnate another cheetah and pass your mutant fast-cheetah genes on to the next generation. If, on the other hand, you were a mutant cheetah who only grew 2 legs, you'd be very unlikely to survive anywhere near long enough to mate, and so your non-beneficial mutation would not be passed on.What this has to do with saccadic masking is that it's not hard to imagine that a creature with the brain structure that processes vision as we do (not all animals do), but who is incapable of saccadic masking, would be in a living hell. Every time its eyes moved, the world would blur like an extremely fast swish pan in a movie. This would be incredibly disorienting, not to mention nauseating. Now put that non-masking creature next to a masking creature and consider the differences - while the masking creature sees an ordered world and walks gracefully through it on its way to food, shelter, and sex, the non-masking creature sees brief flashes of distinguishable images interspersed with insanely disorienting motion blurs. It would stumble about, possibly throw up, have a hard time finding food - in short, its survival would be very much in question. Hence, saccadic masking would logically be naturally selected to be passed on.It should be noted that, as with most "how did this widget in the body evolve" questions, this is highly speculative.
In an ideal circuit, the current flowing through two parallel paths will be dependent on their respective resistances. The path with lower resistance will have higher current flowing through it. This is true because each path (as they are in parallel) will have equal voltage differences. Since V=IR, a lower resistance necessitates a higher current. The only way that current flows through one path and "ignores" the other is if one path has 0 ohms of resistance. In other words, it is a perfect conductor (in real life, even the best conductors have some resistance). Current is higher in the path with less resistance because electrons are able flow through it more easily. Current is essentially the number of electrons that flow through an area in a given amount of time, and resistance effectively slows that flow down. Therefore, less resistance results in greater flow (e.g. higher current). You can think of current like water flow. You have two pipes connected in parallel, one with a lot of blockage and one with little blockage. The water flow will be greater in the pipe with less blockage. The water doesn't "know" which pipe has less blockage. It just flows more easily through the one that does.
More stable than what?  Phosphines, with their three bonds and a lone pair, are perfectly stable until oxygen comes along and spoils everyone's fun.  Same with organic sulfides; they can be oxidized to sulfoxides and sulfones.  The real question here is whether these two elements are actually breaking the octet rule when forming structures whose Lewis dot structures give more than 8 electrons to the S/P atom.  The general (and growing) consensus is that they don't!  The notion that sulfur and phosphorus have d-orbitals available to form extra bonds is a fiction, and not even a particularly useful one (like, say, VSEPR).  What distinguishes S from O or P from N are their large atomic size sand their low electronegativities.  They have a tendency to make more bonds because more atoms fit around them, and they can form bonds with larger ionic character with highly electronegative atoms.  Ever notice how you never see hypervalent compounds with a bunch of bonds to hydrogen, like PH6^- or SH6?  That's because hydrogen isn't electronegative enough to form those bonds with high ionic character.
Extra testosterone won't add new follicles, however it will cause hair to turn from [vellus hair](_URL_0_) to [androgenic terminal hair](_URL_1_) in the classically male pattern.Once a hair turns to a terminal hair it will not turn back to vellus. This can be seen in some women who have polycystic ovarian syndrome which can cause an increase in androgeneic hormones.Another side effect that is really important is the increase in the amount of red blood cells you have. It doesn't sound like a problem, but it really is. It can cause hyperviscosity syndrome which taxes the circulatory system and your body's ability to oxygenate itself. This extra viscosity makes it harder for your heart to pump the same volume of blood throughout your body, so your red blood cells aren't getting oxygenated in the lungs fast enough.Another issue with too many extra RBCs is related to blood clotting. It can cause pulmonary embolisms, deep vein thrombosis, heart attacks, and strokes. All of these side effects can occur at **any age**.All in all unless there is a medical reason, such as gender reassignment, low testosterone, etc. there are too many risks in using testosterone for illicit means.
The vitamins may not absorb correctly. Though they may also not be absorbed from food either.1. Your body may not absorb them correctly without other food to digest.2. The vitamins may not be necessary in the large doses vitamins provide. Excess water soluble vitamins will be excreted. Fat soluble vitamins will likely be stored in your fat. If you take too many fat soluble vitamins, you can get too much, or even overdose.If you're eating a fairly well rounded diet, vitamins are not necessary. Some supplements like Vitamin D can be helpful even with a well rounded diet.
Black holes are generally detected through the xrays emitted from the matter in their accretion disks as it gets compressed and mightily heated as it spirals down toward their event horizons. "Rogue" kind of implies it's moving through space, not bound gravitationality with other objects. We can detect them, but only if they run into something that lights up. Really big ones can be also be detected by their gravitational effects - orbits of stars being deflected. Objects can also be detected through microlensing effects - background stars and galaxies light flaring as it is magnified or dimmed as it is deflected by the gravity of the black hole. At one point their was a theory that dark matter halos of galaxies might be composed of a lot of pretty small black holes. However, to make up the mass, there would need to be a LOT of microlensing events. There were some studies looking for them. Not enough were detected for dark matter to be from the small black hole theory. One could in theory use microlensing to  track a rogue black hole once you'd initially located it and gotten a 2nd fix on its location; but its an awfully big sky and they're pretty small. You might have to look a pretty long time to find your first one.    ---EDIT--- Relevant article _URL_0_
Disclaimer, I've never worked in this field. I'd say it really boils down to them being a custom built. Transformers are in principle very simple. You have them all over your house. The smallest ones can cost just a couple dollars. _URL_0_A very simplistic transformer diagram featured above. And indeed it's almost that simple for very small voltages (100s volts is very small compared to national grids). But on a city scale we are talking about 100,000s of volts. And often they'll be transforming from different input voltages to different output voltages, hence why they tend to be custom orders and not a "shelf" product. Think about the difference between having to build a software that fits your needs (as hospitals often do) compared to just getting one that's already been created. It would still take time to integrate it to your systems but you'd be cutting the whole production time. A city or state will open a bidding war between companies. This will take plenty of time by itself. That company will then need the raw materials to build it, and you can bet that company will have their own bid war on such materials. So we could already be talking 3 countries involved at this stage, if not more. Which means international imports of big, heavy materials and parts. Meanwhile there will be other building phases such as planning, design and testing. Shipping from another country, China to the US for example. And then of course there will be the installation side. This isn't something that happens everyday so you'll need to build the team of engineers to install it. Arrange for the transportation to the location. If you compare the whole process to say, offshore wind turbines, where they're also massive however we do them much faster. How? Because we already have most of the above processes out of the way. That is, if you had to install 100+ of identical transformers it wouldn't take 1 year each. Even if you already had one lying around, you'd still need to assemble a team and equipment to transport and install it. So complex logistics is the issue.
> In other words, are there colors that can't be produced using light or the color wheel but still exist in the visible spectrum?The other posters are wrong. It *is* possible, but not under normal circumstances for normal humans.Most humans are trichromats, meaning that we have three different types of light sensors (called cones) in our eyes. When light comes in, these sensors are excited to different extents, as shown here: _URL_0_Your brain interprets the combination of three types of signals as color. And colors like "brown" don't have a specific wavelength of light (ever seen a brown rainbow?).Note the green and red receptors and how much they overlap. In order to perceive non-standard colors, you have to selectively disable either the green or red receptor, usually by overexposing one color so the receptors get "tired". This will enable signals to be sent that do not correspond to any wavelength of light, allowing you to experience a brand new color as your brain tries to make sense of it. Super greens and reds are possible by this method.
> Can electro magnets be not only switched ON or OFF, but can their percentage of magnetic capabilities also be controlled?Yes, you can tune the field strength by controlling the amount of current flowing through them. > What type of negative effects do magnets have on cell phones, laptops, TVs, etc?Strong, changing magnetic fields can interfere with electronic circuits. They can also mess with hard drives, magnetic strips on credit cards, etc.
What you're asking about are very distantly related birds. In that case, the answer is no. Birds are incredibly diverse, with over 10,000 living species. Distantly related birds not able to hybridize any more than a tiger and a giraffe can hybridize.However, within families you can definitely get some weird hybridization. A number of duck species hybridize with the mallard. For example, here's a report on [American black duck-mallard hybrids](_URL_1_). Several members of the [pheasant family can hybridize](_URL_2_). They're the most extreme example I can think of, because they'll readily hybridize between different genera. This isn't something unique to birds, though. There are multiple instances of this happening with crocs, like [this hybrid](_URL_0_) between a Cuban crocodile (*Crocodylus rhombifer*) and an American crocodile (*C. acutus*). And plenty of mammals hybridize.
In most cases, the moment of death would be defined by the irreversible cessation of a heartbeat. In the scenarios you mentioned:* a lethal blow to the head would cause massive intracranial hemorrhage leading to herniation of the brain, loss of spontaneous breathing, and then cardiac arrest. Herniation may also lead directly to cardiac arrest.* immersion in water leads to lack of oxygen and resulting cardiac arrest.----Patients may die by brain criteria, also called *brain death*, if there is irreversible cessation of function of the entire brain. These patients will continue to have a heartbeat for a short while, often no more than a few days, if continued on a mechanical ventilator. Brain death results in lack of automatic breathing, so patients not on a ventilator will rapidly become hypoxic and have a cardiac arrest. Either way, they can be legally and ethically dead by reason of irreversible whole-brain dysfunction before the heart stops.To give a somewhat grisly example, a person killed by rifle fire to the head would likely be dead by brain criteria immediately, since high-energy rifle rounds cause massive disruption of the skull contents, while the heart (being undamaged) may continue to beat for a short while on the order of a few minutes, gradually deteriorating from decreasing oxygen and blood volume until, starved of both, it stops.
Glaciers deposit rocks and gravel in a "terminal moraine" at their edges: we can map this and estimate the area that was covered by ice sheet.  But the thickness is a little trickier.  There are three ways to calculate the ice sheet thickness:First, we can use mathematical and computer modeling of the ancient ice sheets.  All the modern ice sheets (Greenland, Antarctica) have a particular height profile that depends on the properties of ice, so we assume the same physics applied during the last ice age.We also know the amount that sea level dropped during the last glacial maximum.  We can compare the volume of water in our simulated ice sheets against the volume of water missing from the ocean.Finally, we can identify a few mountains where the ice flowed around the mountain but didn't get over the top: that tells us how high the ice was at that location._URL_1__URL_0_
It depends on how sharp the blade is. If the edge of the blade is larger than cells (such as with any steel knife, then yes you're just separating the tissue rather than cutting cells. Blades made of glass or diamond, such as those used in [ultramicrotomy](_URL_1_) and preparation of samples of transmission electron microscopy are capable of cutting cells. A diamond blade of a microtome can slice a red blood cell into 100 slices! [Diamond blades](_URL_0_) are even capable of slicing viruses which are much much smaller than cells.Blades made of [obsidian](_URL_2_) are also amazingly sharp, producing an smooth edge 3 nanometers thick.
Geometric Mean Distance (GMD) is used when calculating the impedance of three-phase power transmission lines. Some line structures are imbalanced thus causing different inductance values on each phase. This can be mitigated by transposing the phase conductors in the middle of a line to give each the same average inductance. GMD is used to calculate the average (effective) inductance over the entire length. GMD is simply the geometric mean of the distance between each phase conductor. Edit: I removed the word "intrinsic" from "intrinsic impedance."  Intrinsic impedance is a wave impedance of an electromagnetic medium.
Receptors begin to develop within the first several weeks. However, neural pathways for many of these (pain, for example) will not exist until the third trimester, with development of the thalamus. Check out results in: **DISCOVER** (*When does a fetus feel pain?*)**JAMA** (*Fetal pain:A systematic multidisciplinary review of the evidence*)._URL_0_
Once the load (device to be powered/charged) is removed from the charger, very little power will be used.  Most power bricks have little LEDs that remain on, and there is a small amount of power dissipated in the cord/other components that stay electrified (commonly referred to as phantom power), but only a VERY small amount of power is still consumed.
Relative humidity is just the ratio of the observed specific humidity to the maximum possible specific humidity, which itself is a function of temperature.  If it's cold outside, then the maximum specific humidity is very low, and it doesn't take much water vapor at all to get near 100% RH.    Relative humidity isn't a particularly useful product; the actual water-vapor content can remain unchanged, yet the relative humidity starts swinging wildly only because the temperature is changing.  It provides very little useful information.
The closest there is to an animal that spends their entire life in the air is probably the Alpine Swift.  They have recently been found to spend upwards of 200 days in a row airborne and only land at their breeding ground.  They eat, sleep, and drink all while airborne.Nature Paper:_URL_1_But probably easier to read the Wikipedia article:_URL_0_I suppose that, theoretically, creatures like bacteria could spend longer airborne but I'm not aware of any studies done (they'd be very hard to track individually unless we find some type of bacteria that spends its whole life cycle airborne)
There are many variations of dentition (posh word for a set of teeth). Each is relevant to the evolutionary background of the animal. Similarly, there are good reasons for creatures having no teeth at all. It is all to do with what they typically use their teeth for, the structure of the tooth, and how these relate to the lifespan of the animal.Sharks have many rows of teeth - the sheer power of their jaws and the work they have to do to bite and hang on to and kill their pray means often their teeth are left behind in their food (the sheer size of the multi-directional forces mean they often extract their own teeth when hunting and eating). Humans never use this kind of force - we do not use our teeth to hunt!Rodents have teeth that are continuously erupting and being produced - this is because they are constantly wearing their teeth so much that they always need a new supply of tooth material. They retain pockets of tooth structure-producing cells that we are rid of once our teeth have developed. Humans do not typically use our teeth for wear-intensive processes except in pathological habitual grinding scenarios and other anomalies.Horses have very long teeth, that develop whilst they are juveniles and stop growing throughout adulthood, but they erupt constantly as their teeth wear. If a horses' teeth do not wear quickly enough, they grow too long for them. This is why they occasionally have their teeth filed down! Again, humans have no such need for this amount of tooth structure as our diet is more nutrient rich and less volumous than a horses (i.e. we need to do less chewing daily to get our nutrients).These are just a few examples. Then you have our teeth, which have developed into one juvenile set of 20 teeth, followed by an adult set of 32 teeth. We can only speculate what the primordial genetic advantage of this is in the primitive sense - however, how our modern lives differ from the primitive has shaped the way we get dental disease, and hence the way we practice dentistry today. Here's some points on dental history:In history, before the mass production of food was necessary to feed large aggregations of people in cities, we had a diet devoid of refined sugars and mostly consisted of fibrous foods like meat and fresh fruit/vegetables etc. This meant that tooth decay was actually a relatively rare disease. Mostly the problems people had was tooth wear (attrition).When bread started to be produced en masse, it was very gritty due the flour being ground in between 2 stones. In ancient Egypt tooth wear from this grit became a huge problem and people managed to wear their teeth down to the nerves (pulp chambers) before they could fill themselves in with dentine. This would have been very painful and the teeth would have got nasty infections pretty quickly.The discovery and introduction of refined sugars into the diet many centuries later led to us consuming a lot of bacteria-friendly foods that increased the general levels of plaque in people's mouths. These foods are also less fibrous and softer, so the plaque is not naturally sloughed off the teeth due to friction whilst you chew. This is the reason why we need to control the levels of plaque in our mouth today with brushing/flossing/rinsing.
A couple of things jumped out at me here. >  This spontaneous appearance of virtual particles doesn't violate the law, providing that the energy is paid back very quickly, and when I say quickly I mean in an unimaginably short time span.  This idea of "paying back" energy is not generally a useful one. I'm sure you're familiar with the fact that the uncertainty principle is not a limitation of our measurements, it's a fundamental property of the universe (you can say that that the universe "doesn't know" what's going on to arbitrary precision). So, the fact that energy conservation appears to be violated is better understood as that the universe "doesn't know" how to impose energy conservation to arbitrary accuracy, so you get these little "wobbles" in very localized regions in spacetime, which is what is usually stated as these things happening in a small amount of time.  >  This is called Planck Time:The time that a virtual particle exists depends on the energy of the process - it's certainly not true that all virtual particles last for exactly 1 Planck time. The only thing that's special about Planck units (Planck length, Planck time etc) is that our knowledge of physics may not apply below that kind of scale.
It's way past my bedtime, and I'd never heard of correcting spheres until a few minutes ago, so consider this all very speculative. What I gather is that the spheres are made of magnetically soft iron, which also describes the steel the ship is made out of. The notable feature of soft iron is that it greatly enhances any magnetic field that passes through it, which can affect the compass reading if it's distributed asymmetrically (if you like thinking about it this way, the Earth's magnetic field is an H field but what compasses measure is B field). The idea behind the correcting spheres is to put a big chunk of soft iron right next to the compass in such a way that when combined with the steel in the ship it looks symmetric to the compass. That means that all components of the Earth's magnetic field are strengthened the same amount, so the result points in the same direction.Sources: I started with the Wikipedia article on magnetic deviation and worked through part of [this NGA handbook](_URL_0_).Edit: I just want to add that I thought this was a really cool question. I think I'd seen correcting spheres before and never known that they even had a name, much less such a specific technical purpose. That opened up the whole field of compass adjustment, which it had never occurred to me might exist but which is actually fascinating. So, thanks for such a solid contribution to the sub.
Bacteriophages can be used to treat bacterial infections, but phage therapy hasn't really caught on. Viruses can also be used to deliver genes in gene therapy.
All sorts of neat stuff!Besides the basic corticospinal tracts (which control voluntary muscle activity) and the spinothalamic tracts and dorsal columns (which transmit sensation), there are multiple white matter tracts leading from various effectors in the body and the eyes and the ears to the brain that keep us upright.Inputs from joint-position sensors go to the cerebellum, along with inputs from the vestibular nuclei (which process balance) and some inputs from the visual system (outside the usual optic tract-LGN system). There they synapse with cerebellar nuclei and also with cerebellar cortical neurons, mostly in the vermal centerline. Outputs from that area (vestibulospinal, rubrospinal, and other tracts) go down the spinal cord and affect primarily axial musculature to make small adjustments to keep us upright.So, yes: the COM would be moving around: but there's a massive and redundant feedback loop which keeps axial musculature moving to counteract these perturbations and maintain the COM over the feet.
Two points:   Asking why with regards to evolution can often lead to rather ad hoc and pointless speculation. Especially without counter examples or convergent evolution with similar selective pressures to refer to.      The mechanism of peristalsis is old. Worms use the same principle to move around.    Basically though, peristalsis is a good way to move food around through the intestines. I wouldn't be surprised if peristalsis co-evolved with the development of intestinal tracts (but my knowledge of zoology and phylogeny can not back up that supposition) * edit, there are alternative systems to peristalsis used in organisms such as mussels.
Targeting is one of the biggest problems in stem cell research today. If you come up with a solution for it, you'll be a very rich man (or you'll make somebody very rich).We're fairly accomplished at keeping stem cells alive, and we've got a good amount of data on how to differentiate cells into nearly every kind of cell in the body. However, this hasn't really translated into many practical uses, since there aren't a lot of techniques more advanced than "inject them somewhere nearby and hope like crazy it works." I know of a two methods people are working on for this. The first is to immobilize the cells in some kind of gel. The idea is to give cells some time to secrete matrix around themselves, and to expose them to cytokines from neighboring cells for longer to help with differentiation.  The second method is to find a peptide or other drug that binds to the area you want cells to go to. You attach this tag to your stem cells, and hope it glues them in place long enough to settle down.As for the blood-brain barrier, I'd be surprised if active transport could drag an entire cell through it. Active transport is used more for drugs. Eukaryotic cells are bigger, and harder to get across.
It would depend largely on what portion of the insect was damaged, assuming it didn't lose enough hemolymph to die outright. For instance, if it suffered a substantial brain injury - one that inhibits the prothoracic glands, the corpus cardiacum, etc. - then even if it makes it to the pupal stage, the insect will not be able to produce the necessary hormones (prothoracicotropic hormone, ecdysteroids, juvenile hormone) to complete development and become a fully functional adult. If the larva suffers an injury to the muscles that would eventually become the mouth region, it's possible that the the mouthparts and associated glands would not develop properly, preventing the adult from actually exiting the pupal case.That being said, some muscles are destroyed during metamorphosis and not replaced. However, they would provide both energy and cellular materials for other developmental processes.
>  Is there even a surface?There is no real surface >  Could a probe land on it and travel on it?It could not land on it but it could fly through it.  The "visual" surface of saturn for instance is less dense and lower force of gravity than the surface of the earth.  There wouldn't be any oxygen to burn though so your flight would be short. >  Is it the same gas all the way through the planet?No.  As you go down you will run into higher concentrations of denser gases.  They probably have a solid core made of the same kind of rocky stuff earth is made out of.  However there is still no surface.  There would be a gradual transition from gas to liquid to solidy stuff. >  Why are they gas and not rocky like the inner planets in our solar system?The sun blew all the gas away from the inner solar system.  I use gas in the astronomical sense meaning Hydrogen and helium.  Since most of the solar system is made of hydrogen and most of the rest is helium that adds up to a lot of stuff.Earth for instance being the largest rocky planet still does not have enough mass to hold onto hydrogen and helium.  They float to the top of the atmosphere where they are carried off by the solar winds.  When you get to Jupiter however the sun is not strong enough to blow the gas away and it condensed into Jupiter. >  Add anything else that's interesting!I'm not really an expert so this is pretty much it.  If you're interested in this topic however I would really suggest checking out [yale's open course "Frontiers and Controversies in Astrophysics"](_URL_0_).  It's a course designed for non science students split into three parts: Extrasolar planets, Black holes, Dark matter/energy.  The first 8 lectures are on Extrasolar planets of which a few of them are all about planetary system formation and why our solar system is the way it is.  Basically he will answer your questions better than anyone here could.
The second law of thermodynamics states that entropy always increases (things become more disordered) over time for an **isolated system**. One might conclude from this statement that any process where entropy increases is moving forward in time and any process where entropy decreases is moving backwards in time.  & #x200B;However, what should be of no surprise is that we are able to make systems more ordered with some external input back into the system without violating the laws of physics. Suppose I'm at the pub and I'm playing pool with my mate. A few shots into the game, he tells me he's found a way to kick the table such that sometimes all the balls end up back in their original triangle shape. He then goes and demonstrates this and aside from being totally stunned, I'd agree that was rather impressive - certainly deserving of a publication. But I probably wouldn't conclude he had invented a kick that made us travel back in time to before we started the game. In all fairness neither do the authors in their original paper. & #x200B;Fingers should really be pointed at Moscow Institute of Physics and Technology for making a press release entitled "Physicists reverse time using quantum computer". Still the original research is excellent and has generated a large PR buzz, so perhaps they did the right thing. & #x200B;For the scientifically minded I encourage everyone to read the original paper [_URL_0_](_URL_0_)
If your old wives' tale involves ultracentrifugation of a semen sample to separate sperm by the mass difference between the X and Y chromosomes, then there might be something to it.EDIT: That's the way it's often done for the livestock industry and perhaps some humans - that or sorting the cells with a fluorescent dye attached to an antibody that specifically binds one sex chromosome or the other. If there were a simpler way, you'd better believe they'd be all over that.
Read the video description.  Its not actually stopping it, just vibrations synced with the camera to make it *appear* to stay still.
The *right* way to think about compression is in terms of set theory.  Imagine a set of "Things" as 'people in the world'If we assign each 'person' a positive integer between 0 and 7 billion.Now, the number of bits required to represent a particular person is log(7e10)=33, so 33 bits.So the number of bits necessary is 33.  Suppose we have some 'method' to 'compress' that data.  Suppose I claim that I can represent a particular person from all others in only 10 bits.  Since 10 bits can only distinguish between 1000 different possible numbers, by mathematical fact I must be in some way making it impossible to distinguish between more than 1000 people, therefore making my 'compression' impossible.However, I can get around this.  What if I say "Well, yes, a person is 33 bits of data (because of how many unique persons there are).  However, my application need only consider people who are citizens of my small town.  My small town only has 16 thousand people, which means that we can represent each person in my town with a DIFFERENT number such that it only goes from 0 to 16000.  This only takes 14 bits".Then my 'compression' algorithm to convert from a 33-bit person to a 14-bit person can work by simply identifying the person, making sure that they belong to my small town (if not error 'incompressible'), then figuring out their small town id instead....'compressing' the data.As long as you ALREADY know in advance that your 'target' data possible set is a much much smaller subset of items than your 'source' data set, then it's theoretically possible to create a mapping function that 'compresses' by representing an item from your source data set by its ID in the target data set.For example, the reason your mersenne prime example works is that if you represent a mersenne prime by its index in the set of all integers, then the index will be much larger because the number of integers is much much larger than the number of mersenne primes.   However, if you represent the prime by it index in the set of mersenne primes, then you can simply represent it as N where P=2^n -1 ALL compression basically works this way.   Run length encoding compresses from the set of all binary strings to the set of binary strings where there are repeating patterns (smaller).  JPEG encoding compresses from the set of all possible pixel maps to the set of pixel maps with low-frequency changes and smooth colors (much smaller and maps to the real world data better).  Huffman coding compresses from the set of all binary strings to the set of binary strings with uneven frequency distributions in the characters.Compression mathematically CANNOT work if the number of things you need to represent is the same size as the represntation bits for that set.  It only works by mapping a source set to the target subset.
I've read articles both for and against this thesis. Some articles compare energy efficiency between humans and chimps and claim that humans use only a quarter of the calories that chimps do for locomotion. But the same studies show that chimp locomotion is highly variable, and the same individual chimp can vary tremendously in energy efficiency depending on gait. And different chimpanzees can vary significantly too, calling into question the "one quarter energy used" figure.Other studies which use measures such as oxygen consumed show that humans are about 25% more efficient than chimpanzees at locomotion, but **only** when walking. They are not more efficient when running.Some people point to studies like this and go "aha, that's why we're persistence hunters, we don't chase them down because we aren't great runners, but we can outwalk any other species under the sun".But other scientists say this is jumping to conclusions because of the inherent variability in locomotion. 25% more efficient may sound like a lot, but it still falls [within the 95% prediction interval](_URL_0_) for mammals as a whole.So perhaps it's something else, or maybe a combination of things. Our lack of body fur and upright postures make us particularly good at evaporative cooling, so maybe we were persistence hunters because we could go for a long time without overheating in the hot grasslands of Africa. Or maybe it's because we're not very powerful, we don't have huge sharp teeth and powerful jaws, we don't have claws. Maybe catching up quickly with your large prey isn't the best option for us, maybe it's safer to exhaust your prey before you catch up and smash its skull with a large rock.
I believe the phenomenon your friend is referring to is [genetic dominance](_URL_0_). The genetics of skin color, however, are fairly complex (i.e. involve many genes), and to my knowledge, are not yet fully understood, so I'm not sure where the specific figure of 8 generations comes from.
When trying to understand relativity, remember that *where you are* isn't as important as *how you're moving*, or, more accurately, how everything you're observing is moving.  [Here's a popular illustration of relative simultaneity](_URL_2_) involving blinking lights (or, in this case, lightning strikes) on a train.To get a deeper understanding of this and other elements of relativity, you should familiarize yourself with [space-time diagrams](_URL_0_).  In such a diagram, space (ie. position) is on the horizontal axis and time is on the vertical axis.  So something sitting still follows a vertical path, and something moving follows a diagonal path.  The bigger the angle from vertical, the faster the thing is moving, up to an angle of 45^o which corresponds to the speed of light.Points on these diagrams are called *events*.  They describe one particular place and time.  Higher events happen later than lower ones.  You can think of horizontal lines as "slices of simultaneity."  Every event that falls on the same horizontal line happens at the same time.  Now notice the blue axes on the [diagram](_URL_1_) on the Wikipedia page.  These represent a moving reference frame (relative to the black axes).  Notice that not only is the time axis angled (representing a nonzero velocity), but the space axis is also angled.  This shows that this moving observer will have different "slices of simultaneity," so they will see different events as simultaneous.Edit:  So to answer your question, no, there is no universal "now."  Each observer has his or her own "now," although two observers moving at the same velocity (same speed *and* direction) will have the same "now" since they will be in the same *reference frame.*
When a star is rotating, light from the side of the star approaching the observer is blue-shifted, and light from the other side is red-shifted, due to the Doppler effect. If the planet is orbiting the same direction as the star's rotation, it will block some of the blue-shifted light first; otherwise, it blocks the red shifted light first. With sensitive spectroscopes astronomers can (in some cases at least) work out which way the planet is orbiting.
Yes and no. One of the essential processes of life is assimilation, which is where the body takes in organic compounds, such as protein, and then breaks these organic materials down into more useable materials. For example, from proteins come amino acids. These amino acids, the building blocks of proteins, are then synthesised by the body's cells into more useful proteins that are currently needed. For example, a steak you eat may contain lots of actin and myosin (structural and motor proteins), but you body may need more collagen. The body breaks down the proteins in your steak, and uses the amino acids obtained from this process to build new collagen. The key to this is that the body doesn't assimilate non-organic matter very much (with exceptions, such as the inclusion of calcium carbonate in the bone structure) but can use organic molecules (made of atoms...) to manufacture more complex, useful structures. Hope this answers it for you.EDIT: changed 'hopw' into 'hope'. Silly me.ANOTHER EDIT: See humaniteer's comment for more specific information about protein synthesis.
> is there something about viruses that deadly that makes them hard to pass on?There's no evolutionary advantage in spreading rapidly and obliterating all of your potential hosts.
It is all normal evaporation. In warmer weather, the air is able to absorb all of the evaporating moisture. Cold air holds much less moisture so the evaporated pool water condenses into a cloud of tiny droplets until it spreads out enough to no longer be visible. Look up "Dewpoint" and "Relative Humidity" for further information.
Dark matter is a somewhat ambiguous name given to a set of astronomical observations that physical theories not including dark matter don't explain.  These observations tend to suggest the presence of mass that we can't see - hence the choice of "dark matter".For example, if you measure the velocity of a bunch of stars moving around the center of a galaxy, and then plot those velocities as a function of distance from the center, you get what's called a [galaxy rotation curve](_URL_1_).  The velocities of the stars are a function of how much mass is contained in the galaxy.  We can measure how much mass is in the galaxy based on the its luminosity and by combining that with what we know about galactic astrophysics.  However, the velocities of the stars we actually measure are greater than what is predicted by the mass of the galaxy, which implies some extra mass around the outside that we don't see.  This is the "dark matter".They tend to look something like [this](_URL_0_).
You seem to be asking about manufacturing tolerances within the pharmaceutical industry. There are very strict and equally complicated regulations on this sort of thing. It's not as simple as +/- 2% or something like that. In general, in the U.S. (there are similar rules in Europe but I'm not familiar enough with them to comment), the FDA requires that pharma companies follow "Good Manufacturing Practices" and have chemistry and manufacturing controls in place to ensure compliance.  If you want a survey of the relevant regulations, they are on the [FDA's website](_URL_0_).
A photon can only interact with an electron when they're at the same position (physicists say that electromagnetism is "local"). So you have a combined probability distribution for the photon, and *this* electron, and *that* electron, etc. etc. In the combined paths of the photon and *this* electron where they meet somewhere, there's some probability that the electron absorbs the photon - is excited. So altogether that means there's some probability that it excites *this* electron and some probability that it excites *that* electron, etc. etc. (Make a thick enough wall of atoms and it'll almost certainly excite *some* electron).So there's some probability that all of these electrons have been excited. And if the photon travels along all possible paths, then all of the electrons have been excited. With some probability.If you measure the atoms, then you will find that, with only one photon emitted, only one atom can be excited. So you will find which electron has been excited, with some probability. But which one this was, was not "decided" before you measured. (Depending on how you interpret the rules of quantum mechanics, this is either "wavefunction collapse", where the universe "decides" which electron has been emitted because you have measured it, or "decoherence", where your measuring device exists as a probability wave in states that have measured several different atoms, but due to thermal effects the different parts of this wave can't interfere anymore.)
Because there's a piece that holds the transparent screen element (which is what you actually see on the screen) that has a rectangular cutout, which both holds the screen element and blocks out the extraneous light, forming a rectangular beam.If you look at old slides like those used on slide projectors, you'll see the slide has a rectangular piece of cardboard or plastic around it that performs the same function.
Hopefully an actual scientist will chime in here, but broadly the drop in oestrogen signals to the ovaries that the woman is not pregnant to get them to release a new egg. The combined pill (containing oestrogen) tricks a woman's ovaries into behaving as if she's already pregnant so that no egg is released.
Radiolab is an amazing one.  All the podcasts are online at _URL_0_.  They talk about many different interesting science topics, but what's great about the show is that they (1) talk about things that actually have something to do with life, (2) cover the subject in-depth and thoroughly, and (3) explain it very non-technically even though they directly interview experts in the field and so on.  If you are looking for a starting point, my favorite one is probably Words (which is about what language really is and how it affects the brain).
Although I was not yet alive in those times, I do enjoy reading old physics papers from time to time. It is quite well-known that the scientific community was largely divided in the early when it came to quantum mechanics. Famously, Einstein and Bohr became the faces of the two sides of this divide, but both had some prominent people on their side. For Einstein de Broglie and Schrödinger were among his more notable "allies", whereas Bohr's entourage contained people such as Heisenberg, Pauli, Born, et cetera. The latter group was actually far from happy with the EPR paper. There is a reasonably well-know letter which Pauli sent to Heisenberg to complain about this work. He literally states that whenever Einstein voices views on quantum mechanics, it ends up being a catastrophe. In his letter, he urged Heisenberg to respond to the EPR paper in order to avoid confusion for the American readership. However, Bohr was the one who published a [response](_URL_0_) to the EPR paper. It is a very interesting paper, in the sense that it really discusses the concept of realism.It is worth remembering that these people where very dominant figures in science up until the 60's when Bell's work came along. I guess that it is hard to estimate the extent of this divide. It is, however, worth noting that entanglement was certainly not a big research topic in this period. As to the breakthrough step, I am tempted to say that it was Bell's work. There is a serious amount of work on the probabilistic structure of quantum theory which was done in the 70's. Quantum correlations, as captured by violations Bell's inequality are a crucial element of this work. Of course the experiments were a necessary, but I doubt that many people who were active in the field were surprised by the outcomes.
More of a risk. What's in yours are strains of bacteria that your body has already had in it, probably for quite some time, and your immune system is used to keeping them under control. Somebody else's will probably contain at least a few different bacterial strains to yours. Touching their poo might increase the chance you get infected with this different strain (I say might, because if you wash your hands thoroughly afterwards, and haven't wiped those bacteria anywhere else for safe-keeping in the meantime, you should be OK). Your body may not already have the recipe for antibodies (i.e. immunity) against that strain, and respond only slowly to it, allowing the bacteria to multiply enough and make you sick before your immune system finally gets ahead of it. How this relates to a disabled arm and prophylactics, though, you'll have to explain. If it's gross, please leave me ignorant.
You are correct that in general, the surface North Atlantic is saltier than the South Pacific.  However the Gulf of Maine is considerably fresher due to all the rivers which flow into it and the fact that it is isolated from the open ocean by Georges Bank.  The salinity level in the Gulf of Maine is about 33 parts per thousand while most of the North Atlantic is ~ 35.5 parts per thousand.
"The seeds of Capsicum plants are dispersed predominantly by birds: in birds, the TRPV1 channel does not respond to capsaicin or related chemicals in birds (avian vs mammalian TRPV1 show functional diversity and selective sensitivity). This is advantageous to the plant, as chili pepper seeds consumed by birds pass through the digestive tract and can germinate later, whereas mammals have molar teeth which destroy such seeds and prevent them from germinating. Thus, natural selection may have led to increasing capsaicin production because it makes the plant less likely to be eaten by animals that do not help it reproduce."Source: Tewksbury, J. J.; Nabhan, G. P. (2001). "Seed dispersal. Directed deterrence by capsaicin in chilies". Nature 412 (6845): 403–404.
Not a scientist, but i found [this](_URL_0_) - seems like you could make do with a laser, but the following electric arc would probably be very straight, and not all pretty and lightning-like.
The collision is about the pressure that the gas clouds exert on each other. If you try to push two fluids ('fluid' in physics is a broad term encompassing any material that can flow, including gases and plasmas) into each other, the pressure between them will increase.Certainly, the collision between gas clouds is radically different from the way billiard balls collide. There won't be any particular moment when we announce "Look! They've collided!", it's a process that occurs over millions of years. As the gas cloud runs into the gas of the Milky Way disk, that pressure will compress the gas, which will cause dense clumps to form. These clumps will eventually grow into stars.Worth noting that gravitational forces also do play a role in triggering star formation during merger and close encounter processes. Because the nearer part of an object gets pulled more strongly than the farther part, we get what are known as [tidal forces](_URL_0_), which cause a cloud to deform its shape. Essentially, this acts to stir up the gas and disrupt its relatively quiescent state, facilitating the formation of those dense clumps that turn into stars.
It's the change in temperature, not the temperature itself, that causes this to happen.  So water the same temperature as the glass won't cause it to break, but water of a different temperature will.  The water raises or lowers the temperature of the glass it encounters, causing it to expand or contract relative to the rest of the object.  Because glass is brittle and not very elastic, this can cause it to break.
If you're talking about simulations of large-scale structure, most of them don't even simulate anything significantly smaller than a galaxy, and sometimes not even galaxies. For the most part they're not interested in the relatively small-scale processes that occur within galaxies, as the main aim of these simulations is to better understand how large-scale structure (meaning galaxy clusters, superclusters, and cosmic walls  &  filaments) forms and evolves. The evolution of a single star, or even the evolution of an entire galaxy, has very very little effect on the mass distribution of the universe.
No.The easiest way to think about this is with the concept of "cardiac reserve". This is basically how much more you can stress out your cardiovascular system. Think of it like manna in a video game.Take a healthy adult (or a level 8 wizard). When going through daily activities, their heart is working at 30%^1 capacity to keep them functional. That person can sprint up the stairs, go play a game of basketball, or whatever and get that number up to 60^1 or 70%^1. This is that person using up some of their reserve, but they are OK. The blue bar is not that far down, and it will fill back up quickly.Take a nonhealthy adult (or a cursed level 2 wizard). Say you've got a sedentary person that eats too much; has a touch of atheroscleorisis and about 50 extra pounds. This person's heart has to work harder to pump blood through those messed up arteries and all that extra mass. His heart is operating at 70%^1 capacity when walking around. A sprint up the stairs will wind him, and a brief game of basketball will seriously challenge his cardiac reserve, pushing him to the limit. Their blue bar is near zero, and if any more orcs show up he is screwed.Going up Everest is a cardiovascular challenge (for a variety of reasons, only one of which is the altitude), and it will eat into your cardiac reserve. If your baseline cardiovascular workload is challenged due to high blood pressure (or whatever), this puts you dangerously close to (or past) your limit. It's a boss fight. You don't take a cursed level 2 wizard into a boss fight and expect good things to happen.Going to a lower elevation (or getting extra oxygen) will reduce the demand placed on your cardiovascular system. It will decrease the workload a bit; this is why they put people on oxygen in the hospital. The analogy here would be getting a buff on your manna; it doesn't make the spells any cheaper, but it does make it so you can cast more of them.^1 This number is 100% made up because I didn't want to Google the real value.
This is a great question, unfortunately "coupled oscillators" typically takes up an entire chapter in advanced classical mechanics textbooks. To give a complete description in a Reddit comment is a daunting feat.The key point is that sufficiently close to **any** stable equilibrium, a mechanical system will undergo [simple harmonic motion](_URL_1_).In simple harmonic motion, the restoring forces are linear in the displacements from equilibrium (**F** = -k**x**, Hooke's law). So you essentially turn your system of differential equations governing your system into a *linear* system, which can be solved exactly (whereas the more general motion will have a more complicated, nonlinear, set of differential equations which may not be solvable analytically).So you write your system of linear differential equations as a matrix equation, then following the standard procedure in linear algebra, you find the eigenvalues and eigenvectors of the appropriate matrix.These are your [normal modes](_URL_2_). The eigenvalues are the frequencies of the normal modes and the eigenvectors are the normal modes themselves.The normal modes form a complete basis, so any general motion of your system (in the small oscillation approximation) can be expanded in normal modes.You can even define [normal coordinates](_URL_0_) which uncouple your system of differential equations. Then instead of working with a system of coupled oscillators, you can treat it as a system of uncoupled oscillators (just remember that you made a coordinate change when you interpret your results).
According to what I read, you're largely right. From what I read in *The Emperor of All Maladies* by Siddhartha Muhkerjee, most people before the modern era, from ancient Egyptians, Greeks, up to the nineteenth century, were puzzled by it. There was an Egyptian medical treatise that listed several cases and their treatments; the case that seemed to describe cancer had no treatment listed. Furthermore, people just didn't see enough cases of cancers because people during the time didn't live long enough for the mechanisms that cause cancer (e.g., mutations in genes, viruses, etc.) to get to the point that they became symptomatic.
The idea is not and never was viable. It was always a pet theory of the marine biologist who came up with the idea in the 1930s and the [writer](_URL_2_) (without a scientific background) who popularized the idea in the 1980s onward. The hypothesis has several large gaping holes in its logic as well as several factual errors about human and aquatic mammal biology and behavior. [This site](_URL_1_) has long been a clearinghouse of information. It has a [page devoted](_URL_0_) to quickly debunking specific claims of the AAH, such as supposed similarities in skin, sweat glands, and subcutaneous fat shared by humans and aquatic mammals.
EPA states that tap water has no more than 500 ppm of impurities. Say, for sake of conservatism, you start with not lemonade but pure, dehydrated, lemonade concentrate. So that's 1,000,000 ppm "impure". That gives us the equation: 1,000,000 * (1/2)^x = 500. Solve for x and we get 11. So yes! After doing this 11 times you will be unequivocally left with just water.
A while back I was trying to approximate the weight of a skyhook. I assumed the acceleration varied uniformly along the tether from its anchor point to a maximum where it touched the payload. The material had constant strength so the cross section at any point was simply determined by the force needed to support the weight of the tether and the payload below that point. The curve turns out to be the error function. The thickness of the line starts out very close to zero, grows quickly in the middle then has a big thick end near the anchor. Error functions show up in lots of things. In case anyone's wondering, a .13 earth radii long Spectra tether catching a Mach 3 payload and moving it to near mach 15 weighs about 7000 tons.
No. Mars' magnetic field is around ~~1500~~ 15,800-19,900 nanotesla (thanks /u/robolith, I gave the orbital value, useful for some of the later solar wind discussion but not for the magnet discussion!). That's within the range that the earth's magnetic field fluxuates in a solar storm, which isn't exactly something that we need to adjust our compasses for. Even if you were to have an extremely sensitive magnet that field would almost certainly be overwhelmed by magnetic minerals in the Martian crust such as magnetite, hematite, and pyrrhotite. Even those are mainly responsible for localized anomalies in the northern portion of the southern hemisphere, so you couldn't reliably count on them to point in a specific direction if you were close enough to swing a magnetic needle.Essentially the reason Mars is a dead planet now is because it doesn't have a magnetic field shielding it from solar winds. Without an active dynamo (spinning core, roughly) creating enough energy to shield the planet, solar winds blasted away volatiles on the surface and, for this specific question, mean that we can't use a compass to navigate on Mars.----Dunlop, D. J. (2005). Magnetic minerals in the Martian crust. Journal of Geophysical Research, 110(E12). doi:10.1029/2005je002404 Some good more basic information can be found [here](_URL_0_).
The thing is, blood isn't entirely water - it's 55% blood plasma, which of itself is 92% water by volume.The rest of it is a myriad of other compounds and biological materials - electrolytes, dissipated proteins, glucose, hormones, enzymes, red blood cells, white blood cells, etc. Proteins themselves consist of both hydrophobic and hydrophilic-oriented amino acids, and if exposed to the air or other adverse conditions, can denature and come apart, exposing these groups.Proteins will partially or completely unfold as necessary to minimize surface-free energy, and can bind quite well to surfaces, requiring some extra effort to get them off. As red blood cells burst, and as the other proteins get exposed to the knife's surface, it's not likely that the hydrophobic coating will prevent *all* of the genetic material from binding.As an example, serum albumin, the most common protein present in blood, actually has 11 binding domains for hydrophobic compounds, so it could theoretically bind *better* to your knife's surface than if it weren't treated, depending on which methodology you used to make it hydrophobic.
The outcomes for any one area, as I understand, are notoriously difficult to predict due to the vastly interconnected nature of planet wide climate.In general, I doubt you'd find all of the Earth becoming like a single climate. There is too much variation. Additionally, I don't think there would be areas that are completely uninhabitable, though some deserts may expand.What you will see are large upticks in extreme weather, sea level rise, and overall unpredictable changes. This would lead to more hurricanes, more damage from storms, local variations in climate due to shifts in rainfall, as some areas gain it and some lose it, longer and deeper droughts, which could lead to fires, etc.It's hard to predict these things locally (except maybe sea level rise effects), but it's fairly straightforward to answer what happens to a system when you add energy. I'd like to hear from someone who specializes in this field, as it's just an area of interest of mine and not something that I'm really qualified to talk about.
I suspect that your idea of what "all of what mathematics" is is rather narrower than what a professional mathematician thinks of when she thinks of all of mathematics. Most of the math that one encounters in high school and even at the early undergraduate level is computational. You long divide, factor polynomials, simplify radicals, solve triangles, compute derivatives, and so on. These are all things that Wolfram Alpha can do, and Wolfram Alpha can do it a lot faster than you can. That might lead you to the belief that Wolfram Alpha could put mathematicians out of a job—if it can do all of these things faster and more reliably than mathematicians can, then what are mathematicians left to do?The truth is that the things that I listed above and other things that Wolfram Alpha can do are things that most mathematicians would hardly even consider "doing mathematics", in the same way that, say, high intensity interval training isn't what most professional basketball players would consider "playing basketball". Hear me out. A professional basketball player needs to be able to run fast and jump high. This is achieved through high intensity interval training. It's something that most basketball players ought to do, and basketball players in high school ought to do a lot of it if they want to become athletic enough to play in college or professionally. High intensity interval training is something that a basketball player must do, but it is not playing basketball. Completing various computational tasks is something that a mathematician must do, but it is not doing mathematics. And it is indeed done better by computers in the same way that moving fast is done better by cars. But that doesn't mean that a car could replace a professional basketball player.Whether or not all of mathematics is ultimately reducible to logic isn't answered by this question. The computations that Wolfram Alpha can do aren't things that professional mathematicians care about. Wolfram Alpha works on problems that are already solved: it can solve certain kinds of partial differential equations for you, but that is only because mathematicians figured out how to tell a computer how to solve certain kinds of partial differential equations.
Relativistic effects aside, let's live a little and consider we are in a Newtonian universe (linear approximation of reality)100rpm is the angular velocityrpm = 2*pi radians /min = 2*pi radians /(60s) = pi radians /(30s)100rpm = 100 * pi radians /(30s)speed of light is 299,792,458 m/srelevant angular velocity formula w * r = v100 * pi radians /(30s) * r = 299,792,458 m/ssolve for rr = 28,628kmI hope I did that right. But in the future a better place to ask this would probably be r/theydidthemath
This page has a lot on the general concepts;- _URL_1_And here is something specific to the evolution of the penis but mainly as it pertains to the shape;- _URL_2_This is interesting though and shows the penis has been around for a very long time.- _URL_3_"Sexual reproduction came before sexual organs. It came in the form of single celled organisms that have both a diploid state (where all chromosomes are paired) and a haploid state (where the chromosome pairs are separated, so each cell has half the full number of chromosomes). For example, amoebas are normally diploid, but can form small haploid cells ... called spores ... that can travel and combine with other spores to produce new diploid individuals (fertilization). That's basic sexual reproduction.The next step is in the slow specialization of two kinds of haploid cells. Some get smaller and are specialized for mass-production, and for lightness (so they can be carried farther by air or water) ... while others get larger as they contain all the nutrients needed to start a new individual after fertilization. The smaller cells we call "male gametes", and the larger ones we call "female gametes."The next step are organs that specialize in either mass-producing and distributing male gametes, or specialize in producing female gametes and providing an environment for growth after fertilization (e.g eggs in the case of animals or seeds in the case of plants).And finally comes the specialization of individuals to have only one kind of sexual organ or the other, rather than all individuals having both (the way most flowering plants are).Male and female organs will continue to get more and more differentiated from each other, but will always work together. That's because those individuals of any generation that do *not* work well with the sexual organs of the opposite sex, don't reproduce, and therefore those genes don't last long. But other than that ... any slight alteration in the sex organs of either sex that makes it a little better at doing what it does best (e.g. the way that placental mammals slowly kept the egg internally for longer and longer until the egg is never laid outside the body, but becomes a placenta ... and the young "hatch" directly from the mother)"- _URL_0_
You cant. But the odds are pretty good for a planet to last a billion years or sk. We can tell what stage the star is at in its lifecycle. But yeah...especially if it's taking you thousands of years to get there the planet may have been destroyed or chucked out of its orbit (especially in a binary star system)
Sound is generally measured in terms of power per unit area (intensity) or pressure (force/area) rather than energy released by an event. Your question is a bit vague and difficult to answer directly but I'll go through a related calculation which should give you some idea.[This website](_URL_1_) says that a lawnmower measured 3 feet away is around 107 dB. Decibels are a logarithmic unit comparing two things... in this case it's comparing the pressure of the sound to the 20 uPa reference. [You can read this page](_URL_0_) for more information on the unit, or just trust me that 107 = 20\*log10(pressure/20 uPa) gives a sound pressure of 4.5 Pa and a sound intensity of 0.05 watts/m^(2). 3 feet is about one meter, and the surface area that this power is spread over is 4\*pi\*(1^2) = ~12.5 m^2. Multiply intensity by area and you get 0.63 watts.Lawnmowers typically have engines producing a few horsepower, which I'll call 3000 watts... so 0.02% of the power goes toward producing sound. This will obviously vary by what's producing the sound, but unless something is specifically designed to be noisy, the answer to your question is "not much".
The closest thing you could get to a plasma gun would be a plasma torch or plasma cutter, which creates a jet that's usually a couple inches long. You couldn't make something like the sci-fi weapon where you shoot a "bullet" of plasma a very long distance. Creating a plasma requires either enough heat or the right electric fields to ionize a gas. If you were to try to shoot a ball of plasma, the gas could quickly cool and dissipate.
One common approach is to "knock out" or "silence" the gene and then observe the effect on the phenotypes.Another method, which is less reliable, is to infer the function of a gene from other genes that have similar sequences/structures (homologs) and that you know the function of already. you can also infer a gene's fucntion based on genes nearby in the genome (if that region is associated with a particular pathway for instance). These last two methods can be done by BLAST searches of a gene sequence.
If the infection is viral, it has the potential to do a wide range of damage to various parts of the body. Viral respiratory infections for example can start attacking the throat, and then move down into the lungs and cause a cough. The same virus being able to cause multiple symptoms is the reason different people have different experiences while sick from the same thing.
LED displays are commonly multiplexed. This means that it is not on continuously, but is actually flickering in a pattern (usually line by line or something similar). If humming causes your eyes to vibrate at a frequency that is close to a multiple of the display flicker rate, then aliasing occurs. Aliasing is the same phenomenon that causes car wheels or propellers to sometimes look weird in video. Basically, you are seeing a beat pattern between the display refresh/flicker and the vibration of your eyes.
Your brain definitely processes information while you are asleep. Primarily to keep you from danger. Examples, loud noises (including alarm clocks), hot or cold temp changes, dampness, pain, etc will all trigger responses from your body and in many cases make you do something to adjust, be it roll over or wake you up.  Some of these items can impact what you are dreaming about as well, making me want to believe it is actually registering as more than a simple reflexive action against stimuli.  But if you're question is more along the lines of could you listen to audiobooks while asleep and retain the information without ever hearing it while awake, I'm more doubtful of that
We are used to seeing smoke rise up, because it is carried by convection currents. In microgravity, there would still be air currents but no set direction for the smoke to go. If the air is very still it might make a spherical cloud around the source, just like [flames on the  ISS](_URL_0_).
If you are an astronaut, in a space suit, firing a gun, then yes - you will hear something as sound will be transmitted through your glove into the suit. It wont sound anything like a normal gun firing, as most of that noise is generated by the shockwave of the bullet going through the air.The astronaut floating a few feet away will hear nothing, unless the bullet hits them of course
The emission in both comes from ultrarelativistic jets (jets with Lorentz factor >  > 1) which are moving towards us so that their radiation is boosted to very high frequencies/energies, but they are in different systems and last for different times.Blazars are jets coming from a supermassive black holes at the center of galaxies that are continuously accreting matter, and they are quasi-stable objects that can radiate for long periods of time.GRBs are short, catastrophic events lasting from 0.2-2000 seconds that result from the collapse of a massive star or the collision of a neutron star with another neutron star or a black hole.
theoretically yes.just like you can see the blast wave in an explosion you would be able to see the "blast waves" of the sound compression. The issue is that in order to see the wave the force of the wave would be similar to an explosion. obviously no such speaker exists; however you could create a series of explosive packets that would explode in a certain rhythm to create a beat. after all what is music but a collection of sounds arranged to be pleasing to the ears. tl:dr yes but the force of each beat would be the same as an explosion
the best time to do it would be when the moon was black, no sunlight on it.  But the dispersion of light from the moon (or any object) is dictated by the r^2 rule.  As you double the distance from an object, you receive 1/4 the light.  I grabbed some numbers to get an estimate of the power required to generate a barely visible dot on the moon:3.839*10^26 W * 37 / ((100^0.2)^6.5) * (385000km)^2 / (25 light years)^23.839*10^26 W : 1 solar luminosity37: the solar luminosity of vega (which has apparent brightness of 0)(100^0.2)^6.5): the ratio of vega's apparant luminosity to that of a barely visible star in perfect conditions 385000km : distance to the moon25 LY: distance to vegaResult: 95 MegaWattsSo presumably a 95 MW perfectly focused laser  on a black moon in perfect conditions would show a barely visible dot.Things I didnt take into account:-stars emit light in a sphere (all directions, the moon reflects in a non-uniform semi-sphere) (this would lower the result)-The moon is not a prefect reflector (this would raise the result)
The plumes recently reported on Europa by NASA offer a golden opportunity for investigations based on this notion. Plume around Enceladus were identified and examined by Cassini about 3 years ago, and the presence of salt was confirmed. Even more interesting: hydrothermal silica was identified, a litteral "smoking" gun for the existance of the most plausible place for life to exist within an ice moon (hydrothermal vents)! ([source](_URL_0_)).This opens the door on planning a mission *specifically* designed to look at material ejected by Europan plumes. Hydrothermal precipitates and their composition would be highly significant, but one could not rule out the detection of organic molecules (en lieu of frozen fish).
> I was told it would rain (with 100% chance of rain) from 10pm Tuesday-4pm Wednesday.From my interpretation this means that there is a x% chance to be 1mm of rain at some location within the forecast location range over that time period.
Temperature will have two main effects, both related to the density or air decreasing with increasing temperature.First, air density affects the aerodynamics of how the plane flies.  Less dense air means that the plane will have to fly faster to produce the same lift but also that there will be less drag at a given speed.  Those effects cancel to some extent but there will still be a net increase or decrease depending on the exact design of the airplane.Second, air density affects engine performance because you get more or less oxygen in the same volume of air.  Colder/more dense air increases the engine's maximum power output but how it affects efficiency at a given power level again depends on the exact design of the engine.So the answer to your question is that it depends on many details of the design of the airplane and engine.  Your best bet would probably be to research flight performance characteristics for specific aircraft.  If there is data for different altitudes that might give some insight because air density also changes with altitude.
> Assuming some kind of destructive ecological genie were to appear and grant me a wish of one species to wipe off the planet, what reasons should I take into account for not choosing mosquitoes? How severely would such an extinction negatively impact eco-systems? Would there be any other repercussions?Mosquitos are a vital species in the ecosystems they inhabit, at least from a biocentric perspective. The malaria parasite has a number of dead end hosts. If an ecosystem has enough non-human vertebrates, malaria can not become endemic in a region, because the malaria parasite is too likely to end up in a species in which it can not replicate itself. [If an ecosystem has a human population density below 5 people per km and enough non-human vertebrates, the malaria parasite can not establish itself there.](_URL_0_) This may not be particularly great news for any humans who wish for the human population to grow at the cost of their local ecosystem, but for the non-human species who inhabit these regions where malaria is endemic, it is great news.Now, more importantly, if we know that human population density is restrained by the malaria parasite, we could expect a similar phenomenon to occur in other species. There are four different Plasmodium species that are known to infect rodents. One of these is Plasmodium Berghei. The mosquito [Anopheles Dureni](_URL_3_) feeds exclusively on rodents, especially Thamnomys surdaster. It transmits Plasmodium Berghei between these rodents. [It's also known that strong interspecific competition occurs between different species of mosquito in the Aedes genus.](_URL_2_) Thus, if we were to get rid of the species of mosquito that pose a nuisance to humans, we could expect their place to be filled by species that pose a nuisance to non-human vertebrates, affecting their population number.Indirectly this would end up affecting humans, because rodent species diversity through the dillution effect prevents diseases from gaining a foothold in these animals. [When humans disturb a habitat, rodents that harbor hemorrhagic viruses tend to spread rapidly.](_URL_1_)In conclusion, the mosquito has the effect of controling the population numbers of a variety of vertebrate species, increasing vertebrate biodiversity as a result. Because mosquitos, especially their larvae, are in competition with one another, other species may end up filling the niche currently occupied by species that prey on humans. This could affect the biodiversity of the species preyed on by these other mosquitos, which would end up affecting humans too.
It depends on the material, and to a lesser extent the environment. If you have a certain amount of coal and you're using the reaction C + O*_2_* - >  CO*_2_*, that will take a specific amount of oxygen. But of you're burning methane with CH*_4_* + 3 O*_2_* - >  CO*_2_* + 2 H*_2_*O, that will take a different amount. You also could burn carbon, but not get a good burn, and end up with a little 2 C + O*_2_* - >  2 CO, which uses half as much oxygen for a given amount of carbon (and results in poisonous carbon monoxide). You could even use a completely different oxidizer, and burn C + 2 Cl*_2_* - >  CCl*_4_*. For that matter, redox is only one type of reaction. You can have fires without an oxidizer if you use a different type.
It wasn't derived by Newton, it was a supposition he made that was consistent with observation data, and it possible to use it to derive Kepler's empirical laws.You can derive it from arguably more fundamental things, including [Einstein's equation](_URL_1_) and [Gauss' law for gravity](_URL_2_) (although the latter is much the same thing, you can see its generality by extending it to arbitrary dimensionality).Recently [it was derived from thermodynamics](_URL_0_) as well.
Even though a small fraction of the neutrons are delayed, there delayed by such a long time compared to the timescale for prompt neutron emission that they greatly extend the *neutron lifetime*, which is a timescale that’s sort of an average of the prompt and delayed neutron timescales. This is the timescale over which the neutron population evolves, and it’s slow enough that it can be controlled in a reactor. Whereas the prompt neutron lifetime is too short.You can find derivations of this in reactor physics texts, like Lamarsh.
It looks like bollocks to me.  His starting premise is wrong: that the expansion of the universe is not uniform.  He uses the example that we can see distant galaxies receding, but we don't see a ruler growing.  There are two problems with that: first, if a ruler was growing at the rate dictated by Hubble's Law, it would grow about the diameter of an atom per decade.  Not exactly enough for us to watch it grow.  Second, the energy in the chemical bonds so completely swamps the expansion of the universe (at least locally), that we'd not expect the ruler to grow along with the expansion of space.  Similarly, we know that gravity is so strong locally that our solar system won't grow with the expansion of space at any perceptible level, at least for a very long time.As for the centre of the universe being at the big bang and using Euclidean geometry to derive relativity from there... Also bollocks.
Yes, the same proton could exist since the quarks condensed into baryons. In fact quite a lot of them probably have-- the diffuse intergalactic hydrogen gas that makes up so much of the baryonic matter has pretty much been sitting there quiescently for ~14 billion years.
I disagree with your premise. Physical attraction is not so black and white like how you are describing. Yes, there are genetic factors that contribute to people's perception of "beauty" but we don't live in cavemen times anymore and different people are attracted to different things in people now-a-days.
Pixels turn completely white (transparent) when you switch them off. When your screen cracks a conductor that is wired in series is severed, thus pixels are powered off while background light keeps running. The black blotch is the result of messed up polarizing filter and/or pixels cracking and leaking (thus the name liquid crystal display).
Viscosity in liquids is caused by several factors and there is no single model to explain it perfectly. If you imagine two thin layers of liquid moving past each other with different speeds, as molecules diffuse back and forth they will exchange momentum between the layers and cause some viscosity. This is the primary source of viscosity in gases. But the molecules in each stream will also stick to each other through a variety of non-covalent forces, like hydrogen bonding or polar interactions. This also makes it harder for the liquids to flow past each other, the same way sliding friction slows down one solid sliding over another. More complicated molecules with branches and rings can also present more points of interaction.[This paper](_URL_0_) uses a regression approach to estimate the viscosity of several substances. They find the most important factors to consider are the "density" of the molecule, the shape (as measured by the number of rings), and the fraction of the surface that can form hydrogen bonds. Their fit is still imperfect (R\^2 is 0.85) but it gives you some idea of the factors that play a role.  Edit: I should add that "density" isn't the best description of the actual variable they use, which is something called the gravitational index and has dimensions of MASS^(2)/LENGTH^(2). Like density, the gravitational index is a measure of how concentrated the distribution of mass is but they are very different quantities.
facial features are innate, and we know this because blind people emote in the same way as sighted people.source: _URL_0_
Many breeds were selected for their retrieving instinct, so that they could be brought along on bird and rodent hunts and retrieve a shot or injured mark. This helps explain why some dogs seem to "naturally" fetch a ball, while others have to be taught to bring the thing back after they catch it.Canines hunting as a pack will often offer "the other end" of a prey animal to one or more of their peers. The animals will then shake their prey until it's good and dead. This might be what some of our dogs are looking for when they don't give the ball back, and incidentally it's also the instinctive behavior behind playing tug. (If you don't play tug with your dog because you don't want to teach him to "compete" with you, that's stupid. It's you and the dog versus the toy, not you versus the dog.)Credentials: just a very well-educated pet supply pro. Too lazy to source my answers, just saw this wasn't getting much attention so I thought I'd throw my two cents in.
Some have no eyes.  Some have eyes, and generate their own light.You will not find much more than speculation about animals that live on the abysmal floor (or below).  We really do not know, we cannot go there enough to study those animals.
Right. The nucleus has a much larger mass, however, which *usually* corresponds to a smaller uncertainty in position. In addition, if people talk about the uncertain position in an electron, they usually mean the relative position of electron and nucleus. Due to the big mass differences, this is roughly the same as an uncertain position of the electron.
Pills usually weigh a few grams, but only contain a few milligrams of active ingredient. So they can just make the exact same pill, and leave out the active ingredient.For injections, usually Saline (just salt water that matches your blood's salt levels. Also used for emergency blood transfusions if they just need to get blood pressure up), mixed with whatever they need to make it look and feel exactly like the medicine. Or again, the exact same carrier liquid, without the active ingredient.
You're both (sort of) right.  It's very easy to make a time machine to the future by doing what you're proposing.  Essentially if you don't break causality, there isn't much of a problem.  However, once you break the light barrier (which is impossible locally and likely globally), lots of funny things start happening, essentially breaking causality.  The problem is once something goes faster than light, the concept of time is no longer so simple, and that object can look to some observers as going back in time.
You may be thinking of [this Science article](_URL_0_), which reports: > This is preliminary evidence that when people expect information to remain continuously available (such as we expect with Internet access), they are more likely to remember where to find it than to remember the details of the item. One could argue that this is an adaptive use of memory—to include the computer and online search engines as an external memory system that can be accessed at will.
What you see is water vapour condensing in the air. Most of urine contains organic compounds such as urea and creatinine, which have very low vapour pressure at cold or room temperatures, and salts, which doesn't come off the solution phase at all. For all intents and purposes, the vapour that condenses is pure water.
I was talking to a ocean physics guy ("tides specialist") the other day and I asked the same question.  In modern times they're done with [satellite altimetry](_URL_0_), and apparently have some insane depth resolution (10^1-2 millimeters?)  The satellites acquire a single-point depth measurement at a location every ~10 days, but it's continuously acquiring at different locations.  The large amount of data collected can then be used to reconstruct and answer different questions.Edit: Googling lead to [this page](_URL_1_) which has better answers.
A black hole's spin is determined by the matter which has fallen into it (and by its initial spin, for example when a stellar core collapses to form a BH, it has some spin). Since most of the matter which has fallen in came from the plane of the galaxy, we tend to assume that the SMBH's axis of spin is roughly aligned with the axis of spin of the Milky Way. The SMBH's spin does **not**, however, determine the spin of the rest of the galaxy.
A great problem, and probably something you can write a master thesis on.Some assumptions:* Edge and corner pieces are recognizable as such* If two pieces fit together, we always know this.* We cannot use any sort of pattern on the pieces. Apart from the previous two bullet points we have no idea where a piece belongs to.Some initial thoughts:You can make estimates based on the relative number of center (M) and edge (E) pieces, but different length to height ratios will lead to different E to M ratios. All you get that way is a lower limit on the size (corresponding to square puzzles, asymmetric puzzles will have the same ratio at a larger overall size). Corner pieces (C) help: There are just 4 of them, if you draw the first one it doesn't tell you much, but with the second one you can be reasonably confident that the puzzle is not too much larger than what you have already. The third and fourth will refine these estimates even more.You know the length or height once you have a continuous connection between the corresponding edges (you don't need to have them in a straight line). This is a problem in [percolation theory](_URL_0_). In the limit of infinite puzzle size, you need on average half the puzzle pieces for this if I remember correctly.There is another heuristic estimate, and one that will lead to a reliable (but not exact) estimate the fastest: Count the number of connections you found. I don't have an exact formula, but in a puzzle of N pieces (N >  > 1), the probability that two random pieces are next to each other is approximately 4/N. With sqrt(N) pieces drawn your expected number of connections is 2, while your expected number of corner pieces is 4. With 2sqrt(N) pieces drawn you expect 8 connections and 8 corner pieces. With 4sqrt(N) pieces drawn you expect 32 connections and 16 corner pieces. The number of connections grows much faster, with its inevitable sqrt(observed) scaling it gives a more reliable estimate than the corner pieces. In addition, its dependence on the overall puzzle shape is much smaller.
Epigenetically, sperm and eggs are different, carrying different patterns called "genetic imprinting."In sperm and eggs, there are some genes (less than 1% of the genome) that are always epigenetically "turned off" by way of methylation (adding CH4 groups to the DNA) or histone modification (changing the protein core that the DNA is wrapped around in order to make the DNA more or less accessible to be translated into protein) so that they can't be expressed. The genes which are turned off are consistent and different in sperm or egg cells, such that all sperm have some specific things inactive and all eggs have other things inactive. That means that a few genes in your body are only expressed in the paternal allele and others only from the maternal allele. If gene A was turned off in your mother's egg, all the active gene A in your body is derived from your father. This is one of the main problems when making "male eggs" that another poster listed below. The ovum is capable of dividing and has in it the necessary proteins for fertilization, but if you take out the egg genetic material and add sperm genetic material and try to fertilize this "male egg" with sperm, the resulting fetus is going to be deficient in the maternally-expressed genes.
It is an autoimmune reaction triggered by gluten.  Gluten is a protein found in wheat, barley and rye.  If you have celiacs and you eat gluten ,  your immune system attacks your own tissue in the small intestines.  Causes lots of pain,  lots of gastrointestinal symptoms,  and can cause many other widespread non GI symptoms due to malabsorption of nutrients caused by the intestinal damage.    It sucks,  and having one autoimmune condition makes developing others much more likely.  Also chronic inflammation issues.   All can be solved by strictly avoiding gluten,  including things incidentally contaminated with gluten. People with celiac also tend to not tolerate dairy well as the intestinal damage in the small intestines makes them deficient in the enzyme that breaks lactose.  If they follow their gluten free diet long enough for the intestines to heal,  the tolerance to dairy can return.    The protein in oats is similar enough to gluten that cell biopsy’s from people with celiacs disease will all react to oats.  Not as severely,  but enough that I also won’t eat any oats.Some People claim to have a non celiac gluten intolerance,  but it looks from what I have read to not be typically based in science.Causes of celiacs?  Idk,  but there is a genetic component as it runs in families,  but people will not always manifest symptoms at birth.  I didn’t start having problems with gluten until my late twenties.There is a clinical trial going on right now for a series of injections that is possibly curative?  Idk for sure,  but even if you could just modulate the amount of reaction so that incidental contamination wouldn’t cause symptoms,  that would be a game changing development for people with celiacs.  You could eat at restaurants that have shared kitchens,  and you could buy products that are produced on machinery that also is used to process wheat.I also have heard of an oral medication in development that has a protective effect that allows incidental gluten exposure without causing intestinal inflammation.But right now,  you just have to be super careful about what you eat,  as there is no other treatments available
Particles, virtual or otherwise live on the spacetime background. Think billiard balls on a pool table, the table is still there even without the balls. With that said, a real spacetime cannot actually be divorced from the fluctuations which exist on it and constantly occur, therefore it feels disingenuous to say that a spacetime always can exist without the frothing quantum fields which sit on it, future physics might marry the two concepts.Here's a pretty accessible article from Nature which explores that idea,  * _URL_0_
No a long slender body is the ideal shape. Picture kinda like an arrow but points on both end
I’m unsure of many animals, but owls eat mice, shrews, and other birds whole. They will digest the animal’s soft tissues and regurgitate the hair, feathers, and bones as a “pellet”. They’re fairly interesting-in seventh grade we dissected them, and a pellet the size of a 100 grand candy bar could have two whole skeletons in it.
Objects float due to their displacement of water. The water would need somewhere to be displaced to, so whatever non-container holds it up would need to have room for the water to move. The depth of the water would need to be sufficient for the draft of the vessel. This is, of course, if the water were behaving as if in a normal gravity environment regardless of what hokum is used to separate it from the ground.
I'll start by admitting that I don't know the supposed science behind this, but the fact that the trial is unpublished (especially given its dramatic claims) should raise red flags. I've checked out the information on the website, and it's really not complete enough to make a judgment. I've also emailed Dr Hirsch asking for a complete copy of the study.
Yes. Peripheral nerves, such as in the arm, will grow back in the proper setting. Central nerves in the spinal cord or in the brain will not.  A nerve that is cut in the arm will die out past the cut, but the part nearer the spinal cord is still alive.  You can stitch the two ends together and the alive part will cross the repair site and it will grow through the dead area at about a rate of 1 mm per day and it will [regain function](_URL_0_)
Strangely enough, there sort-of *is* a maximum temperature, and this maximum temperature is *also* 0 Kelvin. First, you have to understand how temperature is defined. It is defined in terms of the energy E of a system and the entropy S of a system. For many systems, as you add energy to them, they gain entropy. The rate of change of the entropy of the system with respect to the energy of the system is defined to be the inverse of the temperature. That is, `[; \frac{1}{T} = \frac{dS}{dE} ;]`For some systems, however, the rate of change can be *negative*. That is, they gain entropy as they lose energy. These systems have negative temperature. If you put a system with negative temperature in contact with a system of positive temperature, then energy will transfer from the negative temperature system to the positive temperature system. Which is to say, *the system with negative temperature is hotter than the system with positive temperature*. This agrees with the second law of thermodynamics: as the negative-temperature system loses energy, it gains entropy. As the positive-temperature system gains energy, it gains entropy. Overall, entropy is gained.Now that we know that negative temperatures are hotter than positive temperatures, let's compare two negative-temperature systems.Take a system "C" with temperature -1 and a system "H" with temperature -1/2 and put them into contact. What happens? Both systems gain entropy from losing energy. System "C" gains one unit of entropy for losing one unit of energy; but system "H" gains *two* units of entropy for losing one unit of energy. So when you put these two systems together, energy transfers from "H" to "C". That is, system "H" is hotter than system "C". So *systems with "small negative" temperatures are hotter than systems with "large negative" temperatures.*Which is to say, in terms of how "hot" a system is, the temperature scale goes something like this:           positive T                negative T    0|-------------------+inf -inf-------------------|0    coldest     warm         hot     v. hot      hottest
Without three dimensional bonds, there's not enough information here to say they are different.
Surface tension is simply the energetic cost of producing additional surface area, since atomic bonds are generally unsatisfied to some degree at a surface. As long as the system is more than a few molecules deep, the surface tension is independent of the depth or the total thermal energy. However, it is strongly dependent on the temperature.
Sudden increase in humidity.  The coil gets wet from condensation but when the compressor is running the air is cold so it's ability to absorb water is very low.  When the compressor turns off the air heats back up, absorbs the water from the coil and blows the humid air out of the vents.
Please speak to a doctor for recommendations on drug treatments for anxiety.
Well, in a way yes. Albinism is caused by a malfunctioning gene that produces melanin, and since most species have melanin in their system, they do have the gene that codes for the synthesis of it. Since apart from pigmentation, this gene doesn't exactly affect anything else, it's one of the few "bad" mutations, that actually allows the animal to survive and procreate with. Sure it inhibits camouflage ability, it makes protection from the sun basically nonexistant, but apart from that everything else functions fine. Therefore, especially animals that live furter from the equator, where extreme sunlight isn't as big of a problem, these animals have a chance to survive and have offspring, which also enhances the probability of seeing an animal with albinism.It's in a way similar in polydactily, in that animals that have it can survive, just that it's way easier to spot a completelly white animal, than an individual that has 6 fingers on each limb.
Certainly it is possible.It has already happened in fact (although it was not a guided or intentional effort).Merely look around at all the different races of humans.  Japanese look distinctly different from Germans.  Mexicans look distinctly different from Sudanese (and so on).This is exactly what you are talking about.  Each race has distinct traits which sets them apart from other races.  These differences arose from selective breeding.  The selection was not due to some master plan but cultural pressures and other pressures saw certain societies favor certain traits and over time became a distinct population.The problem with setting out a planned course for selectively breeding humans is:1)  Humans take a long time to mature and reproduce.  You probably would not want to have a couple reproduce till about 20 years of age so all traits were apparent and you could select appropriately.  Then wait another 20 years for the next set and so on.  Even if you pushed it down to 13 years old you still have to wait a long time and thus getting an effect from the selective breeding would take centuries.2)  You will have a tough time keeping a large enough breeding population (and all their offspring and their offspring) in line, in track and breeding the way you direct.  People tend to have sex with whom they choose and not who someone else tells them to do it with.3)  It is insanely creepy.But sure, in theory you could do it.
[Doctors](_URL_0_) who play games may make fewer errors.
Maybe, if you are talking about quantum mechanics.  From a classical (non-quantum) perspective, it would not change the weight for sure.How batteries work: Imagine a nine-volt battery.  It has a positive terminal and a negative terminal.  Imagine that underneath those terminals are two little tanks (compartments) filled with atoms. (Protons, neutrons, and electrons)The difference between an empty battery and a charged battery is that in an empty battery, both tanks are filled with equal amounts electrons and protons.  In a live battery, one of the tanks has all the electrons for both of the tanks, and the other tank has only protons and neutrons.The negative terminal is attached to the tank with lots of electrons, and when the negative terminal is connected to the positive terminal, the extra electrons flow from the negative terminal to the positive terminal, thus restoring the balance.When you charge a battery, you suck electrons from the positive tank and put them into the negative tank, making the electrons want to flow back to the positive tank as well.
Yes. Pretty much all of the sound comes from the air the lightning goes through, not from the target itself. By far most lightning goes only through the storm cloud itself and we can hear these aswell. Only reason they do not seem as loud is because they are further away than if lightning strikes near you.
As others have stated, some epiphytes will get nitrogen from bacteria or fungi that fix N2 from the atomosphere.  But for the most part, epiphytes rely on atmospheric deposition for mineral nutrients.  Dry deposition (including ions as vapor in the air) will provide sulfur and nitrogen, mostly as nitrate but also as ammonium and nitrite.  Wet deposition knocks fine dust/soil particles out of the air and onto / near the plant.  This is the source of most minerals -- K, P, Fe, Mg, Ca, etc.  I've heard it suggested that the ability to collect dust/minerals is the stronger selective force for many tropical epiphytes to have water-collecting leaf morphology since it's humid enough that they're not experiencing high transpirational losses.
The leading theory on how gold in the Earths crust exists nowadays is by asteroid impacts in the late heavy bombardment era. If those are correct there should be gold on the moon. _URL_0_LCROSS detected gold in October 2009 during an impact test: _URL_1_
This is already under development, although tungsten is denser (higher terminal velocity), and less prone to melt compared to steel.  The real problem is that the radar signature of the incoming attack is the same as a nuclear ballistic missile strike, land based nuclear weapons systems are designed to be launched before such a strike hits the ground, so a pinpoint attack could result in global retaliation.[Popsci isn't a great source for scholarly information, but it is a perfect intro.](_URL_0_)
As you said, an anti-inflammatory drug will exert its effect systematically and it does harm the body if used long-term. A classic example is corticosteroid, a powerful anti-inflammatory class of drugs. It has a slew of side effects from long-term use and one of them is increased risk of infection because of suppressed immune response (inflammation is a necessary component of immune response.)For short-term use, however, it's mostly safe especially when used as prescribed. Also, there are many instances where anti-inflammatories are injected locally, like in epidural space or inside a joint capsule to treat pain. In those cases, the drug will stay in the closed compartment and will not have systemic effects.
Preamble: Geographic isolation today does not necessarily correlate to isolation throughout history. However, the large mouth bass is a sport fish that is stocked throughout most of the USA. According to the USGS, the natural range of the species is: > Native Range: St. Lawrence and Great Lakes, Hudson Bay (Red River), and Mississippi River basins from southern Quebec to Minnesota and south to the Gulf; Atlantic Slope drainages from North Carolina to Florida; Gulf Slope drainages from southern Florida into northern Mexico (Page and Burr 2011).So to answer your original question of the hypothetical catches in MA and CO, both would actually be classified as introduced (not native). [Here's the link to the USGS species page](_URL_0_) Hope that helps!
I assume you mean "for what reason does a proton attract *an electron* fundamentally".It's kind of 'cause that's how it works'. Electromagnetism is one of the fundamental forces and it has no underlying mechanic (what we know of).How they attract can be explained on a QM level with exchange of virtual particles: [_URL_0_](_URL_0_)Bonus: Feynman on basically the same question: [_URL_1_](_URL_1_)
In 3d you can have situations requiring arbitrarily many colors. Take a cylinder, cut it into N slices like a pizza for any number N, and then on the top of the cylinder attach N concentric rings. Every ring touches every wedge and vice versa, so for each wedge pick one ring to fuse it with, and now you have N different 3D regions that all touch each other. You then need N colors to color them all differently. Since N was arbitrary, we can make it as big as we like.
Energy conservation is a direct result of time independent laws of physics. Expansion is time dependant, so conservation of energy does not need to hold._URL_0_
I've answered this question before. So I am just gonna copy my old post.   > We are very sure the impact caused the KT extinction. At least we are quite sure that the [Chicxulub impact](_URL_4_) triggered the extinction.  > [(first paper)](_URL_0_) > [(crater theory)](_URL_2_) > [(newer article)](_URL_5_) > there is also some evidence that the [deccan traps](_URL_1_) played a role too. Quite likely it was the combination of asteroid impact which triggered the eruption of the Deccan traps and the combined climate change from both events that caused the extinction.[(article)](_URL_3_)   > also sorry that these papers are all behind paywalls.
If the modification using CRISPR occurred in the sperm or egg, yes, that could be passed on to offspring.
As you read, gravitons is just a name for (quantized) gravity waves. Just like photons are just a name for (quantized) electromagnetic waves. The way you manipulate light is by creating currents and moving charges around, and the way to create gravitons is by moving masses around. But gravitons are by definition just small perturbations, and what you want is to create big heavy configurations, so the understanding of gravity at this "linear level" doesn't give you anything.
Short answer: It's a clade, though some people also call it a superorder. There's not a total consensus.Longer answer: The traditional view that ancestral groups can be stuffed into exactly 7 levels (Kingdom, Phylum, etc. etc.) turns out not to reflect reality well. What the old named levels (Class, Order, etc.) really represent, in reality, is the *last common ancestor* of a given cluster of descendants, typically just after a novel evolutionary innovation occurred. Classifications are really a sequential list of evolutionary innovations, in the order that they occurred in the history of a given lineage. But here's the problem, *a lot of lineages had more than 7 such innovations* and need *way* more than 7 tiers.Take the Cetacea, from your example. Here's the traditional way we used to classify the bottlenose dolphin:1. Kingdom Animalia2. Phylum Chordata3. Class Mammalia4. Order Cetacea5. Family Delphinidae6. Genus *Tursiops*7. Species *truncatus*But the above list doesn't come close to capturing all the important evolutionary innovations that occurred in the history of the bottlenose dolphin. It doesn't show where vertebrates arose, or the moment when lobe-finned fishes first crawled up onto land, or the fact that bottlenose dolphins are toothed whales and not baleen whales. To solve this problem, at first new tiers were simply stuffed into the existing system, resulting in a classification something like this: (many variants exist and the Cetartiodactyla that you asked about may end up in several different places)1. Domain Eukarya2. Kingdom Animalia3. Subkingdom Metazoa (multicellular animals)4. Phylum Chordata5. Subphylum Vertebrata (vertebrates)6. Superclass Gnathostomata (vertebrates with jaws)7. Class Mammalia8. Subclass Theria (animals with placentas)9. Infraclass Eutheria (animals with *well developed* placentas - excludes the marsupials)10. **Superorder Cetartiodactyla** - here's the one you asked about.11. Order Cetacea12. Suborder Odontoceti (toothed whales  &  dolphins)13. Family Delphinidae14. Genus *Tursiops*15. Species *truncatus*... but that STILL doesn't capture all the critical evolutionary events. There was a whole series of innovations that occurred between the invention of jaws (Gnathostomata) and Class Mammalia (for example, in order: the origin of bone, lobe-fins, the transition to land, the amniotic egg, and the unique skull design that led to the mammals.) Trying to stuff five more levels in between "Superclass" and "Class" illustrates how artificial the whole idea of 7 tiers is. What we going to call the five new levels - hyperclass? megaclass? Basically, every evolutionary lineage has a *different number* of important evolutionary events and there is really no reason that one should be called a "Class" and another one an "Order".So now we come to what a lot of biologists do now - simply abandoning the words "Kingdom", "Phylum", etc. So now we end up with this: 1. Eukarya2. Animalia3. Metazoa4. Bilateria5. Deuterostomia 6. Chordata 7. Craniata 8. Vertebrata9. Gnathostomata (vertebrates with jaws)10. Sarcopterygii (lobe-fins and their descendants)11. Tetrapoda (four-footed animals)12. Reptiliomorpha (this excludes the amphibians)13. Amniota (animals with amniotic eggs)14. Synapsida (the mammal-like reptiles)15. Therapsida16. Mammalia17. Theria18. Eutheria (placental mammals)19. Cetartiodactyla20. Cetacea21. Odontoceti (toothed whales  &  dolphins)22. Delphinoidea (dolphins + beluga + narwhal)23. Delphinidae (just the dolphins)24. *Tursiops*25. *truncatus*Now this is starting to look too long and it's becoming apparent that every damn little evolutionary branching event is going to get its own name, isn't it? But that's the reality of what really happened. In actual practice we are sort of in an uneasy compromise now. Biologists have tacitly agreed that some of those branching points, like Craniata and Vertebrata and Amniota, are definitely important and should be named. Others (like Reptiliomorpha and possibly Therapsida) are of little interest except to paleontologists. Overall, the words "Kingdom", "Phylum", "Class" and "Order" are increasingly not used at all. Yet people doing fieldwork - those out in the wild working with actual animals - tend to still use the lowest of the old traditional levels, "Family" and "Genus", because they are handy mnemonic devices for remembering the most closely related clusters of species.Back to your main question: When I hear people use Cetartiodactyla they usually don't try anymore to specify whether it's a "class" or "order", because that's completely arbitrary. They usually just say "Cetartiodactyla". And there are some biologists, probably including your professor, who grew up with the older system and are accustomed to calling Cetartiodactyla an order or a superorder.tl;dr - No consensus yet. Sorry for length
_URL_0_ >  Loose connective tissue is a category of connective tissue which includes areolar tissue, reticular tissue, and adipose tissue. Loose connective tissue is the most common type of connective tissue in vertebrates. It holds organs in place and attaches epithelial tissue to other underlying tissues. It also surrounds the blood vessels and nerves.If you've ever slaughtered an animal, you've seen that stuff. It's usually a thin, I would call it diaphanous membrane that's easily cut or pulled away, but strong enough to stabilize positions of organs in situ.
Per _URL_0_ it would appear that the brain switches into a different form of functionality when sleep deprived.  Certain parts of the brain stop reacting normally(as compared to being wide awake), and other parts start over-reacting.  The prefrontal cortex tends to become over-active and that could explain why our behaviors become more irratic and irrational as we become more and more exhausted.  What I personally find most interesting though is the act of microsleep.  Where the brain basically says 'fuck it' and just forces you into sleep for small moments of time, no matter what.
As far as I know, Autism is not suitable for cognitive based therapies.  Applied behavioral analysis is used as means to modify autistic behaviors and develop self care abilities, but little has suggested any cognitive techniques to be applicable to autism.  As for timelines, there's not a clear answer its not like psychoanalysis was just singly supplanted by one other thing.  Multiple different paradigms coexisted and still coexist to this day.  The American Academy of Child and Adolescent Psychiatry adopted as official stance that psychotherapy in general was of "limited use" for autism in 1999.  When those notions were really accepted and where, I don't know. But its not like there was a move from Freudian to CBT, instead the move was in general away from both and trying to manage it behaviorally. People still surely use both, but neither has any substantial weight to their application to autism, and in general more complete understanding of the condition and more experimental data are needed.
>  have we ever seen a planet form?Astronomical objects like stars and planets form over what humans would consider very long timescales (from as low as a million years to around a billion), so we haven't been observing anywhere near long enough to see any new objects grow from practically non-existent to full-fledged planets/stars.  We have, however, observed an enormous amount of protostars, although you wouldn't expect them to undergo significant evolutionary changes over the course of a single human lifetime.  They tend to experience temporary shifts in temperature and brightness due to thermal instabilities though, and those *do* occur over readily observable timescales (for example, the protostar [V1647 Orionis](_URL_2_) rapidly expanded into a supergiant back in 2004).Also, [a candidate protoplanet](_URL_1_) (still in the process of formation) was found orbiting the pre-main sequence star HD 100546 a few years ago.  Its mass is predicted to be 15-20 times that of Jupiter though, which is high enough that it might actually be able to fuse deuterium in its core - and that would make it a [brown dwarf](_URL_0_) instead of a planet.  In addition, we've observed protoplanetary discs around other stars, although the evidence for planets forming within them tends to be indirect (usually being based on gaps and distortions within the discs themselves).
I was just reviewing this last night for my wife who is not a physicist! She asked your same question just as I was getting into the derivation of the Lagrangian. I wish I had the answer off the top of my head but I eventually found [this beautiful explanation](_URL_0_) on the internet.Turns out,  the classical action is what it is because of the radially symmetric gravitational potential and the non-relativistic speed of the particle(s) in motion.
It is possible to develop deep vein thrombosis if sitting for long periods of time, which can the cause a pulmonary embolism, or blood clot in the lungs, which can certainly be fatal. This is why it suggested that you do some simple exercises while on long haul flights or sitting at a computer for hours every day. The pulmonary embolism itself could cause pulmonary oedema, which could be interpreted as frothing from the mouth by the media.
Evolution of spinal motion roughly went like this: * Bottom-dwelling marine organisms (such as worms) developed rudimentary cartilaginous spine and, because they were bottom-dwelling, lateral spine motion * They eventually gained the ability to move away from the bottom; their spine evolved from being cartilaginous to being bony, while retaining lateral spine motion. You still see this today in fish — [elasmobranchii](_URL_0_) have cartilaginous skeletons. Bony skeletons are advantageous because they can support stronger muscles, which make for faster and more efficient swimming. * These marine animals eventually moved to land and became the first amphibians. They retained bony spine and lateral spine motion, and developed lungs. The problem with lungs and lateral spine motion in amphibians is that you compress one lung and expand the other every time you make a step, so you have to synchronize your breathing to your steps (or you have to stop to breathe).  * This gradually leads to development of transverse spinal motion, which also leads to changes in gait — rather than the lizard-like gait of lateral spinal flexion you get mammal-like gait of transverse spinal flexion * At this point, two interesting things happen. One, transverse spinal motion ultimately enables bipedal gait, which eventually leads to humans.  * Second, which is what you were actually asking about, some vertebrates with transverse spinal flexion return to marine habitats. All marine mammals are descended from that lineage, which is why all marine mammals have transverse spinal flexion.
When light is presented as an electromagnetic wave, one often sees a picture of two sine-waves oscillating in phase, but at an angle of 90 degrees with respect to one another. It is important to notice that the depth in such a picture does not refer to length, but to field strengths. It's not that light roughly moves a long a line while wiggling around it, it's that the field strengths of the electric and magnetic fields oscillate while light moves along the line. They oscillate and thus repeat, and the length after which 1 repetition occurs is 10 meters, in your example.It's not very accurate to assign the frame of classical EM waves to a single photon, as it is a quantum object, so we can't really talk any more about perfectly oscillating EM fields. Plane waves, however, can fit this description and are often used in classical optics.
Pressure does not directly affect buoyancy because it does not cause a net force; an air bubble in water feels a force in every direction due to the water pressure so pressure will never result in a net downward force. This is assuming there isn't somehow a huge gradient in water pressure on a length scale commensurate with the size of the air bubble, but that isn't the question. Instead, the buoyant force is equal to the weight of displaced fluid. Air will always displace a weight of water larger than its own weight because water is more dense than air. Water pressure can indirectly change the buoyancy of air in it by changing the water's density but water is almost completely incompressible and its density is nearly unchanged by very large changes in pressure. An air bubble should always float up in water.  After writing up this answer I googled it and found [this](_URL_0_) post that goes into some more numbers and reaches the conclusion that nitrogen (air is mostly nitrogen) is unlikely (read: realistically impossible) to ever be denser than water for physically meaningful conditions.
It may be hard to calculate if a observable difference exists as the overall data reporting process has become better and the rates of events may be the same but our ability to record sinkholes has vastly improved. This can cause an uptick in sinkhole events. A secondary source of more sinkholes is our water transportation infrastructure is growing as urbanization has increased over the years. Broken water mains are often a source of sinkholes, therefore an increase in the total miles of pipes will lead to an increase in the probability of failure somewhere. When a failure occurs a sinkhole is possible as the water may erode the soil that is supporting the layers that rest on top. It is likely that more sinkholes are occurring due to anthropogenic causes. Hope this helps, this is my first time responding in the sub.
Paleontology is more of a coal thing. If you look at coal under a microscope you can often still see the details of long-dead land plants and grains of pollen. Sometimes there are larger fossils, and sometimes animals. Many coal towns have fossils on display as trophies.As a result of coal mining and coal research there's a lot of bizarrely specific and rich knowledge about the eras and places when significant amounts of coal was being laid down. Paleontologists have named this era the carboniferous, a time dominated by bizarre horsetail relative trees called lycopods that looked like they were designed by Dr. Seuss, alongside dragonflies the size of hawks and primitive tetrapods from before mammals and reptiles diverged.There are biomarkers in oil, but it was mostly dead oceanic algae. Not much of the original microbes remain. Oil companies still give a few biologists jobs, but the microbes they're most financially interested in are oil-eating scavengers who came much later.
In terms of getting a tan:  glass absorbs UV light, the kind of light that causes sunburn and tanning.  So, if you are exposed to sunlight through the glass of a window, your rate of tanning will be greatly reduced.  In addition, as explained by others, some light will be reflected and some will be refracted, but that won't affect your tan much.  The effects of the speed of light changing is negligible.
Water (the hydrosphere) is the key factor in our mineral cycle. Without it, no clays, and all the instable minerals (mafics, feldspars, etc.) which end as clays will remain as an inheritance from the source rock.Mars has had a hydrosphere, now gone, which produced ancient clays, sulphates and hydroxydes. But more recent sediments are dominated by the host-rock mineralogy and are often close to regolith.Titan has some kind of liquid seas/lakes of hydrocarbons. preliminary indications are that longer chained hydrocarbon sediments surround these bodies. It is unclear how the inheretance from the source rock would evolve in that context, probably not much as there is very little chemical interaction between most silicates and hydrocarbons (but there could always be local surprises).
In short, no. We know of no physically possible solution to the equations that create a wormhole.
(PhD Bacteriology)"Smoking preserves fish by drying, by deposition of creosote ingredients, and, when the fish are near the source of heat, by heat penetration" ref: _URL_0_In fact, smoking is not a very good way of preservation.  There are lots of bacteria and fungi that don't care about the smoke at all, and will grow in spite of it.
In quantum mechanics conservation of information is phrased as "unitary evolution" or you might say the conservation of probability. I think typically you'd consider this a postulate of the theory rather than a consequence of some symmetry, but it can be related to (for example) the "phase symmetry" of the wave function: only the magnitude of the state vector matters, not its phase in the complex plane.
If it's a "very rare disease", then the number of surgeons with experience/training in that procedure is going to be limited.  Surgery isn't like working on a car, where one guy can pretty much do anything.  It's pretty specialized.  (Yes, there are genral surgeons, but they do general surgeries like tonselectomies, appendectomies, wound closures, etc...)So, even though medical costs in general are outrageous, there is a matter of supply and demand involved when it comes to "rare" procedures.
The cranes you describe use electromagnets.Electric currents create magnetic fields around them. _URL_0_By repeatedly looping wire around a metal rod and then running a large electric current through it, you can create a magnetic field similar to a permanent magnet (the kind you have on your fridge). The magnetic field from the wire loops adds up in one direction. It also magnetizes the metal rod. This happens because the atoms inside the metal all have what is called a magnetic moment (they all have a small magnetic field of their own). Normally the magnetic moments of the atoms in the metal are random, and so they all pretty much cancel out. But when the magnetic field from the wires goes through the metal, it causes all the atoms' magnetic moments to line up, which means the magnetic fields from all the atoms is now adding up, not canceling out. This amplifies the wire's magnetic field and results in a powerful over all field. [Here is an image showing the wires, the metal atoms' moments and the field](_URL_1_).Now that the current is flowing through the wire, the whole thing acts like one big powerful magnet. But when you turn off the electric current, the wire stops creating a magnetic field and most of the magnetic field goes away. The metal atoms which were lined up by the field quickly become randomized again when the field is turned off, and so the system stops acting like a magnet very fast.
Chemical processes do not affect the rate of radioactive decay. Of course, if you burn radioactive wood the smoke will be radioactive, so if you inhaled it you would have greater radiation exposure. No change in the fundamental decay processes though.
A good example here is Jupiter, because each atmospheric band rotates at a slightly different speed to another - this is called differential rotation. Jupiter's polar regions rotate about 5 minutes slower than it's equator, at 9h 55m, while it's equator takes 9h 50m. The official speed of rotation of Jupiter is measured by its magnetosphere, which is also 9h 55m. This was determined by radio astronomers. Venus has no appreciable magnetosphere, so Magellan in the early 1990's used it's radar to accurate determine its rotation of the surface. ESA's Venus Express spacecraft used Infrared to look at its surface last year and found Venus' rotation has actually slowed considerably (6.5min!) since Magellan visited.
Short answer: almost definitely.  Long answer: In 1687, Isaac Newton published something called "Philosophiæ Naturalis Principia Mathematica," which could be considered the Bible for physics.  Included in it was the Law of Universal Gravitation, which describes the force of gravity between two objects at a given distance.  Around a hundred years later, Henry Cavendish performed experiments that determined the mass of the earth, along with an accurate value for a constant ("G", the gravitational constant) that made Newton's gravity equation work.  Since the scientists involved in putting objects in space knew, with reasonable accuracy, how far away from the earth's center of mass those objects would be, they also would have known that those objects would be experiencing weightlessness, or to be more specific, microgravity.  But, as Sycosys worded it, freefall is probably the most accurate way to describe this--it's why you can simulate being in space with a gut-wrenching airplane ride.
>  Will we notice how one had obviously larger momentum by the way the debris flies after the collision?Remember that relativistic momentum is conserved in all frames, so it must be conserved in the center of mass frame.  If there is net center-of-mass momentum (i.e., one of the asteroids is much larger or much higher gamma than the other) then the collision products will all be produced in a fast-moving CoM frame.  So yes, the debris would be a pretty clear indicator of which one had higher momentum. >  Or assuming an they could crash and get stuck together, would they maintain a large velocity in the direction of the faster asteroid?It would depend on how large the difference in gamma was between them, but certainly if they are the same mass and one is moving with v much closer to c, the combined product after collision (if they somehow stuck together, which would be difficult considering how much energy would have to be dissipated) would move also at nearly c, and in the direction of the originally-faster asteroid.  So again, yes.
Technically, Central America is part of North America. They have quite a few monkey species. Additionally, Trinidad, an island of the Caribbean has two types of native monkeys. I have no answer for your question regarding Mexico, U.S.A and Canada.
So I can't speak to the your secondary question about mutation rates, but as for your initial question, >  Would solar systems with young stars have more radioactive isotopes?...the answer is definitely yes.The main sources of radioactivity on Earth today are primarily Thorium-232, Uranium-238, and Potassium-40. These all have long half-lives of 14 billion years, 4.5 billion years, and 1.3 billion years, respectively. This makes sense, considering that the age of the Earth is somewhere around 4.6 billion years - all the shorter half-life isotopes would have mostly decayed by now. That said, there are definitely shorter half-life isotopes that were really important for the formation of the Solar System as we currently observe it. When we look around at the asteroids, we notice that there's a surprising amount of differentiation among them, which strongly suggests their parent bodies had at least partially molten interiors that allowed the different elements to separate out. This is why we see that certain asteroids like [16 Psyche](_URL_0_) are particularly metal-rich - it's very likely the remnant of an iron core from a forming protoplanet that eventually broke up.The problem is that when you carry forward the amount of energy available to initially melt and differentiate these small bodies, the heat from release of gravitational potential as well as the heat from Uranium, Thorium, and Potassium decay simply don't provide enough energy for their cores to melt. However, if you include the heat added by the decay of short-lived isotopes - most notably, [Aluminum-26](_URL_1_), with a half-life of 700,000 years - suddenly all the energy equations balance, and we can reproduce the early differentiation of the Solar System on paper.
Those side effects were witnessed in clinical trials. In those trials,  a statistically relevant numbers of patients were seen with the "issue". Further, statistical outliers, assuming quality controls were in place, are not permitted to be excluded, because they impact public health.
The tricky part of extrasolar capture is that you have conservation of energy to deal with. If a planet that wasn't orbiting the sun was on a trajectory that brought it close by, it would have enough kinetic energy to escape the sun as well. You need to add a third body to make capture work. For example, a planet could graze by Jupiter and transfer some kinetic energy, leaving the planet trapped in an orbit and adding boosting Jupiter to a higher average distance from the Sun.It is possible though, and [this paper](_URL_0_) explores the topic in more depth. They talk about clusters of stars that might have some extrasolar planets floating around. Capturing an extrasolar planet would probably leave you with a higher eccentricity and an orbit in a different plane from the other planets, so those features would be clues that capture happened. But a planet that formed around our sun could be sent into a funny orbit by interacting with another planet as well, so it would be tough to prove how a given planet was formed.The 8 planets in our solar system have pretty low eccentricities and they line up in a nice plane, so they were most likely all formed from the same protoplanetary disk. An extrasolar capture would have to graze an existing planet just right to settle into one of those orbits, and even then it would have an orbit that was too close for comfort with at least one other planet.
Don't know if you care but, an aircraft also has this to consider:Magnetic dipThe compass dial will tend to align itself with the geomagnetic field and dip toward the northern magnetic pole when in the northern hemisphere, or toward the southern magnetic pole when in the southern hemisphere. At the equator this error is negligible. As an aircraft flies closer to either pole the dipping error becomes more prevalent to the point that the compass can become unreliable because its pivot point has surpassed its 18 degrees of tilt. Magnetic dip is caused by the downward pull of the magnetic poles and is greatest near the poles themselves. To help negate the effect of this downwards force, the center of gravity of the compass bowl hangs below the pivot.The 2008 FAA Instrument Flying Handbook mentioned a dip compensation weight. The 2012 edition talks instead about the pendulous mounting arrangement. Compass navigation near the polar regions, however, is nearly impossible due to the errors caused by this effect.
No, they can't. They may look similar, but they're quite distantly related, and they diverged a long time ago.  Alligatoroidea and Crocodyloidea, the larger groups that contain modern alligators and crocodiles, respectively, extend back into the Cretaceous. However, lots of different croc species can successfully hybridize. And I'll head folks off at the pass on species definitions: crocs care not one whit for how we define a species. For more info on how biologists grapple with species definitions, check out [this FAQ](_URL_2_). Edit: I mention the divergence between crocodiles and alligators not because there's some hard rule about divergence dates or even taxonomic rank being the deciding factor in hybridization, but to illustrate that these animals are quite different despite the fact that they may look superficially visually similar. I mentioned weird bird hybrids in another comment, but I think it's worth pointing out that there have been hybrids between sand dollars and sea urchins *in different orders* ([source](_URL_1_)). While kind of thing this is rare, it's worth noting that it can happen. Ultimately, rules about different genera/families/hybrids are infertile/etc.  are not going to hold up. Okay, back to crocodiles. The American crocodile (*Crocodylus acutus*) and Cuban crocodile (*Crocodylus rhombifer*) can successfully hybridize. While their ranges overlap and hybridization can occur naturally, they're doing so more and more often. See [this article](_URL_0_) and [this article](_URL_3_) on the subject. The American crocodile is also known to hybridize with the Morelet's crocodile ([source](_URL_4_) and [source](_URL_6_)). These are all New World croc species that are fairly closely related.Also, the saltwater crocodile (*C. porosus*) can hybridize with some of the Indopacific species. The Philippine crocodile (*C. mindorensis*) is one of them ([source](_URL_7_)). The Siamese crocodile, *Crocodylus siamensis* can hybridize with the saltwater crocodile as well. The weirdest croc hybrid I can think of off the top of my head is that *C. siamensis* can hybridize with the Cuban crocodile ([source](_URL_5_)). So no, there are no gator/croc hybrids out there, but modern crocodylians *can* do some wonky things. Some level of background hybridization is natural and expected where species overlap. However, as some populations are reduced, habitat is lost, and climate change impacts coastal habitat, these hybridizations seem to be on the rise. Many crocodylians are endangered, and some are critically endangered. Increased hybridization could put additional pressure on struggling species. Hybridization also occur in captivity, which can be problematic for captive breeding programs trying to preserve species.
There are quite a few satiety (fullness) signals that reach the brain, all of which are integrated together to form a perception of being full.The first signals from the stomach come much earlier than 20 minutes, but it can take up to 20 minutes for all the signals the stomach sends to reach as it sends signals through various nerves and peptide horomones. The slowest of them take up to 20 minutes to reach the brain.Not all of the signals are from your stomach though. You get some signals from taste, smell, sight etc… when eating and then further on in your intestines and liver, additional horomones are sent to the brain to indicate further digestion. In the long term, the brain also gets signals from the blood and fat tissue, the levels of glucose and leptin in your blood help control how full or hungry you feel when not currently eating.
10 km/h means that it's practically still relative to Earth and would crash into us due to mutual gravity.But assuming it was travelling fast enough to just fly past without ever coming closer than the orbit of Moon, it would cause some pretty strong tidal effects. The strength of the tidal forces would be about eighty times as strong as those of Moon. What exactly would happen I can't say.Also it would probably cause a significant change to Earth's orbit around the Sun, details of that would depend on the exact trajectory of the planet.
Yes. The two electron states are separated by a fixed energy, which corresponds to a specific wavelength. The transition will either absorb or emit that specific energy via a photon of that wavelength.So if the transition absorbs a 500nm photon, the excited electron will emit a 500nm photon when it falls back to the previous state. There might be other paths possible though: If the electron can hop down to an intermediate state and then to the ground state it can emit two photons with different wavelengths than 500nm. The precise path is governed by chance and certain selection rules.
Your muscles don't know the difference between a "real" workout, and an incidental one... all they care about is how much work they're required to do, and whether it's demanding enough to elicit an adaptation response.So, pushups done in your office are the same as pushups done in the gym.  However, if you're well trained in pushups, you may need a stronger stimulus to create an adaptation response.  In this case, you'd be better off in the gym, because I presume you don't have a squat rack in your office or bedroom.
You make a drosophila line that expresses the yeast gene gal4 under control of a promoter of interest (say actin for example).You make a separate cell line that expresses a gene of interest (say green fluorescent protein) under control of UAS. When you cross the two lines, any drosophila cell that acrivates your promoter of interest (actin) will express gal4, which will in turn bind to UAS and express your gene of interest (GFP). Now all actin expressing cells glow green!It's a split system because it requires the crossing of two genetic elements to see a phenotype. Either individual line is usually phenotype free.
At the moment, the tallest structure in the world is the [Burj Khalifa](_URL_1_) building in Dubai, UAE. It stands as about 830 meters, though nearly two hundred meters of it isn't for human occupation.  The answer to this questions is currently about a kilometer is as high as you can get with today's technology. Currently being built is the [Kingdom Tower](_URL_3_) in Saudi Arabia which aims to reach an even 1,000 meters. There are some others planned around this height as well. The problem with super-tall towers is you have to deal with the torque such a building will generate on itself--so you need to make sure the center of gravity isn't too high up the tower. This is why such super tall towers are wider at the base and thin out as you get higher, it's a more stable configuration. The [Warsaw radio mast](_URL_2_) is a good example of this, it was almost 650 meters tall and bent in half and collapsed back in 1991.  There are proposed towers even taller than this--outside today's technology. One of the most massive is the [X Seed 4000](_URL_0_) at a whopping 4,000 meters. As you notice from the picture, the base is enormous. You can actually find completed design plans for it. More fantastic projects are also being discussed with the most famous being the [Space Elevator](_URL_4_) which would be go somewhere far past 36,000 km (geostationary orbit). The "idea" is a bit different here as it's be more like "hanging down" a tower than one traditionally supporting its own weight.
It is convention only, to allow scientists to talk to each other without having to describe which coordinate system they are using every time. Let me explain. The direction of the angular momentum of an object doesn't mean anything by itself. What matters is that when object A with angular momentum interacts with object B with angular momentum, that the angular momentum is conserved. Then, you can know how the objects will be acting afterwards. The reason we use these conventions, is that you don't always want to start back at the very beginning. Say you know how a certain experiment will end up, and then you want to move on. You can start with "this experiment will lead to an angular momentum in the +z direction" and move on, without having to describe what that means. If instead we used a left hand rule, but used it consistently throughout all calculations, everything would work out just the same.
Yes, it does. With vagal deinnervation of the heart, it will continue to beat. However, the brainstem keeps you breathing. Without oxygen, the heart will eventually cease to beat.
Both gonorrhea and chlamydia are asymptomatic in at least half of infected people. That's actually why there's been the attempt to shift from "sexually transmitted disease" to "sexually transmitted infection," as "disease" tends to suggest symptoms. It's also hard to figure out how many people have a disease without symptoms.Between men and women, symptoms are a bit different, as men will get urethritis (burning on peeing+discharge) while women get cervicitis (pain+discharge, but not related to peeing.)
We know that two particles were entangled because of the their measurement statistics. Specifically, an ensemble of similarly prepared two particle systems will violate a Bell type inequality if the two particles were entangled.
Wouldn't the brains that conceived of modern medicine also be part of the evolutionary process?Also, what does "rate of evolution" really mean?  It's not like it proceeds along at a steady pace. I feel like what you are trying to ask is, does the fact that we are allowing genes into the gene pool that might not have made it before affect the course of evolution?  Since we are potentially eliminating a genetic bottleneck, I would think so.  I would guess that it would be a hard thing to determine scientifically until we had a good bit of data.  Since evolution proceeds at such a slow pace and modern medicine is fairly new, I'm guessing we don't have the data yet.
Because they either contain theobromine, or caffeine (which is partially metabolized to theobromine).  Dogs are the most popular example of this, but most animals that can get toxicity from it are due to the same reason:  they lack the ability to metabolize and excrete it rapidly, so it builds up and starts causing problems.  Should be noted that the type of chocolate and size of the dog plays a huge role in this too.  Milk chocolate is relatively safe (compared to the other chocolate types), dark chocolates are medium of the way (depends on purity), baker's chocolate can get you toxicity pretty quickly.  And a large dog will be able to handle more theobromine than a smaller dog.
The big bang is incredibly well supported, but I'd say there are specifically two big guns we can point towards:  1. The universe is expanding. Objects are receding away from us proportionally to their distance to us. We know this by measuring the redshift of galaxies. (Though the full picture is a bit more complicated as the rate of expansion is dynamic.)2. If the universe is expanding, then at one point in the past everything must have been very close, dense and hot. The cosmic microwave blackground is the evidence of this hot and dense past.
Most people speculate that RNA came first, since it is replicable and can catalyze certain chemical reactions.The only way we know of proteins to be made is by using RNA, so it is unknown how proteins could come before RNA.
Dairy isn't UNHEALTHY for the human body. But there are other ways to get calcium in your diet.Mother's breast milk is dairy. It isn't necessarily a cow's milk as many people assume.Calcium, Vitamin D, and other nutrients found in dairy are essential for life. Your body needs calcium to operate the muscles, to provide strength for bones, etc.As for lactose, it is a sugar that most people are able to process and use in their body. However some people are intolerant to lactose, and it can lead to gas, diarrhea, upset stomach, etc. Just like how some people can't eat gluten, peanuts, etc...some people are just unable to process certain chemicals in food. Lactose in itself isn't necessary for life though, but the sugar/energy found in it is.Do you have any other specific questions regarding it?
Well, some form of low-attenuation light-speed communication is probably best.  Broadcasting an simple yet artificial-looking electro-magnetic waveform is best at this point.
No it does not, for several reasons. In fact, events like these support the conclusion that our climate is changing.For starters, no single weather event proves or disproves climate change. Climate by definition is looking at long term trends. Climate change today is occurring on a global scale over years and decades. While this can seem like a long time, and it's long enough to look at climate, keep in mind that in terms of the Earth's ~4.5 billion year history, this is extremely rapid. We have climate change events recorded in the geologic record, and while it has happened before, this event is occurring very quickly. Regardless, what we're looking at is a trend, which requires taking data over that time frame and fitting a line to those points. This has a couple implications. One is that aberrant events do happen. Statistically, subsequent events are likely to fall closer to that trend line. This is known as [regression towards the mean](_URL_3_). It means that a year of relatively cooler weather following an extremely warm year (or a year of fewer extreme storms following a very active year) does not negate the trend even though from an individual perspective it seems to. Another example would be a year of relatively more sea ice, which is used as an indicator of warming polar temperatures, following years of record lows. The expansion of sea ice seems significant in the very short term, but the longer trend still shows a significant decrease in the ice. This is illustrated in [this GIF](_URL_4_) (from [this article](_URL_10_)).The other implication is that the line describing the overall trend will have points both above and below it, just by the nature of fitting a line to data. That means that some years will be cooler or warmer than that trend predicts.  There can even be several years of stable temperatures followed by a burst of warming. The globe overall is still getting warmer, and [that trend is still there](_URL_2_) (image is from the same article as above).That's generally why you have to look at the big picture here. In terms of increased snowfall, there are a number of ongoing, interrelated meteorological phenomena that can [cause colder, wetter winters](_URL_7_). Warmer Arctic summers and melting sea ice seem to be leading to more atmospheric moisture in the northern hemisphere, which is in turn [causing more snowfall in the winter](_URL_8_) ([additional source 1](_URL_6_) and [additional source 2](_URL_9_), both PDFs).  Events like this can be caused by the [polar vortex weakening](_URL_5_). The polar vortex is a large body of air that rotates over a center of low pressure at the poles. It is cyclonic, so it spins with Earth's rotation. When the polar vortex is strong, it tends to stay more compact around the poles. When the atmosphere, and particularly the stratosphere, warms, the polar vortex weakens and sends cold air down to lower latitudes.  The degree to which this cold air spreads away from the poles depends on high pressure systems that surround it, which is tracked using something known as the Arctic Oscillation index. A positive AO index shows strong high pressure systems, while a negative AO index shows weak high pressure systems and allows that [expansion of cold polar air](_URL_1_). [Here is a recent article](_URL_0_) looking at these trends over the past few years. How much this factored into the most recent snows (like what the AO was around that time) I don't know.
Basically, tides happen because the Earth has a non-zero size (it's not a "point mass"). The gravitational force of the Moon on the Earth is slightly bigger on the moonward side and slightly smaller on the opposite side because gravity falls off like 1/r^2 and r is slightly different. In a simplistic case (say, if the Earth was all deep ocean) this force mismatch results in a tidal bulge (the Earth bulged both towards and away from the Moon) and as the Earth rotates this bulge tries to stay aligned with the Moon. In actuality tides on Earth are a bit more complicated. Both land and oceans respond to tidal forces (i.e. develop a tidal bulge), but the oceans respond with a much greater amplitude. Also, on Earth bathymetry (shape of the shorelines and the ocean floor) plays a large role in the exact timing of high and low tides in a given location because, basically, land is getting in the way of where the water would otherwise go. See also [the Wikipedia article on tides](_URL_0_).The only requirement for a terrestrial object to be affected by the Moon's force is for it to have some mass. For it to be noticeably affected by tidal forces it's size would have to be very large (large enough to be noticeable when compared to the distance between the Earth and the Moon).
Sort of. Several neutrinos from the 1987 Supernova were detected about three hours before the light arrived. However, at the time I don't think anyone made the connection that it was a supernova until after the fact._URL_0_
There was an /r/askscience discussion of this a few years ago:_URL_0_
It's because we all came from a single common ancestor whose DNA was a right-handed helix (spins counterclockwise as you move in a single direction). Thus this structure was passed down ever since then. This common ancestor was assumedly one of the first living things. However, the DNA helix may become left-handed under certain conditions. This DNA conformation is referred to as [Z-DNA](_URL_0_), and may be useful for reducing strain in DNA when it's in the process of being copied, though I don't think its presence has been proven in vivo (in a living thing), only in a lab setting. Feel free to ask for more clarification if need be
In species with tool use, a common strategy is to poke it with a stick.But seriously, it's not something you can generalize. It's like along how animals eat. In ant colonies, a dead ant will give off a particular chemical signal that causes other ants to respond to it as if it's dead and take it to the rubbish heap, and they'll do this even if it's alive and resisting and the signal was just squirted onto it by a mischievous scientist. Meanwhile mammals with a lot of parental care behavior, or animals with strong pair bonding, will respond to the death of their imprinted attachments with behaviors that look like self-destructive grieving.In general, instincts toward a conspecific or toward a predator, prey species, etc. are generally going to differ from instincts relating to a corpse, and there's no high level abstraction needed to "understand" that something is dead. But that's still not really general - the general ways that human animals inuit that their conspecific is dead are going to be common at least to the great apes and likely a lot of others.Maybe you can rephrase your question a little more specifically?
It's all about immune system. All mammals have a similar immune system meaning problems that affect one mammal can likely affect others. Invertebrates immune systems are wildly different and not very well understood currently (horseshoe crabs being a prime weird example).I've never personally seen any literature that suggests that they do have hypersensitivity reactions but it is possible we will find something similar but not the same in the future as we learn more about their immune strategies.
Well physiologist are actually the ones who do this and it can be done in a few ways.You can measure how much oxygen an organism is consuming and how much CO2 they are expelling to approximate how much glucose is being metabolized. This could then be used to determine how much ATP is produced. From there you could estimate how many ATP is used per reaction. I did the math and its around 10^25 reactions in a day or about 10^20 reactions per secondThis is a form of indirect [Calorimetry](_URL_0_)Exercising significantly increases theses numbers.
Actually the space shuttle is really bad in terms of efficiency of it's wings regarding lift and is more like a "flying brick". Just so you can have an idea, the plane the use to train astronauts to land the shuttle needs to be heavily modified so it has a sink rate of 6 times the usual.  A wing is more efficient when is is very long and thin like the ones you find in gliders, or the U2. But in there are a lot of factors the need to be taken in consideration that define how a wing is shaped aside efficiency, like speed at which the aircraft must fly, expected load, limitations of the materials that are used, etc.  in the case of the shuttle, the wing is a something that is really more like a drag inducing appendage to make it slow down and give it a way to return to earth as a glider, but it would not be really useful in a conventional aircraft.
The shape of the arc is roughly a magnetic field line. Solar flares are thought to be caused by [magnetic reconnection.](_URL_0_)
Materials Scientist - The ends of batteries and the terminals on the remote are made from either nickel or steel. In the atmosphere, both of these metals exist with an oxide film. Even brand new, there is a thin layer of oxide on this metal. It just comes with exposure to oxygen.Metal oxide is an insulator that electrons will not travel through. The only reason metal contacts work is that the oxide layer is small enough that either the electron can avoid the oxide atom or it can quantum tunnel through the layer.The other thing going on here is a battery's charge changes as it is drained. A rechargeable NiMH will be 1.4V when it is just charged, 1.2V through most of its life, and 1.1V when it is close to death. Alkaline and heavy duty batteries are similar. The thickness of oxide an electron can tunnel through is related to its voltage, so near death the oxide layer is thicker and the voltage is lower.When you rotate the battery, you remove some, but not all, of the oxide layer and allow new paths to go through and this gives you just a bit longer battery life.
It's not hot enough to boil your blood. You feel pain from the temperature, but not from your blood heating up (in the sense that your blood does not contain heat/pain receptors). When your skin encounters high enough temperature, some types of nociceptors like the wide dynamic range nociceptor respond (their afferent fibers are embdedded throughout your cutaneous tissue). They have varying thresholds of temperature at which they fire pain signals. Others, like myelinated fast conducting A fibers can be triggered by heat (mechanothermal receptors) as well. As a side note, your skin sends pain signals at about 42 degrees Celsius (106 degrees Fahrenheit), although the exact temperature threshold varies from person to person, and areas of the skin to different areas.
Reactors for power generation keep the fission reaction at a neutrally-sustaining level - graphite rods moderate the reaction to control it.  In a bomb, the fission reaction is designed to happen as quickly as possible to release the maximum amount of energy before the generated heat blows the nuclear material apart.
Yes, or at least mitigate it significantly.See [this](_URL_0_)I'm sure there are plenty of reasons this would be difficult with a car, one of which is the requirement to have license plates.
Motion does not require energy.  It would take energy to speed up the moon, or to put the moon into a higher orbit, but every 28 days its in the same place at the same speed.
If you wake up by yourself you will feel more refreshed, as an alarm clock will almost certainly interrupt a natural sleep cycle.
To a certain extent, yes.As you probably know, acoustic waves are mechanical: they exist as the motion of particles in a medium. They have a speed based on the medium (primarily the density and elasticity of the material), and they have a wavelength that's related to the speed and frequency of the wave. The medium, be that a solid, liquid or gas, has it's own properties. One of these properties will be some fundamental length scale. For a solid, it's the size of the lattice structure. For a gas, it's the mean-free-path (the average distance a particle moves before interacting with another particle).Long story short, for an acoustic wave to be self-sustaining, the wavelength needs to be much bigger than the fundamental length scale of the medium. Normally you'd set the limit at 10 times that fundamental scale, but the larger the better. If you go beyond that limit, the acoustic energy quickly transforms into heat, which gets absorbed by the medium. For reference, the Mean Free Path in air at STP is 68 nm, which gives us a maximum frequency of 504 MHz.That said, there are other length scales that can come into play before the distance between particles. For example, the thermal penetration depth tells about how far temperature diffuses during a cycle of the wave. Since sound waves are also temperature waves, if that scale is large compared to a wavelength, the sound will become severely damped. Similarly, the viscous penetration depth can damp particle motion to kill a wave.*Edit: Just ran the numbers, and the frequencies of import for air are these: 50.4 MHz (100x the Mean-free-path), 194.5 MHz (10x the thermal penetration depth), 235.4 MHz (10x the viscous penetration depth), and 504 MHz (10x the Mean-free-path).*
This is actually one of the things we studied in forensic toxicology - the case of [Ross Rebagliati](_URL_0_), a Canadian snowboarder whose Olympic gold medal was in jeopardy after testing positive for marijuana. His defense was that he did not partake in smoking, but was in the vicinity as others smoked.The conclusion in our class is that passive inhalation is usually not enough to give significant blood THC concentrations - one study reporting blood THC levels of 1 - 6 ng/mL right after exposure (to give context: with normal inhalation, blood THC rises to above 100 ng/mL in the minutes immediately after, and settles to about 30 ng/mL in about 20 minutes, in a typical user). And even obtaining that level required _extreme exposure_ - high concentration of smoke and limited volume ("hot-boxing"). Subjects complained of such severe eye irritation that they requested sealed goggles.So my toxicology professor is adamant passive inhalation does next to nothing, physiologically.
Since we don't currently know if life forms exist on the other planetary bodies in our solar system, this is a Very Bad Idea.Recent science seems to indicate that Europa may be mostly water under an icy crust, and if that is the case, life may exist near undersea vents like on Earth, or at the border between the ice and the water. Blindly seeding bacterial life on a poorly understood and unexplored planet would essentially destroy our ability to verify if extraterrestrial life exists there, because from that point on anytime evidence of bacterial or bacterial activity was found, we'd have to spend a lot of effort to make sure that it wasn't actually our Panspermia Thing. This may turn out to be impossible to resolve.So no, this is something we should never, ever do.
The domestication of the cat (and the dog) are both instances of artificial selection. Essentially, humans picked the cats/dogs with the best traits for life among humans, ie, friendliness, companionship. Those that were unfriendly or aggressive were eventually phased out (although, of course, not completely). That could be one of the reasons why cats like to be around people. There are other reasons as well, that have to do with the social structure of cats and their psychology. Generally, among most mammals, it is favored to form alliances with those that can help you. We see this among chimps, for example, who groom each other. Keeping close proximity and affirming relationships through contact / lack of aggression helps strengthen relationships and increases your chances of access to food, help fighting predators, etc.
Not even remotely. With your bison example, neither. They were waiting for it to succumb to its wounds so it'd be an easier kill. They are not sadistic masterminds, they are following the rule of nature in that they want to expend the least amount of energy for the maximum they can gain. Attacking a dominant, defensive bison will almost certainly lead to injury.Wolves almost never attack humans, its very rare. Also wolves are relatively small, the Alpha in The Grey was the size of a grizzly. Seriously it was a film.
In classifying phases and phase transitions, classically we (in condensed matter) rely on local order parameters, such as magnetisation or density. Essentially one can classify phases and transitions by looking at the dimensionality of the order parameter, the dimensionality of space(time), the symmetries of the problem and the range of the interactions. Wilsonian renormalisation formally implements this and allows calculations to predict universal properties of these phases and transitions.Topological ordering is everything else. The term is woolly and its meaning can depend on who you talk to and the context. Take topological insulators for instance; the order parameter is non-local and the result of integrating over momentum space. Another (frequent but not necessary) phenomenon is the existence of discrete, degenerate ground states.My personal preference for understanding quantum systems is real-space (or entanglement) renormalisation of the density matrix, where one progressively coarse grains out high-frequency components, and eventually end up with just a matrix that describes the system. The rank of the matrix then encodes for the "amount" of topological ordering in the ground state. Unfortunately, this doesn't seem to generalise nicely to statistical (rather than quantum) problems.
>  Do all wavelengths of light travel at the same speed?Yes.  In fact, anything massless will travel at this speed at all times.  It gets weirder when you look into relativity and find out that it's same no matter how you're moving, so if you move at 99.99999% the speed of light away from me and I shine a flashlight, you'll still see the light going by at the usual speed. >  If so, what is the speed of light based off of?It's just a fundamental property of the universe.  The definition of the meter is based off the speed of light, but the speed of light is one of those things that just "is". >  What would be the biggest implications (scientifically) of breaking the light barrier?1.  Faster than light travel.2.  Relativity.3.  Causality (the principle that if A causes B, then A comes before B).Only 2 of these can be true.  If relativity and causality are true, then FTL travel is impossible.  If relativity and FTL travel are possible, then it's possible to break causality.  If FTL travel is possible and causality holds, then relativity goes out the window.
What does "verify" mean in this case? If you mean "cogently describe all solutions to", then yikes, this is *way* out of the league of high-school algebra. The difficulty of proving Fermat's Last Theorem is just a tiny baby corner case of the eldritch horrors that lurk in the darkness of algebraic geometry, which is where you have to go to deal with this sort of thing.To be specific, as one small example, here's a perfectly reasonable question in the style you proposed: are there any positive integer triples in the solution set to x^(4) + y^(4) - z^(4) = 0? You need at least some reasonably clever number-theoretic arguments to demonstrate that there are not. If you replace 4 by 400, things get totally out of hand.
There are very strong meta-analyses on the subject which basically show LDL is particularly bad in conjunction with low HDL (cardioprotective). HDL tends to go down when you are physically inactive, smoke, obesity etc.LDL tends to go up when you eat a lot of crap like foods high in saturates.Atherosclerosis is a disease as we age where our vessels harden with horrible fibrofatty plaques that can essentially predispose us to thromboembolic disease if one of these plaques were to rupture and promote thrombogenesis ie. clots in our arteries that can result in a heart attack, ischaemic stroke etc..(sorry if you know this shit). In other words, high LDL is shown to drive this process, with several other factors such as smoking, inactivity, diabetes etc accelerating the process, but the main issue is the high LDL cholesterol and low HDL cholesterol, because that is the stuff that is driven into the structure of your blood vessels, producing these plaques.As we age it happens anyway but to a lesser degree if we look after ourselves. At your age, your cardiovascular risk isn't that high BUT the point is,atherosclerosis is a chronic disease that manifests itself after a long period of time so if your blood levels are constantly exposed to these deranged lipids, you will develop significant atherosclerosis and probably ischaemic heart disease after a few decades... As my professor at uni says ' there's no such thing as an acute-MI ( sudden heart attack) it's taken years and years of preparation through inactivity and eating crap you don't need.'So basically, there is a strong correlation at the moment with LDL and heart disease. I only know this because I've had a consultant of cardiology and epidemiology ranting about this over the entire of last week. (cardiovascular bsc student)Of course there will be doubters, just like 9-11 conspiracy theorists and as you said with climate change deniers and so on. These generally have very poor evidence behind it, often misrepresented in poorly conducted trials and so on.Oh and to improve your cholesterol levels:exercise exercise exercisedon't eat crap, avoid saturates and so on. It's pretty obvious when you're eating crap.don't smoke (just don't)lose weight?Alcohol, a modest intake has been shown to actually improve your HDL!Sorry ranted a bit there but I hope that pushes you in the right direction.
Likely no. I work with several marine-mammal stranding response teams that do necropsies (animal autopsies) on stranded carcasses, and it takes quite a while to cut *into* a sperm whale even when you have large knives, multiple people and can brace yourself on solid ground. (There is an excellent 1-hr documentary on a sperm whale necropsy [here](_URL_0_), for the curious, with a great comparative anatomist). You'd only have a minute or two before you passed out from lack of air; not nearly enough time.
Wind chill doesn't *change* the temperature. It changes how *fast* you loose heat energy. A thermometer will reach the same reading whatever exposed to wind or not, but one exposed to wind will reach it *faster*.This is essentially why we use fans to improve the function of heat sinks. The fan moves air over the heat sink, allowing more air to touch the hot surface, and carry away heat.
It undoubtedly depends on the snail, its envirionment, and a few other factors. However, snails are likely incapable of sustaining top speeds for long periods of time due to depletion of the mucous membrane. The freshwater snails that I study take on average 106 seconds to traverse 1 inch.
Ze French 'ave used this for ages to [ouvrir bouteilles de vin](_URL_0_).
Head colds actually significantly impacted Apollo 7, the first manned Apollo launch.  All three astronauts developed head colds during the course of the 11-day mission.  They became snappish and irritable, and refused a number of orders from the ground.  The blame for this "mutiny in space" is mostly placed on mission commander Wally Schirra.  One of the original Mercury 7, he was NASA's most senior astronaut and the only person to fly in all three manned rocket programs: Mercury, Gemini, and Apollo.  When he began refusing to cooperate, his two crewmates followed his lead.  Experiments outside the scope of testing the new capsule were scrapped, one of those "live from space" TV interviews was refused, and the entire mission took on an air of stubborn negativity.  Everything came to a peak before re-entry: the astronauts were supposed to put their helmets on, in case of depressurization.  But the astronauts, with head colds and fearing burst eardrums, wanted to be able to pinch their noses to equalize their sinus pressure as they landed.  They ended up disobeying a direct order to put their helmets on, and Schirra basically told the flight director to go to hell.None of the three astronauts flew again: Schirra retired, while the two younger astronauts kept their jobs but were permanently grounded.  Schirra actually used the experience to star in commercials for a cold remedy.For later missions, I'm unaware if illness has ever significantly affected performance.  However, there have been recorded infections: at least 29 according to [this article from 2012](_URL_0_).  These can potentially be serious, as zero gravity is a terrible place to get sick.  For reasons we don't really understand, the immune system is significantly weakened in zero-g, while pathogens are strengthened.  And the aerosol cloud from a sneeze doesn't drift to the ground like it does on Earth - it just flies outward, to land on and stick to all the instrument panels and such.  Infection control in space is serious business.
A qubit is the basic unit of information in a quantum system (it's exactly analagous to a 'bit' in conventional computing). A qubit can be made of any two-level quantum system that exhibits entanglement and superposition. The hydrogen atom is a useful model for this, but more commonly scientists will create an 'artificial atom' because they can be constructed to have specific energy gaps that don't occur naturally in atoms. Common models include partially-superconducting circuits, quantum dot electron traps, microwave cavities, etc.A qubit, unlike a regular bit, doesn't just exist in state |0 >  or state |1 > ; it can exist in any superposition of those two states, e.g. Y = A*|0 >  + B*|1 > . This is sometimes represented using the Bloch sphere (the state of the qubit represents a point on the sphere).Qubits achieve the special quantum computing outcomes they do because when you perform an operation on them, you're effectively performing it on multiple states at the same time with relevant probability weights between each. This makes a quantum computer really good at certain types of operations (factorising large numbers is one, 'searching' or oracle algorithms are another).
I asked Ron Ellingson from Mount Baldy Ski Lifts (who provides the balls) and he replied: The balls are black because of the uv protection in the balls. They last longer. Black blocks the sun which is what warms the water .
Water absorbs least strongly at around 470nm. Interestingly, the highest spectral irradiance (a wavelength dependent measure of irradiance) of sunlight at sea level is also around 470nm (exercise to the reader to figure out why :D). This means that blue light at 470nm travels furthest through water (this is why water is blue). I'm not sure where the "dark zone" starts, we can define the cutoff as 1% of original intensity. If the absorption coefficient a of water at 470nm is .0002, we use d = 1/a to determine the distance at which the intensity of light is reduced by a factor of e (2.718). Continuing this math, we find that only 1% of 470nm light is present after 230m, which corresponds very nicely with this diagram: _URL_0_TL;DR Apparently pure water is not that much clearer than ocean water.
Even though changes in the gravitational field propagate at finite speed (c), and it takes about 8 minutes for signals from the sun to reach Earth, the Earth accelerates toward where the sun is **now** rather than where it was 8 minutes ago.[Here](_URL_0_) is a paper explaining why.
AT & T has a [doc](_URL_0_) comparing energy consumption between UMTS (3G) and LTE (4G). It depends. Overall it seems too me that despite of: >  The bottom line is that while LTE is much faster than 3G, it also uses more energy...when you also regard the much higher data rate it's more energy efficient per transmitted KB.
Maybe this is too far off topic, but it's reminiscent of the way we think about cliches and colloquialisms. If you hear a phrase repeated to you throughout your lifetime, you may stop thinking consciously about the literal meaning of the words while still understanding the implication of the phrase.
All of the metals you listed do indeed function as enzyme cofactors, as do most trace, essential elements of the human body. I'll go over each and some of their basic functions:**Copper** has the most different functions of the metals you listed. It is extremely important for essentially all levels of life. It's primary functions in humans are the facilitation of metabolic processes, human development, and erythrocyte synthesis. Biochemically, it serves as a cofactor for various oxidase enzymes around the body.Source: _URL_2_**Selenium** is a bit more niche. It is involved in the synthesis and function of glutathione peroxidases, which serve to protect the body from harmful oxidation reactions. Specifically, selenium atoms are contained in selenocysteine, a rare amino acid, which are residues in selenoproteins. Glutathione peroxidases are a category of selenoproteins. Finally, thioredoxin reductases, which are involved in sulfur bond formation, are also selenoproteins.Source: _URL_0_**Chromium's** mechanisms are less understood, but it is believed to be involved in metabolism of carbohydrates, lipids, and proteins, as well as insulin release.Source: _URL_1_**Molybdenum** is also an enzyme cofactor. It has a known role in the function of sulfite oxidases, xanthine oxidases, aldehyde oxidases, and mitochondrial amidoxime reducing components (mARCs).Source: _URL_3_A few others that you might be aware of are iron, well known for its role in oxygen transport, and magnesium, which is often used to stabilize phosphate groups in phosporylated compounds.
This is somewhat complicated -- the answer will change depending on if you mean by volume or by mass. I believe that by volume the answer is yes, because otherwise your lungs would be constantly expanding or shrinking. I think that by mass the answer should be that we breathe out more than we breathe in, because we convert oxygen to carbon dioxide and we add some water vapor. However, I don't have a source for this so this answer is just temporary until someone with a source or more authority can respond.
I think you would probably be better off just taking the aforementioned capsule before eating. It's hard to say whether the vitamins in the powder would be able to withstand the boiling process. I'm by no means an expert on these things, but I would think that if you prepared your rice, or what-have-you, then took the supplement before eating that it would be just as beneficial as having it in a smoothie - after all, it's just tossed into smoothies, so it shouldn't be a problem. Maybe call a local nutritionist to get some more precise info on it? Either way I hope whatever you choose to do works out for you. ^.^
Friction is a good culprit in mechanical systems, but equivalent types of loss occur in other systems (e.g. viscosity leads to drag in fluids; randomization of electron paths leads to ohmic resistance in electrical systems).I think the concept you're reaching for is this:  it is never, in practice, possible to create a completely ordered system, and slight amounts of disorder in any energy-transducing system will yield loss of ordered energy (mechanical, electrical, chemical) to disordered energy (heat at uniform temperature).   Friction is due to lack of order in the physical shape of sliding solids on the molecular scale, or to viscosity in liquids or gases -- which in turn is due to momentum transfer by disordered molecular motion perpendicular to applied shear.  Electrical resistance is due to disorder in the electron-nucleus interaction in a conductor.  Etc.The problem is that such statements have to be so general (to encompass all the forms of disorder and of ordered energy) that they just boil down to restatements of the second law of thermodynamics.
Inheriting two copies of the gene usually leads to death in infancy [1], and a lot of achrondroplasic dwarfs have chronic pain, which would cause a general decrease in "fitness" (in the Darwinian sense). It seems fair to say it probably puts people at a pretty serious sexual disadvantage as well. 1. _URL_0_
Erm, I'm not going to answer all of your question, but I'll just pick up on a few points.There are several models used to describe a nucleus. Science describes models rather than reality. One model of the nucleus is the liquid drop model that sees it as a sphere analgous to a drop of water. If this droplet is too large - eg in a U238 nucleus, it is unstable, and nucleons can spontaneously be emitted. (This isn't a prefect model by any means, but was one of the first used to describe radiation due to nuclear decay).As to quarks - they are seen as point like particles and the quarks in the nucleons are held together by the strong force. They are also moving around very quickly - so fast that the majority of the rest mass of a nucleon is due to the relativistic increase in mass of its constituent quarks.
Designing a computer language is a pretty tricky business, really. There are a lot of tradeoffs to be made, which explains why there are [so dang many](_URL_10_) of them. When starting a new one from scratch, you ask yourself a lot of questions. Ultimately, the question that matters most is, "What do I want to be _easy_ in this language?" You might even call it the First Question of Computing.That's only half the problem, however. To understand the second half, let's take a little detour into the mid 20th century, and look at computers themselves.Now, ever since [the first computers](_URL_28_) came online, we brave and foolish folks who program them have had a vast number of varied answers to this question. Some folks wanted to [make war simpler](_URL_11_), some wanted to [make intelligence simpler](_URL_23_). But in general, the early computers were often single purpose machines.Enter [ENIAC](_URL_17_), which is often called the first "general purpose" computer. All of a sudden, we had a machine which could do a lot of different things. This was exciting! And terrifying at the same time. How do you tell a computer the size of a small house that you want to calculate the logarithm of any number you give it, just as a simple example?The answer was to have a very small number of very simple instructions that the computer could perform, and then build up from this small [instruction set](_URL_6_), combining them in various orders, until you eventually make a "program" that does what you want. Amazingly, this still holds true today! Your typical PC running what's called the [x86 instruction set](_URL_3_) is basically just performing a bunch of the same small(-[ish](_URL_19_)) number of instructions over and over, until you get [what you wanted](_URL_5_) to get.[As a brief aside, mathematicians had already attempted this reduction of an algorithm to the most [basic set](_URL_31_) of operations and postulates - let's just say it [didn't go so well](_URL_21_), and both mathematicians and computer programmers are struggling with some [fundamental problems](_URL_9_) that fell out even today.]One key feature of almost all instruction sets is their emphasis on arithmetic. There's a reason we call computers "computers", after all. The designers of the earliest computers answered the First Question of Computing with "I want _math_ to be easy." So computers got really good at math, [really quickly](_URL_18_).Unfortunately, as the things we asked computers to do became more and more complex, it became very tedious to construct programs using that very small set of possible instructions. One particularly [forward thinking programmer](_URL_7_) decided one day to add a [layer of indirection](_URL_22_) between the program writer, and the machine. Basically, she decided to answer the First Question of Computing with, "I want to make _writing complex mathematical algorithms_ easy." The first of the truly great computer programming languages, [FORTRAN](_URL_27_), was finally born.FORTRAN allows the programmer to type things like "do the following thing [10 times](_URL_2_)", written not in instruction-set codes, but in plain old [English](_URL_32_). This was an enormous step forward, but involved some sleight of hand behind the scenes. Basically, the FORTRAN compiler would read in the program which was nice to human eyes, and for each line of code, it would create a bunch of those instructions from the instruction set that [preserved the intent](_URL_12_) of that line of code, but could now be executed by the machine. This truly was wizardry of the highest order.Very much like a growing baby, FORTRAN changed and grew as the years went by, as different people asked it to answer the First Question of Computing in different ways. Computers started to get smaller and faster, and made their way into the home. All of a sudden, folks much like myself started to give [_very_ different answers](_URL_15_) to the First Question of Computing. We were playing with the computer, exploring what it would let us do, what it could be pushed to do.With this large set of new things that people wanted to be _easy_ to do on a computer, a whole slew of new languages popped up. Some of them let you [manipulate lists](_URL_20_) really easily, some of them let you [manipulate hardware](_URL_0_) really easily. In each language, it was easy to do some things, but remember those tradeoffs I mentioned right at the beginning? They were right about to bite us programmers in the butt.In C, for instance, it is in fact very easy to manipulate hardware. Many [operating systems](_URL_13_) are written in C for just this reason. Unfortunately, making it easy to manipulate hardware makes it really hard to [manage your computer's memory](_URL_8_), among other things. C programmers spend a lot of time worrying about where _exactly_ they stored this variable or that string, how to get rid of it, how to let other parts of the program know where it is. Needless to say, if you're not answering the First Question of Computing with "I want to make hardware manipulation easy", C is going to give you a rough ride.The designers of [Java](_URL_25_), for instance, answered the First Question of Computing with, "I want to make [running on lots of different machines](_URL_30_) easy". While the jury may still be out on whether or not they succeeded, they did have a clear vision because they succinctly answered the First Question of Computing. (A few other global principles went into the design as well, of course.)Now for each of these new computer languages, you'd have a different [grammar](_URL_1_) that defined what a legal line of code looks like, much like English grammar is different than Finnish grammar. Both let you speak and [convey meaning](_URL_16_), but they sound pretty darn different.What's the same, however, is that for each line of code in the "high-level" language, we use a compiler or interpreter to transform our friendly code into the kind of instructions the machine likes to read. This constant, this fundamental purpose of the compiler, is the second half of designing a computer language. First it [parses](_URL_26_) your friendly code, then [generates](_URL_24__generation_(compiler\)) machine code.We can now hopefully answer what it means to create a new programming language. First, you need to answer the First Question of Computing. Once you have decided how _you_ want to answer that question, then you write the grammar that fulfills your answer, and the compiler that translates your grammar to the grammar of the underlying machine instruction set.This process, this mapping between two different levels of representation, but a map that _preserves meaning_, is far and away one of the most amazing ideas I've ever learned about. It has applications in a huge number of different [endeavors](_URL_14_), across all [walks of life](_URL_4_). It is the idea of a [_code_](_URL_24_). The fact that you asked this question means you've taken your first step into a truly amazing journey. Stay curious :)
The second one is kind of BS but said a lot.  In reality light (i.e. photons) doesn't travel through materials at all.  Light is an oscillating EM wave and when it is incident on a solid surface its electromagnetic field INDUCES a corresponding polarization within the material.  By polarization I mean a net local squishing of the positive (atomic nuclei) and negative (electrons) charges in the material.  In general there are equal numbers of positive and negative charges but when they are spatially separated, or squished, you get a brief net dipole of polarization.  When we talk about "light" moving in a material we really mean this polarization wave and it necessarily travels slower than light.  When it reachs the other side it effectively induces a net varying electric field at the surface which then is basically a light wave coming out the other side.From this perspective it it easy to see why it's not too mind bending that waves of instantaneous polarization propagating through a material are slower than light and how that presents no relativity or causality concerns.
Here's the shot on youtube, it's only about 20 s long:_URL_0_Two major errors stand out as very wrong to me.  I see from the wiki page for the movie that the planet is much larger than earth, and in orbit around the sun.  I'll assume it is twice the radius of the earth* The other planet is moving ***wayyyyyyyyyyy too fast***.  A collision between earth and another planet in an orbit near earth's would be on the scale of the planetary escape velocity, so probably a few 10's of km/s.  We can do a quick estimate of its speed from the movie.  Assuming the field of view of the camera is about 30 degrees wide, I see that it went from spanning 20 degrees to 30 degrees between the 3:03 and 3:14 marks, which means it covered... (back of the envelope trig)... 24,000 km in those 11 seconds, which means it is closing at about 2,200 km/s. That's about 100 times too fast!* No tidal effects and earthquakes.  The planets would have been tearing each other apart from tidal effects before they hit.  See the Roche limit, linked in this thread.  They would not have been sitting peacefully, they would have been tossed around, possibly into a (literal) vast chasm of darkness.Edit:  because the collision is happening so ridiculously quickly, there may not have been too much time for the tidal effects to do much.  The wiki page says that the planet made a close pass earlier in the film, and surely that would have caused major tectonic havoc.
> So, to control the power of the gun, you only need to adjust the amount of power being supplied? Yes. Powerful railguns build up their power through letting the charge in capacitors or pulsators build up over time. > and the fire button is basically just a switch allowing the current to flow? On simple designs, yes. In more complex systems(such as high power railguns like those I mentioned above), the fire button/trigger would connect to a circuit that tells the capacitors to begin building charge. > Also what is the armature?  In this case it's the projectile. You may want someone more qualified to answer this subquestion.
Off the top of my head, not that I've heard of. If we did, the main identifying features would be the abundances of elements and isotope ratios in the object - however, we're not really too sure of the compositions of the Asteroid Belt or Kuiper Belt, let alone the Oort Cloud! It could well be that some interesting surprises turn up as we study these in further detail.
The black hole would do the pulling like any normal way. The quark outside the black hole will have its pair created, nothing special. As for the one that falls inside the black hole, another forms, but both are destroyed (or whatever actually happens) as it reaches the singularity. The black hole increases in mass/energy.But wait, did we see a breaking of conservation of energy in this? We started off with a black hole and a pair of quarks, but we ended up with an identical pair of quarks and a black hole of slightly larger mass. Where did the extra mass/energy of the black hole come from? Someone else know what's not right here?Edit: thanks to /u/dgm42 for realizing that the extra energy comes from holding one of the quarks from being sucked inside the black hole!
Not quite, but basically yes to within a few degrees.[Wikipedia has the exact values.](_URL_0_)What about this question interests you?
Energy is not an emergent property, even a single particle in free space has energy.Fundamentally, energy (or really the Hamiltonian) is the generator of translations through time. Whether you're doing quantum mechanics or classical mechanics, if you know the state of your system at one instant of time, the Hamiltonian is what ultimately determines what the state of your system will be in later instants of time. The Hamiltonian is often equivalent to the total energy in your system, but not always.
To represent negative numbers, you use the first bit to represent the sign (and also [two's complement](_URL_0_) to solve the addition problem you mentioned, but that's not so important here). For example, in an 8-bit byte, you can use the first bit as the sign and the remaining seven bits as the number. However, you don't *have* to do this - you can instead use all 8 bits to represent a number.This means that a byte can represent either the values -128 to +127 (an signed integer, because you use a bit for the sign), or the values 0 to +255 (an unsigned integer).Internally on the CPU, it makes no difference - what's important is how the value is interpreted afterwards. You can certainly get some interesting results if you interpret a value wrongly! Another consideration is that unsigned integers can represent larger positive values than signed ones - in some cases this may be important in the design of a program.
Fire in the classical sense as we know it burns around 1000 degrees Celsius.But you can still have a combustion reaction and a flame on lower temperatures, down to 120 degrees Celsius. This has lately been researched a bit on the International Space Station as these flames are a lot easier to study in microgravity.These cool flames have a completely different chemistry and produces carbon monoxide and formaldehyde instead of soot, carbon dioxide and water vapour.You can find some more information if you are interested [here.](_URL_0_)
>  air bodies have a very hard time crossing the equator.There's a ~1 year timescale for equatorial transport (see Fig. [4-12](_URL_0_)) and a 5~10 year timescale for strat-trop exchange (see Fig. [4-24](_URL_1_)). >  What was the mechanism that lead to CFCs being able to concentrate so well in the Southern hemisphere?CFCs have 100+ year lifetimes.  This leads to them being roughly uniformly mixed in the troposphere and stratosphere.  CFCs don't actually break down until they get very high up in the atmosphere where they're exposed to high energy photons.  So strat-trop exchange is fast relative to the lifetime of CFCs, thus they can reach high concentrations in the stratosphere.The ozone hole occurs due to some crazy chemistry and very particular atmospheric dynamics.  There are four main factors leading to the ozone hole:1.  **The production of CFCs:** CFCs are inert in the troposphere but can photolyze high in the stratosphere, (CFC-12 example: CFC2Cl2 + hv - >  CF2Cl + Cl).2.  **The polar vortex:** The polar vortex "isolates" the south pole allowing chemistry to proceed unimpeded. This also causes very cold temperatures (180~190K in the polar winter).3.  **ClO-dimer chemistry:** The ClO-dimer breaks at the Cl-O bond, not the weaker O-O bond. This allows for effcient recycling of ClO that wouldn't occur with the [standard ClOx cycle](_URL_2_) ([O] is too low).4.  **De-nitrification of the stratosphere:** HCl and ClONO2 can react on PSCs (HCl + ClONO2 - >  Cl2 + HNO3) and free Cl from two reservoirs. HNO3 can then deposit from the stratosphere, thus eliminating potential Cl reservoirs.Edit: Fixed a typo on the second figure number.
We don't know what happens inside a black hole, it's an open question in physics. According to general theory of relativity, a black hole forms a point with infinite density, and within quantum field theory there are no black holes. There is an ongoing effort to create a theory that can unite GR and QM to hopefully solve this problem. >  Doesn't this mean that a sufficiently massive neutron star could bend light enough to let none escapeNot quite. If an object does not let light escape, it means it cannot hold itself, because repulsive forces that prevent the object from collapsing (such as EM/strong/weak forces) cannot propagate "outside", and outer layers just fall.So once an object is dense enough that it doesn't let the light out, nothing can stop it from gravitational collapse.
sucli and gyri (the grooves and ridges, respectively) exist to increase surface area of the neocortex.  This allows for more grey matter, which is where things like spacial reasoning, decision making, language, and most 'intelligent' behaviors occur within the brain.
Turbines can only really do work on dry vapor without being completely destroyed by cavitation. The real energy storage/ release is usually in phase change, so that makes turbines impractical for that kind of task.
energy in * efficiency = energy out.The energy you put in is 30kg(300N) multiplied by 0.33 m pump stroke. That's 100J.The car weighs 20kN so 100J will raise it by  100/20,000 = 5mmIn practice you'll also lose some energy in friction so the rise will be less.
This isn't really a science question, more of a social science question. However I'll take a gander...  > At what point did the need for individual names ariseFirst names couldn't have come about before the development of language. The origins of language are highly debated but two basic ideas stand out:1. That language developed over time from pre-linguistic systems from our pre-human ancestors and gained complexity within modern homo sapiens species.2. That language is strictly a homo sapiens trait, which developed quickly at the onset of our speciation and is unique to us.  I am more in camp 1 given the information we have at hand about proto-languages (including the possible use of gestural language). In any case modern language arose a long time ago, in the early stages of our species history some 250,000 - 100,000 years ago.Moreover your question would raise a secondary question of how complex does language - or the communication of ideas - have to be to be in order to have names? We may also ask if their cultures necessitated names. Just because names are possible does not mean they are used, or need to be used.I guess my answer is I don't have a clear answer to that question. > Many domesticated animals know their name when we call them, and they respondThis is more of a conditioning response, the animal (probably) does not "know" that is is named "calvin". Part of understanding the meaning of a name involves theory of mind which is knowing that you are a separate being from other beings with your own independent thoughts. I know my thoughts differ from yours, and I also know that you have thoughts of your own. Some animals have been observed to show theory of mind mainly - dolphins, apes, other primates, birds (crows, ravens, pigeons). But the depth and complexity of this knowing the self and others is unknown and debated. I am inclined to think that an animal responding to its name is more of a conditional response then an actually knowing of self. That being said... > Do we know if animals have proper names for each other in any wayNo, we do not know if animals give proper names to each other because we do not speak the communication of animals. Communication is complex, and its not really solid yet whether animals actually link particular sounds up with particular meanings (semantics). So that Call A means "hawk! duck down" or if Call A just elicits the response to "duck down" without the animal thinking through a complex thought process - "ok hawk above me, look quickly, then jump down into the canopy for cover". Lots of debate, my personal opinion is that there is some semantical meaning to animal communication systems, however it is not as complex nor as adaptive as human language.That being said animals can recognize individuals and remember individuals based on previous positive or negative acts directed towards them. Patterns in fur, stripes, size, pheromones... all are cues used by animals to recognize familiar and unfamiliar individuals of the same or different species.  Moreover groups of animals can recognize members of their own group or members of other groups based on calls. They have no need for a name - their physiological traits and calls are their "name".I hope this clarifies things a bit...
The Ventricaria ventricosa is not exactly a "traditional" single cell organism. It contains sections of cytoplasm with a nucleus and chloroplasts. You could see this sections as single cells, but without the membranes. They form together this rather big structure, which is stabilised by a central vacuole and cytosceleton.So no, their organelles are not enlarged, but it has a high percentage of cytoplasm, like most cells.
We use the same techniques on thin skin and thick skin. Some areas like the scrotum and large breasts are very forgiving and scarring is terrific. In young people upper shoulders and back, while treated the same, scar much worse.
No it has never been done and no it will never be possible. I really wish that it weren't such a common thing in sci-fi, because it simply does not have any basis in scientific fact.
Anyone feel free to correct me, but I believe the problem isnt the computer screen so much (even though they do cause some strain) - but more so sitting in front of an object with the same focal length for long periods of time. In a lit room/during the day, you constantly have different objects in the room to focus on. In a dark room, there is nothing to refocus to so the eyes become 'lazy'.
Yes, slightly.However when shaking it around, you are also increasing the heat transfer between the air in the container and the ice in the container, the ice and the water, etc. The reason the heat transfer will increase is because you will now have forced convection rather than natural convection. This would have a much more significant effect than the kinetic energy.
It just depends on whether the causative effect leaves a record on something that is persistent enough to be viewed later.  Craters on the Moon, for example, provide records of collisions from long ago.  The distortion of space-time creates a measurable pattern in the cosmic microwave background radiation.  There was nothing to undo that distortion, so it was still present when the cosmic microwave background (not microwaves at the time, actually) formed 380,000 years after the Big Bang, so it was imprinted on that background.  In the billions of years since, the cosmic microwave background has not changed in pattern, only in scale as the universe has expanded (including an elongation of the photon wavelengths themselves); this is because the universe is essentially transparent and so the photons in the background radiation have had next to nothing to affect them in the past 13+ billion years.
I've been checking this post for the last 7 hours refreshing now and then, and I'm sad that no one has replied here yet, I'm really interested in this as well.
Infinity doesn't imply ~~certainty~~ totality.  For instance, there are an infinite number of real numbers between 0 and 1, but none of them are 2.
Practically, it is slower than the speed of light, because of the capacitance of the wire (which is very roughly about 10pF a foot, depending on the wire). With long, fine/high resistance wires, this can make for a significant filter. But in a theoretical, frictionless, vacuum world, one often says it happens at the speed of light.But it's worth mentioning that the delay cause by these so called parasitic capacitance are real and significant in computing. Indeed, it is my understanding that the delay even if there was zero capacitance, i.e. just the speed of light is an important and relevant limit in the designs of CPUs. That is to say, it would take about 30 picoseconds for light to travel from one end of a CPU to the other. That limits the speed of a CPU to 30 gigahertz. While that is a way away from modern CPU limits, it's not really THAT far at all.P.S. just for the pedants. Yes, I know the gate capacitance of the transistors is far far more important, but still, the point was to illustrate that the speed of light, while fast, is actually getting kinda slow for modern computing.
This article says that the idea that gravitational and inertial mass are unequal depending on gravity fields is **only a hypothesis**, promoted by this guy but hardly in wide currency in physics. There is as of yet no evidence that they are unequal in any circumstances.
>  >  given the intensity of radiation is greater in the forward direction, will the source not be acting like a photon drive, and hence decelerate?No - the total force due to the photons emitted in the forward and backward directions will be equal in the reference frame of the moving object. Hence, no deceleration in any and all inertial frames.Edit: this is because all inertial reference frames agree on whether there is a net force acting on the object. No net force in one of them means no net force in all of them (and correspondingly no acceleration).
The spots are essentially the vaporized remnants of bomb casing and test stand. The spikes are vaporized guy wires. I hate to use Wikipedia as a source, but its articles on the Trinity test and surrounding topics are surprisingly well-written. _URL_0_
In a very large system, say a balloon full of gas, there are only a few numbers we use to describe it: pressure, temperature, volume. These define the macroscopic state, or macrostate, of the system. But there are many many possible microscopic states (microstates)---positions and velocities and rotations of the molecules making up the gas---that correspond to each possible macrostate.The assumption of thermodynamic equilibrium is that all of the possible microstates that are consistent with any conserved quantities, like energy, are equally likely, since there's no reason to prefer one over another, and they typically change between microstates very frequently.But different *macro*states have different numbers of *micro*states, so the macrostate with the *most* microstates is the most likely.In this picture, entropy is just a measurement of how many microstates a given macrostate has, so the macrostate with the most entropy is the most likely one.There are a few more details to work out, such as the fact that the number of microstates typically is exponentially large, so entropy is the logarithm of that number; and because of that exponential behavior large systems (with ~a mole of particles) are overwhelmingly likely to be found exactly at the state of maximum entropy (within experimental precision), even though the underlying process is random. It's also necessary to connect this definition of entropy with classical ones (such as the change in entropy being equal to heat flow per unit temperature).
[Only about 0.001% of all the Earth's water is in the atmosphere](_URL_0_). > If all of the water in the atmosphere rained down at once, it would only cover the globe to a depth of 2.5 centimeters, about 1 inch.
Most types of cells used in a cell culture systems (e.g. HeLa cells) can easily be grown to really large numbers without having to passage them too often. Passaging just means that you take the cells from one surface (or one suspension) onto a new one, ususally with a smaller number of cells. These cells are then fractioned into small numbers (usueally still more than 100k cells) that can be frozen in liquid nitrogen at 77 K (or −196 °C).In this frozen state the cells can survive for several decades and be thawed up and reproduced when needed. There are special institutes keeping copies of these nearly original cells which a company can order and use for their research. Or they can simply freeze and store the cells by themselves.Source: I am a lab technician working with cell cultures
The electrical load on each dynamo would determine how much force was exerted on the wheel so they wouldn't necessarily be the same. I doubt it would be noticeable but it would slow you down or cause you to pedal harder to some extent.
There are three categories of causes of volcanism common within ocean basins:1) [Subduction related volcanism](_URL_0_) (the one you mentioned) which tend to form [island arcs](_URL_3_). Japan is an excellent example (along with a host of other archipelagos in the South Pacific).2) Hotspot volcanism, the best idea for these still being that they are the result of a [mantle plume](_URL_1_). The Hawaiian islands are a good example of hotspot volcanism.3) [Mid-oceanic ridge](_URL_4_), where two oceanic plates diverge and a string of volcanoes form, e.g. the Mid-Atlantic Ridge.Of these three, the first two tend to form emergent volcanoes (and sometimes pretty significant landmasses, e.g. Japan again) where as the last only forms emergent islands in somewhat odd circumstances (e.g. Iceland, but there it seems you have a plume located under a ridge).As to how they become islands, largely it's from successive eruptions. I.e. at some point a particular vent system initiates, it erupts and creates some amount of topography on the sea floor. If that vent system keeps erupting in roughly the same place the volcanic edifice will gradually build up. If enough eruptions happen for long enough, the edifice may be high enough to be emergent. An additional important contribution is [isostasy](_URL_2_). Generally, hotter crust will be a little less dense and thus more buoyant and will 'rise' higher than surrounding cooler oceanic crust. In the case of sustained magmatic activity, you are maintaining a heat source (keep a region of the oceanic crust a little more buoyant) and building topography through successive eruptions.With that bit of info, we can return to the three broad types of volcanism and see why the first two tend to build emergent topography and the third generally does not. For subduction related volcanism, barring changes in the angle of the subducting slab, magmatism will be located in roughly the same spot in the over-riding plate for a long time (10s to 100s of millions of years) as subduction continues giving you both the heat and magma production to build up volcanoes that will be emergent. For hotspot volcanism, the over-riding plate is moving with respect to the hotspot (imagine a piece of paper moved over a candle flame) giving you trails of volcanoes (i.e why the Hawaiian islands are a chain) but here the magma and heat supply are sufficient to have a lot of eruptions (to build up topography) and a lot of heat (to buoy up portions of the crust) at least while a particular region is in the vicinity of the plume (these tend to erode and subside once the hotspot is passed, e.g. compare the big island of Hawaii with the lesser islands and the Emperor sea mount chain). For spreading ridges, the heat and magma source is localized along the ridge axis and the amount of melt produced is generally not as large (or at least as localized) as in a hotspot, and the eruptive products are constantly moved away from the heat/magma source so they don't get new contributions of eruptions and they cool and sink, generally precluding these from ever building enough topography to reach the surface of the ocean and become emergent.
Panic attacks have been shown to cause pretty strong dissociative symptoms such as depersonalization or derealization. The dissociation is the brains defense mechanism against the feeling of a panic attack. This would explain the feeling with your body, which to me sounds a lot like depersonalization.
Specifically it is a non polar molecule called lycopene that is causing the stains.  The plastic is porous and it enters the pores and diffuses through the container.  To help prevent this you can rub the container down with a little butter before dumping the sauce in.
We don't exactly know what happens when a tiny black hole evaporates into nothing. We don't have a theory of quantum gravity, but there is a consensus that it would just release some x-rays and then stop existing; we are trying to create tiny black holes in particle accelerators now,
Short version: all of spacetime has infinite volume.Longer version....You are asking about how to calculate the hypervolume of spacetime, which is a 4-dimensional manifold. Putting issues of how to define such volumes in a coordinate-independent way aside, the only interesting spacetimes are *non-compact*. A compact manifold, intuitively and roughly, among other properties, has finite volume. (For instance, spheres are compact.)Physics is arguably interesting only on so-called *globally hyperbolic* spacetimes, which are spacetimes that satisfy an additional technical property that basically says that if you are given initial data in all space at some instance of time, you can find everything you want for all time in the future and past. Globally hyperbolic spacetimes turn out to be homeomorphic to R x S, where R = real numbers (essentially, the time axis) and S is a 3-dimensional manifold. Since *R* is not compact, neither is the spacetime. In simple terms, the only interesting spacetimes are those that are non-compact, and so *should* generally have infinite volume under any meaningful definition of spacetime volume, although there are exceptions. (For reference, the proper volume element is √(-g)d**x** where *g* is the determinant of the metric tensor and d**x** is the usual 4-dimensional volume element, so something like dtdxdydz. [See this response below](_URL_0_) for an example of non-compact spacetime that has finite hypervolume.)Having said that, the cosmological models all describe the universe as some spacetime homeomorphic to R x S, where S is the topology of the spatial universe (several possibilities for *S*, but the most commonly considered one is flat space R^(3)). You're right that, in a sense, the volume of any region of spacetime should really be something like the 3-dimensional volume of the spatial cross-section times the 1-dimensional length of the temporal cross-section. Since we commonly assume the spatial universe is infinite, the entirety of spacetime is also infinite. Again [see below](_URL_0_) for an example of a non-compact cosmology that nevertheless has finite hypervolume.---For the math-inclined, there are actually better reasons why the only interesting spacetimes are non-compact. For one, a non-compact manifold always admits a Lorentz metric. But a compact manifold admits a Lorentz metric iff its Euler characteristic is 0. (So the 2-sphere does not admit a Lorentz metric, but the 2-torus does.) Second, and much more important, if a spacetime is compact, its so-called *chronology violating set* is necessarily non-empty, which means the spacetime must have closed timelike curves. This necessary violation of causality means that all interesting physical spacetimes must be non-compact. >  Side question, do we know what region of the universe is the oldest? Youngest?If you measure the age of a region by the time since the big bang, then I suppose a particle whose world line is both at rest with respect to the CMB frame and which has avoided gravity wells (like black holes, stars, etc.) the most will measure the universe to be oldest. In the FLRW model of cosmology, in which the universe is homogeneous and isotropic, the universe is oldest in the isotropic frame (CMB frame). The universe can, in principle, be arbitrarily young, as seen by an observer traveling with speed arbitrarily close to *c* with respect to the CMB frame.
Short answer: We don't completely know. It has to do with how [neurons](_URL_0_) work and how neurons are structured and connected.Long answer: We know many of the mechanisms that allows the [brain to learn new things](_URL_3_). The term for this 'automatic' behavior is (not surprisingly) called '[Automaticity](_URL_5_)'. The exact mode by which automaticity occurs is still contested, but [neural plasticity](_URL_7_), [habituation](_URL_8_) and [neural adaptation](_URL_6_) are probably all involved.There are several studies where it has been purported to be demonstrated that the our subconscious mind does most of our work for us and only brings certain parts of our world to consciousness. [ERP](_URL_4_) demonstrates this effect. Actions that are performed 'unconsciously', like driving, do not necessarily trigger [P300](_URL_9_) (specifically P3b) spikes. Typically P3b spikes are necessary for '[Conscious](_URL_1_)' actions which would include memory and or temporal time processing (Where am I? How long is this going to take?).How the brain adapts to produce this behavior is a difficult question. It is most likely a combination of: 1) Strengthening of existing neural connections.  2) Weakening of existing neural connections that conflict with the goal skill.   3) Adding new neural connections.  4) Pruning (removing) existing neural connections that conflict.  5) Modifying the physical structure of individual neurons.  6) Changing [myelination](_URL_2_) of neurons. 7) Other processes.[Edit: Formatting]
Don’t know about Ebola, but HIV has many different strains and the strain a person has can mutate. That’s why people who are on antiretroviral medications switch their regimens often because if they take the same meds every day for a long time the virus will mutate to become resistant to that antiviral medication. So there would have to be a vaccine for every HIV strain out there.
We can estimate the total density parameter by measuring the spatial curvature. The Universe  is flat as far as we can tell so this is 1. Then we estimate the matter density parameter because we count the baryonic matter density and we add dark matter, of which we know how much there is from rotation curves. We also know the radiation density parameter is negligible by counting. We therefore can deduce the dark energy density parameter by subtracting.
Color is not the cause but the effect of selective absorption. A surface is red **because** it absorbs the shorter wavelengths of the visible spectrum, not the other way round. But why are some colors reflected, while others are not?Visible light is a part of the e[lectromagnetic spectrum](_URL_0_) and contains all wavelengths from ~400 - ~700 nm (1 nanometer = 10^-9 meter). Red is on the one end of the spectrum - the end with the longest wavelengths; and blue is on the short-wavelength end. What we see as colour, is our brain's way of representing different wavelengths.  An object appears red, when most of the longer wavelengths are being reflected, while the shorter wavelengths are being absorbed.Similarly, the light that has gone through an object appears red, when most of the shorter wavelengths have been absorbed or reflected, while the longer wavelengths have been transmitted.But what determines, which wavelengths are being absorbed in the first-place?To answer this question, we have to take a closer look at what happens when an electromagnetic wave (I will abbreviate as EM-wave from now on) travels through different media.   When an EM-wave hits a medium such as an object, one of three things happens:* Absorption - That means the energy of the EM-wave is transferred to the particles that make up the object. Thus, those particles start to shake. (Or electrons are exited etc...) However, this can only happen if the frequency of the light has just the right "rhythm" so the molecules or atoms can shake "in step".* Reflection - The EM-wave bounces off the object* Transmission - The EM-wave passes through the object. Since matter is made up of charged particles, and EM-waves interact with charged particles, this will have an effect on the microscopic structure of the object.Now we can answer your initial question:Whether light is absorbed, reflected or transmitted when it hits an object depends on the molecular and atomic structure of the object.If the structure of the object is such, that the molecules and atoms can shake with the frequency of the EM-wave, the energy is absorbed.If not, the energy is either transmitted or reflected. Whether one or the other of these happens depends, again, on the way the molecules interact with a particular frequency of light.
I've always been fascinated with the phenomenon of music, how it can stir up memories, as fresh as if they just happened, how a certain song can make you feel how you feel when you used to listen to it.The effect music has on humans is wide and varying, and still there are no real answers as to why, because at the end of the day, this music is just sound waves.
Body-produced (endogenous) testosterone plays [a necessary role in sperm production](_URL_1_), but it is not the dominant regulator of sperm production rates. Both testosterone release and sperm production are driven ultimately by the same hypothalmic hormone: GnRH (which signals to the pituitary to release LH and FSH hormones, which signal to the testes to produce testosterone and sperm). This means that if a healthy male experiences a natural upswing in testosterone, he will also have higher sperm production. It's not that the testosterone directly regulates the sperm production, but that they are both regulated by the same hormone pathways (it's correlation, not causation). But note that this is only for a healthy male. A lot of things can go wrong in the hormone feedback loop and in the testes themselves, so that testosterone and sperm production become decoupled. In many cases, a male can have normal testosterone levels and be infertile. In such cases, boosting endogenous testosterone levels has no effect on fertility.Now, hormone replacement therapy (exogenous testosterone) is a separate situation. In this situation, the externally provided testosterone suppresses the body's natural release of testosterone. It does this by effectively over-taking the negative feedback cycle and suppressing the body's release of GnRH, which has the side effect of suppressing sperm production. In short, testosterone replacement therapy can *cause* infertility, even in males who had healthy reproduction before going on the hormone replacement therapy. _URL_0_In some cases, if the reason for going on testosterone replacement therapy is a problem with the pituitary gland/hypothalmus and not the testes themselves (central hypogonadism), the male can go on replacement therapy of GnRH, LH or LH analogs in order to preserve fertility while still raising testosterone to normal levels.
Volcanic eruptions are powered by the interplay of a couple of forces and effects:The buoyancy of hot magma makes it less dense than its suroundings. This gives it a tendency to ascend. It will do so either by infiltrating a network of faults and fractures or by progressively eating it's way upwards by ripping overhanging blocks through stoping. If no mechanism allows it to ascend (no fractures, or refractory rocks in the way), it will just stay where it is and cool into some intrusive rock.Fractional ascent of the magma will reduce the lithostatic load it bears. In response to this, dissolved gases will form bubbles which will reduce density further still by augmenting volume. This may push the magma upwards through the fracture network it is exploiting, not unlike foaming in a soft drink can propell the liquid out of the bottle.
Some oases are formed by humans for crop production. Naturally, though, the creation comes from migratory birds visiting the water.An oasis is fed by heavy rainstorms or an underground water source, usually aquifers or springs. This water pools at the surface and is very attractive to migratory birds. The birds stop along their trip to drink and cool down and leave their droppings. Within their droppings are seeds from the last places they visited, some seeds are not digested in the birds' stomachs. The seeds, which are surrounded by natural fertilizer, grow into plants. From there they can reproduce on their own and fill out the oasis.Birds are excellent ecosystem builders in that regard! For more on oases, here are a few articles:*  [*Oasis*](_URL_5_) - National Geographic Society* [*What is an oasis?*](_URL_1_) - World AtlasI've been looking through journal articles for vegetation links for you, but so far all I am finding are agriculture oases ([Moore et al. 1994](_URL_4_), [Zi-li et al. 2004](_URL_0_)). I'll keep looking.This paper, [*Modern pollen spectra from dakhleh oasis, western egyptian desert*](_URL_3_) mentions a few native species for that region such as Acacia and several other woody plants, living in fragments around the human created croplands. While not exactly what you were referring to, [this article on invasive fish](_URL_2_) in an oasis in the Mojave Desert is really interesting, in case anyone wants to check it out.
Equines also. Evolved in the Americas, went across the land bridge, evolved to the present day horse, died out in America, then the Spanish brought horses back to the Americas.
It has happened - many times.  Google "blind cave fish", and you'll see a bunch of species to which this has happened.  I'm pretty sure I've also hear of other species, such as lizards and the like, but I'm less certain about that.The biggest problem with your question is that the loss of evolutionary characters doesn't happen in constant time.  Humans still have an appendix, and we haven't lost all our body hair, etc etc.  If there's no strong pressure to remove a trait, it can happen in one generation or in a million generations - and natural selection just won't push that along unless there's an advantage to that trait.  in your example, there's no advantage to either the sighted cave dweller and a blind cave dweller - so there will be no clock running.Beyond that, it's also hard to say how long it took for the cave fish to lose their eyes - determining when the cave was cut off would tell you the upper limits, but wouldn't tell you how long it actually took.  Again - because there's no pressure, it might never happen.
It's because those screens also work through polarization.Polarized sunglasses work by filtering horizontally polarized light, which is common in reflections of the sun (like off the ocean or snow). TN-style LCDs work by having a backlight, a polarizing filter, a thin film that can twist the light, and another polarizing filter. The thin film can switch from "twist light" to "don't twist light" for each pixel on the screen, so when it twists it can make the light get filtered and when it's not twisted, it doesn't get filtered. The end result is that all the light coming off your screen has the same polarization (if it didn't, the second filter would have already filtered it for you).
This happens, people tend to follow one mutation down generations only for simplicity of demonstration but of course each and every gene develop in parallel. Millions of genes all develop at the same time.Mathematically, however, the most common mutations are minor, insignificant mutations that do not affect reproductive capacity. Thus any strong beneficial mutations will be diluted within a population. Also, there can also be detrimental mutations that may be passed on. Thus the timescales are still very long.
There are such things as thermal rectifiers and diodes.  Though I'm not aware of any commercially available as they tend to involve some fancy nano-structures.It is important to point out that such devices can't/won't violate the second law of thermodynamics and allow cold to flow to hot.  But rather, as you said, the flow is always from hot to cold, but if the hot side is on the left of the device you get a different thermal resistance through the device than if the hot was on the right.
Yes-ish.  The movement of conducting seawater through Earth's magnetic field does create an induced voltage via [Faraday's Law](_URL_2_): this voltage can be [measured using an undersea cable.](_URL_3_), and people have used this to measure changes in ocean currents over time.However, magnetic forces have no significant effect in pushing ocean currents around: the [Stuart number](_URL_0_), which measures the importance of magnetic forces compared to the fluid's own inertia, effects is less than 1 millionth._URL_1_As a result, the relationship between fluid motion and electromagnetism is one-way: fluid flow drives electrical changes, but not vice versa.  This is in sharp contrast to other magnetic fluids like the solar wind or Earth's liquid iron outer core, where the interaction is two-way.
No, go to any university on move-in day and look at all the Asian kids next to their parents.
Like a black circle which lenses background light around itself. Probably something a bit like [this artist's rendition](_URL_0_). That's assuming it's just a black hole with no accretion disk.The event horizon of a black hole describes a spherical shape in space.
It gets lower, as you are further from the bulk of the mass. What's interesting is that if the earth were of uniform density, it would also get lower digging into the earth, but since the iron core is much denser, it actually gets stronger deeper into the earth.
Heat can be transferred either via processes known as *conduction* or *convection*, which require contact with surrounding matter, or via a process known as *radiative heat transfer* (a.k.a. *radiation*), in which the heat energy is transported by photons (e.g., infrared light).  Photons can easily travel through vacuum, and therefore do not require contact with matter in order to heat or cool an object.-Radiation is the reason why, when you are near a fire, the part of your body that faces the fire feels hotter than the parts of your body that face away from the fire.  A small amount of heat is transported via contact with the air (convective heat transfer), and this is what you would feel on body parts that don't face the fire.  A much larger amount of heat is transported by radiation; because the photons that carry the heat will only be absorbed by the part of your body that faces the fire, this part will feel much warmer.
I would suggest that you are getting distracted by the word "define".  The word define has a broad meaning in this context.  A computer program could be argued to be a definition of the actions the user wants the computer to take.At a low level computers are able to perform a set of operations such as store, retrieve, add, shift on values at given memory locations.  In your example you are asking the computer to assign the key word "apple" to the value 3.  Computer programs are text files written in a high level language (i.e. a language easy for humans to understand and use).  A compiler parses the computer program and turns the high level language into a binary form that the computer can understand.  In the case of Java the compiler takes the java code and turns it into byte-code that the JVM can run.  The high level program is translated by the compiler into a series of low level operations that the computer can perform.  So the line "apple = 3;" could be translated into something like: allocate four bytes of memory, put the value 3 into the memory, add the string "apple" to the symbol table and associated it with the address of the four bytes of memory.
I know its an incredibly layman's response, but mythbusters covered this exact question pretty thoroughly.  Using an eye patch, and walking into a dark room, they where able to acclimate to the darkness much more effectively than the control.  A link to some discussion: _URL_0_
Herr Mr. med student here.If you stay in the same position for too long the bony bits on your body, head, hips, knees, etc tend to loose blood flow due to the pressure that the weight of your body puts on them. In extreme cases you can get bed sores -(_URL_0_). This is common in bed ridden patients- we turn them every few hours so it doesn't happen. If you want a freak show google it and look at the pics.In most cases this isn't going to happen to you in your squishy bed overnight, but, you have to remember we're not designed to sleep on beds. Our ancestors didn't have cushy beds, and were most likely at much higher risk of getting bedsores. Many of those who did most likely died of infection -- leading to the natural selection of people who move around in their sleep becoming a common trait in humans as it increased fitness (survival).This answers the why portion of your question, a neurobiologist could give you an answer as to how we do it. But, that's out of my league.edit: Grammar and puctuation
Haven't seen your data treatment or your analysis, but you are comparing two quite different subsets of data, so you might have an "apple to oranges" thing going here... The southern hemisphere has a much smaller part of the Ring of Fire included within it than the northern one (Essentially the parts along the Andes  &  the part from the Indo-Malay archipelago to Papua-New-Guinea). Furthermore, the nature of the seismic zones in the 2 subsets is not the same. The southern hemisphere is pretty much dominated by ocean/continent collisions and subduction, while pretty much all of the continent/continent collisions are in the Northern Hemisphere (consider the Himmalaya to European Alps segment). Given the different nature of the processes involved in both subsets, you should not be too surprised to see different seismic behavior.There might also be other effects depending on where you've put your threshold for "significant earthquakes". For instance, seismic effects due to post-glacial isostatic rebound would be overrepresented in the northern hemisphere because of the geography, and that would tend to decrease the value of the median northern quake, since they tend to be weaker than subduction-related ones.
You need to convert dinitrogen into ammonia; from ammonia, it's straightforward to make amino acids and proteins. The initial nitrogen fixation is far from trivial. It's not even fully known how bacteria do it. To fix nitrogen, you need to break the triple bond, which is very strong, so you're already thermodynamically disadvantaged. At room temperature, "burning" nitrogen is not thermodynamically favorable, so the reaction must be "forced" to go forward. You can do this with energy input by removing the product, ammonia, as it is formed, and "manually" feeding more electrons to force the reduction to go forward. Also, for any catalytic reaction, you need to have the nitrogen bind on the catalyst. Nitrogen is fairly inert, so it's not easy to get to form a complex that could react.Bacteria have an enzyme with a catalytic center called [FeMoco](_URL_0_). In FeMoco, the iron atoms are activated with a carbide (a carbon bound to six iron atoms). This allows dinitrogen to become a ligand and form a complex with the iron, like Fe(III)-NN. If you add an electron to reduce the complex (usually from the reaction NADH to NAD+ + H+ + 2e- in biological systems), then the extra electron can be transferred to iron (Fe(II)-N2) and from there to the nitrogen, like this: Fe(III)-N=N(-). The dangling negative end is immediately protonated:; Fe(III)-N=NH. The same is repeated until the N2 is completely converted into NH3. [Hallmen 2014](_URL_1_), [Kästner 2007](_URL_2_).Humans and other higher animals haven't evolved this since we've been doing just fine stealing the ammonia and amino acids from the bacteria.
It depends on quite a few factors, but can basically be boiled down to two: carbohydrate composition of the diet, and muscle mass.The body needs a certain amount of carbohydrates to function. Yes, a ketogenic diet can be used to reduce the amount of glucose the body needs, but it'll still likely be in the 100 gram/day range. If the body doesn't get enough carbs, it will create glucose in a process called gluconeogenesis, which uses amino acids (protein) as a substrate. The protein can come from diet, or lean body mass (read: muscle). As long as sufficient carbs are in the diet, amino acid use in gluconeogenesis won't be increased, therefore catabolism is reduced, and anabolism (muscle building) is possible.Next there's muscle mass. Muscle is constantly being broken down and repaired/reformed. It takes energy for that process to occur. As long as there's sufficient energy from the diet and from stored fat available, the process will continue and muscle mass will be maintained. During resistance training, the body is signaled to supercompensate for the training and build more muscle. As long as sufficient energy and amino acids are available, some muscular hypertrophy will occur. However, once muscle mass increases, the energy demands for maintaining that muscle mass increase, thus less energy is available for putting aminos together to form muscle.There's no real preference as to where the energy comes from. Depending on the individual, their diet, blood circulation, fat levels, and hormone levels, the energy might be more from diet or from fat stores, but in the end it doesn't matter, since only whatever energy is "left over" from other body processes will be used for anabolism (muscle building).There's a commonly used "bricklayer" analogy. As long as there are bricks, and your bricklayers are fed, they will keep the walls repaired. They'll even make the walls thicker and stronger if they have the materials and energy. But once you start to limit how much work your bricklayers can do, you limit the size of the wall they can maintain. Once the walls are so big that all their energy goes towards maintenance, fortifying the walls and making them bigger and stronger will stop. Too little energy, and not enough maintenance gets done, and the walls deteriorate, getting smaller and weaker.So, in a nutshell: eat enough carbs so protein doesn't get used to make glucose instead of being available for muscle building, and know that a beginner of resistance training can still make significant gains in strength and muscle size while dieting, whereas a more experienced athlete won't.
It is not "known." It's hypothesized based on indirect observations called proxies.One of the best and most commonly used proxies for estimating paleotemperatures is the abundance of heavy stable isotopes of common elements like Oxygen. Two stable isotopes of Oxygen have atomic masses 16 and 18 and because of their difference in mass, molecules that include them such as water or carbonate (CO3), will respond differently during phase changes. Molecules containing the heavier isotope will condense out before the lighter isotope, a process called fractionation. However the exact ratio of fractionation depends on the ambient temperature at which the phase change occurs with the imbalance decreasing the warmer the temperature is.So the ratio of 18-O to 16-O in ice (in the case of relatively recent records from e.g. glacial cores) or in the calcium carbonate fossil shells of animals (in very ancient records where there is no continuous ice record) can be measured and the temperature at which they formed reconstructed.Generally multiple proxies are used and when they agree with one another, scientists are confident to put forward a temperature reconstruction. Other proxies that support the period of warming you're describing (called the Paleocene-Eocene Thermal Maximum) include enrichment of deuterium (heavy hydrogen) in terrestrial systems due to more active evaporation of water from the oceans, and also study of fossilized bacterial lipids that were produced to regulate cell membrane fluidity and so are modified by the organisms in direct response to environmental temperature.
It is not how many people are receiving the signal.  Everyone within the range of the access point or router receives the same signal.  A router transmits and receives packets, most of which are intended for a single recipient.  Each device using the channel has a unique address.  When the router relays a packet,  each device looks at the address and decides whether it needs to process it.  Usually this is done by the network card, such that it does not interrupt you computer to handle a message that you don't care about.When you want to send a packet, your network card will listen to try to avoid stomping on someone else's packet.  If you do stomp on another packet, either the network card will detect that condition or eventually toe computer will figure out that a packet was dropped (because the recipient did not acknowledge receipt).It multiple people are trying to use the channel at the same time, the waiting for the channel to be open (and the retried when two devices try to transmit at the same time) limits the available bandwidth.  Limits on the size of a single packet prevent a single device from monopolizing the channel.
Hard question to answer, because as you point out DNA topoisomerases would have been required once double stranded DNA genomes started to appear. It's so difficult to provide a satisfying answer, I'd gather, because we are now discussing things that popped up right around the time of the last common ancestor of the entire tree of life. That's old. So what's the thinking? Let's just talk about the topoisomerases in general, because the gyrases can be traced from their evolution. Here's a few papers to get you started. [Origin and evolution of DNA topoisomerases.](_URL_0_)[Evolution of DNA Topoisomerases and DNA Polymerases: a Perspective from Archaea](_URL_1_)The bottom line is that topoisomerases are enzymes that combine several functions. They have to have DNA binding domains, they have to have nuclease activity (to cut DNA) as well as ligase activity (to put DNA back together). Some have ATPase activity and there are other more subtle, specialized activities. What most likely occurred is the emergence of these functions separately as single proteins "before there was a need for a true topoisomerase" and then combination (through various genetic events) into multi-functional enzymes during the RNA world and early DNA world (before dsDNA was the norm). Since they are so necessary for a DNA genome, there would have been considerable selection to arrive at the heterofunctional topoisomerases we think of today.Read the papers or skip to the origin hypothesis sections. Hope this helps.
Blood transfusions absolutely can be rejected, although it is rare as doctors are aware of its existence. Im sure you will have heard of blood types such as O/A/B. If the new blood doesn’t match up with the persons normal blood then the person will reject it. For more information google Acute Haemolytic reaction The same is true for bone marrow transplants although for different reasons.
In some sense your body is constantly fighting cancer. All types of cancer result from random replication errors that produce mutant cells. Cells are designed to die after a certain number or replications and only replicate as needed, but if these mechanisms are altered by a mutation in a cell it may allow the cell to replicate unrestricted and indefinitely. There are tumor-suppressor genes that code for proteins that can identify damaged DNA and either fix it or destroy it. There are also Lymphocytes called Natural Killer cells that are part of your innate immune systems and seek out tumor cells and inject proteins into the cells that cause them to self-destruct. In the vast majority of cases would-be cancerous mutations are dealt with by some combination of genetic fail-safes and innate immune system responses, but these are not fool proof and unfortunately some mutations are able to self-propagate until a point where they are too out of control for the body to normally handle on its own.This is also why people with suppressed immune systems are at a higher risk for blood and lymphatic cancers.
If I'm not mistaken this is how guitar pickups work.
You are right about the fact that other things would have different points of no return, but for the sake of the math, and for the sake of the breakdown of physics, the "point of no return" that is a critical phenomenon, is the point at which even light cannot escape. We call this the Swartzchild radius, because its a value of very high importance, and is the point at which our physics understanding breaks down, as well as **nothing** being able to escape. It's kind of the "absolute" of the statement, that makes it so special. **nothing**, not even light, can escape from the event horizon.Also, the value for the [Schwarzschild radius](_URL_0_) goes as: 2 G m/ c^2, which is to say, it does change in size depending on the mass of the black hole.
So, first of all, we actually do have fusion reactors; they're not even that hard to build. The problem is, all of the ones we've built use more power than they output. They're still useful if you need to generate some neutrons, but, obviously, the key requirement for a power generator is that it outputs more power than it takes to run it. The tough part with fusion is that you need to generate temperatures and pressures comparable to those found in the Sun.That being said, we're working on it and, if the boys at Lawrence Livermore National Laboratories can be believed, we're getting close. I took a tour of their NIF (National Ignition Facility) over my Christmas break and saw their setup. Basically, they have a laser system that's about as big as two football fields in this huge building. They split up the laser outputs and send them into a huge spherical vacuum chamber with a tiny pill-sized hollow gold cylinder positioned at the center. Inside that little cylinder is a pin-head sized amount of fusion fuel (heavy hydrogen). They focus all these laser beams into the cylinder (not directly at the fuel) and the resulting heat and x-rays generated from the walls of the cylinder compresses the fuel and, theoretically, causes it to fuse.
It can't slow down Jupiter alone, because it can't take up so much angular momentum. But we can make many Voyager probes each doing a single fly-by before escaping the solar system very fast. Jupiter's escape velocity is 60 km/s. We can send probes at ~ 30 km/s to Jupiter and let them get deflected by something like a 90 degree angle. There is some optimum but I don't know where exactly. For a probe mass of 800 kg, this changes the momentum by 30 km/s \* sqrt(2) \* 800 kg = 34,000,000 kg m/s. If we do the process fast compared to Jupiter's orbital speed, or always do it at apohelion, we need to change its momentum by (mass of Jupiter)\*(orbital velocity), plugging in numbers we get [7\*10^23](_URL_1_) probes, with a total combined mass [close to Saturn](_URL_0_). A bit lower if you optimize the probe approach speed. On the other hand, getting this mass to this speed will need some propellant as well.
Well it depends of your definition of "anything". If you're mentioning probes, for instance, no - actually, the nearest black hole is way too far to send probes to study it. However, some stars are sucked into black holes right now, so yes. >  I have heard that if I were falling into one, I would experience such extreme time dilation that I would see stars die and be bornYou would actually be crushed by tidal forces before you could experience anything.
Aha! This is my field, and I may be able to help you with this. Beware: we are going to go deep, deep down the rabbit hole into the land of aperture synthesis interferometry. Even those who've been doing it for years may still find it confusing at times, so if it seems totally incomprehensible, that's normal. [This webpage](_URL_4_) may help you._________________________________________________________________In a telescope such as ALMA, the signals from each pair of dishes can be combined to form a **baseline**. For an interferometer the number of baselines is N(N-1)/2, where N is the number of dishes. So for ALMA there will be 2145 baselines total. Now, each baseline is basically a single example of a [double slit experiment](_URL_1_). A 2-dish interferometer will form an image that looks basically like what you get from passing a beam of light through a double slit, because it is essentially the same thing. The image of an interference pattern produced by a double-slit experiment basically looks like a bunch of parallel lines.  Imagine that our interferometer is a set of detectors on a beach that detect when waves wash in. I wish I had a chalkboard, but oh well. Let's say I have detectors A, B, and C, which are equally space in a line along the shore. Detector A detects a wave, and a second later B detects that wave, and a second later C detects that wave. Based on the difference in timing, I can work out what angle the wave was coming in at. Now think about a line of 3 radio dishes-- they do basically the same thing, but with much much higher precision. Let's say this line of dishes is ranged east-west. During a short measurement, they could tell me about the precise position of sources in the east-west direction, but they can't tell me much about the source's position in the north-south direction (in astronomical terms, east-west is Right Ascension and north-south is declination, or for short, RA and dec). This is why the dishes are arranged in all sorts of different locations, so that we can get good angular resolution in each direction. _________________________________________________________________For a single radio dish, the resolution is limited by the diameter of the dish-- the equation is **theta = 1.22 lambda / d** where theta is the angular resolution in radians, lambda is the wavelength being observed, and d is the diameter of the dish. For an interferometer, d is the length of the longest baseline. So for example, the [Very Large Array](_URL_0_) in New Mexico has 25 meter wide dishes, but its maximum baseline is about 35 kilometers, so its actual maximum resolution is 1400 times better than a single dish.**Imaging** the data is a more complicated question. In order to properly understand it, one needs to have a good understanding of [Fourier transforms](_URL_3_). In a very rough sense, though, waves which are hitting a telescope aperture are [*convolved*](_URL_2_) by the aperture (if you've done optical astronomy, you may have seen [Airy rings](_URL_5_), which are another example of the convolution which an aperture applies to a signal). Raw radio data come in the form of *visibilities*, which are just data measurements along a particular baseline for a short period of time. In order to turn it into an image, a computer program runs an inverse Fourier transform on the visibilities, which can be thought of as de-convolving the signal.**An interferometer gives you the resolution of a much larger telescope, but its sensitivity (i.e., light gathering power) is still limited by the total collecting area of the dishes.**I'm sure this has done as much to muddy the waters as to clear them, but feel free to ask me followup questions. I'm not really sure what, if any, your physics background, and this may have been a bit technical.
The 'common cold' is usually caused by a rhinovirus.  Cold temperature itself does not cause illness.  [However, temperature effects may facilitate viral infection:](_URL_0_) > Although not all studies agree, most of the available evidence from laboratory and clinical studies suggests that inhaled cold air, cooling of the body surface and cold stress induced by lowering the core body temperature cause pathophysiological responses such as vasoconstriction in the respiratory tract mucosa and suppression of immune responses, which are responsible for increased susceptibility to infections. This is further confounded by the fact that people may stay indoors during the cold months, further allowing spread of the virus.
Stirring the pot increases the convective heat transfer. The faster you spin, the better heat transfer you get. Its the same effect as blowing of your food to help cool it down. Here's a little jewel, the guy the unit of energy is named after (Joule) went around with a machine that had a horse walk around a bucket of water, essentially stirring it with a paddle wheel. Eventually, the water would boil with no fire or anything. Cool story right?Edit: And yes, it is very measurable.
> Is it likely we will once day have a cousin "rival"?Since you're referring to Earth specifically, the problem is that the pace of biological evolution is vastly overwhelmed by the rapid pace of our technological evolution.  We could be actively reengineering our genomes within the century, and it would take far, far longer than that for any meaningful change to occur in the intelligence of other species without human intervention.  We might actively "uplift" some other  species to higher levels of intelligence within this millennium (we'll almost certainly have the ability if civilization doesn't derail), and that's a blink of the eye in evolutionary timescales.Still, were homo sapiens to go extinct, there's always a chance that another "intelligent" species could arise later (as long as the biosphere is still intact).  For a fun but extremely speculative program about the hypothetical future evolution of life on Earth with humans out of the picture, see [The Future is Wild.](_URL_0_)Apparently the episodes are all on Youtube [here](_URL_1_), though I have not checked them for quality or completeness.
Excepting brain cancer, pain in cancer is frequently due to disruption of the normal anatomy which produces local pain that may be so severe or vague it feels like it’s spreading. For example, liver cancer can stretch out the sac that surrounds the liver (its capsule) and produce excruciating pain, but since the nerves inside your body aren’t as god at locating pain as the ones in your skin, the brain could misattribute that pain to pretty much the whole belly. As another example, bony metastases from prostate cancer usually cause pretty bad local pain in the bone they’re invading, which is worsened by injury to said weakened bone.
Beta decay can be speed up by ionizing the atom.  This is because it opens up a new way for the nucleus to decay: [by sending the beta particle (an electron) directly into orbit around the nucleus ("bound state decay").](_URL_0_)  The more ways a nucleus has of decaying, the faster it decays.For most nuclei this is a tiny effect, but for a few which are just barely able to decay otherwise, it can speed it up immensely.
Roughly speaking, all tissue in your body has cells (which are alive) and other things (which aren't). Some tissue (like muscles) has a lot of cells and a little of other things. Some tissue (like cartilage) has very few cells and is mostly made of other things.Immune reactions primarily target living tissue. Heart valves are made of is almost entirely non-living tissue, and after being harvested from pigs, those valves are treated with chemicals to kill off any residual pig cells. As a result, when they are implanted, they usually do not cause immune reactions because there are no cells within them to cause an immune reaction.This is similar to receiving ligament grafts from deceased human donors.
> However, the slowdown of the Earth's rotation is not occurring fast enough for the rotation to lengthen to a month before other effects make this irrelevant: About 2.1 billion years from now, the continual increase of the Sun's radiation will cause the Earth's oceans to vaporize, removing the bulk of the tidal friction and acceleration. Even without this, the slowdown to a month-long day would still not have been completed by 4.5 billion years from now when the Sun will evolve into a red giant and likely destroy both the Earth and Moon.
Your question contained your answer, and you didn't even know it: >  My attention was caught.What you've come across is what is called by a lot of names, including *attention*, *selective attention*, *feature attention*, etc. [Wikipedia has a decent article on the topic](_URL_0_).The most basic idea behind attention is that there is not enough capacity for the brain to process every bit of information that hits our eyes. Most of it is redundant info (the shape, size, colour, etc of the leaves on the trees), and it would be a waste of energy to devote a lot of resources to this task. The brain that we have now, the one that is limited in its capacity, is already intensely hungry for energy, so you don't want to increase this. To counteract this limitation, we have developed a number of systems that try to deal with this. They all fall under the term *attention*. The basic idea of all attention research is that it is some mechanism that allows you to boost the processing of specific sensory information.You can *shift* your attention to a specific point in your visual field, and what will happen in the brain is that the activity of that part of the cortex gets boosted, with a slight decrease for information outside of what you are attending. So, seeing someone you know in a crowd and paying attention to them, or listening to a single conversation (the [cocktail party effect](_URL_1_)) in a noisy room, is you selectively engaging your attention to a specific object, and boosting it's representation in your sensory cortical areas to allow that information to break out from the noise around it. > What leads to me paying attention to these people and what creates this feeling where you see him/her pop out from the environment which would have been otherwise visual static noise?The popping out you're referring to is a very prominent feature of the [Biased Competition model](_URL_2_) of attention. I talked above about you directing attention to a specific object or part of space. The other side of the attention coin is that some objects will grab attention irregardless of what you're doing (bottom-up effect; the alternative that I described above is a top-down effect or directed attention).For example, a loud noise, or a sudden change in contrast (aka bright light), will cause you to attend to the source of this stimulus, and you'll often swivel your head towards the source of this stimulus. You can also see this for other types of stimuli. For example, your name will often pop out and capture attention even when you're suppressing that source of information. Think of the cocktail party example. You're talking to someone, let's say Lisa, and ignoring all the other conversations in the room. Then you hear your name in one of those conversations. You turn and say "huh?" to John. You don't know what John said because you weren't attending to that stream of info, because you were talking to Lisa, but your brain had processed enough of the info to be able to pick out your name, orangek1tty, to be able to pop your attention away from what you were doing and to that other info.
It depends. Some patients, though vegatative, can breathe on their own. In that case all that is needed is a feeding tube, usually placed via a surgically placed hole in the abdomen (a GT tube). In other cases, when the patient has some ability to breathe, a tracheotomy is done allowing adequate spontaneous respirations. If the patient doesn't have adequate respirations even with the trach a ventilator is necessary. In any event round the clock nursing care is required to maintain the trach/vent/GT and to administer feedings as well as hygiene and turning at least every two hours to avoid bedsores. In addition medications may need to be given as well as ongoing stretching exercises (ROM) to minimize contractures. There are a variety of other considerations, but this is the basic care.
On a four stroke or a diesel the only real problem you would have is lubrication. Oil is typically sprayed/splashed onto the bottom of the cylinders and allowed to drip down via gravity or by using the piston as a scraper. It is then collected in the oil pan and recirculated through the engine. After a long enough period most of the oil would probably* be floating around in the cavity that houses the rotating assembly and not in the bottom of the oil pan where it can be collected. I say probably because I don't believe the piston would necessarily send the oil back to the bottom of the pan, and even if it did, gravity wouldn't be there to force it to the low point where the pickup is. This would cause the engine to be oil starved and seize up. Similar problems exist with other oil routines within the motor. This all assumes a there is a pressurized fuel delivery system is in place to move fuel from the tank to the engine.  Some two stroke engines would probably be fine because they are lubricated via the fuel delivery system.
Not 100% on this, but since nobody else is here I'll take a crack at the second part. Rhyming could be considered associative learning. Basically taking something that is very familiar (a strong neural pathway that is used frequently such as recognition of certain linguistic patterns) and attempting to connect these pathways with less used or less well defined pathways (such as a new memory). The brain is very comfortable firing well-used pathways, and the process of association begins to train the two pathways to fire together. These pathways firing can arise as "thoughts" in your conscious mind. The byproduct of this is that when we use mnemonic methods to create these associations we can think in a way that is more comfortable to the brain and after a time of learning, it will begin to fire the weaker associated pathway, bringing a less familiar "thought" into your mind. Regarding music and the mind, my mother really enjoyed Musicophilia: Tales of Music and the Brain by Dr. Oliver Sacks. I haven't read it yet, but it seems to be a book that might interest you.
There are two competing forces in the nuclei of an atom 1) The Coulomb force (electromagnetism) which pushes protons apart and 2) the nuclear force (strong interaction) which pulls neutrons and protons together. In some atom configurations one force is stronger causing the atom to be unstable and decay. Radioactive decay is decay where the decay product is ionizing, i.e. when it carries enough energy to knock electrons of other atoms and thus ionize them. There are 4 types of radioactive decay: Alpha decay: Ejects alpha particles consisting of 2 protons and 2 neutrons. Beta- decay: A neutron is converted to a proton and a free electron is emitted.Beta+ decay: A proton is converted to a neutron and a free positron is emitted (the antiparticle of the electron).Gamma decay: Excess energy is emitted as high energy photons.Carbon dating is possible due to radioactive decay. A carbon-14 atom is a carbon atom with two extra neutrons, making it unstable. The particle undergoes beta- decay, converting a neutron into a proton thus becoming nitrogen + a free electron. A substance can be radioactive but not dangerous. XKCD has a nice chart for scale: _URL_1_Other links where one can read more:_URL_4_  _URL_0_  _URL_2_  _URL_3_  _URL_5_
I've had to use Mathieu functions because they describe the behavior of ions in [quadrupole traps](_URL_0_), and found this book useful:*Theory and Application of Mathieu Functions* by N. W. McLachlan, 1964.Maybe your university library will have it.
The setup you are describing is a little strange (I'm not sure what a Random number generator has to do with this, for example). But let's run with it.So say you do have a RNG algorithm that you can run to create a number's digits (and let's ignore for a second the fact that you'd have to run it forever to generate a single number). And let's further say that you can do this a countable number of times. Is there any possible way you can create all of the real numbers between 0 and 1? Let's assume you did!Now since you ran this number generator a countable number of times, we can assign a counting number (1,2,3...) to each of the runs of your number generator (this is the definition of countability). I can show that there is at least one number between 0 and 1 that is not in your list. We will construct this number. First we will look at the first digit after the decimal point in the first number you made (the one we assigned "1" to). Say it's 5. I choose for my number something else, like 8. So far my number is 0.8. For the second digit in the hundreths place, we will look at your second number's hundreth place. Say it's 2. I pick something else, say 7. So now my number is 0.87. Keep on doing this for the k-th digit of my number by picking something different than the k-th digit in your k-th number. This is the diagonalization part, since we are going diagonally down the digits of your numbers and constructing mine to be different in each place.Ok so what? I claim my number 0.87....... is not in your list. After all, it's not the first number. It's different in the first digit. It's not the second number, it differs in the second place. And so on.But wait, my number is a totally valid number between 0 and 1. But it's not in your list...you missed one! But this is a contradiction to the assumption that the process we described is capable of producing all the numbers between 0 and 1. Therefore that process couldn't have produced all the numbers in the first place. This is pretty much the [Cantor diagonalization argument](_URL_0_) that the real numbers are uncountable.
The ball on the ramp would take longer to reach the ground, but it would have the same speed and kinetic energy as the falling one when it hits the ground. The ball on the ramp accelerates slower because for a 45 deg ramp, only half of the force of gravity is acting on the ball along the downslope direction. The other half is perpendicular to the direction of motion and countered by the normal force.
Presumably you mean what's the chance of it occurring one or more times in 30 days?You really need to calculate the chance of it *not* happening. That's 0.96 every day. The chance of it not happening on all 30 days consecutively is 0.96^30 = 0.294..., so the chance of it happening is 1 - 0.294 = 0.706. Of course, this includes all possible outcomes where it happens one or more times.Your method to get 120% is wrong because it simply doesn't make sense, you don't add probabilities like that. Consider a simple example, flipping a coin twice. Perhaps this makes it clearer how your logic is wrong; the chance of getting tails twice is not 1, but 0.25. The chance of getting tails one or more times is 0.75.
It is, as matts2 said, a seed distribution mechanism, as a very efficient one at that. This contributes to the overall adaptive strategy of these various species, which is to colonise arid environments with low competition and patchy water distribution.
There are more scientists at my single institution than there are players in all of Major League Baseball.  Throw in another institution each for football, hockey, and basketball and you've covered the athletes of major professional sports in North America and you haven't left my state in terms of scientists.  Don't confuse hearing about something with the frequency of that something.  There are lots of us out there.  But if I had to wonder why there aren't more - science is a mentally and emotionally taxing job that requires a whole lot of schooling and dedication and on the back end you might, if you're very good and very smart, after many years of hard work, make about as much as someone straight out of an average MBA program.
The CMB is a remnant of the big bang. In the beginning, it was the temperature of the opaque gas right before the universe became cool enough for electrons to bind to atomic nuclei (and thus become transparent). It was 3000 K. As the universe expanded, the temperature of this background kept decreasing until it was the 2.7 K now (due to redshifting caused by expansion), and it will continue to decrease as long as the universe keeps expanding. Keep in mind this temperature decrease is proportional to the volume of the observable universe.
Unless the wind farm is powering a beam that beams the energy into space, then the energy is still here on earth, and it will still become heat here on earth.
tl;drs moved to the top for readability.tl;dr fuel is spent when it either passes its regulatory lifetime limits, when it no longer has sufficient reactivity for another cycle, or when the thermal penalties of using that fuel are excessive and would erode your operating or safety margins. spent fuel is not cost effective to use for power generation as it has low heat outputOther quick notes: This was posted with the idea that we would be trying to extract energy from the fuel without reprocessing it. If you reprocess it, you open up all sorts of interesting opportunities.-----------------------------------------------Nuclear engineer here.I'm going to start with a practical example and some rough numbers.The Spent fuel pool heat exchangers at my plant (BWR) are rated for 13.4 Million BTU/hr of heat removal. Our pool is sized to hold 4 full reactor core loads of spent fuel. This means that when the pool is full, we should be at or below 13.4 Million BTU/hr of heat generation from the spent fuel. I'm going to use an initial assumption that a spent fuel pool is producing 13.4 MBTU/hr for this example.[A quick wolfram alpha shows that the heat generated by 13.4 Million BTU/hr is approximately 4 MW thermal energy.](_URL_0_) (Note: according to this [NIRS Report](_URL_2_), the heat load of the average spent fuel pool is around 4 MW, so this lines up with my initial assumption. Additionally [Fukushima's spent fuel pools on March 11 were all below 4 MW](_URL_1_).) This is raw heat, to produce electricity we would need to put all the spent fuel in a pressure vessel/boiler. This means we would need a feedwater system to fill the boiler, a steam relief system to draw steam from the boiler. A small turbine to generate electricity. We would need a condenser for that turbine. I would also need safety valves, probably need another containment, and would need emergency cooling systems. And because this all will be carrying radioactive water with the potential for a release causing a substantial radioactive release to a member of the public, it would all need to be classified as nuclear safety related and would have all the regulatory requirements of your reactor's safety systems. Considering a typical rankine cycle for a boiling nuclear power plant is capable of converting at best 33.3% of its thermal output into electricity, this means I would need all of this equipment just to make 1.33 MW of electricity. Some other points to remember, the fuel that has most recently been removed generates over 80% of the heat in the spent fuel pool. So only a small amount of the fuel produces the majority of the heat load. The fuel that has been removed for more than 10 years produces less than 10% of the pool's heat load. So a small amount of fuel is responsible for the majority of the heat in the fuel.It is not cost effective to do so. So electricity generation is out. Even if we assumed a higher heat load or lower heat load, we are at the 1 MW order of magnitude, we aren't going to see a significant increase or decrease if we do a more realistic analysis.What about things like heating? This is certainly a possibility. However there are some issues. The water used to cool spent fuel is contaminated. Fission products leech out of the spent fuel constantly at very low rates. If we do not filter these fission products, it will lead to increased radiation rates and the potential for airborne contamination. The filters used for spent fuel pools are resin based. Resins cannot withstand temperatures of  >  140 degrees F (nominally it should be kept at or below 120 degrees F). So this limits the maximum temperature I can have in my spent fuel pool, which limits how much zone heating I could do with this water.Ideally the best thing to do with spent fuel is keep it cooled. After sufficient time has passed the water is no longer there for cooling and is instead there for shielding and radioactive material scrubbing (it becomes air coolable after 3-5 months, depending on fuel and configuration, according to the [NRC's Spent Fuel Pool Beyond Design Basis](_URL_3_) study).  > In this study, without mitigative action, fuel is estimated to be air coolable for all but roughly 10% of the operating cycle > The actual time is between 37 days (not air coolable) and 107 days (air coolable), with 60 days representing the demarcation point between these two Operating Cycle Phases. The citation of 60 days as a representative value is reasonable based on other separate effects analyses not documented in this report. The actual time to air coolability could be more or less, depending on specific conditions.tl;dr spent fuel is not cost effective to use for power generation as it has low heat loadsAs for why it is considered spent, there are a few reasons we call the fuel spent. First, we have imposed limits on how many years in core or how many GWd (giga-watt-days) of energy a fuel bundle is allowed to produce (whichever is more limiting). This is to ensure the fuel rods retain their integrity after they have been removed from the core for decades. These limits are 'hard' limits and regulatory requirements. There are other reasons we pull fuel out of the reactor. Generally you remove fuel because it no longer has sufficient reactivity to maintain criticality in your reactor at your desired power level for the desired cycle length. In other words, if there isn't enough fuel to make it another 2 year cycle, that fuel bundle needs to be replaced with new fuel. (It's more than just fuel, fission products build up and absorb neutrons over time, so the not only do you run low on fuel but you build up more poisons as well). You may also remove fuel if you aren't capable of maintaining sufficient thermal limits during the next operating cycle. Older fuel has stricter limitations on LHGR (linear heat generation rate), and also has much more constrictive MCPR (minimum critical power ratio). For rough numbers, new BWR fuel can handle around 12-14 kw/ft (kiloWatts of heat per foot of fuel), but after 2-3 years in the core it can only handle around 5 kw/ft of heat generation. New PWR fuel can handle 20-24 kw/ft and old PWR fuel 12-14 kw/ft. So you can find yourself in a position where if you have too much old fuel, your reactor's power output is limited based on the safety margins remaining in the fuel. As fuel is burned up in the reactor, you also get a buildup of plutonium and a shift in the delayed neutron fraction. This means your old fuel will respond much more rapidly and aggressively to reactivity transients, which limits your MCPR ratings. There are other limitations, but these are the big ones.tl;dr fuel is spent when it either passes its regulatory lifetime limits, when it no longer has sufficient reactivity for another cycle, or when the thermal penalties of using that fuel are excessive and would erode your operating or safety margins.Hope this helps!-edit:When I wrote this, I was just looking at the energy due to decay heat. I wasn't looking at assembling spent fuel into a low power reactor (possible, but not cost effective), I wasn't looking at reprocessing (politics/cost/proliferation concerns, but you can re-mix many components of the fuel into new fuel), breeder reactors, or other parts of the nuclear fuel cycle. - Moved tl;dr to the top so people don't have to melt their brains reading half a page of technical stuff
When a body develops an allergy to something, it treats the allergen as if it were an invading pathogen and attempts to destroy the allergenic cell. The antibodies created are immunoglobin antibodies. For allergies, it is usually IgE antibodies, although for learned (non atopic) allergies IgG antibodies seem to play a bigger role. In the case of allergies, the allergenic antibodies bind to mast cells, which contain histamine. When they are destroyed by the immune system, they release histamine, and the allergy symptoms occur.Contrary to your question, repeated exposure to allergens generally makes the response worse, because your body has antibodies specific to the allergen encountered. Why you may think it could confer resistance is because while the body treats the allergenic cell like a pathogen, *real* pathogens cause unpleasant symptoms when they are not destroyed, whereas allergenic cells are only harmful *when* destroyed. So while repeated exposure to a flu virus may help your body become more resistant, repeated exposure to an allergen will generally make the response (and symptoms) quicker and possibly more severe.Antihistamines are actually your best method of reducing symptoms, and they are most useful if taken before encountering the allergen in question.
I think the issue here is that you are assuming that only a brain can help an organism make a decision. This is not the case, and jellyfish have a very primitive nervous system called a [nerve net](_URL_0_). This nerve net is not like the densely populated nervous system that we have - neurons are spaced, and they usually respond reflexively to touch signals. If you respond based on touch alone, then you certainly do not need a brain to process the signals!Also, as is sometimes mentioned, cnidarians have a very, very simple circulation system - because their membrane is so thin, they can actually diffuse oxygen directly from the water into their somatic cells. That's nifty. In fact, if you just want to look at how primitive a creature is and as to how it 'lives', look at sponges. They don't have brains, they don't have muscles, they don't have any sensory organs (jellyfish do!), and they don't have a nervous system, but they are still considered animals and alive.
Yeah, you can see them on [this map](_URL_0_). In the units they use, a gal is 1 cm/s/s.
Ah this is the classic [twin paradox](_URL_0_).Special relativity states that reference frames that are uniform are equivalent. i.e. they are either traveling at a constant speed or stationary. The thought experiment is: if you are on a bus that's traveling at a constant speed, it is indistinguishable from if you are stationary. You can construe yourself as being stationary and the whole world is moving backwards at the constant speed.But the moment the bus accelerates or decelerates, you will be jolted forwards or backwards (this leads to general relativity, beginning with the equivalence of accelerating frames and gravity). So in this case, the astronaut has to accelerate out, decelerate *and then* make a round-about change in direction. The people on Earth stay stationary relevant to the astronaut and experience no such accelerations/decelerations/change of direction. The two reference frames are no longer equivalent.This proves to be an simplification - more details are provided in the link above.
Hyperbolic trig functions are very much an analogue of the 'traditional' trig functions. If we look at the definition of the 2 normal trig functions: cos(x) = (e^(ix) + e^(-ix))/2 sin(x) = (e^(ix) - e^(-ix))/2i, where i is a solution of y^2 + 1 = 0.We can compare these to the hyperbolic trig functions: cosh(x) = (e^x + e^-x )/2 sinh(x) = (e^x - e^-x )/2So the hyperbolics seem like a 'non-complex number' form of the standard trig functions. This makes sense in practice. One of the main uses of trig functions is of solutions to differential equations; the equation x'' + x = 0 (that of simple harmonic motion, SHM) has as its solutions Acos(x) + Bsin(x), with A,B constants. We expect the graph of a particle undergoing SHM to be look like a wave; sin and cos do also, so the solutions kind of make sense.If we look at the corresponding equation x'' - x = 0, this has solutions Ce^x + De^-x with C,D constants. But we can rewrite this as C'cosh(x) + D'sinh(x), so we see immediately there is some symmetry going on in the answers to the two equations.Exponentials crop up a lot as solutions to differential equations; it's very useful having a shorthand of cosh and sinh to rewrite them, as there are loads of easy-to-remember manipulation rules for hyperbolic trig functions, which saves a lot of time compared to just dealing with the exponentials.
Solar energy per area is proportional to inverse square of the distance from the Sun, 1/r^(2). We can calculate this at the periapsis and apoapsis of the orbit (closest and furthest point).     Pp/Pa = (C/rp^2)/(C/ra^2)           = (ra/rp)^2Eccentricity is     e = (ra - rp) / (ra +rp)And another way of writing that is    ra/rp = (1+e)/(1-e)So we can write the power per area ratio as    Pp/Pa = ( (1+e)/(1-e) )^2Then we can plug in eccentricities of different planets (yes, Pluto is not a planet) to see how much the eccentricity affects solar power input per area    Mercury 2.30    Venus   1.03    Earth   1.07    Mars    1.45    Jupiter 1.21    Saturn  1.25    Uranus  1.20    Neptune 1.04    Pluto   2.72So on Mars, the solar power per area increases by 45% going from apoapsis to periapsis, that's a pretty significant change. And the values for Mercury and Pluto are even bigger.
This might be a more precise question: Does it make a difference at all if gravity is defined as a force versus being defined as the effect of curved space?
Great Question! The answer is quite simple but also kind of boring: depends on the wave.Here is a picture of a running electromagnetic wave which is the standard picture physics students see when they are told to imagine a light beam as a wave. However, waves don't need to be just sin or cos. Usually they are described as many, or even infinite, amounts of sin/cos added together which can give any kinds of shape or form.[_URL_0_](_URL_0_)
In many species, a female will mate with many partners when she's "in heat".  Having the fastest and strongest sperm means that you are more likely to supply the lucky sperm that gets to fertilize the egg, meaning that you beat out your competitors, which is what this procreation business is all about.There's actually a correlation where if many males mate with one female (say chimpanzees for example), their sperm will be stronger and faster than that of a male from a species where one guy gets all the girls (say gorillas for example).The above was experimentally verified on 2008 by [Berns et al](_URL_0_).  This is actually a pretty cool study because they used laser tweezers and optical trapping to measure sperm speed and swimming strength.
I'll add [tapirs](_URL_1_) to the list... technically they are separate species, however they are so unique in form and function that it is interesting that they are only found both in central and south america as well as the south pacific. And [ospreys](_URL_0_) although they are found globally (except Australia etc.) and not restricted to the two regions you mentioned.
This is an appropriate question for r/askscience, but the same standards must apply to this question as others. AskScience requires answers to be based upon expertise and/or have sources. Using a computer does not make you an expert. Please keep this in mind when answering.
I've had a quick look into this for you. I'm assuming you're asking about speed reading, and what effect speed reading rather than normal reading has on comprehension.I'm not that familiar with speed reading. It's one of those things I've always wanted to look into and maybe try to develop, but just haven't got around to (ditto for learning to program Python and play the ukelele). Anyway, back to what you were asking.From what I could find, there are a number of different techniques that people use to be able to speed read. Some of these involve skimming the text, and [these appear to reduce comprehension](_URL_1_). Other techniques involve not using subvocalization, which is reading out loud in one's head. I was able to find [this study](_URL_2_) which showed that disrupting subvocalization negatively impacted comprehension. This study isn't too great for your question though, because this was in individuals who hadn't learned to suppress subvocalization whilst reading, so it's not clear if not subvocalizing at all is different to the interference design used in that experiment. I haven't been able to find anything more specific than this.I also found this [review of the speed reading pop literature](_URL_0_) that you might find interesting.
It is kind of a harder force to wrap your head around than the other forces. From my limited understanding, it is the force that turns particles into other particles, mediated by W and Z bosons, just as electromagnetism is mediated by photons and strong force is mediated by gluons.
Using only reflection and refraction, it's impossible: in classical optics, if it can get in, it can get out.Using absorption and interferences, you can do better. Maybe not capture all the light, but most of it. But it won't be trapped inside indefinitely: it will be absorbed by the material and will just heat it up. It will just look like a dark object.
It's quite wishy-washy. The important thing to keep in mind is we don't understand how the human brain works yet, so people assume that the brain computes in a way that is roughly analogous to a parallel computer. But this is completely unknown, there is no known way to use a brain as a computer. For all we know a single neuron take an entire computer to match (I've read theories along this line, but they seem extreme).Here's a [relevant wikipedia link](_URL_0_) >  An estimate of the brain's processing power, based on a simple switch model for neuron activity, is around 1014 (100 trillion) neuron updates per second.[34] Kurzweil looks at various estimates for the hardware required to equal the human brain and adopts a figure of 1016 computations per second (cps).[35] He uses this figure to predict the necessary hardware will be available sometime between 2015 and 2025, if the current exponential growth in computer power continues.
>  Logically I'm assuming that the relatively low gravity on Europa would lessen the force of water pressing down on the probe.Yes. The force of the water is the mass of water pressing down x the acceleration due to gravity. The mass of water, m, is given by m = rho x A x hwhere rho is the density of water, A is the cross sectional area and h is your depth.Rho is constant (pretty much), so the pressure isP = F/A = rho x h x g. g on Europa is about a tenth of that on Earth so the pressure at a given depth will be 10 times less.
When sounds from two sources overlap, their signals add together.  So, you don't hear "just train" or "just voice", but "train + voice + other sounds", meaning that the information encoded in the voice sound waves is still present.Now, the brain is pretty good at filtering human voices out of noise (there are only a handful of sounds it has to recognize to do this).  This would have been a very valuable skill for, say, paleolithic hunters in a windy setting where hearing each other is difficult, meaning that natural selection would favor it.  Additionally, it's an important skill in the noisy world we live in today, so most people develop it well.There's also the fact that the train noise is probably mainly low-frequency, whereas the voice has high frequencies included.  So, if the brain focuses on the high frequencies, it can pick out voices that are much weaker than ambient noise.
Congestive heart failure causes an increase in pulmonary vein blood pressure, essentially due to failure of the heart to pump well.  This increase in pressure increases the overall [Starling forces](_URL_0_) that push fluid out of lung capillaries into the alveoli and interstitial space (lung tissue).  This fluid build-up is called pulmonary edema.  Unlike a bronchitis, where there are large mucus collections in the upper airways that manifest as a productive cough, the fluid is at the level of air exchange, and can't really be coughed out.
I think your question may be ill posed. It seems impossible trying to prove that the earth is flat, we can only try to prove that the earth curvature is larger than something. Let's suppose I measure a really big area (like 100km^(2) ) and it seems to be statistically flat (like +-0.05 m on a 95% confidence). In that case I would be able to say with a 95% confidence that the earth radius is at least 318 096 km, but I wouldn't be able to say that the earth is flat. You can also find this problem when you try to measure the [curvature of the universe](_URL_0_). The universe seems flat as far as we have measured it, but it is impossible to prove.*Calculations:**If you have a sampled area S=100 km**^(2)* *in the shape of a circle, the radius of the circle would be r=sqrt(S/π). Then if the +-0.05m bump is in the middle of the arc you will have a right triangles a triangle formed by the radius of the earth (R) as the hypotenuse, (R-x) where x is the bump as the long side, and r as the short side (where r is the radius of the sampled area), then r**^(2)* *+ (R-x)**^(2)* *= R**^(2)* *. If x is much smaller than R (because x is the error in the measurement) x <  < R you can approximate R=S/(2πx)**Note that this calculation assumes that the highest bump is greater at the center of the bump and not on one side, which may change depending on the type of experiment***But I can pose the question in another way: What is the maximum area I can measure that will not prove significantly that the earth is round?**This is also a tricky question, since it depends on how you are measuring the curvature of the earth. There are many experiments that may come to my mind, but the one I decided will be more effective for this problem is: A balloon or satellite of some sort that can measure the distance of every point in the surface relative to it. You can calculate what are the distances from each point in the surface to the balloon/satellite depending on the altitude if the surface was a plane. Then you can measure what is the error depending on the roughness of the surface.If we could measure the elevation with a precision of 0.05m, then the area needed to sample the earth would be around 2km^(2) . NASA's Shuttle Radar Topography Mission (SRTM) is reported to have an accuracy of around 16m. Using this number the minimum flat area you would need to search would be 600km^(2) . But the earth is not flat, no pun intended. The area around month Everest (sampled around 200km^(2) ) has a standard deviation of around 1650 km, so the area you would need to sample supposing most of the area had the same standard deviation would be 66 000 km^(2) . As an upper bound, the biggest difference in heights on earth would be its ME height (8848m). In that case, the area you would need to sample to know for certain that the earth is round is  354 000 km^(2) .But this is not the best experiment you can make. If you want to sample a small area you would need to look for a really flat area and use other measurements, like a laser. In that case this equations do not apply, and the minimum area would be much smaller.
Beer has chemical compounds like gluten, sugars, and more that can collect around a small droplet to form a "shell" similar to the surface of a soap bubble. This may have been the cause of the stability.Qualification: Homebrewer
Totally. It would be really fun to try that too, (correct me if I'm wrong here), the Google technology works on pattern recognition, right? It's essentially searching for correlation between pixels, which is actually a lot easier with audio data, then feeding back the output of the pattern recognition to the input. It's essentially a DSP (digital signal processing) system that performs auto-correlation, by feeding the output back to the input, you end up with a minor danger-stability, but there's a particular case where by having those feedback loops and getting the amount of feedback just right, you get oscillations. When those oscillations are in the audio frequency band, we can hear them. Now there are way better ways of synthesizing sound in a controllable way using DSP, but it would be an interesting thing to try for sure.
Some people theorize that the Earth may have had a ring or two in it's past, and that they caused massive climate changes. Because of the Earth's significant tilt, a ring would cause winters to be far colder due to the increased shade. It is also thought that the Earth could not hold on to a ring for more than a million years or so due to solar wind and interference from the moon.Source: [Sandia National Laboratories](_URL_0_)[Astroscience](_URL_1_)
One of the problems with measuring the resistance of a plasma is that it has a negative slope of the VI curve. Basically a negative resistance. Raise the current through the plasma and its voltage difference drops!See this on [Arc Discharges](_URL_0_). > An electric arc has a non-linear relationship between current and voltage. Once the arc is established (either by progression from a glow discharge[10] or by momentarily touching the electrodes then separating them), increased current results in a lower voltage between the arc terminals. This negative resistance effect requires that some positive form of impedance (as an electrical ballast) be placed in the circuit to maintain a stable arc. This property is the reason uncontrolled electrical arcs in apparatus become so destructive, since once initiated, an arc will draw more and more current from a fixed-voltage supply until the apparatus is destroyed.In this respect a plasma is totally different than a metal, which has positive resistance.
Several factors play in to comparative immunology, so this question is hard to answer. There are very few studies on immunocompetence across species, but here are some considerations. Botulism is a poor example because of the mechanism of disease, but lets take E. coli as an example.If all things were equal except for mass, the smaller animal would probably become sickest/die first. This is not because the number of leukocytes, but rather the cytokines that would be invoked by the leukocytes. When we say that people die of sepsis, they are succumbing to the effects of a cytokine storm after infection, causing organ failure. Of course, animals don't exist in a vacuum and there are TONS of other considerations. For example, their endocrine pathways interact with the immune system (especially the stress response). There are multiple neuroendocrine pathways mediating the amount of resources/energy the individual will put in to the immune system, and this can vary by season, breeding status, location, or even time of day.  Metabolic rate also plays a large role in immunocompetence. So, the best answer is we don't really know. It's not a dumb question, and it's actually being raised by those studying comparative immunology. Hope this helps a little.
1. There is no difference between the "ancient" genetic code and the "modern" genetic code, they are one and the same. The code evolved over billions of years, before eukaryotes incorporated mitochondria into their cells, and has not changed since. We know this because any change, however small, in how the cell reads the genetic code invariably leads to cell death.2. Eukaryotic cells incorporated mitochondria before they differentiated and evolved into the different organisms seen today. Their genomes were never the same, although over time some mitochondrial genes were incorporated into the nuclear genome and vice versa. This occurred because mitochondria became so necessary for cell survival that they needed to be better controlled  and regulated. Still, if a cell loses its mitochondria, it cannot "grow" new mitochondria because it is missing the necessary DNA.3. Mitochondria are under very little selective pressure to evolve, since their role in our cells was cemented over a billion years ago. Even still, changes in non-coding regions can occur that do not affect the function of mitochondria. In order for these mutations to be passed on, they must originate in germ line cells (sperm or eggs). Also, mitochondria are not inherited normally from species to species. In humans, we only inherit the mitochondria from the maternal germ cell, so any changes in our fathers' sperm cell mitochondria is lost.
Calculators compute things differently than we would. The basic operations that a calculator can perform are typically just addition, subtraction, multiplication and division.For all other functions, calculators use various techniques to approximate the function with a simpler one that uses just the basic operations. One such approximation technique is a polynomial expansion (often a Taylor series), which is a way to express a function (with certain properties) as an infinite polynomial, that is a function that looks like this:f(x) = a + b * x + c * x^2 + d + x^3 + ...You'll note that this polynomial is constructed of just addition and multiplication (the exponentiation in the expression is just repeated multiplication). The calculator will cut off this polynomial at a certain point (because infinite polynomials are just a bit too long) and what remains should be a reasonable approximation to the original function.There are other approaches than just polynomial expansion, but they too suffer from the fact that they're just approximations.As humans, we recognize that sin(8 pi) is actually just sin(0), due to the periodicity of the sin() function, but calculators usually don't apply this level of heuristic and immediately apply whatever approximation algorithm they are programmed with for that particular function.Some computation software does take the extra step. This is often refered to as "algebraic computation", where the software is able to work with variables and simplification of expressions in a similar way that a human would. An example of such software is Mathematica, or its web-frontend Wolfram Alpha.So a regular calculator sees sin(8 pi), then first computes 8 * pi (with limited accuracy) and then applies the approximation algorithm for the sin function to the outcome. Algebraic computation software will see sin(8 pi) and will recognize the argument as an integer multiple of 2 pi, reduce the expression to sin(0) and conclude that the outcome is zero.Unfortunately, sophisticated algebraic computation software hasn't made it down to the pocket calculator level just yet.
A similar question was asked about a year ago, I've copied my previous answer to that question:It depends on the coordinate system (there are more that one, each with different definitions and things to which they are referenced). To think about this we can compare two common coordinate systems (at least if you're in the US), [North American Datum of 1983 (or NAD83)](_URL_4_) and the [World Geodetic System of 1984 (or WGS84)](_URL_1_). As nicely laid out in this [Scientific American article](_URL_3_), these two coordinate systems have different references. For NAD83, coordinates are tied to the North American plate so for the majority of the US (the portion of California on the Pacific plate would be an exception) coordinates move with the North American plate so do not change as a function of long-term plate motion (but could still change due to local tectonic effects not accounted for in the reference frame). For WGS84, the reference system is based on the Earth's center of mass and is not tied to any particular plate so the coordinates for locations change through time (i.e. the angular and distance relations between two coordinates do not change, so if the angular and distance relations between two points on land change, this means that they have new coordinates). As a consequence (and as illustrated in the Sci Am article) this means there is a gradual increasing disagreement between NAD83 coordinates and WGS84 in the US.As described in some level of technical detail in this set of [lecture slides](_URL_2_), these days most coordinate systems are tied to the [International Terrestrial Reference Frame](_URL_0_), which is a combination of a lot of things, but includes a regularly updated estimate of the location of the Earth's center of mass (for reference systems which use this as their zero point) and plate motion models so that one can specify a time and get a coordinate. As you can also see if you dig into those slides enough, both WGS84 and NAD83 have been updated periodically to account for changes, for WGS84 changing approximations of the Earth's center of mass mean slight changes in the coordinates and for NAD83, I think the big change was just a way to transform between NAD83 coordinates and ITRF based coordinates. Now, a related question might be, for the average person, does this matter? Probably not. If you were to measure your position with a handheld GPS in WGS84 coordinates (internally they all are using WGS84, if you have it display the coordinates in something else, it's doing a conversion anyway) at the exact same spot year after year, theoretically the coordinates would change, but in practice, using consumer grade GPS receivers, your position is never accurate enough for this to matter. Plates are moving at mm to cm per year, so even in places where plates are moving 'fast' at say 2 cm/yr, if your GPS has a horizontal accuracy of 1 m (and that's a good one for most consumer grade units), it's going to take more than 50 years of measurements for you to have moved enough that your measurements are not completely within the uncertainty of your measurements. The exception might be in the case of rapid changes in location, like extreme surface deformation associated with an earthquake. Say, if you had driven a spike into the ground right next to a fault and measured your location in WGS84 and then an earthquake happened and there was 10 meters of motion on the fault at the surface and you then remeasured your location, you might see a change in your coordinates, again depending on the accuracy of your GPS receiver. However, for things that require VERY precise surveying or knowledge of distances between locations and when using commercial grade GPS receivers and differential GPS systems, things like this start to matter, hence why there is such effort put into setting up precise time-sensitive reference frames like the ITRF.
Are you sure one eye was consistently warmer than the other, even if you alternated the order of closing them? If not, this sounds to me like a chromatic [afterimage](_URL_0_) effect that was being caused by each eye being differentially exposed to the blue sky vs. your eyelid.
Petroleum jelly is hydrophobic. When you apply it to skin, it creates a barrier that prevents moisture from being lost to the surrounding air. The moisture in your skin comes from the inside, so protecting dry skin from air will allow your body to replenish its moisture without it being lost immediately.
There was an experiment done in 1968 with a morbidly obese, 450lb man who underwent a medically supervised fast for over a year where he was given absolutely no food whatsoever (but did of course have minerals, vitamins and water). He survived very well indeed just off his fat stores._URL_0_Just in case you can't access the article, here are some of the interesting bits:**Patient A.B. aged 27 years, weighed on admission456 lb (207 kg). During the 382 days of his fast,vitamin supplements were given daily as 'Multivite'(BDH), vitamin C and yeast for the first 10 monthsand as 'Paladac' (Parke Davis), for the last 3 months.Non-caloric fluids were allowed ad libitum. FromDay 93 to Day 162 only, he was given potassiumsupplements (two effervescent potassium tabletsBPC supplying 13 mEq daily) and from Day 345 toDay 355 only he was given sodium supplements (2 5 gsodium chloride daily). No other drug treatment wasgiven. Initially, the patient was treated in hospitalbut for the greater part of the time he was allowedhome, attending regularly as an out-patient forcheck-up.****The amount of weight lost by Mr A.B. was 276 lb,with an average rate of loss of 0-72 lb/day, comparingfavourably with the rates of weight loss in otherlong-term fasts ( >  200 days) which have ranged from0-41 lb/day (Thomson, Runcie  &  Miller, 1966) to0 67 lb/day (Runcie  &  Thomson, 1970).**
Sounds cruel.But the result of the quarantine will eradicate some diseases but not others: * Pathogens that are human-only, if the infectious disease comes from a bacteria that can be found in soil or other animals, the quarantine will not prohibit resurgence. * Every disease that makes the host stay contagious for more than 40 days (STDs are examples as you said) or diseases that take a long time between infection and contagiousness would also not be eradicated. * AFAIK pertussis, measles would be eradicated.* TB would not be eradicated, AFAIK incubation is quite long so someone who catches the disease at the beginning of the quarantine would be contagious at the end of it. * Flu, even if temporarily eradicated in humans, would probably come back from animals.
